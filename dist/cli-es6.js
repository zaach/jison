#!/usr/bin/env node


import fs from 'fs';
import path from 'path';
import recast from '@gerhobbelt/recast';
import assert from 'assert';
import XRegExp from '@gerhobbelt/xregexp';
import json5 from '@gerhobbelt/json5';
import astUtils from '@gerhobbelt/ast-util';
import process$1 from 'process';
import nomnom from '@gerhobbelt/nomnom';

// Return TRUE if `src` starts with `searchString`. 
function startsWith(src, searchString) {
    return src.substr(0, searchString.length) === searchString;
}



// tagged template string helper which removes the indentation common to all
// non-empty lines: that indentation was added as part of the source code
// formatting of this lexer spec file and must be removed to produce what
// we were aiming for.
//
// Each template string starts with an optional empty line, which should be
// removed entirely, followed by a first line of error reporting content text,
// which should not be indented at all, i.e. the indentation of the first
// non-empty line should be treated as the 'common' indentation and thus
// should also be removed from all subsequent lines in the same template string.
//
// See also: https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Template_literals
function rmCommonWS$2(strings, ...values) {
    // As `strings[]` is an array of strings, each potentially consisting
    // of multiple lines, followed by one(1) value, we have to split each
    // individual string into lines to keep that bit of information intact.
    // 
    // We assume clean code style, hence no random mix of tabs and spaces, so every
    // line MUST have the same indent style as all others, so `length` of indent
    // should suffice, but the way we coded this is stricter checking as we look
    // for the *exact* indenting=leading whitespace in each line.
    var indent_str = null;
    var src = strings.map(function splitIntoLines(s) {
        var a = s.split('\n');
        
        indent_str = a.reduce(function analyzeLine(indent_str, line, index) {
            // only check indentation of parts which follow a NEWLINE:
            if (index !== 0) {
                var m = /^(\s*)\S/.exec(line);
                // only non-empty ~ content-carrying lines matter re common indent calculus:
                if (m) {
                    if (!indent_str) {
                        indent_str = m[1];
                    } else if (m[1].length < indent_str.length) {
                        indent_str = m[1];
                    }
                }
            }
            return indent_str;
        }, indent_str);

        return a;
    });

    // Also note: due to the way we format the template strings in our sourcecode,
    // the last line in the entire template must be empty when it has ANY trailing
    // whitespace:
    var a = src[src.length - 1];
    a[a.length - 1] = a[a.length - 1].replace(/\s+$/, '');

    // Done removing common indentation.
    // 
    // Process template string partials now, but only when there's
    // some actual UNindenting to do:
    if (indent_str) {
        for (var i = 0, len = src.length; i < len; i++) {
            var a = src[i];
            // only correct indentation at start of line, i.e. only check for
            // the indent after every NEWLINE ==> start at j=1 rather than j=0
            for (var j = 1, linecnt = a.length; j < linecnt; j++) {
                if (startsWith(a[j], indent_str)) {
                    a[j] = a[j].substr(indent_str.length);
                }
            }
        }
    }

    // now merge everything to construct the template result:
    var rv = [];
    for (var i = 0, len = values.length; i < len; i++) {
        rv.push(src[i].join('\n'));
        rv.push(values[i]);
    }
    // the last value is always followed by a last template string partial:
    rv.push(src[i].join('\n'));

    var sv = rv.join('');
    return sv;
}

// Convert dashed option keys to Camel Case, e.g. `camelCase('camels-have-one-hump')` => `'camelsHaveOneHump'`
/** @public */
function camelCase(s) {
    // Convert first character to lowercase
    return s.replace(/^\w/, function (match) {
        return match.toLowerCase();
    })
    .replace(/-\w/g, function (match) {
        var c = match.charAt(1);
        var rv = c.toUpperCase();
        // do not mutate 'a-2' to 'a2':
        if (c === rv && c.match(/\d/)) {
            return match;
        }
        return rv;
    })
}

// Convert dashed option keys and other inputs to Camel Cased legal JavaScript identifiers
/** @public */
function mkIdentifier$3(s) {
    s = camelCase('' + s);
    // cleanup: replace any non-suitable character series to a single underscore:
    return s
    .replace(/^[^\w_]/, '_')
    // do not accept numerics at the leading position, despite those matching regex `\w`:
    .replace(/^\d/, '_')
    .replace(/[^\w\d_]+/g, '_')
    // and only accept multiple (double, not triple) underscores at start or end of identifier name:
    .replace(/^__+/, '#')
    .replace(/__+$/, '#')
    .replace(/_+/g, '_')
    .replace(/#/g, '__');
}

// properly quote and escape the given input string
function dquote$1(s) {
    var sq = (s.indexOf('\'') >= 0);
    var dq = (s.indexOf('"') >= 0);
    if (sq && dq) {
        s = s.replace(/"/g, '\\"');
        dq = false;
    }
    if (dq) {
        s = '\'' + s + '\'';
    }
    else {
        s = '"' + s + '"';
    }
    return s;
}

//
// Helper library for safe code execution/compilation, including dumping offending code to file for further error analysis
// (the idea was originally coded in https://github.com/GerHobbelt/jison/commit/85e367d03b977780516d2b643afbe6f65ee758f2 )
//
// MIT Licensed
//
//
// This code is intended to help test and diagnose arbitrary chunks of code, answering questions like this:
//
// the given code fails, but where exactly and why? It's precise failure conditions are 'hidden' due to 
// the stuff running inside an `eval()` or `Function(...)` call, so we want the code dumped to file so that
// we can test the code in a different environment so that we can see what precisely is causing the failure.
// 


// Helper function: pad number with leading zeroes
function pad(n, p) {
    p = p || 2;
    var rv = '0000' + n;
    return rv.slice(-p);
}


// attempt to dump in one of several locations: first winner is *it*!
function dumpSourceToFile(sourcecode, errname, err_id, options, ex) {
    var dumpfile;

    try {
        var dumpPaths = [(options.outfile ? path.dirname(options.outfile) : null), options.inputPath, process.cwd()];
        var dumpName = path.basename(options.inputFilename || options.moduleName || (options.outfile ? path.dirname(options.outfile) : null) || options.defaultModuleName || errname)
        .replace(/\.[a-z]{1,5}$/i, '')          // remove extension .y, .yacc, .jison, ...whatever
        .replace(/[^a-z0-9_]/ig, '_');          // make sure it's legal in the destination filesystem: the least common denominator.
        if (dumpName === '' || dumpName === '_') {
            dumpName = '__bugger__';
        }
        err_id = err_id || 'XXX';

        var ts = new Date();
        var tm = ts.getUTCFullYear() +
            '_' + pad(ts.getUTCMonth() + 1) +
            '_' + pad(ts.getUTCDate()) +
            'T' + pad(ts.getUTCHours()) +
            '' + pad(ts.getUTCMinutes()) +
            '' + pad(ts.getUTCSeconds()) +
            '.' + pad(ts.getUTCMilliseconds(), 3) +
            'Z';

        dumpName += '.fatal_' + err_id + '_dump_' + tm + '.js';

        for (var i = 0, l = dumpPaths.length; i < l; i++) {
            if (!dumpPaths[i]) {
                continue;
            }

            try {
                dumpfile = path.normalize(dumpPaths[i] + '/' + dumpName);
                fs.writeFileSync(dumpfile, sourcecode, 'utf8');
                console.error("****** offending generated " + errname + " source code dumped into file: ", dumpfile);
                break;          // abort loop once a dump action was successful!
            } catch (ex3) {
                //console.error("generated " + errname + " source code fatal DUMPING error ATTEMPT: ", i, " = ", ex3.message, " -- while attempting to dump into file: ", dumpfile, "\n", ex3.stack);
                if (i === l - 1) {
                    throw ex3;
                }
            }
        }
    } catch (ex2) {
        console.error("generated " + errname + " source code fatal DUMPING error: ", ex2.message, " -- while attempting to dump into file: ", dumpfile, "\n", ex2.stack);
    }

    // augment the exception info, when available:
    if (ex) {
        ex.offending_source_code = sourcecode;
        ex.offending_source_title = errname;
        ex.offending_source_dumpfile = dumpfile;
    }    
}




//
// `code_execution_rig` is a function which gets executed, while it is fed the `sourcecode` as a parameter.
// When the `code_execution_rig` crashes, its failure is caught and (using the `options`) the sourcecode
// is dumped to file for later diagnosis.
//
// Two options drive the internal behaviour:
//
// - options.dumpSourceCodeOnFailure        -- default: FALSE
// - options.throwErrorOnCompileFailure     -- default: FALSE
//
// Dumpfile naming and path are determined through these options:
//
// - options.outfile
// - options.inputPath
// - options.inputFilename
// - options.moduleName
// - options.defaultModuleName
//
function exec_and_diagnose_this_stuff(sourcecode, code_execution_rig, options, title) {
    options = options || {};
    var errname = "" + (title || "exec_test");
    var err_id = errname.replace(/[^a-z0-9_]/ig, "_");
    if (err_id.length === 0) {
        err_id = "exec_crash";
    }
    const debug = 0;

    if (debug) console.warn('generated ' + errname + ' code under EXEC TEST.');
    if (debug > 1) console.warn(`
        ######################## source code ##########################
        ${sourcecode}
        ######################## source code ##########################
        `);

    var p;
    try {
        // p = eval(sourcecode);
        if (typeof code_execution_rig !== 'function') {
            throw new Error("safe-code-exec-and-diag: code_execution_rig MUST be a JavaScript function");
        }
        p = code_execution_rig.call(this, sourcecode, options, errname, debug);
    } catch (ex) {
        if (debug > 1) console.log("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@");

        if (debug) console.log("generated " + errname + " source code fatal error: ", ex.message);

        if (debug > 1) console.log("exec-and-diagnose options:", options);

        if (debug > 1) console.log("@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@");
        
        if (options.dumpSourceCodeOnFailure) {
            dumpSourceToFile(sourcecode, errname, err_id, options, ex);
        }
        
        if (options.throwErrorOnCompileFailure) {
            throw ex;
        }
    }
    return p;
}






var code_exec$1 = {
    exec: exec_and_diagnose_this_stuff,
    dump: dumpSourceToFile
};

//
// Parse a given chunk of code to an AST.
//
// MIT Licensed
//
//
// This code is intended to help test and diagnose arbitrary chunks of code, answering questions like this:
//
// would the given code compile and possibly execute correctly, when included in a lexer, parser or other engine?
// 


//import astUtils from '@gerhobbelt/ast-util';
assert(recast);
var types = recast.types;
assert(types);
var namedTypes = types.namedTypes;
assert(namedTypes);
var b = types.builders;
assert(b);
// //assert(astUtils);




function parseCodeChunkToAST(src, options) {
    // src = src
    // .replace(/@/g, '\uFFDA')
    // .replace(/#/g, '\uFFDB')
    // ;
    var ast = recast.parse(src);
    return ast;
}




function prettyPrintAST(ast, options) {
    var new_src;
    var s = recast.prettyPrint(ast, { 
        tabWidth: 2,
        quote: 'single',
        arrowParensAlways: true,

        // Do not reuse whitespace (or anything else, for that matter)
        // when printing generically.
        reuseWhitespace: false
    });
    new_src = s.code;

    new_src = new_src
    .replace(/\r\n|\n|\r/g, '\n')    // platform dependent EOL fixup
    // // backpatch possible jison variables extant in the prettified code:
    // .replace(/\uFFDA/g, '@')
    // .replace(/\uFFDB/g, '#')
    ;

    return new_src;
}




// validate the given JavaScript snippet: does it compile?
// 
// Return either the parsed AST (object) or an error message (string). 
function checkActionBlock(src, yylloc) {
    // make sure reasonable line numbers, etc. are reported in any
    // potential parse errors by pushing the source code down:
    if (yylloc && yylloc.first_line > 0) {
        var cnt = yylloc.first_line;
        var lines = new Array(cnt);
        src = lines.join('\n') + src;
    } 
    if (!src.trim()) {
        return false;
    }

    try {
        var rv = parseCodeChunkToAST(src);
        return false;
    } catch (ex) {
        return ex.message || "code snippet cannot be parsed";
    }
}







var parse2AST = {
    parseCodeChunkToAST,
    prettyPrintAST,
    checkActionBlock,
};

/// HELPER FUNCTION: print the function in source code form, properly indented.
/** @public */
function printFunctionSourceCode(f) {
    return String(f);
}

/// HELPER FUNCTION: print the function **content** in source code form, properly indented.
/** @public */
function printFunctionSourceCodeContainer(f) {
    return String(f).replace(/^[\s\r\n]*function\b[^\{]+\{/, '').replace(/\}[\s\r\n]*$/, '');
}



var stringifier = {
	printFunctionSourceCode,
	printFunctionSourceCodeContainer,
};

var helpers = {
    rmCommonWS: rmCommonWS$2,
    camelCase,
    mkIdentifier: mkIdentifier$3,
    dquote: dquote$1,

    exec: code_exec$1.exec,
    dump: code_exec$1.dump,

    parseCodeChunkToAST: parse2AST.parseCodeChunkToAST,
    prettyPrintAST: parse2AST.prettyPrintAST,
    checkActionBlock: parse2AST.checkActionBlock,

	printFunctionSourceCode: stringifier.printFunctionSourceCode,
	printFunctionSourceCodeContainer: stringifier.printFunctionSourceCodeContainer,
};

/*
 * Introduces a typal object to make classical/prototypal patterns easier
 * Plus some AOP sugar
 *
 * By Zachary Carter <zach@carter.name>
 * MIT Licensed
 */

var mkIdentifier$2 = helpers.mkIdentifier;


var create = Object.create || function (o) { 
    function F(){} 
    F.prototype = o; 
    return new F(); 
};
var position = /^(before|after)/;

// basic method layering
// always returns original method's return value
function layerMethod(pos, key, prop, fun) {
    if (pos === 'after') {
        return function () {
            var ret = prop.apply(this, arguments);
            var args = [].slice.call(arguments);
            args.splice(0, 0, ret);
            fun.apply(this, args);
            return ret;
        };
    } else if (pos === 'before') {
        return function () {
            fun.apply(this, arguments);
            var ret = prop.apply(this, arguments);
            return ret;
        };
    }
    return fun;
}

// mixes each argument's own properties into calling object,
// overwriting them or layering them. i.e. an object method 'meth' is
// layered by mixin methods 'beforemeth' or 'aftermeth'
function typal_mix() {
    var i, o, k;
    for (i = 0; i < arguments.length; i++) {
        o = arguments[i];
        if (!o) continue;
        if (Object.prototype.hasOwnProperty.call(o, 'constructor')) {
            this.constructor = o.constructor;
        }
        if (Object.prototype.hasOwnProperty.call(o, 'toString')) {
            this.toString = o.toString;
        }
        for (k in o) {
            if (Object.prototype.hasOwnProperty.call(o, k)) {
                var match = k.match(position);
                var key = k.replace(position, '');
                if (match && typeof this[key] === 'function') {
                    this[key] = layerMethod(match[0], key, this[key], o[k]);
                } else {
                    this[k] = o[k];
                }
            }
        }
    }
    return this;
}

// Same as typal_mix but also camelCases every object member and 'standardizes' the key set of every input
// argument through a caLLback function.
// 
// This is useful for processing options with dashes in their key, e.g. `token-stack` --> tokenStack.
function typal_camel_mix(cb) {
    var i, o, k;

    // Convert first character to lowercase
    function lcase0(s) {
        return s.replace(/^\w/, function (match) { 
            return match.toLowerCase(); 
        });
    }

    for (i = 1; i < arguments.length; i++) {
        o = arguments[i];
        if (!o) continue;
        if (Object.prototype.hasOwnProperty.call(o, 'constructor')) {
            this.constructor = o.constructor;
        }
        if (Object.prototype.hasOwnProperty.call(o, 'toString')) {
            this.toString = o.toString;
        }
        if (cb) {
            o = cb(o);
        }
        for (k in o) {
            if (Object.prototype.hasOwnProperty.call(o, k)) {
                var nk = mkIdentifier$2(k);
                var match = k.match(position);
                var key = k.replace(position, '');
                // This anticipates before/after members to be camelcased already, e.g.
                // 'afterParse()' for layering 'parse()': 
                var alt_key = lcase0(key);
                if (match && typeof this[key] === 'function') {
                    this[key] = layerMethod(match[0], key, this[key], o[k]);
                }
                else if (match && typeof this[alt_key] === 'function') {
                    this[alt_key] = layerMethod(match[0], alt_key, this[alt_key], o[k]);
                } else {
                    this[nk] = o[k];
                }
            }
        }
    }
    return this;
}

var typal = {
    // extend object with own properties of each argument
    mix: typal_mix,

    camelMix: typal_camel_mix,

    // sugar for object begetting and mixing
    // - Object.create(typal).mix(etc, etc);
    // + typal.beget(etc, etc);
    beget: function typal_beget() {
        return arguments.length ? typal_mix.apply(create(this), arguments) : create(this);
    },

    // Creates a new Class function based on an object with a constructor method
    construct: function typal_construct() {
        var o = typal_mix.apply(create(this), arguments);
        var constructor = o.constructor;
        var Klass = o.constructor = function () { return constructor.apply(this, arguments); };
        Klass.prototype = o;
        Klass.mix = typal_mix; // allow for easy singleton property extension
        return Klass;
    },

    // no op
    constructor: function typal_constructor() { return this; }
};

// Set class to wrap arrays

var setMixin = {
    constructor: function Set_constructor(set, raw) {
        this._items = [];
        if (set && set.constructor === Array) {
            this._items = raw ? set: set.slice(0);
        }
        else if (arguments.length) {
            this._items = [].slice.call(arguments, 0);
        }
    },
    concat: function concat(setB) {
        this._items.push.apply(this._items, setB._items || setB);
        return this;
    },
    eq: function eq(set) {
        return this._items.length === set._items.length && this.subset(set) && this.superset(set);
    },
    indexOf: function indexOf(item) {
        if (item && item.eq) {
            for (var k = 0; k < this._items.length; k++) {
                if (item.eq(this._items[k])) {
                    return k;
                }
            }
            return -1;
        }
        return this._items.indexOf(item);
    },
    intersection: function intersection(set) {
        return this.filter(function intersection_filter(elm) {
            return set.contains(elm);
        });
    },
    complement: function complement(set) {
        var that = this;
        return set.filter(function sub_complement(elm) {
            return !that.contains(elm);
        });
    },
    subset: function subset(set) {
        var cont = true;
        for (var i = 0; i < this._items.length && cont; i++) {
            cont = cont && set.contains(this._items[i]);
        }
        return cont;
    },
    superset: function superset(set) {
        return set.subset(this);
    },
    joinSet: function joinSet(set) {
        return this.concat(this.complement(set));
    },
    contains: function contains(item) { 
        return this.indexOf(item) !== -1; 
    },
    item: function item(v) { 
        return this._items[v]; 
    },
    i: function i(v) { 
        return this._items[v]; 
    },
    assign: function assign(index, value) { 
        this._items[index] = value;
        return this; 
    },
    first: function first() { 
        return this._items[0]; 
    },
    last: function last() { 
        return this._items[this._items.length - 1]; 
    },
    size: function size() { 
        return this._items.length; 
    },
    isEmpty: function isEmpty() { 
        return this._items.length === 0; 
    },
    copy: function copy() { 
        return new Set(this._items); 
    },
    toString: function toString() { 
        return this._items.toString(); 
    }
};

'push shift unshift forEach some every join sort'.split(' ').forEach(function (e, i) {
    setMixin[e] = function () { 
        return Array.prototype[e].apply(this._items, arguments); 
    };
    //setMixin[e].name = e;
});
'filter slice map'.split(' ').forEach(function (e, i) {
    setMixin[e] = function () { 
        return new Set(Array.prototype[e].apply(this._items, arguments), true); 
    };
    //setMixin[e].name = e;
});

var Set = typal.construct(setMixin);

// hack:
var assert$1;

/* parser generated by jison 0.6.1-214 */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `quoteName()` to reference this function
 *               at the end of the `parse()`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `yyval` internal object, which has members (`$` and `_$`)
 *                             to store/reference the rule value `$$` and location info `@$`.
 *
 *                 One important thing to note about `this` a.k.a. `yyval`: every *reduce* action gets
 *                 to see the same object via the `this` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use `yyval` a.k.a. `this` for storing you own semi-permanent data.
 *
 *                 `this.yy` is a direct reference to the `yy` shared state object.
 *
 *                 `%parse-param`-specified additional `parse()` arguments have been added to this `yy`
 *                 object at `parse()` start and are therefore available to the action code via the
 *                 same named `yy.xxxx` attributes (where `xxxx` represents a identifier name from
 *                 the %parse-param` list.
 *
 *               - `yytext`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, `yytext` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - `yyleng`  : ditto as `yytext`, only now for the lexer.yyleng value.
 *
 *               - `yylineno`: ditto as `yytext`, only now for the lexer.yylineno value.
 *
 *               - `yyloc`   : ditto as `yytext`, only now for the lexer.yylloc lexer token location info.
 *
 *                               WARNING: since jison 0.4.18-186 this entry may be NULL/UNDEFINED instead
 *                               of an empty object when no suitable location info can be provided.
 *
 *               - `yystate` : the current parser state number, used internally for dispatching and
 *                               executing the action code chunk matching the rule currently being reduced.
 *
 *               - `yysp`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. `##$ === ##0 === yysp`, while `##1` is the stack index for all things
 *                 related to the first rule term, just like you have `$1`, `@1` and `#1`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - `yyrulelength`: the current rule's term count, i.e. the number of entries occupied on the stack.
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *               - `yyvstack`: reference to the parser value stack. Also accessed via the `$1` etc.
 *                             constructs.
 *
 *               - `yylstack`: reference to the parser token location stack. Also accessed via
 *                             the `@1` etc. constructs.
 *
 *                             WARNING: since jison 0.4.18-186 this array MAY contain slots which are
 *                             UNDEFINED rather than an empty (location) object, when the lexer/parser
 *                             action code did not provide a suitable location info object when such a
 *                             slot was filled!
 *
 *               - `yystack` : reference to the parser token id stack. Also accessed via the
 *                             `#1` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any `#n` reference to
 *                 its numeric token id value, hence that code wouldn't need the `yystack` but *you* might
 *                 want access this array for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - `yysstack`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in `yystate`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - `...`     : the extra arguments you specified in the `%parse-param` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - `state`  --> hash table
 *               - `symbol` --> action (number or array)
 *
 *                 If the `action` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO `state`
 *
 *                 If the `action` is a number, it is the GOTO `state`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   var infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   var retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic `parseError` handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `parseError()` to reference this function
 *               at the end of the `parse()`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given `input` and return the parsed value (or `true` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of this grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Parser's additional `args...` parameters (via `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *               The lexer MAY add its own set of additional parameters (via the `%parse-param` line in
 *               the lexer section of the grammar spec): these will be inserted in the `yy` shared state
 *               object and any collision with those will be reported by the lexer via a thrown exception.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API is invoked at the end of the `parse()` call, unless an exception was thrown
 *               and `%options no-try-catch` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the `post_parse` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    yyMergeLocationInfo: function(first_index, last_index, first_yylloc, last_yylloc, dont_look_back),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API can be invoked to calculate a spanning `yylloc` location info object.
 *
 *               Note: %epsilon rules MAY specify no `first_index` and `first_yylloc`, in which case
 *               this function will attempt to obtain a suitable location marker by inspecting the location stack
 *               backwards.
 *
 *               For more info see the documentation comment further below, immediately above this function's
 *               implementation.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" `yy` once
 *                             received via a call to the `.setInput(input, yy)` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the `collect_expected_token_set()`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal `$$` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while `this` will reference the current parser instance.
 *
 * When `parseError` is invoked by the lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When `parseError` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the `expected` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the `.yy` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy)
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`.
 *  Parser.post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`. When it does not return any value,
 *                 the parser will return the original `retval`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy)
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of `lex()`) but immediately after the invocation of
 *                 `parser.pre_parse()`).
 *      post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 `retval` contains the return value to be produced by `Parser.parse()`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 `retval`.
 *                 This function is invoked immediately before `parser.post_parse()`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *      quoteName: function(name),
 *                 optional: overrides the default `quoteName` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this `%option` has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError.prototype, Error.prototype);
} else {
    JisonParserError.prototype = Object.create(Error.prototype);
}
JisonParserError.prototype.constructor = JisonParserError;
JisonParserError.prototype.name = 'JisonParserError';



        // helper: reconstruct the productions[] table
        function bp(s) {
            var rv = [];
            var p = s.pop;
            var r = s.rule;
            for (var i = 0, l = p.length; i < l; i++) {
                rv.push([
                    p[i],
                    r[i]
                ]);
            }
            return rv;
        }
    


        // helper: reconstruct the defaultActions[] table
        function bda(s) {
            var rv = {};
            var d = s.idx;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var j = d[i];
                rv[j] = g[i];
            }
            return rv;
        }
    


        // helper: reconstruct the 'goto' table
        function bt(s) {
            var rv = [];
            var d = s.len;
            var y = s.symbol;
            var t = s.type;
            var a = s.state;
            var m = s.mode;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var n = d[i];
                var q = {};
                for (var j = 0; j < n; j++) {
                    var z = y.shift();
                    switch (t.shift()) {
                    case 2:
                        q[z] = [
                            m.shift(),
                            g.shift()
                        ];
                        break;

                    case 0:
                        q[z] = a.shift();
                        break;

                    default:
                        // type === 1: accept
                        q[z] = [
                            3
                        ];
                    }
                }
                rv.push(q);
            }
            return rv;
        }
    


        // helper: runlength encoding with increment step: code, length: step (default step = 0)
        // `this` references an array
        function s(c, l, a) {
            a = a || 0;
            for (var i = 0; i < l; i++) {
                this.push(c);
                c += a;
            }
        }

        // helper: duplicate sequence from *relative* offset and length.
        // `this` references an array
        function c(i, l) {
            i = this.length - i;
            for (l += i; i < l; i++) {
                this.push(this[i]);
            }
        }

        // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
        function u(a) {
            var rv = [];
            for (var i = 0, l = a.length; i < l; i++) {
                var e = a[i];
                // Is this entry a helper function?
                if (typeof e === 'function') {
                    i++;
                    e.apply(rv, a[i]);
                } else {
                    rv.push(e);
                }
            }
            return rv;
        }
    

var parser$1 = {
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   default action mode: ............. classic,merge
    //   try..catch: ...................... true
    //   default resolve on conflict: ..... true
    //   on-demand look-ahead: ............ false
    //   error recovery token skip maximum: 3
    //   yyerror in parse actions is: ..... NOT recoverable,
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. NOT recoverable,
    //   debug grammar/output: ............ false
    //   has partial LR conflict upgrade:   true
    //   rudimentary token-stack support:   false
    //   parser table compression mode: ... 2
    //   export debug tables: ............. false
    //   export *all* tables: ............. false
    //   module type: ..................... es
    //   parser engine type: .............. lalr
    //   output main() in the module: ..... true
    //   has user-specified main(): ....... false
    //   has user-specified require()/import modules for main():
    //   .................................. false
    //   number of expected conflicts: .... 0
    //
    //
    // Parser Analysis flags:
    //
    //   no significant actions (parser is a language matcher only):
    //   .................................. false
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses ParseError API: ............. false
    //   uses YYERROR: .................... true
    //   uses YYRECOVERING: ............... false
    //   uses YYERROK: .................... false
    //   uses YYCLEARIN: .................. false
    //   tracks rule values: .............. true
    //   assigns rule values: ............. true
    //   uses location tracking: .......... true
    //   assigns location: ................ true
    //   uses yystack: .................... false
    //   uses yysstack: ................... false
    //   uses yysp: ....................... true
    //   uses yyrulelength: ............... false
    //   uses yyMergeLocationInfo API: .... true
    //   has error recovery: .............. true
    //   has error reporting: ............. true
    //
    // --------- END OF REPORT -----------

trace: function no_op_trace() {},
JisonParserError: JisonParserError,
yy: {},
options: {
  type: "lalr",
  hasPartialLrUpgradeOnConflict: true,
  errorRecoveryTokenDiscardCount: 3
},
symbols_: {
  "$": 17,
  "$accept": 0,
  "$end": 1,
  "%%": 19,
  "(": 10,
  ")": 11,
  "*": 7,
  "+": 12,
  ",": 8,
  ".": 15,
  "/": 14,
  "/!": 39,
  "<": 5,
  "=": 18,
  ">": 6,
  "?": 13,
  "ACTION": 32,
  "ACTION_BODY": 33,
  "ACTION_BODY_CPP_COMMENT": 35,
  "ACTION_BODY_C_COMMENT": 34,
  "ACTION_BODY_WHITESPACE": 36,
  "ACTION_END": 31,
  "ACTION_START": 28,
  "BRACKET_MISSING": 29,
  "BRACKET_SURPLUS": 30,
  "CHARACTER_LIT": 46,
  "CODE": 53,
  "EOF": 1,
  "ESCAPE_CHAR": 44,
  "IMPORT": 24,
  "INCLUDE": 51,
  "INCLUDE_PLACEMENT_ERROR": 37,
  "INIT_CODE": 25,
  "NAME": 20,
  "NAME_BRACE": 40,
  "OPTIONS": 47,
  "OPTIONS_END": 48,
  "OPTION_STRING_VALUE": 49,
  "OPTION_VALUE": 50,
  "PATH": 52,
  "RANGE_REGEX": 45,
  "REGEX_SET": 43,
  "REGEX_SET_END": 42,
  "REGEX_SET_START": 41,
  "SPECIAL_GROUP": 38,
  "START_COND": 27,
  "START_EXC": 22,
  "START_INC": 21,
  "STRING_LIT": 26,
  "UNKNOWN_DECL": 23,
  "^": 16,
  "action": 68,
  "action_body": 69,
  "any_group_regex": 78,
  "definition": 58,
  "definitions": 57,
  "error": 2,
  "escape_char": 81,
  "extra_lexer_module_code": 87,
  "import_name": 60,
  "import_path": 61,
  "include_macro_code": 88,
  "init": 56,
  "init_code_name": 59,
  "lex": 54,
  "module_code_chunk": 89,
  "name_expansion": 77,
  "name_list": 71,
  "names_exclusive": 63,
  "names_inclusive": 62,
  "nonempty_regex_list": 74,
  "option": 86,
  "option_list": 85,
  "optional_module_code_chunk": 90,
  "options": 84,
  "range_regex": 82,
  "regex": 72,
  "regex_base": 76,
  "regex_concat": 75,
  "regex_list": 73,
  "regex_set": 79,
  "regex_set_atom": 80,
  "rule": 67,
  "rule_block": 66,
  "rules": 64,
  "rules_and_epilogue": 55,
  "rules_collective": 65,
  "start_conditions": 70,
  "string": 83,
  "{": 3,
  "|": 9,
  "}": 4
},
terminals_: {
  1: "EOF",
  2: "error",
  3: "{",
  4: "}",
  5: "<",
  6: ">",
  7: "*",
  8: ",",
  9: "|",
  10: "(",
  11: ")",
  12: "+",
  13: "?",
  14: "/",
  15: ".",
  16: "^",
  17: "$",
  18: "=",
  19: "%%",
  20: "NAME",
  21: "START_INC",
  22: "START_EXC",
  23: "UNKNOWN_DECL",
  24: "IMPORT",
  25: "INIT_CODE",
  26: "STRING_LIT",
  27: "START_COND",
  28: "ACTION_START",
  29: "BRACKET_MISSING",
  30: "BRACKET_SURPLUS",
  31: "ACTION_END",
  32: "ACTION",
  33: "ACTION_BODY",
  34: "ACTION_BODY_C_COMMENT",
  35: "ACTION_BODY_CPP_COMMENT",
  36: "ACTION_BODY_WHITESPACE",
  37: "INCLUDE_PLACEMENT_ERROR",
  38: "SPECIAL_GROUP",
  39: "/!",
  40: "NAME_BRACE",
  41: "REGEX_SET_START",
  42: "REGEX_SET_END",
  43: "REGEX_SET",
  44: "ESCAPE_CHAR",
  45: "RANGE_REGEX",
  46: "CHARACTER_LIT",
  47: "OPTIONS",
  48: "OPTIONS_END",
  49: "OPTION_STRING_VALUE",
  50: "OPTION_VALUE",
  51: "INCLUDE",
  52: "PATH",
  53: "CODE"
},
TERROR: 2,
EOF: 1,

// internals: defined here so the object *structure* doesn't get modified by parse() et al,
// thus helping JIT compilers like Chrome V8.
originalQuoteName: null,
originalParseError: null,
cleanupAfterParse: null,
constructParseErrorInfo: null,
yyMergeLocationInfo: null,

__reentrant_call_depth: 0, // INTERNAL USE ONLY
__error_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
__error_recovery_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

// APIs which will be set up depending on user action code analysis:
//yyRecovering: 0,
//yyErrOk: 0,
//yyClearIn: 0,

// Helper APIs
// -----------

// Helper function which can be overridden by user code later on: put suitable quotes around
// literal IDs in a description string.
quoteName: function parser_quoteName(id_str) {
    return '"' + id_str + '"';
},

// Return the name of the given symbol (terminal or non-terminal) as a string, when available.
//
// Return NULL when the symbol is unknown to the parser.
getSymbolName: function parser_getSymbolName(symbol) {
    if (this.terminals_[symbol]) {
        return this.terminals_[symbol];
    }

    // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
    //
    // An example of this may be where a rule's action code contains a call like this:
    //
    //      parser.getSymbolName(#$)
    //
    // to obtain a human-readable name of the current grammar rule.
    var s = this.symbols_;
    for (var key in s) {
        if (s[key] === symbol) {
            return key;
        }
    }
    return null;
},

// Return a more-or-less human-readable description of the given symbol, when available,
// or the symbol itself, serving as its own 'description' for lack of something better to serve up.
//
// Return NULL when the symbol is unknown to the parser.
describeSymbol: function parser_describeSymbol(symbol) {
    if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
        return this.terminal_descriptions_[symbol];
    } else if (symbol === this.EOF) {
        return 'end of input';
    }
    var id = this.getSymbolName(symbol);
    if (id) {
        return this.quoteName(id);
    }
    return null;
},

// Produce a (more or less) human-readable list of expected tokens at the point of failure.
//
// The produced list may contain token or token set descriptions instead of the tokens
// themselves to help turning this output into something that easier to read by humans
// unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
// expected terminals and nonterminals is produced.
//
// The returned list (array) will not contain any duplicate entries.
collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
    var TERROR = this.TERROR;
    var tokenset = [];
    var check = {};
    // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
    // If so, use that one instead of the less palatable token set.
    if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
        return [this.state_descriptions_[state]];
    }
    for (var p in this.table[state]) {
        p = +p;
        if (p !== TERROR) {
            var d = do_not_describe ? p : this.describeSymbol(p);
            if (d && !check[d]) {
                tokenset.push(d);
                check[d] = true; // Mark this token description as already mentioned to prevent outputting duplicate entries.
            }
        }
    }
    return tokenset;
},
productions_: bp({
  pop: u([
  54,
  54,
  s,
  [55, 6],
  56,
  57,
  57,
  s,
  [58, 11],
  59,
  59,
  60,
  60,
  61,
  61,
  62,
  62,
  63,
  63,
  64,
  64,
  s,
  [65, 4],
  66,
  66,
  67,
  67,
  s,
  [68, 3],
  s,
  [69, 9],
  s,
  [70, 4],
  71,
  71,
  72,
  s,
  [73, 4],
  s,
  [74, 4],
  75,
  75,
  s,
  [76, 17],
  77,
  78,
  78,
  79,
  79,
  80,
  s,
  [80, 4, 1],
  83,
  84,
  85,
  85,
  s,
  [86, 6],
  87,
  87,
  88,
  88,
  s,
  [89, 3],
  90,
  90
]),
  rule: u([
  s,
  [4, 3],
  s,
  [5, 4, -1],
  0,
  0,
  2,
  0,
  s,
  [2, 3],
  s,
  [1, 3],
  3,
  3,
  2,
  3,
  3,
  s,
  [1, 7],
  2,
  1,
  2,
  c,
  [23, 3],
  4,
  c,
  [32, 4],
  2,
  c,
  [22, 3],
  3,
  s,
  [2, 8],
  0,
  s,
  [3, 3],
  0,
  1,
  3,
  1,
  s,
  [3, 4, -1],
  c,
  [21, 3],
  c,
  [40, 3],
  s,
  [3, 4],
  s,
  [2, 5],
  c,
  [12, 3],
  s,
  [1, 6],
  c,
  [16, 3],
  c,
  [10, 8],
  c,
  [9, 3],
  s,
  [3, 4],
  c,
  [10, 4],
  c,
  [82, 4],
  1,
  0
])
}),
performAction: function parser__PerformAction(yyloc, yystate /* action[1] */, yysp, yyvstack, yylstack) {

          /* this == yyval */

          // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
          var yy = this.yy;
          var yyparser = yy.parser;
          var yylexer = yy.lexer;

          

          switch (yystate) {
case 0:
    /*! Production::    $accept : lex $end */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yylstack[yysp - 1];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    break;

case 1:
    /*! Production::    lex : init definitions rules_and_epilogue EOF */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    for (var key in yyvstack[yysp - 2]) {
      this.$[key] = yyvstack[yysp - 2][key];
    }
    
    // if there are any options, add them all, otherwise set options to NULL:
    // can't check for 'empty object' by `if (yy.options) ...` so we do it this way:
    for (key in yy.options) {
      this.$.options = yy.options;
      break;
    }
    
    if (yy.actionInclude) {
      var asrc = yy.actionInclude.join('\n\n');
      // Only a non-empty action code chunk should actually make it through:
      if (asrc.trim() !== '') {
        this.$.actionInclude = asrc;
      }
    }
    
    delete yy.options;
    delete yy.actionInclude;
    return this.$;
    break;

case 2:
    /*! Production::    lex : init definitions error EOF */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 3];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        There's an error in your lexer regex rules or epilogue.
        Maybe you did not correctly separate the lexer sections with a '%%'
        on an otherwise empty line?
        The lexer spec file should have this structure:
    
                definitions
                %%
                rules
                %%                  // <-- optional!
                extra_module_code   // <-- optional epilogue!
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
    break;

case 3:
    /*! Production::    rules_and_epilogue : "%%" rules "%%" extra_lexer_module_code */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-)
    
    
    if (yyvstack[yysp].trim() !== '') {
      this.$ = { rules: yyvstack[yysp - 2], moduleInclude: yyvstack[yysp] };
    } else {
      this.$ = { rules: yyvstack[yysp - 2] };
    }
    break;

case 4:
    /*! Production::    rules_and_epilogue : "%%" error rules "%%" extra_lexer_module_code */

    // default action (generated by JISON mode classic/merge :: 5,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 4];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
    // END of default action (generated by JISON mode classic/merge :: 5,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        There's probably an error in one or more of your lexer regex rules.
        The lexer rule spec should have this structure:
    
                regex  action_code
    
        where 'regex' is a lex-style regex expression (see the
        jison and jison-lex documentation) which is intended to match a chunk
        of the input to lex, while the 'action_code' block is the JS code
        which will be invoked when the regex is matched. The 'action_code' block
        may be any (indented!) set of JS statements, optionally surrounded
        by '{...}' curly braces or otherwise enclosed in a '%{...%}' block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 3])}
    
          Technical error report:
        ${yyvstack[yysp - 3].errStr}
    `);
    break;

case 5:
    /*! Production::    rules_and_epilogue : "%%" rules "%%" error */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 3];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        There's an error in your lexer epilogue a.k.a. 'extra_module_code' block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 6:
    /*! Production::    rules_and_epilogue : "%%" error rules */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        There's probably an error in one or more of your lexer regex rules.
        The lexer rule spec should have this structure:
    
                regex  action_code
    
        where 'regex' is a lex-style regex expression (see the
        jison and jison-lex documentation) which is intended to match a chunk
        of the input to lex, while the 'action_code' block is the JS code
        which will be invoked when the regex is matched. The 'action_code' block
        may be any (indented!) set of JS statements, optionally surrounded
        by '{...}' curly braces or otherwise enclosed in a '%{...%}' block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
    break;

case 7:
    /*! Production::    rules_and_epilogue : "%%" rules */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = { rules: yyvstack[yysp] };
    break;

case 8:
    /*! Production::    rules_and_epilogue : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = { rules: [] };
    break;

case 9:
    /*! Production::    init : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-):
    this.$ = undefined;
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-)
    
    
    yy.actionInclude = [];
    if (!yy.options) yy.options = {};
    break;

case 10:
    /*! Production::    definitions : definitions definition */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    if (yyvstack[yysp] != null) {
      if ('length' in yyvstack[yysp]) {
        this.$.macros[yyvstack[yysp][0]] = yyvstack[yysp][1];
      } else {
        switch (yyvstack[yysp].type) {
        case 'names':
          for (var name in yyvstack[yysp].names) {
            this.$.startConditions[name] = yyvstack[yysp].names[name];
          }
          break;
    
        case 'unknown':
          this.$.unknownDecls.push(yyvstack[yysp].body);
          break;
    
        case 'imports':
          this.$.importDecls.push(yyvstack[yysp].body);
          break;
    
        case 'codeSection':
          this.$.codeSections.push(yyvstack[yysp].body);
          break;
    
        default:
          yyparser.yyError(rmCommonWS$4`
            Encountered an unsupported definition type: ${yyvstack[yysp].type}.
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
          `);
          break;
        }
      }
    }
    break;

case 11:
    /*! Production::    definitions : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
      macros: {},           // { hash table }
      startConditions: {},  // { hash table }
      codeSections: [],     // [ array of {qualifier,include} pairs ]
      importDecls: [],      // [ array of {name,path} pairs ]
      unknownDecls: []      // [ array of {name,value} pairs ]
    };
    break;

case 12:
    /*! Production::    definition : NAME regex */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 1], yyvstack[yysp]];
    break;

case 13:
    /*! Production::    definition : START_INC names_inclusive */
case 14:
    /*! Production::    definition : START_EXC names_exclusive */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp];
    break;

case 15:
    /*! Production::    definition : action */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$1(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The '%{...%}' lexer setup action code section does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    yy.actionInclude.push(yyvstack[yysp]);
    this.$ = null;
    break;

case 16:
    /*! Production::    definition : options */
case 102:
    /*! Production::    option_list : option */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = null;
    break;

case 17:
    /*! Production::    definition : UNKNOWN_DECL */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
        type: 'unknown', 
        body: yyvstack[yysp]
    };
    break;

case 18:
    /*! Production::    definition : IMPORT import_name import_path */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
        type: 'imports', 
        body: { 
            name: yyvstack[yysp - 1], 
            path: yyvstack[yysp] 
        } 
    };
    break;

case 19:
    /*! Production::    definition : IMPORT import_name error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        You did not specify a legal file path for the '%import' initialization code statement, which must have the format:
            %import qualifier_name file_path
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 20:
    /*! Production::    definition : IMPORT error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        %import name or source filename missing maybe?
    
        Note: each '%import'-ed initialization code section must be qualified by a name, e.g. 'required' before the import path itself:
            %import qualifier_name file_path
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 21:
    /*! Production::    definition : INIT_CODE init_code_name action */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$1(yyvstack[yysp], yylstack[yysp]);
    var name = yyvstack[yysp - 1];
    var code = yyvstack[yysp];
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The '%code ${name}' action code section does not compile: ${rv}
    
            ${code}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
        `);
    }
    this.$ = {
        type: 'codeSection',
        body: {
          qualifier: yyvstack[yysp - 1],
          include: yyvstack[yysp]
        }
    };
    break;

case 22:
    /*! Production::    definition : INIT_CODE error action */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Each '%code' initialization code section must be qualified by a name, e.g. 'required' before the action code itself:
            %code qualifier_name {action code}
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2], yylstack[yysp])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
    break;

case 23:
    /*! Production::    init_code_name : NAME */
case 24:
    /*! Production::    init_code_name : STRING_LIT */
case 25:
    /*! Production::    import_name : NAME */
case 26:
    /*! Production::    import_name : STRING_LIT */
case 27:
    /*! Production::    import_path : NAME */
case 28:
    /*! Production::    import_path : STRING_LIT */
case 64:
    /*! Production::    regex_list : regex_concat */
case 69:
    /*! Production::    nonempty_regex_list : regex_concat */
case 71:
    /*! Production::    regex_concat : regex_base */
case 96:
    /*! Production::    escape_char : ESCAPE_CHAR */
case 97:
    /*! Production::    range_regex : RANGE_REGEX */
case 113:
    /*! Production::    module_code_chunk : CODE */
case 116:
    /*! Production::    optional_module_code_chunk : module_code_chunk */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp];
    break;

case 29:
    /*! Production::    names_inclusive : START_COND */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {type: 'names', names: {}}; this.$.names[yyvstack[yysp]] = 0;
    break;

case 30:
    /*! Production::    names_inclusive : names_inclusive START_COND */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1]; this.$.names[yyvstack[yysp]] = 0;
    break;

case 31:
    /*! Production::    names_exclusive : START_COND */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {type: 'names', names: {}}; this.$.names[yyvstack[yysp]] = 1;
    break;

case 32:
    /*! Production::    names_exclusive : names_exclusive START_COND */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1]; this.$.names[yyvstack[yysp]] = 1;
    break;

case 33:
    /*! Production::    rules : rules rules_collective */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1].concat(yyvstack[yysp]);
    break;

case 34:
    /*! Production::    rules : %epsilon */
case 40:
    /*! Production::    rule_block : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [];
    break;

case 35:
    /*! Production::    rules_collective : start_conditions rule */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    if (yyvstack[yysp - 1]) {
        yyvstack[yysp].unshift(yyvstack[yysp - 1]);
    }
    this.$ = [yyvstack[yysp]];
    break;

case 36:
    /*! Production::    rules_collective : start_conditions "{" rule_block "}" */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-)
    
    
    if (yyvstack[yysp - 3]) {
        yyvstack[yysp - 1].forEach(function (d) {
            d.unshift(yyvstack[yysp - 3]);
        });
    }
    this.$ = yyvstack[yysp - 1];
    break;

case 37:
    /*! Production::    rules_collective : start_conditions "{" error "}" */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 3];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you made a mistake while specifying one of the lexer rules inside
        the start condition
           <${yyvstack[yysp - 3].join(',')}> { rules... }
        block.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylexer.mergeLocationInfo((yysp - 3), (yysp)), yylstack[yysp - 3])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
    break;

case 38:
    /*! Production::    rules_collective : start_conditions "{" error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you did not correctly bracket a lexer rules set inside
        the start condition
          <${yyvstack[yysp - 2].join(',')}> { rules... }
        as a terminating curly brace '}' could not be found.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 39:
    /*! Production::    rule_block : rule_block rule */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1]; this.$.push(yyvstack[yysp]);
    break;

case 41:
    /*! Production::    rule : regex action */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$1(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The rule's action code section does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = [yyvstack[yysp - 1], yyvstack[yysp]];
    break;

case 42:
    /*! Production::    rule : regex error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 1], yyvstack[yysp]];
    yyparser.yyError(rmCommonWS$4`
        Lexer rule regex action code declaration error?
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 43:
    /*! Production::    action : ACTION_START action_body BRACKET_MISSING */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Missing curly braces: seems you did not correctly bracket a lexer rule action block in curly braces: '{ ... }'.
    
          Offending action body:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 44:
    /*! Production::    action : ACTION_START action_body BRACKET_SURPLUS */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Too many curly braces: seems you did not correctly bracket a lexer rule action block in curly braces: '{ ... }'.
    
          Offending action body:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 45:
    /*! Production::    action : ACTION_START action_body ACTION_END */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    var s = yyvstack[yysp - 1].trim();
    // remove outermost set of braces UNLESS there's
    // a curly brace in there anywhere: in that case
    // we should leave it up to the sophisticated
    // code analyzer to simplify the code!
    //
    // This is a very rough check as it will also look
    // inside code comments, which should not have
    // any influence.
    //
    // Nevertheless: this is a *safe* transform!
    if (s[0] === '{' && s.indexOf('}') === s.length - 1) {
        this.$ = s.substring(1, s.length - 1).trim();
    } else {
        this.$ = s;
    }
    break;

case 46:
    /*! Production::    action_body : action_body ACTION */
case 51:
    /*! Production::    action_body : action_body include_macro_code */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + '\n\n' + yyvstack[yysp] + '\n\n';
    break;

case 47:
    /*! Production::    action_body : action_body ACTION_BODY */
case 48:
    /*! Production::    action_body : action_body ACTION_BODY_C_COMMENT */
case 49:
    /*! Production::    action_body : action_body ACTION_BODY_CPP_COMMENT */
case 50:
    /*! Production::    action_body : action_body ACTION_BODY_WHITESPACE */
case 70:
    /*! Production::    regex_concat : regex_concat regex_base */
case 82:
    /*! Production::    regex_base : regex_base range_regex */
case 92:
    /*! Production::    regex_set : regex_set regex_set_atom */
case 114:
    /*! Production::    module_code_chunk : module_code_chunk CODE */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 52:
    /*! Production::    action_body : action_body INCLUDE_PLACEMENT_ERROR */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        You may place the '%include' instruction only at the start/front of a line.
    
          Its use is not permitted at this position:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 53:
    /*! Production::    action_body : action_body error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you did not correctly match curly braces '{ ... }' in a lexer rule action block.
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 54:
    /*! Production::    action_body : %epsilon */
case 65:
    /*! Production::    regex_list : %epsilon */
case 117:
    /*! Production::    optional_module_code_chunk : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '';
    break;

case 55:
    /*! Production::    start_conditions : "<" name_list ">" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    break;

case 56:
    /*! Production::    start_conditions : "<" name_list error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you did not correctly terminate the start condition set <${yyvstack[yysp - 1].join(',')},???> with a terminating '>'
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 57:
    /*! Production::    start_conditions : "<" "*" ">" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = ['*'];
    break;

case 58:
    /*! Production::    start_conditions : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-):
    this.$ = undefined;
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-)
    break;

case 59:
    /*! Production::    name_list : NAME */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp]];
    break;

case 60:
    /*! Production::    name_list : name_list "," NAME */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2]; this.$.push(yyvstack[yysp]);
    break;

case 61:
    /*! Production::    regex : nonempty_regex_list */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    // Detect if the regex ends with a pure (Unicode) word;
    // we *do* consider escaped characters which are 'alphanumeric'
    // to be equivalent to their non-escaped version, hence these are
    // all valid 'words' for the 'easy keyword rules' option:
    //
    // - hello_kitty
    // - γεια_σου_γατούλα
    // - \u03B3\u03B5\u03B9\u03B1_\u03C3\u03BF\u03C5_\u03B3\u03B1\u03C4\u03BF\u03CD\u03BB\u03B1
    //
    // http://stackoverflow.com/questions/7885096/how-do-i-decode-a-string-with-escaped-unicode#12869914
    //
    // As we only check the *tail*, we also accept these as
    // 'easy keywords':
    //
    // - %options
    // - %foo-bar
    // - +++a:b:c1
    //
    // Note the dash in that last example: there the code will consider
    // `bar` to be the keyword, which is fine with us as we're only
    // interested in the trailing boundary and patching that one for
    // the `easy_keyword_rules` option.
    this.$ = yyvstack[yysp];
    if (yy.options.easy_keyword_rules) {
      // We need to 'protect' `eval` here as keywords are allowed
      // to contain double-quotes and other leading cruft.
      // `eval` *does* gobble some escapes (such as `\b`) but
      // we protect against that through a simple replace regex:
      // we're not interested in the special escapes' exact value
      // anyway.
      // It will also catch escaped escapes (`\\`), which are not
      // word characters either, so no need to worry about
      // `eval(str)` 'correctly' converting convoluted constructs
      // like '\\\\\\\\\\b' in here.
      this.$ = this.$
      .replace(/\\\\/g, '.')
      .replace(/"/g, '.')
      .replace(/\\c[A-Z]/g, '.')
      .replace(/\\[^xu0-9]/g, '.');
    
      try {
        // Convert Unicode escapes and other escapes to their literal characters
        // BEFORE we go and check whether this item is subject to the
        // `easy_keyword_rules` option.
        this.$ = JSON.parse('"' + this.$ + '"');
      }
      catch (ex) {
        yyparser.warn('easy-keyword-rule FAIL on eval: ', ex);
    
        // make the next keyword test fail:
        this.$ = '.';
      }
      // a 'keyword' starts with an alphanumeric character,
      // followed by zero or more alphanumerics or digits:
      var re = new XRegExp('\\w[\\w\\d]*$');
      if (XRegExp.match(this.$, re)) {
        this.$ = yyvstack[yysp] + "\\b";
      } else {
        this.$ = yyvstack[yysp];
      }
    }
    break;

case 62:
    /*! Production::    regex_list : regex_list "|" regex_concat */
case 66:
    /*! Production::    nonempty_regex_list : nonempty_regex_list "|" regex_concat */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2] + '|' + yyvstack[yysp];
    break;

case 63:
    /*! Production::    regex_list : regex_list "|" */
case 67:
    /*! Production::    nonempty_regex_list : nonempty_regex_list "|" */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + '|';
    break;

case 68:
    /*! Production::    nonempty_regex_list : "|" regex_concat */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '|' + yyvstack[yysp];
    break;

case 72:
    /*! Production::    regex_base : "(" regex_list ")" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '(' + yyvstack[yysp - 1] + ')';
    break;

case 73:
    /*! Production::    regex_base : SPECIAL_GROUP regex_list ")" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + ')';
    break;

case 74:
    /*! Production::    regex_base : "(" regex_list error */
case 75:
    /*! Production::    regex_base : SPECIAL_GROUP regex_list error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you did not correctly bracket a lex rule regex part in '(...)' braces.
    
          Unterminated regex part:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 76:
    /*! Production::    regex_base : regex_base "+" */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + '+';
    break;

case 77:
    /*! Production::    regex_base : regex_base "*" */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + '*';
    break;

case 78:
    /*! Production::    regex_base : regex_base "?" */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + '?';
    break;

case 79:
    /*! Production::    regex_base : "/" regex_base */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '(?=' + yyvstack[yysp] + ')';
    break;

case 80:
    /*! Production::    regex_base : "/!" regex_base */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '(?!' + yyvstack[yysp] + ')';
    break;

case 81:
    /*! Production::    regex_base : name_expansion */
case 83:
    /*! Production::    regex_base : any_group_regex */
case 87:
    /*! Production::    regex_base : string */
case 88:
    /*! Production::    regex_base : escape_char */
case 89:
    /*! Production::    name_expansion : NAME_BRACE */
case 93:
    /*! Production::    regex_set : regex_set_atom */
case 94:
    /*! Production::    regex_set_atom : REGEX_SET */
case 99:
    /*! Production::    string : CHARACTER_LIT */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp];
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    break;

case 84:
    /*! Production::    regex_base : "." */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '.';
    break;

case 85:
    /*! Production::    regex_base : "^" */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '^';
    break;

case 86:
    /*! Production::    regex_base : "$" */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '$';
    break;

case 90:
    /*! Production::    any_group_regex : REGEX_SET_START regex_set REGEX_SET_END */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 91:
    /*! Production::    any_group_regex : REGEX_SET_START regex_set error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        Seems you did not correctly bracket a lex rule regex set in '[...]' brackets.
    
          Unterminated regex set:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 95:
    /*! Production::    regex_set_atom : name_expansion */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    if (XRegExp._getUnicodeProperty(yyvstack[yysp].replace(/[{}]/g, ''))
        && yyvstack[yysp].toUpperCase() !== yyvstack[yysp]
    ) {
        // treat this as part of an XRegExp `\p{...}` Unicode 'General Category' Property cf. http://unicode.org/reports/tr18/#Categories
        this.$ = yyvstack[yysp];
    } else {
        this.$ = yyvstack[yysp];
    }
    //yyparser.log("name expansion for: ", { name: $name_expansion, redux: $name_expansion.replace(/[{}]/g, ''), output: $$ });
    break;

case 98:
    /*! Production::    string : STRING_LIT */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = prepareString(yyvstack[yysp]);
    break;

case 100:
    /*! Production::    options : OPTIONS option_list OPTIONS_END */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = null;
    break;

case 101:
    /*! Production::    option_list : option option_list */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = null;
    break;

case 103:
    /*! Production::    option : NAME */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp];
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    
    
    yy.options[yyvstack[yysp]] = true;
    break;

case 104:
    /*! Production::    option : NAME "=" OPTION_STRING_VALUE */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yy.options[yyvstack[yysp - 2]] = yyvstack[yysp];
    break;

case 105:
    /*! Production::    option : NAME "=" OPTION_VALUE */
case 106:
    /*! Production::    option : NAME "=" NAME */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yy.options[yyvstack[yysp - 2]] = parseValue(yyvstack[yysp]);
    break;

case 107:
    /*! Production::    option : NAME "=" error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$4`
        Internal error: option "${$option}" value assignment failure.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 108:
    /*! Production::    option : error */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp];
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$4`
        Expected a valid option name (with optional value assignment).
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 109:
    /*! Production::    extra_lexer_module_code : optional_module_code_chunk */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$1(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The extra lexer module code section (a.k.a. 'epilogue') does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = yyvstack[yysp];
    break;

case 110:
    /*! Production::    extra_lexer_module_code : extra_lexer_module_code include_macro_code optional_module_code_chunk */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    // Each of the 3 chunks should be parse-able as a JS snippet on its own.
    //
    // Note: we have already checked the first section in a previous reduction
    // of this rule, so we don't need to check that one again!
    var rv = checkActionBlock$1(yyvstack[yysp - 1], yylstack[yysp - 1]);
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The source code %include-d into the extra lexer module code section (a.k.a. 'epilogue') does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
        `);
    }
    rv = checkActionBlock$1(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$4`
            The extra lexer module code section (a.k.a. 'epilogue') does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 111:
    /*! Production::    include_macro_code : INCLUDE PATH */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var fileContent = fs.readFileSync(yyvstack[yysp], { encoding: 'utf-8' });
    // And no, we don't support nested '%include':
    this.$ = '\n// Included by Jison: ' + yyvstack[yysp] + ':\n\n' + fileContent + '\n\n// End Of Include by Jison: ' + yyvstack[yysp] + '\n\n';
    break;

case 112:
    /*! Production::    include_macro_code : INCLUDE error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$4`
        %include MUST be followed by a valid file path.
    
          Erroneous path:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp].errStr}
    `);
    break;

case 115:
    /*! Production::    module_code_chunk : error CODE */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$4`
        Module code declaration error?
    
          Erroneous code:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1])}
    
          Technical error report:
        ${yyvstack[yysp - 1].errStr}
    `);
    break;

case 151:       // === NO_ACTION[1] :: ensures that anyone (but us) using this new state will fail dramatically!
                // error recovery reduction action (action generated by jison,
                // using the user-specified `%code error_recovery_reduction` %{...%}
                // code chunk below.

                
                break;
            
}
},
table: bt({
  len: u([
  13,
  1,
  12,
  15,
  1,
  1,
  11,
  19,
  21,
  2,
  2,
  s,
  [11, 3],
  4,
  4,
  12,
  4,
  1,
  1,
  19,
  18,
  11,
  12,
  18,
  29,
  30,
  22,
  22,
  17,
  17,
  s,
  [29, 7],
  31,
  5,
  s,
  [29, 3],
  s,
  [12, 4],
  4,
  11,
  3,
  3,
  2,
  2,
  1,
  1,
  12,
  1,
  5,
  4,
  3,
  7,
  17,
  23,
  3,
  19,
  30,
  29,
  30,
  s,
  [29, 5],
  3,
  20,
  3,
  30,
  30,
  6,
  s,
  [4, 3],
  12,
  12,
  s,
  [11, 6],
  s,
  [27, 3],
  s,
  [11, 8],
  2,
  11,
  1,
  4,
  c,
  [55, 3],
  3,
  3,
  17,
  16,
  3,
  3,
  1,
  3,
  7,
  s,
  [29, 3],
  21,
  s,
  [29, 4],
  4,
  13,
  13,
  s,
  [3, 4],
  6,
  3,
  3,
  23,
  s,
  [18, 3],
  14,
  14,
  1,
  14,
  3,
  1,
  20,
  2,
  17,
  14,
  17,
  3
]),
  symbol: u([
  1,
  2,
  s,
  [19, 7, 1],
  28,
  47,
  54,
  56,
  1,
  c,
  [14, 11],
  57,
  c,
  [12, 11],
  55,
  58,
  68,
  84,
  s,
  [1, 3],
  c,
  [17, 10],
  1,
  2,
  3,
  5,
  9,
  10,
  s,
  [14, 4, 1],
  19,
  26,
  s,
  [38, 4, 1],
  44,
  46,
  64,
  c,
  [15, 6],
  c,
  [14, 7],
  72,
  s,
  [74, 5, 1],
  81,
  83,
  27,
  62,
  27,
  63,
  c,
  [55, 13],
  c,
  [11, 20],
  2,
  20,
  26,
  60,
  c,
  [4, 3],
  59,
  2,
  s,
  [29, 9, 1],
  51,
  69,
  2,
  20,
  85,
  86,
  s,
  [1, 3],
  c,
  [102, 16],
  65,
  70,
  c,
  [19, 17],
  64,
  c,
  [85, 13],
  9,
  c,
  [12, 9],
  c,
  [143, 12],
  c,
  [141, 6],
  c,
  [30, 3],
  c,
  [58, 6],
  s,
  [20, 7, 1],
  28,
  c,
  [29, 6],
  47,
  c,
  [29, 7],
  7,
  s,
  [9, 9, 1],
  c,
  [33, 14],
  45,
  46,
  47,
  82,
  c,
  [58, 3],
  11,
  c,
  [80, 11],
  73,
  c,
  [81, 6],
  c,
  [22, 22],
  c,
  [121, 12],
  c,
  [17, 22],
  c,
  [108, 29],
  c,
  [29, 199],
  s,
  [42, 6, 1],
  40,
  43,
  77,
  79,
  80,
  c,
  [123, 89],
  c,
  [19, 7],
  27,
  c,
  [590, 11],
  c,
  [12, 27],
  c,
  [611, 3],
  61,
  c,
  [630, 14],
  c,
  [3, 3],
  28,
  68,
  28,
  68,
  28,
  28,
  c,
  [634, 11],
  88,
  48,
  2,
  20,
  48,
  85,
  86,
  2,
  18,
  20,
  c,
  [9, 4],
  1,
  2,
  51,
  53,
  87,
  89,
  90,
  c,
  [629, 17],
  3,
  c,
  [750, 13],
  67,
  c,
  [751, 8],
  7,
  20,
  71,
  c,
  [691, 20],
  c,
  [632, 23],
  c,
  [662, 65],
  c,
  [526, 145],
  2,
  9,
  11,
  c,
  [788, 15],
  c,
  [808, 7],
  11,
  c,
  [201, 59],
  82,
  2,
  40,
  42,
  43,
  77,
  80,
  c,
  [6, 4],
  c,
  [4, 8],
  c,
  [495, 33],
  c,
  [11, 59],
  3,
  4,
  c,
  [449, 8],
  c,
  [401, 15],
  c,
  [27, 54],
  c,
  [603, 11],
  c,
  [11, 78],
  52,
  c,
  [182, 11],
  c,
  [683, 3],
  49,
  50,
  1,
  51,
  88,
  1,
  53,
  1,
  51,
  1,
  51,
  c,
  [5, 3],
  53,
  c,
  [647, 17],
  2,
  4,
  c,
  [691, 13],
  66,
  2,
  28,
  68,
  2,
  6,
  8,
  6,
  c,
  [4, 3],
  c,
  [740, 8],
  c,
  [648, 57],
  c,
  [531, 31],
  c,
  [528, 13],
  c,
  [756, 8],
  c,
  [668, 115],
  c,
  [568, 5],
  c,
  [321, 10],
  53,
  c,
  [13, 13],
  c,
  [1004, 3],
  c,
  [3, 9],
  c,
  [273, 4],
  c,
  [272, 3],
  c,
  [328, 5],
  c,
  [310, 14],
  c,
  [1001, 9],
  1,
  c,
  [496, 10],
  c,
  [27, 7],
  c,
  [18, 36],
  c,
  [1078, 14],
  c,
  [14, 14],
  20,
  c,
  [15, 14],
  c,
  [461, 3],
  53,
  c,
  [843, 20],
  c,
  [480, 3],
  c,
  [474, 16],
  c,
  [163, 14],
  c,
  [505, 18],
  6,
  8
]),
  type: u([
  s,
  [2, 11],
  0,
  0,
  1,
  c,
  [14, 12],
  c,
  [26, 13],
  0,
  c,
  [15, 12],
  s,
  [2, 20],
  c,
  [32, 14],
  s,
  [0, 8],
  c,
  [23, 3],
  c,
  [57, 32],
  c,
  [62, 9],
  c,
  [113, 13],
  c,
  [67, 4],
  c,
  [40, 20],
  c,
  [21, 18],
  c,
  [96, 36],
  c,
  [141, 7],
  c,
  [30, 28],
  c,
  [221, 43],
  c,
  [223, 9],
  c,
  [22, 34],
  c,
  [17, 34],
  s,
  [2, 224],
  c,
  [239, 141],
  c,
  [139, 19],
  c,
  [673, 16],
  c,
  [14, 5],
  c,
  [180, 13],
  c,
  [764, 35],
  c,
  [751, 9],
  c,
  [98, 19],
  c,
  [632, 31],
  c,
  [662, 75],
  c,
  [511, 151],
  c,
  [513, 34],
  c,
  [231, 35],
  c,
  [821, 238],
  c,
  [735, 74],
  c,
  [43, 27],
  c,
  [740, 39],
  c,
  [1202, 78],
  c,
  [756, 30],
  c,
  [696, 140],
  c,
  [1001, 31],
  c,
  [461, 114],
  c,
  [121, 58]
]),
  state: u([
  s,
  [1, 4, 1],
  6,
  11,
  12,
  20,
  22,
  23,
  25,
  26,
  31,
  32,
  37,
  36,
  43,
  45,
  47,
  51,
  55,
  56,
  57,
  61,
  62,
  64,
  66,
  c,
  [16, 5],
  67,
  c,
  [5, 4],
  71,
  73,
  74,
  c,
  [13, 5],
  75,
  c,
  [7, 6],
  76,
  c,
  [5, 4],
  77,
  c,
  [5, 4],
  81,
  78,
  79,
  84,
  88,
  89,
  98,
  103,
  57,
  105,
  108,
  107,
  110,
  112,
  c,
  [67, 7],
  113,
  61,
  62,
  117,
  c,
  [60, 11],
  c,
  [6, 6],
  71,
  81,
  125,
  132,
  135,
  137,
  143,
  108,
  107,
  c,
  [15, 5],
  145,
  c,
  [32, 5],
  108,
  146,
  148,
  c,
  [52, 8],
  132,
  c,
  [23, 5]
]),
  mode: u([
  s,
  [2, 23],
  s,
  [1, 12],
  c,
  [24, 13],
  c,
  [41, 28],
  c,
  [44, 15],
  c,
  [89, 27],
  c,
  [17, 13],
  c,
  [88, 11],
  c,
  [64, 34],
  c,
  [38, 14],
  c,
  [123, 15],
  c,
  [92, 12],
  1,
  c,
  [107, 10],
  c,
  [27, 6],
  c,
  [72, 23],
  c,
  [40, 8],
  c,
  [45, 7],
  c,
  [15, 13],
  s,
  [1, 24],
  s,
  [2, 234],
  c,
  [236, 98],
  c,
  [97, 24],
  c,
  [24, 15],
  c,
  [374, 20],
  c,
  [432, 5],
  c,
  [409, 15],
  c,
  [585, 9],
  c,
  [47, 20],
  c,
  [45, 25],
  c,
  [36, 14],
  c,
  [578, 18],
  c,
  [602, 53],
  c,
  [459, 145],
  c,
  [735, 19],
  c,
  [797, 33],
  c,
  [29, 25],
  c,
  [776, 238],
  c,
  [813, 51],
  c,
  [289, 5],
  c,
  [648, 7],
  c,
  [298, 21],
  c,
  [738, 18],
  c,
  [621, 8],
  c,
  [376, 7],
  c,
  [651, 22],
  c,
  [874, 59],
  c,
  [1219, 170],
  c,
  [960, 9],
  c,
  [947, 23],
  c,
  [1151, 89],
  c,
  [805, 17],
  s,
  [2, 53]
]),
  goto: u([
  s,
  [9, 11],
  s,
  [11, 11],
  8,
  5,
  s,
  [7, 4, 1],
  s,
  [13, 7, 1],
  s,
  [10, 11],
  34,
  21,
  s,
  [34, 16],
  24,
  27,
  29,
  33,
  34,
  35,
  40,
  28,
  30,
  38,
  39,
  42,
  41,
  44,
  46,
  s,
  [15, 11],
  s,
  [16, 11],
  s,
  [17, 11],
  48,
  49,
  50,
  52,
  53,
  s,
  [54, 12],
  59,
  58,
  1,
  2,
  7,
  58,
  63,
  s,
  [58, 6],
  60,
  s,
  [58, 7],
  s,
  [34, 17],
  s,
  [12, 11],
  61,
  61,
  65,
  s,
  [61, 9],
  c,
  [125, 12],
  s,
  [69, 3],
  c,
  [15, 5],
  s,
  [69, 7],
  40,
  69,
  c,
  [23, 7],
  71,
  71,
  c,
  [3, 3],
  71,
  68,
  70,
  s,
  [71, 18],
  72,
  71,
  71,
  65,
  65,
  27,
  65,
  c,
  [68, 11],
  c,
  [15, 15],
  c,
  [95, 12],
  c,
  [12, 12],
  s,
  [81, 29],
  s,
  [83, 29],
  s,
  [84, 29],
  s,
  [85, 29],
  s,
  [86, 29],
  s,
  [87, 29],
  s,
  [88, 29],
  s,
  [89, 31],
  38,
  80,
  s,
  [98, 29],
  s,
  [99, 29],
  s,
  [96, 29],
  s,
  [13, 9],
  82,
  13,
  13,
  s,
  [29, 12],
  s,
  [14, 9],
  83,
  14,
  14,
  s,
  [31, 12],
  85,
  86,
  87,
  s,
  [20, 11],
  s,
  [25, 3],
  s,
  [26, 3],
  16,
  16,
  23,
  24,
  100,
  s,
  [90, 8, 1],
  99,
  101,
  102,
  59,
  58,
  102,
  103,
  104,
  103,
  103,
  s,
  [108, 3],
  117,
  106,
  117,
  109,
  s,
  [33, 17],
  111,
  c,
  [684, 13],
  114,
  115,
  6,
  c,
  [630, 8],
  116,
  s,
  [58, 7],
  s,
  [67, 3],
  c,
  [34, 5],
  s,
  [67, 7],
  40,
  67,
  c,
  [42, 6],
  67,
  s,
  [68, 3],
  c,
  [24, 5],
  s,
  [68, 7],
  40,
  68,
  c,
  [24, 6],
  68,
  70,
  70,
  69,
  s,
  [70, 3],
  c,
  [7, 3],
  s,
  [70, 17],
  72,
  70,
  70,
  s,
  [76, 29],
  s,
  [77, 29],
  s,
  [78, 29],
  s,
  [82, 29],
  s,
  [97, 29],
  119,
  120,
  118,
  64,
  64,
  27,
  64,
  c,
  [259, 11],
  122,
  120,
  121,
  79,
  79,
  69,
  s,
  [79, 3],
  68,
  70,
  s,
  [79, 18],
  72,
  79,
  79,
  80,
  80,
  69,
  s,
  [80, 3],
  68,
  70,
  s,
  [80, 18],
  72,
  80,
  80,
  124,
  38,
  123,
  80,
  s,
  [93, 4],
  s,
  [94, 4],
  s,
  [95, 4],
  s,
  [30, 12],
  s,
  [32, 12],
  s,
  [18, 11],
  s,
  [19, 11],
  s,
  [27, 11],
  s,
  [28, 11],
  s,
  [21, 11],
  s,
  [22, 11],
  s,
  [43, 27],
  s,
  [44, 27],
  s,
  [45, 27],
  s,
  [46, 11],
  s,
  [47, 11],
  s,
  [48, 11],
  s,
  [49, 11],
  s,
  [50, 11],
  s,
  [51, 11],
  s,
  [52, 11],
  s,
  [53, 11],
  127,
  126,
  s,
  [100, 11],
  101,
  131,
  130,
  128,
  129,
  3,
  101,
  5,
  133,
  109,
  109,
  116,
  116,
  134,
  s,
  [113, 3],
  s,
  [35, 17],
  136,
  s,
  [40, 14],
  138,
  16,
  140,
  139,
  141,
  142,
  s,
  [59, 3],
  117,
  144,
  117,
  109,
  s,
  [66, 3],
  c,
  [627, 5],
  s,
  [66, 7],
  40,
  66,
  c,
  [434, 6],
  66,
  s,
  [72, 29],
  s,
  [74, 29],
  63,
  63,
  27,
  63,
  c,
  [508, 11],
  s,
  [73, 29],
  s,
  [75, 29],
  s,
  [90, 29],
  s,
  [91, 29],
  s,
  [92, 4],
  s,
  [111, 13],
  s,
  [112, 13],
  s,
  [104, 3],
  s,
  [105, 3],
  s,
  [106, 3],
  s,
  [107, 3],
  c,
  [259, 4],
  s,
  [115, 3],
  s,
  [114, 3],
  147,
  c,
  [949, 13],
  38,
  38,
  149,
  s,
  [38, 15],
  s,
  [41, 18],
  s,
  [42, 18],
  s,
  [55, 14],
  s,
  [56, 14],
  150,
  s,
  [57, 14],
  4,
  101,
  133,
  62,
  62,
  27,
  62,
  c,
  [115, 11],
  110,
  110,
  s,
  [36, 17],
  s,
  [39, 14],
  s,
  [37, 17],
  s,
  [60, 3]
])
}),
defaultActions: bda({
  idx: u([
  0,
  2,
  6,
  11,
  12,
  13,
  16,
  18,
  19,
  21,
  22,
  s,
  [31, 8, 1],
  40,
  41,
  s,
  [42, 4, 2],
  49,
  50,
  53,
  54,
  59,
  61,
  s,
  [68, 5, 1],
  s,
  [79, 22, 1],
  102,
  103,
  107,
  109,
  110,
  115,
  118,
  119,
  s,
  [121, 11, 1],
  133,
  134,
  s,
  [137, 4, 1],
  142,
  s,
  [146, 5, 1]
]),
  goto: u([
  9,
  11,
  10,
  15,
  16,
  17,
  54,
  1,
  2,
  34,
  12,
  81,
  s,
  [83, 7, 1],
  98,
  99,
  96,
  29,
  31,
  20,
  25,
  26,
  23,
  24,
  108,
  33,
  76,
  77,
  78,
  82,
  97,
  93,
  94,
  95,
  30,
  32,
  18,
  19,
  27,
  28,
  21,
  22,
  s,
  [43, 11, 1],
  100,
  101,
  109,
  113,
  35,
  59,
  72,
  74,
  73,
  75,
  90,
  91,
  92,
  111,
  112,
  s,
  [104, 4, 1],
  115,
  114,
  41,
  42,
  55,
  56,
  57,
  110,
  36,
  39,
  37,
  60
])
}),
parseError: function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable) {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
},
parse: function parse(input) {
    var self = this;
    var stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
    var sstack = new Array(128);        // state stack: stores states (column storage)

    var vstack = new Array(128);        // semantic value stack
    var lstack = new Array(128);        // location stack
    var table = this.table;
    var sp = 0;                         // 'stack pointer': index into the stacks
    var yyloc;

    


    var symbol = 0;
    var preErrorSymbol = 0;
    var lastEofErrorStateDepth = Infinity;
    var recoveringErrorInfo = null;
    var recovering = 0;                 // (only used when the grammar contains error recovery rules)
    var TERROR = this.TERROR;
    var EOF = this.EOF;
    var ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    var NO_ACTION = [0, 151 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

    var lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    var sharedState_yy = {
        parseError: undefined,
        quoteName: undefined,
        lexer: undefined,
        parser: undefined,
        pre_parse: undefined,
        post_parse: undefined,
        pre_lex: undefined,
        post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly in both ES5 and ES6 modes!
    };

    var ASSERT;
    if (typeof assert$1 !== 'function') {
        ASSERT = function JisonAssert(cond, msg) {
            if (!cond) {
                throw new Error('assertion failed: ' + (msg || '***'));
            }
        };
    } else {
        ASSERT = assert$1;
    }

    this.yyGetSharedState = function yyGetSharedState() {
        return sharedState_yy;
    };


    this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
        return recoveringErrorInfo;
    };


    // shallow clone objects, straight copy of simple `src` values
    // e.g. `lexer.yytext` MAY be a complex value object,
    // rather than a simple string/value.
    function shallow_copy(src) {
        if (typeof src === 'object') {
            var dst = {};
            for (var k in src) {
                if (Object.prototype.hasOwnProperty.call(src, k)) {
                    dst[k] = src[k];
                }
            }
            return dst;
        }
        return src;
    }
    function shallow_copy_noclobber(dst, src) {
        for (var k in src) {
            if (typeof dst[k] === 'undefined' && Object.prototype.hasOwnProperty.call(src, k)) {
                dst[k] = src[k];
            }
        }
    }
    function copy_yylloc(loc) {
        var rv = shallow_copy(loc);
        if (rv && rv.range) {
            rv.range = rv.range.slice(0);
        }
        return rv;
    }

    // copy state
    shallow_copy_noclobber(sharedState_yy, this.yy);

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;





    // *Always* setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions as it is paramount
    // to have *their* closure match ours -- if we only set them up once,
    // any subsequent `parse()` runs will fail in very obscure ways when
    // these functions are invoked in the user action code block(s) as
    // their closure will still refer to the `parse()` instance which set
    // them up. Hence we MUST set them up at the start of every `parse()` run!
    if (this.yyError) {
        this.yyError = function yyError(str /*, ...args */) {











            var error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
            var expected = this.collect_expected_token_set(state);
            var hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
            // append to the old one?
            if (recoveringErrorInfo) {
                var esp = recoveringErrorInfo.info_stack_pointer;

                recoveringErrorInfo.symbol_stack[esp] = symbol;
                var v = this.shallowCopyErrorInfo(hash);
                v.yyError = true;
                v.errorRuleDepth = error_rule_depth;
                v.recovering = recovering;
                // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                recoveringErrorInfo.value_stack[esp] = v;
                recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                ++esp;
                recoveringErrorInfo.info_stack_pointer = esp;
            } else {
                recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                recoveringErrorInfo.yyError = true;
                recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                recoveringErrorInfo.recovering = recovering;
            }


            // Add any extra args to the hash under the name `extra_error_attributes`:
            var args = Array.prototype.slice.call(arguments, 1);
            if (args.length) {
                hash.extra_error_attributes = args;
            }

            var r = this.parseError(str, hash, this.JisonParserError);
            return r;
        };
    }







    // Does the shared state override the default `parseError` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default `quoteName` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = function quoteNameAlt(id_str) {
            return sharedState_yy.quoteName.call(this, id_str);
        };
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a `finally { ... }` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `sharedState`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        var rv;

        if (invoke_post_methods) {
            var hash;

            if (sharedState_yy.post_parse || this.post_parse) {
                // create an error hash info instance: we re-use this API in a **non-error situation**
                // as this one delivers all parser internals ready for access by userland code.
                hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
            }

            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }

            // cleanup:
            if (hash && hash.destroy) {
                hash.destroy();
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;
        lstack.length = 0;
        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;


            for (var i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                var el = this.__error_recovery_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_recovery_infos.length = 0;

            // `recoveringErrorInfo` is also part of the `__error_recovery_infos` array,
            // hence has been destroyed already: no need to do that *twice*.
            if (recoveringErrorInfo) {
                recoveringErrorInfo = undefined;
            }


        }

        return resultValue;
    };

    // merge yylloc info into a new yylloc instance.
    //
    // `first_index` and `last_index` MAY be UNDEFINED/NULL or these are indexes into the `lstack[]` location stack array.
    //
    // `first_yylloc` and `last_yylloc` MAY be UNDEFINED/NULL or explicit (custom or regular) `yylloc` instances, in which
    // case these override the corresponding first/last indexes.
    //
    // `dont_look_back` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
    // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
    // yylloc info.
    //
    // Note: epsilon rule's yylloc situation is detected by passing both `first_index` and `first_yylloc` as UNDEFINED/NULL.
    this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
        var i1 = first_index | 0,
            i2 = last_index | 0;
        var l1 = first_yylloc,
            l2 = last_yylloc;
        var rv;

        // rules:
        // - first/last yylloc entries override first/last indexes

        if (!l1) {
            if (first_index != null) {
                for (var i = i1; i <= i2; i++) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
        }

        if (!l2) {
            if (last_index != null) {
                for (var i = i2; i >= i1; i--) {
                    l2 = lstack[i];
                    if (l2) {
                        break;
                    }
                }
            }
        }

        // - detect if an epsilon rule is being processed and act accordingly:
        if (!l1 && first_index == null) {
            // epsilon rule span merger. With optional look-ahead in l2.
            if (!dont_look_back) {
                for (var i = (i1 || sp) - 1; i >= 0; i--) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
            if (!l1) {
                if (!l2) {
                    // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                    // without look-ahead and no preceding terms and/or `dont_look_back` set:
                    // in that case we ca do nothing but return NULL/UNDEFINED:
                    return undefined;
                } else {
                    // shallow-copy L2: after all, we MAY be looking
                    // at unconventional yylloc info objects...
                    rv = shallow_copy(l2);
                    if (rv.range) {
                        // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                        rv.range = rv.range.slice(0);
                    }
                    return rv;
                }
            } else {
                // shallow-copy L1, then adjust first col/row 1 column past the end.
                rv = shallow_copy(l1);
                rv.first_line = rv.last_line;
                rv.first_column = rv.last_column;
                if (rv.range) {
                    // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                    rv.range = rv.range.slice(0);
                    rv.range[0] = rv.range[1];
                }

                if (l2) {
                    // shallow-mixin L2, then adjust last col/row accordingly.
                    shallow_copy_noclobber(rv, l2);
                    rv.last_line = l2.last_line;
                    rv.last_column = l2.last_column;
                    if (rv.range && l2.range) {
                        rv.range[1] = l2.range[1];
                    }
                }
                return rv;
            }
        }

        if (!l1) {
            l1 = l2;
            l2 = null;
        }
        if (!l1) {
            return undefined;
        }

        // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
        // at unconventional yylloc info objects...
        rv = shallow_copy(l1);

        // first_line: ...,
        // first_column: ...,
        // last_line: ...,
        // last_column: ...,
        if (rv.range) {
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            rv.range = rv.range.slice(0);
        }

        if (l2) {
            shallow_copy_noclobber(rv, l2);
            rv.last_line = l2.last_line;
            rv.last_column = l2.last_column;
            if (rv.range && l2.range) {
                rv.range[1] = l2.range[1];
            }
        }

        return rv;
    };

    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        var pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: lexer.yytext,
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,
            loc: copy_yylloc(lexer.yylloc),
            expected: expected,
            recoverable: recoverable,
            state: state,
            action: action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,
            location_stack: lstack,
            stack_pointer: sp,
            yy: sharedState_yy,
            lexer: lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };

    // clone some parts of the (possibly enhanced!) errorInfo object
    // to give them some persistence.
    this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
        var rv = shallow_copy(p);

        // remove the large parts which can only cause cyclic references
        // and are otherwise available from the parser kernel anyway.
        delete rv.sharedState_yy;
        delete rv.parser;
        delete rv.lexer;

        // lexer.yytext MAY be a complex value object, rather than a simple string/value:
        rv.value = shallow_copy(rv.value);

        // yylloc info:
        rv.loc = copy_yylloc(rv.loc);

        // the 'expected' set won't be modified, so no need to clone it:
        //rv.expected = rv.expected.slice(0);

        //symbol stack is a simple array:
        rv.symbol_stack = rv.symbol_stack.slice(0);
        // ditto for state stack:
        rv.state_stack = rv.state_stack.slice(0);
        // clone the yylloc's in the location stack?:
        rv.location_stack = rv.location_stack.map(copy_yylloc);
        // and the value stack may carry both simple and complex values:
        // shallow-copy the latter.
        rv.value_stack = rv.value_stack.map(shallow_copy);

        // and we don't bother with the sharedState_yy reference:
        //delete rv.yy;

        // now we prepare for tracking the COMBINE actions
        // in the error recovery code path:
        //
        // as we want to keep the maximum error info context, we
        // *scan* the state stack to find the first *empty* slot.
        // This position will surely be AT OR ABOVE the current
        // stack pointer, but we want to keep the 'used but discarded'
        // part of the parse stacks *intact* as those slots carry
        // error context that may be useful when you want to produce
        // very detailed error diagnostic reports.
        //
        // ### Purpose of each stack pointer:
        //
        // - stack_pointer: points at the top of the parse stack
        //                  **as it existed at the time of the error
        //                  occurrence, i.e. at the time the stack
        //                  snapshot was taken and copied into the
        //                  errorInfo object.**
        // - base_pointer:  the bottom of the **empty part** of the
        //                  stack, i.e. **the start of the rest of
        //                  the stack space /above/ the existing
        //                  parse stack. This section will be filled
        //                  by the error recovery process as it
        //                  travels the parse state machine to
        //                  arrive at the resolving error recovery rule.**
        // - info_stack_pointer:
        //                  this stack pointer points to the **top of
        //                  the error ecovery tracking stack space**, i.e.
        //                  this stack pointer takes up the role of
        //                  the `stack_pointer` for the error recovery
        //                  process. Any mutations in the **parse stack**
        //                  are **copy-appended** to this part of the
        //                  stack space, keeping the bottom part of the
        //                  stack (the 'snapshot' part where the parse
        //                  state at the time of error occurrence was kept)
        //                  intact.
        // - root_failure_pointer:
        //                  copy of the `stack_pointer`...
        //
        for (var i = rv.stack_pointer; typeof rv.state_stack[i] !== 'undefined'; i++) {
            // empty
        }
        rv.base_pointer = i;
        rv.info_stack_pointer = i;

        rv.root_failure_pointer = rv.stack_pointer;

        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_recovery_infos.push(rv);

        return rv;
    };

    function stdLex() {
        var token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    function fastLex() {
        var token = lexer.fastLex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    var lex = stdLex;


    var state, action, r, t;
    var yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    var p;
    var yyrulelen;
    var this_production;
    var newState;
    var retval = false;


    // Return the rule stack depth where the nearest error rule can be found.
    // Return -1 when no error recovery rule was found.
    function locateNearestErrorRecoveryRule(state) {
        var stack_probe = sp - 1;
        var depth = 0;

        // try to recover from error
        while (stack_probe >= 0) {
            // check for error recovery rule in this state









            var t = table[state][TERROR] || NO_ACTION;
            if (t[0]) {
                // We need to make sure we're not cycling forever:
                // once we hit EOF, even when we `yyerrok()` an error, we must
                // prevent the core from running forever,
                // e.g. when parent rules are still expecting certain input to
                // follow after this, for example when you handle an error inside a set
                // of braces which are matched by a parent rule in your grammar.
                //
                // Hence we require that every error handling/recovery attempt
                // *after we've hit EOF* has a diminishing state stack: this means
                // we will ultimately have unwound the state stack entirely and thus
                // terminate the parse in a controlled fashion even when we have
                // very complex error/recovery code interplay in the core + user
                // action code blocks:









                if (symbol === EOF) {
                    if (lastEofErrorStateDepth > sp - 1 - depth) {
                        lastEofErrorStateDepth = sp - 1 - depth;
                    } else {









                        --stack_probe; // popStack(1): [symbol, action]
                        state = sstack[stack_probe];
                        ++depth;
                        continue;
                    }
                }
                return depth;
            }
            if (state === 0 /* $accept rule */ || stack_probe < 1) {









                return -1; // No suitable error recovery rule available.
            }
            --stack_probe; // popStack(1): [symbol, action]
            state = sstack[stack_probe];
            ++depth;
        }









        return -1; // No suitable error recovery rule available.
    }


    try {
        this.__reentrant_call_depth++;

        lexer.setInput(input, sharedState_yy);

        // NOTE: we *assume* no lexer pre/post handlers are set up *after* 
        // this initial `setInput()` call: hence we can now check and decide
        // whether we'll go with the standard, slower, lex() API or the
        // `fast_lex()` one:
        if (typeof lexer.canIUse === 'function') {
            var lexerInfo = lexer.canIUse();
            if (lexerInfo.fastLex && typeof fastLex === 'function') {
                lex = fastLex;
            }
        } 

        yyloc = lexer.yylloc;
        lstack[sp] = yyloc;
        vstack[sp] = null;
        sstack[sp] = 0;
        stack[sp] = 0;
        ++sp;





        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single `==` condition below covers both these `===` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];











                // handle parse error
                if (!action) {
                    // first see if there's any chance at hitting an error recovery rule:
                    var error_rule_depth = locateNearestErrorRecoveryRule(state);
                    var errStr = null;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    if (!recovering) {
                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                        } else {
                            errStr = 'Parse error: ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                        // DO NOT cleanup the old one before we start the new error info track:
                        // the old one will *linger* on the error stack and stay alive until we 
                        // invoke the parser's cleanup API!
                        recoveringErrorInfo = this.shallowCopyErrorInfo(p);

                        r = this.parseError(p.errStr, p, this.JisonParserError);









                        // Protect against overly blunt userland `parseError` code which *sets*
                        // the `recoverable` flag without properly checking first:
                        // we always terminate the parse when there's no recovery rule available anyhow!
                        if (!p.recoverable || error_rule_depth < 0) {
                            if (typeof r !== 'undefined') {
                                retval = r;
                            }
                            break;
                        } else {
                            // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                        }
                    }










                    var esp = recoveringErrorInfo.info_stack_pointer;

                    // just recovered from another error
                    if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                        // SHIFT current lookahead and grab another
                        recoveringErrorInfo.symbol_stack[esp] = symbol;
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(lexer.yytext);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                        recoveringErrorInfo.state_stack[esp] = newState; // push state
                        ++esp;

                        // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                        yyloc = lexer.yylloc;

                        preErrorSymbol = 0;
                        symbol = lex();









                    }

                    // try to recover from error
                    if (error_rule_depth < 0) {
                        ASSERT(recovering > 0, "line 897");
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                        // while we are still busy recovering from another error:
                        var po = this.__error_infos[this.__error_infos.length - 1];

                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                        } else {
                            errStr = 'Parsing halted while starting to recover from another error';
                        }

                        if (po) {
                            errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                        } else {
                            errStr += ': ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, false);
                        if (po) {
                            p.extra_error_attributes = po;
                        }

                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }

                    preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                    symbol = TERROR;            // insert generic error symbol as new lookahead

                    const EXTRA_STACK_SAMPLE_DEPTH = 3;

                    // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                    recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                    if (errStr) {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            errStr: errStr,
                            errorSymbolDescr: errSymbolDescr,
                            expectedStr: expected,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };









                    } else {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                    }
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    yyval.$ = recoveringErrorInfo;
                    yyval._$ = undefined;

                    yyrulelen = error_rule_depth;









                    r = this.performAction.call(yyval, yyloc, NO_ACTION[1], sp - 1, vstack, lstack);

                    if (typeof r !== 'undefined') {
                        retval = r;
                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // and move the top entries + discarded part of the parse stacks onto the error info stack:
                    for (var idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                        recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(vstack[idx]);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lstack[idx]);
                        recoveringErrorInfo.state_stack[esp] = sstack[idx];
                    }

                    recoveringErrorInfo.symbol_stack[esp] = TERROR;
                    recoveringErrorInfo.value_stack[esp] = shallow_copy(yyval.$);
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(yyval._$);

                    // goto new state = table[STATE][NONTERMINAL]
                    newState = sstack[sp - 1];

                    if (this.defaultActions[newState]) {
                        recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                    } else {
                        t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                        recoveringErrorInfo.state_stack[esp] = t[1];
                    }

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    // allow N (default: 3) real symbols to be shifted before reporting a new error
                    recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;










                    // Now duplicate the standard parse machine here, at least its initial
                    // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                    // as we wish to push something special then!
                    //
                    // Run the state machine in this copy of the parser state machine
                    // until we *either* consume the error symbol (and its related information)
                    // *or* we run into another error while recovering from this one
                    // *or* we execute a `reduce` action which outputs a final parse
                    // result (yes, that MAY happen!).
                    //
                    // We stay in this secondary parse loop until we have completed
                    // the *error recovery phase* as the main parse loop (further below)
                    // is optimized for regular parse operation and DOES NOT cope with
                    // error recovery *at all*.
                    //
                    // We call the secondary parse loop just below the "slow parse loop",
                    // while the main parse loop, which is an almost-duplicate of this one,
                    // yet optimized for regular parse operation, is called the "fast
                    // parse loop".
                    //
                    // Compare this to `bison` & (vanilla) `jison`, both of which have
                    // only a single parse loop, which handles everything. Our goal is
                    // to eke out every drop of performance in the main parse loop...

                    ASSERT(recoveringErrorInfo, "line 1049");
                    ASSERT(symbol === TERROR, "line 1050");
                    ASSERT(!action, "line 1051");
                    var errorSymbolFromParser = true;
                    for (;;) {
                        // retrieve state number from top of stack
                        state = newState;               // sstack[sp - 1];

                        // use default actions if available
                        if (this.defaultActions[state]) {
                            action = 2;
                            newState = this.defaultActions[state];
                        } else {
                            // The single `==` condition below covers both these `===` comparisons in a single
                            // operation:
                            //
                            //     if (symbol === null || typeof symbol === 'undefined') ...
                            if (!symbol) {
                                symbol = lex();
                                // **Warning: Edge Case**: the *lexer* may produce
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided `yyvalue`
                                // and `yylloc`:
                                errorSymbolFromParser = false;
                            }
                            // read action for current state and first input
                            t = (table[state] && table[state][symbol]) || NO_ACTION;
                            newState = t[1];
                            action = t[0];










                            // encountered another parse error? If so, break out to main loop
                            // and take it from there!
                            if (!action) {










                                ASSERT(recoveringErrorInfo, "line 1087");

                                // Prep state variables so that upon breaking out of
                                // this "slow parse loop" and hitting the `continue;`
                                // statement in the outer "fast parse loop" we redo
                                // the exact same state table lookup as the one above
                                // so that the outer=main loop will also correctly
                                // detect the 'parse error' state (`!action`) we have
                                // just encountered above.
                                newState = state;
                                break;
                            }
                        }










                        switch (action) {
                        // catch misc. parse failures:
                        default:
                            // this shouldn't happen, unless resolve defaults are off
                            //
                            // SILENTLY SIGNAL that the outer "fast parse loop" should
                            // take care of this internal error condition:
                            // prevent useless code duplication now/here.
                            break;

                        // shift:
                        case 1:
                            stack[sp] = symbol;
                            // ### Note/Warning ###
                            //
                            // The *lexer* may also produce TERROR tokens on its own,
                            // so we specifically test for the TERROR we did set up
                            // in the error recovery logic further above!
                            if (symbol === TERROR && errorSymbolFromParser) {
                                // Push a special value onto the stack when we're
                                // shifting the `error` symbol that is related to the
                                // error we're recovering from.
                                ASSERT(recoveringErrorInfo, "line 1131");
                                vstack[sp] = recoveringErrorInfo;
                                lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                            } else {
                                ASSERT(symbol !== 0, "line 1135");
                                ASSERT(preErrorSymbol === 0, "line 1136");
                                vstack[sp] = lexer.yytext;
                                lstack[sp] = copy_yylloc(lexer.yylloc);
                            }
                            sstack[sp] = newState; // push state

                            ++sp;
                            symbol = 0;
                            // **Warning: Edge Case**: the *lexer* may have produced
                            // TERROR tokens of its own volition: *those* TERROR
                            // tokens should be treated like *regular tokens*
                            // i.e. tokens which have a lexer-provided `yyvalue`
                            // and `yylloc`:
                            errorSymbolFromParser = false;
                            if (!preErrorSymbol) { // normal execution / no error
                                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                                yyloc = lexer.yylloc;

                                if (recovering > 0) {
                                    recovering--;









                                }
                            } else {
                                // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                ASSERT(recovering > 0, "line 1163");
                                symbol = preErrorSymbol;
                                preErrorSymbol = 0;









                                // read action for current state and first input
                                t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                if (!t[0] || symbol === TERROR) {
                                    // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                    // (simple) stuff might have been missing before the token which caused the error we're
                                    // recovering from now...
                                    //
                                    // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                    // recovery, for then this we would we idling (cycling) on the error forever.
                                    // Yes, this does not take into account the possibility that the *lexer* may have
                                    // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!









                                    symbol = 0;
                                }
                            }

                            // once we have pushed the special ERROR token value,
                            // we REMAIN in this inner, "slow parse loop" until
                            // the entire error recovery phase has completed.
                            //
                            // ### Note About Edge Case ###
                            //
                            // Userland action code MAY already have 'reset' the
                            // error recovery phase marker `recovering` to ZERO(0)
                            // while the error symbol hasn't been shifted onto
                            // the stack yet. Hence we only exit this "slow parse loop"
                            // when *both* conditions are met!
                            ASSERT(preErrorSymbol === 0, "line 1194");
                            if (recovering === 0) {
                                break;
                            }
                            continue;

                        // reduce:
                        case 2:
                            this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                            yyrulelen = this_production[1];










                            r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                            if (typeof r !== 'undefined') {
                                // signal end of error recovery loop AND end of outer parse loop
                                action = 3;
                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                retval = r;
                                break;
                            }

                            // pop off stack
                            sp -= yyrulelen;

                            // don't overwrite the `symbol` variable: use a local var to speed things up:
                            var ntsymbol = this_production[0];    // push nonterminal (reduce)
                            stack[sp] = ntsymbol;
                            vstack[sp] = yyval.$;
                            lstack[sp] = yyval._$;
                            // goto new state = table[STATE][NONTERMINAL]
                            newState = table[sstack[sp - 1]][ntsymbol];
                            sstack[sp] = newState;
                            ++sp;









                            continue;

                        // accept:
                        case 3:
                            retval = true;
                            // Return the `$accept` rule's `$$` result, if available.
                            //
                            // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                            // default, action):
                            //
                            //     $accept: <startSymbol> $end
                            //                  %{ $$ = $1; @$ = @1; %}
                            //
                            // which, combined with the parse kernel's `$accept` state behaviour coded below,
                            // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                            // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                            //
                            // In code:
                            //
                            //                  %{
                            //                      @$ = @1;            // if location tracking support is included
                            //                      if (typeof $1 !== 'undefined')
                            //                          return $1;
                            //                      else
                            //                          return true;           // the default parse result if the rule actions don't produce anything
                            //                  %}
                            sp--;
                            if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                retval = vstack[sp];
                            }
                            sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                            break;
                        }

                        // break out of loop: we accept or fail with error
                        break;
                    }

                    // should we also break out of the regular/outer parse loop,
                    // i.e. did the parser already produce a parse result in here?!
                    // *or* did we hit an unsupported parse state, to be handled
                    // in the `switch/default` code further below?
                    ASSERT(action !== 2, "line 1272");
                    if (!action || action === 1) {
                        continue;
                    }
                }


            }










            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                r = this.parseError(p.errStr, p, this.JisonParserError);
                if (typeof r !== 'undefined') {
                    retval = r;
                }
                break;

            // shift:
            case 1:
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;
                lstack[sp] = copy_yylloc(lexer.yylloc);
                sstack[sp] = newState; // push state

                ++sp;
                symbol = 0;

                ASSERT(preErrorSymbol === 0, "line 1352");         // normal execution / no error
                ASSERT(recovering === 0, "line 1353");             // normal execution / no error

                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                yyloc = lexer.yylloc;
                continue;

            // reduce:
            case 2:
                ASSERT(preErrorSymbol === 0, "line 1364");         // normal execution / no error
                ASSERT(recovering === 0, "line 1365");             // normal execution / no error

                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                yyrulelen = this_production[1];










                r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                if (typeof r !== 'undefined') {
                    retval = r;
                    break;
                }

                // pop off stack
                sp -= yyrulelen;

                // don't overwrite the `symbol` variable: use a local var to speed things up:
                var ntsymbol = this_production[0];    // push nonterminal (reduce)
                stack[sp] = ntsymbol;
                vstack[sp] = yyval.$;
                lstack[sp] = yyval._$;
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[sstack[sp - 1]][ntsymbol];
                sstack[sp] = newState;
                ++sp;









                continue;

            // accept:
            case 3:
                if (sp !== -2) {
                    retval = true;
                    // Return the `$accept` rule's `$$` result, if available.
                    //
                    // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                    // default, action):
                    //
                    //     $accept: <startSymbol> $end
                    //                  %{ $$ = $1; @$ = @1; %}
                    //
                    // which, combined with the parse kernel's `$accept` state behaviour coded below,
                    // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                    // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                    //
                    // In code:
                    //
                    //                  %{
                    //                      @$ = @1;            // if location tracking support is included
                    //                      if (typeof $1 !== 'undefined')
                    //                          return $1;
                    //                      else
                    //                          return true;           // the default parse result if the rule actions don't produce anything
                    //                  %}
                    sp--;
                    if (typeof vstack[sp] !== 'undefined') {
                        retval = vstack[sp];
                    }
                }
                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        }
        else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }
        else {
            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;
    }   // /finally

    return retval;
},
yyError: 1
};
parser$1.originalParseError = parser$1.parseError;
parser$1.originalQuoteName = parser$1.quoteName;
/* lexer generated by jison-lex 0.6.1-214 */

/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a direct reference!
 *
 *               This "shared context" object was passed to the lexer by way of 
 *               the `lexer.setInput(str, yy)` API before you may use it.
 *
 *               This "shared context" object is passed to the lexer action code in `performAction()`
 *               so userland code in the lexer actions may communicate with the outside world 
 *               and/or other lexer rules' actions in more or less complex ways.
 *
 *  }
 *
 *  Lexer.prototype: {
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    yy:        The overall "shared context" object reference.
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance. 
 *                               `yy_` is an alias for `this` lexer instance reference used internally.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *                             Note:
 *                             The extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file are passed to the lexer via this object
 *                             reference as member variables.
 *
 *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function(),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the **parser** or the jison run-time; 
 *               when such a collision is detected an exception is thrown to prevent the generated run-time 
 *               from silently accepting this confusing and potentially hazardous situation! 
 *
 *    cleanupAfterLex: function(do_not_nuke_errorinfos),
 *               Helper function.
 *
 *               This helper API is invoked when the **parse process** has completed: it is the responsibility
 *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired. 
 *
 *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *    setInput: function(input, [yy]),
 *
 *
 *    input: function(),
 *
 *
 *    unput: function(str),
 *
 *
 *    more: function(),
 *
 *
 *    reject: function(),
 *
 *
 *    less: function(n),
 *
 *
 *    pastInput: function(n),
 *
 *
 *    upcomingInput: function(n),
 *
 *
 *    showPosition: function(),
 *
 *
 *    test_match: function(regex_match_array, rule_index),
 *
 *
 *    next: function(),
 *
 *
 *    begin: function(condition),
 *
 *
 *    pushState: function(condition),
 *
 *
 *    popState: function(),
 *
 *
 *    topState: function(),
 *
 *
 *    _currentRules: function(),
 *
 *
 *    stateStackSize: function(),
 *
 *
 *    performAction: function(yy, yy_, yyrulenumber, YY_START),
 *
 *
 *    rules: [...],
 *
 *
 *    conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *  
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


var lexer = function() {
  /**
   * See also:
   * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
   * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
   * with userland code which might access the derived class in a 'classic' way.
   *
   * @public
   * @constructor
   * @nocollapse
   */
  function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
      enumerable: false,
      writable: false,
      value: 'JisonLexerError'
    });

    if (msg == null)
      msg = '???';

    Object.defineProperty(this, 'message', {
      enumerable: false,
      writable: true,
      value: msg
    });

    this.hash = hash;
    var stacktrace;

    if (hash && hash.exception instanceof Error) {
      var ex2 = hash.exception;
      this.message = ex2.message || msg;
      stacktrace = ex2.stack;
    }

    if (!stacktrace) {
      if (Error.hasOwnProperty('captureStackTrace')) {
        // V8
        Error.captureStackTrace(this, this.constructor);
      } else {
        stacktrace = new Error(msg).stack;
      }
    }

    if (stacktrace) {
      Object.defineProperty(this, 'stack', {
        enumerable: false,
        writable: false,
        value: stacktrace
      });
    }
  }

  if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
  } else {
    JisonLexerError.prototype = Object.create(Error.prototype);
  }

  JisonLexerError.prototype.constructor = JisonLexerError;
  JisonLexerError.prototype.name = 'JisonLexerError';

  var lexer = {
    
// Code Generator Information Report
// ---------------------------------
//
// Options:
//
//   backtracking: .................... false
//   location.ranges: ................. true
//   location line+column tracking: ... true
//
//
// Forwarded Parser Analysis flags:
//
//   uses yyleng: ..................... false
//   uses yylineno: ................... false
//   uses yytext: ..................... false
//   uses yylloc: ..................... false
//   uses lexer values: ............... true / true
//   location tracking: ............... true
//   location assignment: ............. true
//
//
// Lexer Analysis flags:
//
//   uses yyleng: ..................... ???
//   uses yylineno: ................... ???
//   uses yytext: ..................... ???
//   uses yylloc: ..................... ???
//   uses ParseError API: ............. ???
//   uses yyerror: .................... ???
//   uses location tracking & editing:  ???
//   uses more() API: ................. ???
//   uses unput() API: ................ ???
//   uses reject() API: ............... ???
//   uses less() API: ................. ???
//   uses display APIs pastInput(), upcomingInput(), showPosition():
//        ............................. ???
//   uses describeYYLLOC() API: ....... ???
//
// --------- END OF REPORT -----------

EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state  

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup  
    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use  
    done: false,                                /// INTERNAL USE ONLY  
    _backtrack: false,                          /// INTERNAL USE ONLY  
    _input: '',                                 /// INTERNAL USE ONLY  
    _more: false,                               /// INTERNAL USE ONLY  
    _signaled_error_token: false,               /// INTERNAL USE ONLY  
    conditionStack: [],                         /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`  
    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!  
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far  
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt  
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.  
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far  
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)  
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located  
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction  

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
      msg = '' + msg;

      // heuristic to determine if the error message already contains a (partial) source code dump
      // as produced by either `showPosition()` or `prettyPrintRange()`:
      if (show_input_position == undefined) {
        show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
      }

      if (this.yylloc && show_input_position) {
        if (typeof this.prettyPrintRange === 'function') {
          var pretty_src = this.prettyPrintRange(this.yylloc);

          if (!/\n\s*$/.test(msg)) {
            msg += '\n';
          }

          msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
        } else if (typeof this.showPosition === 'function') {
          var pos_str = this.showPosition();

          if (pos_str) {
            if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
              msg += '\n' + pos_str;
            } else {
              msg += pos_str;
            }
          }
        }
      }

      /** @constructor */
      var pei = {
        errStr: msg,
        recoverable: !!recoverable,
        text: this.match,           // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...  
        token: null,
        line: this.yylineno,
        loc: this.yylloc,
        yy: this.yy,
        lexer: this,

        /**
         * and make sure the error info doesn't stay due to potential
         * ref cycle via userland code manipulations.
         * These would otherwise all be memory leak opportunities!
         * 
         * Note that only array and object references are nuked as those
         * constitute the set of elements which can produce a cyclic ref.
         * The rest of the members is kept intact as they are harmless.
         * 
         * @public
         * @this {LexErrorInfo}
         */
        destroy: function destructLexErrorInfo() {
          // remove cyclic references added to error info:
          // info.yy = null;
          // info.lexer = null;
          // ...
          var rec = !!this.recoverable;

          for (var key in this) {
            if (this.hasOwnProperty(key) && typeof key === 'object') {
              this[key] = undefined;
            }
          }

          this.recoverable = rec;
        }
      };

      // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
      this.__error_infos.push(pei);

      return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     * 
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
      if (!ExceptionClass) {
        ExceptionClass = this.JisonLexerError;
      }

      if (this.yy) {
        if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
          return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        } else if (typeof this.yy.parseError === 'function') {
          return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        }
      }

      throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
     * 
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str /*, ...args */) {
      var lineno_msg = '';

      if (this.yylloc) {
        lineno_msg = ' on line ' + (this.yylineno + 1);
      }

      var p = this.constructLexErrorInfo(
        'Lexical error' + lineno_msg + ': ' + str,
        this.options.lexerErrorsAreRecoverable
      );

      // Add any extra args to the hash under the name `extra_error_attributes`:
      var args = Array.prototype.slice.call(arguments, 1);

      if (args.length) {
        p.extra_error_attributes = args;
      }

      return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     * 
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
      // prevent lingering circular references from causing memory leaks:
      this.setInput('', {});

      // nuke the error hash info instances created during this run.
      // Userland code must COPY any data/references
      // in the error hash instance(s) it is more permanently interested in.
      if (!do_not_nuke_errorinfos) {
        for (var i = this.__error_infos.length - 1; i >= 0; i--) {
          var el = this.__error_infos[i];

          if (el && typeof el.destroy === 'function') {
            el.destroy();
          }
        }

        this.__error_infos.length = 0;
      }

      return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     * 
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
      this.yytext = '';
      this.yyleng = 0;
      this.match = '';

      // - DO NOT reset `this.matched`
      this.matches = false;

      this._more = false;
      this._backtrack = false;
      var col = (this.yylloc ? this.yylloc.last_column : 0);

      this.yylloc = {
        first_line: this.yylineno + 1,
        first_column: col,
        last_line: this.yylineno + 1,
        last_column: col,
        range: [this.offset, this.offset]
      };
    },

    /**
     * resets the lexer, sets new input
     * 
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
      this.yy = yy || this.yy || {};

      // also check if we've fully initialized the lexer instance,
      // including expansion work to be done to go from a loaded
      // lexer to a usable lexer:
      if (!this.__decompressed) {
        // step 1: decompress the regex list:
        var rules = this.rules;

        for (var i = 0, len = rules.length; i < len; i++) {
          var rule_re = rules[i];

          // compression: is the RE an xref to another RE slot in the rules[] table?
          if (typeof rule_re === 'number') {
            rules[i] = rules[rule_re];
          }
        }

        // step 2: unfold the conditions[] set to make these ready for use:
        var conditions = this.conditions;

        for (var k in conditions) {
          var spec = conditions[k];
          var rule_ids = spec.rules;
          var len = rule_ids.length;
          var rule_regexes = new Array(len + 1);             // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple! 
          var rule_new_ids = new Array(len + 1);

          for (var i = 0; i < len; i++) {
            var idx = rule_ids[i];
            var rule_re = rules[idx];
            rule_regexes[i + 1] = rule_re;
            rule_new_ids[i + 1] = idx;
          }

          spec.rules = rule_new_ids;
          spec.__rule_regexes = rule_regexes;
          spec.__rule_count = len;
        }

        this.__decompressed = true;
      }

      this._input = input || '';
      this.clear();
      this._signaled_error_token = false;
      this.done = false;
      this.yylineno = 0;
      this.matched = '';
      this.conditionStack = ['INITIAL'];
      this.__currentRuleSet__ = null;

      this.yylloc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      this.offset = 0;
      return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse, 
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the `unput()` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current `yyloc` cursor location or any history. 
     * 
     * Use this API to help implement C-preprocessor-like
     * `#include` statements, etc.
     * 
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The `cpsArg` argument value is passed to the callback
     * as-is.
     *
     * `callback` interface: 
     * `function callback(input, cpsArg)`
     * 
     * - `input` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - `cpsArg` is `cpsArg` passed into this API.
     * 
     * The `this` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API. 
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the `"" + retval`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html 
     * -- that way any returned object's `toValue()` and `toString()`
     * methods will be invoked in a proper/desirable order.)
     * 
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
      var rv = callback.call(this, this._input, cpsArg);

      if (typeof rv !== 'string') {
        if (rv) {
          this._input = '' + rv;
        } 
        // else: keep `this._input` as is.  
      } else {
        this._input = rv;
      }

      return this;
    },

    /**
     * consumes and returns one char from the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
      if (!this._input) {
        //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
        return null;
      }

      var ch = this._input[0];
      this.yytext += ch;
      this.yyleng++;
      this.offset++;
      this.match += ch;
      this.matched += ch;

      // Count the linenumber up when we hit the LF (or a stand-alone CR).
      // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
      // and we advance immediately past the LF as well, returning both together as if
      // it was all a single 'character' only.
      var slice_len = 1;

      var lines = false;

      if (ch === '\n') {
        lines = true;
      } else if (ch === '\r') {
        lines = true;
        var ch2 = this._input[1];

        if (ch2 === '\n') {
          slice_len++;
          ch += ch2;
          this.yytext += ch2;
          this.yyleng++;
          this.offset++;
          this.match += ch2;
          this.matched += ch2;
          this.yylloc.range[1]++;
        }
      }

      if (lines) {
        this.yylineno++;
        this.yylloc.last_line++;
        this.yylloc.last_column = 0;
      } else {
        this.yylloc.last_column++;
      }

      this.yylloc.range[1]++;
      this._input = this._input.slice(slice_len);
      return ch;
    },

    /**
     * unshifts one char (or an entire string) into the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
      var len = ch.length;
      var lines = ch.split(/(?:\r\n?|\n)/g);
      this._input = ch + this._input;
      this.yytext = this.yytext.substr(0, this.yytext.length - len);
      this.yyleng = this.yytext.length;
      this.offset -= len;
      this.match = this.match.substr(0, this.match.length - len);
      this.matched = this.matched.substr(0, this.matched.length - len);

      if (lines.length > 1) {
        this.yylineno -= lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;

        // Get last entirely matched line into the `pre_lines[]` array's
        // last index slot; we don't mind when other previously 
        // matched lines end up in the array too. 
        var pre = this.match;

        var pre_lines = pre.split(/(?:\r\n?|\n)/g);

        if (pre_lines.length === 1) {
          pre = this.matched;
          pre_lines = pre.split(/(?:\r\n?|\n)/g);
        }

        this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
      } else {
        this.yylloc.last_column -= len;
      }

      this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
      this.done = false;
      return this;
    },

    /**
     * cache matched text and append it on next action
     * 
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
      this._more = true;
      return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     * 
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
      if (this.options.backtrack_lexer) {
        this._backtrack = true;
      } else {
        // when the `parseError()` call returns, we MUST ensure that the error is registered.
        // We accomplish this by signaling an 'error' token to be produced for the current
        // `.lex()` run.
        var lineno_msg = '';

        if (this.yylloc) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
          false
        );

        this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
      }

      return this;
    },

    /**
     * retain first n characters of the match
     * 
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
      return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of
     * input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     * 
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
      var past = this.matched.substring(0, this.matched.length - this.match.length);

      if (maxSize < 0)
        maxSize = past.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = past.length;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substr` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      past = past.substr(-maxSize * 2 - 2);

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = past.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(-maxLines);
      past = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis prefix...
      if (past.length > maxSize) {
        past = '...' + past.substr(-maxSize);
      }

      return past;
    },

    /**
     * return (part of the) upcoming input, i.e. for error messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input 
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block. 
     * >
     * 
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
      var next = this.match;

      if (maxSize < 0)
        maxSize = next.length + this._input.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = maxSize;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substring` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      if (next.length < maxSize * 2 + 2) {
        next += this._input.substring(0, maxSize * 2 + 2);   // substring is faster on Chrome/V8 
      }

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = next.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(0, maxLines);
      next = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis postfix...
      if (next.length > maxSize) {
        next = next.substring(0, maxSize) + '...';
      }

      return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     * 
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
      var pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
      var c = new Array(pre.length + 1).join('-');
      return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the `preceding` and `following` locations, IFF those are available,
     * and reconstruct the `actual` location info from those.
     * If this fails, the heuristic is to take the `current` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     * 
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
      var loc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      if (actual) {
        loc.first_line = actual.first_line | 0;
        loc.last_line = actual.last_line | 0;
        loc.first_column = actual.first_column | 0;
        loc.last_column = actual.last_column | 0;

        if (actual.range) {
          loc.range[0] = actual.range[0] | 0;
          loc.range[1] = actual.range[1] | 0;
        }
      }

      if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
        // plan B: heuristic using preceding and following:
        if (loc.first_line <= 0 && preceding) {
          loc.first_line = preceding.last_line | 0;
          loc.first_column = preceding.last_column | 0;

          if (preceding.range) {
            loc.range[0] = actual.range[1] | 0;
          }
        }

        if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
          loc.last_line = following.first_line | 0;
          loc.last_column = following.first_column | 0;

          if (following.range) {
            loc.range[1] = actual.range[0] | 0;
          }
        }

        // plan C?: see if the 'current' location is useful/sane too:
        if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
          loc.first_line = current.first_line | 0;
          loc.first_column = current.first_column | 0;

          if (current.range) {
            loc.range[0] = current.range[0] | 0;
          }
        }

        if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
          loc.last_line = current.last_line | 0;
          loc.last_column = current.last_column | 0;

          if (current.range) {
            loc.range[1] = current.range[1] | 0;
          }
        }
      }

      // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
      // or plan D heuristics to produce a 'sensible' last_line value:
      if (loc.last_line <= 0) {
        if (loc.first_line <= 0) {
          loc.first_line = this.yylloc.first_line;
          loc.last_line = this.yylloc.last_line;
          loc.first_column = this.yylloc.first_column;
          loc.last_column = this.yylloc.last_column;
          loc.range[0] = this.yylloc.range[0];
          loc.range[1] = this.yylloc.range[1];
        } else {
          loc.last_line = this.yylloc.last_line;
          loc.last_column = this.yylloc.last_column;
          loc.range[1] = this.yylloc.range[1];
        }
      }

      if (loc.first_line <= 0) {
        loc.first_line = loc.last_line;
        loc.first_column = 0;  // loc.last_column; 
        loc.range[1] = loc.range[0];
      }

      if (loc.first_column < 0) {
        loc.first_column = 0;
      }

      if (loc.last_column < 0) {
        loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
      }

      return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced 
     * by the given location info range, plus a few lines of context.
     * 
     * This function pretty-prints the indicated section of the input, with line numbers 
     * and everything!
     * 
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     * 
     * - `loc` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by `^`
     *   characters below each character in the entire input range.
     * 
     * - `context_loc` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by `loc`. This can help provide context for the displayed
     *   error, etc.
     * 
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     * 
     * - `context_loc2` is another *optional* location info object, which serves
     *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     * 
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     * 
     * Special Notes:
     * 
     * - when the `loc`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   `...continued...` message will be printed between them.
     * 
     *   This serves the purpose of not printing a huge amount of text when the `loc`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     * 
     * - this function can display lines of input which whave not yet been lexed.
     *   `prettyPrintRange()` can access the entire input!
     * 
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
      loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
      const CONTEXT = 3;
      const CONTEXT_TAIL = 1;
      const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
      var input = this.matched + this._input;
      var lines = input.split('\n');
      var l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
      var l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
      var lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
      var ws_prefix = new Array(lineno_display_width).join(' ');
      var nonempty_line_indexes = [];

      var rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
        var lno = index + l0;
        var lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
        var rv = lno_pfx + ': ' + line;
        var errpfx = new Array(lineno_display_width + 1).join('^');
        var offset = 2 + 1;
        var len = 0;

        if (lno === loc.first_line) {
          offset += loc.first_column;

          len = Math.max(
            2,
            ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
          );
        } else if (lno === loc.last_line) {
          len = Math.max(2, loc.last_column + 1);
        } else if (lno > loc.first_line && lno < loc.last_line) {
          len = Math.max(2, line.length + 1);
        }

        if (len) {
          var lead = new Array(offset).join('.');
          var mark = new Array(len).join('^');
          rv += '\n' + errpfx + lead + mark;

          if (line.trim().length > 0) {
            nonempty_line_indexes.push(index);
          }
        }

        rv = rv.replace(/\t/g, ' ');
        return rv;
      });

      // now make sure we don't print an overly large amount of error area: limit it 
      // to the top and bottom line count:
      if (nonempty_line_indexes.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
        var clip_start = nonempty_line_indexes[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
        var clip_end = nonempty_line_indexes[nonempty_line_indexes.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
        var intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';
        intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
        rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
      }

      return rv.join('\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input `yylloc` location object.
     * 
     * Set `display_range_too` to TRUE to include the string character index position(s)
     * in the description if the `yylloc.range` is available.
     * 
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
      var l1 = yylloc.first_line;
      var l2 = yylloc.last_line;
      var c1 = yylloc.first_column;
      var c2 = yylloc.last_column;
      var dl = l2 - l1;
      var dc = c2 - c1;
      var rv;

      if (dl === 0) {
        rv = 'line ' + l1 + ', ';

        if (dc <= 1) {
          rv += 'column ' + c1;
        } else {
          rv += 'columns ' + c1 + ' .. ' + c2;
        }
      } else {
        rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
      }

      if (yylloc.range && display_range_too) {
        var r1 = yylloc.range[0];
        var r2 = yylloc.range[1] - 1;

        if (r2 <= r1) {
          rv += ' {String Offset: ' + r1 + '}';
        } else {
          rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
        }
      }

      return rv;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     * 
     * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
     * contains the actually matched text string.
     * 
     * Also move the input cursor forward and update the match collectors:
     * 
     * - `yytext`
     * - `yyleng`
     * - `match`
     * - `matches`
     * - `yylloc`
     * - `offset`
     * 
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
      var token, lines, backup, match_str, match_str_len;

      if (this.options.backtrack_lexer) {
        // save context
        backup = {
          yylineno: this.yylineno,

          yylloc: {
            first_line: this.yylloc.first_line,
            last_line: this.yylloc.last_line,
            first_column: this.yylloc.first_column,
            last_column: this.yylloc.last_column,
            range: this.yylloc.range.slice(0)
          },

          yytext: this.yytext,
          match: this.match,
          matches: this.matches,
          matched: this.matched,
          yyleng: this.yyleng,
          offset: this.offset,
          _more: this._more,
          _input: this._input,

          //_signaled_error_token: this._signaled_error_token,
          yy: this.yy,

          conditionStack: this.conditionStack.slice(0),
          done: this.done
        };
      }

      match_str = match[0];
      match_str_len = match_str.length;

      // if (match_str.indexOf('\n') !== -1 || match_str.indexOf('\r') !== -1) {
      lines = match_str.split(/(?:\r\n?|\n)/g);

      if (lines.length > 1) {
        this.yylineno += lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;
        this.yylloc.last_column = lines[lines.length - 1].length;
      } else {
        this.yylloc.last_column += match_str_len;
      }

      // }
      this.yytext += match_str;

      this.match += match_str;
      this.matched += match_str;
      this.matches = match;
      this.yyleng = this.yytext.length;
      this.yylloc.range[1] += match_str_len;

      // previous lex rules MAY have invoked the `more()` API rather than producing a token:
      // those rules will already have moved this `offset` forward matching their match lengths,
      // hence we must only add our own match length now:
      this.offset += match_str_len;

      this._more = false;
      this._backtrack = false;
      this._input = this._input.slice(match_str_len);

      // calling this method:
      //
      //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
      token = this.performAction.call(
        this,
        this.yy,
        indexed_rule,
        this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
      );

      // otherwise, when the action codes are all simple return token statements:
      //token = this.simpleCaseActionClusters[indexed_rule];

      if (this.done && this._input) {
        this.done = false;
      }

      if (token) {
        return token;
      } else if (this._backtrack) {
        // recover context
        for (var k in backup) {
          this[k] = backup[k];
        }

        this.__currentRuleSet__ = null;
        return false;  // rule action called reject() implying the next rule should be tested instead. 
      } else if (this._signaled_error_token) {
        // produce one 'error' token as `.parseError()` in `reject()`
        // did not guarantee a failure signal by throwing an exception!
        token = this._signaled_error_token;

        this._signaled_error_token = false;
        return token;
      }

      return false;
    },

    /**
     * return next match in input
     * 
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
      if (this.done) {
        this.clear();
        return this.EOF;
      }

      if (!this._input) {
        this.done = true;
      }

      var token, match, tempMatch, index;

      if (!this._more) {
        this.clear();
      }

      var spec = this.__currentRuleSet__;

      if (!spec) {
        // Update the ruleset cache as we apparently encountered a state change or just started lexing.
        // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
        // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
        // speed up those activities a tiny bit.
        spec = this.__currentRuleSet__ = this._currentRules();

        // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
        // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
        if (!spec || !spec.rules) {
          var lineno_msg = '';

          if (this.options.trackPosition) {
            lineno_msg = ' on line ' + (this.yylineno + 1);
          }

          var p = this.constructLexErrorInfo(
            'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
            false
          );

          // produce one 'error' token until this situation has been resolved, most probably by parse termination!
          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        }
      }

      var rule_ids = spec.rules;
      var regexes = spec.__rule_regexes;
      var len = spec.__rule_count;

      // Note: the arrays are 1-based, while `len` itself is a valid index,
      // hence the non-standard less-or-equal check in the next loop condition!
      for (var i = 1; i <= len; i++) {
        tempMatch = this._input.match(regexes[i]);

        if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
          match = tempMatch;
          index = i;

          if (this.options.backtrack_lexer) {
            token = this.test_match(tempMatch, rule_ids[i]);

            if (token !== false) {
              return token;
            } else if (this._backtrack) {
              match = undefined;
              continue;  // rule action called reject() implying a rule MISmatch. 
            } else {
              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          } else if (!this.options.flex) {
            break;
          }
        }
      }

      if (match) {
        token = this.test_match(match, rule_ids[index]);

        if (token !== false) {
          return token;
        }

        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
        return false;
      }

      if (!this._input) {
        this.done = true;
        this.clear();
        return this.EOF;
      } else {
        var lineno_msg = '';

        if (this.options.trackPosition) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': Unrecognized text.',
          this.options.lexerErrorsAreRecoverable
        );

        var pendingInput = this._input;
        var activeCondition = this.topState();
        var conditionStackDepth = this.conditionStack.length;
        token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

        if (token === this.ERROR) {
          // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
          // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
          // has not consumed/modified any pending input or changed state in the error handler:
          if (!this.matches && // and make sure the input has been modified/consumed ...
          pendingInput === this._input && // ...or the lexer state has been modified significantly enough
          // to merit a non-consuming error handling action right now.
          activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
            this.input();
          }
        }

        return token;
      }
    },

    /**
     * return next match that has a token
     * 
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
      var r;

      // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
      if (typeof this.pre_lex === 'function') {
        r = this.pre_lex.call(this, 0);
      }

      if (typeof this.options.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.pre_lex.call(this, r) || r;
      }

      if (this.yy && typeof this.yy.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.pre_lex.call(this, r) || r;
      }

      while (!r) {
        r = this.next();
      }

      if (this.yy && typeof this.yy.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.post_lex.call(this, r) || r;
      }

      if (typeof this.options.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.post_lex.call(this, r) || r;
      }

      if (typeof this.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.post_lex.call(this, r) || r;
      }

      return r;
    },

    /**
     * return next match that has a token. Identical to the `lex()` API but does not invoke any of the 
     * `pre_lex()` nor any of the `post_lex()` callbacks.
     * 
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
      var r;

      while (!r) {
        r = this.next();
      }

      return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     * 
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
      var rv = {
        fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
      };

      return rv;
    },

    /**
     * backwards compatible alias for `pushState()`;
     * the latter is symmetrical with `popState()` and we advise to use
     * those APIs in any modern lexer code, rather than `begin()`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
      return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     * 
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
      this.conditionStack.push(condition);
      this.__currentRuleSet__ = null;
      return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
      var n = this.conditionStack.length - 1;

      if (n > 0) {
        this.__currentRuleSet__ = null;
        return this.conditionStack.pop();
      } else {
        return this.conditionStack[0];
      }
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     * 
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
      n = this.conditionStack.length - 1 - Math.abs(n || 0);

      if (n >= 0) {
        return this.conditionStack[n];
      } else {
        return 'INITIAL';
      }
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     * 
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
      if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
        return this.conditions[this.conditionStack[this.conditionStack.length - 1]];
      } else {
        return this.conditions['INITIAL'];
      }
    },

    /**
     * return the number of states currently on the stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
      return this.conditionStack.length;
    },

    options: {
      xregexp: true,
      ranges: true,
      trackPosition: true,
      parseActionsUseYYMERGELOCATIONINFO: true,
      easy_keyword_rules: true
    },

    JisonLexerError: JisonLexerError,

    performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
      var yy_ = this;
      switch (yyrulenumber) {
      case 0:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %\{ */
        yy.depth = 0;

        yy.include_command_allowed = false;
        this.pushState('action');
        this.unput(yy_.yytext);
        yy_.yytext = '';
        return 28;
        break;

      case 1:
        /*! Conditions:: action */
        /*! Rule::       %\{([^]*?)%\} */
        yy_.yytext = this.matches[1].replace(/%\\\}/g, '%}');    // unescape any literal '%\}' that exists within the action code block 

        yy.include_command_allowed = true;
        return 32;
        break;

      case 2:
        /*! Conditions:: action */
        /*! Rule::       %include\b */
        if (yy.include_command_allowed) {
          // This is an include instruction in place of an action:
          //
          // - one %include per action chunk
          // - one %include replaces an entire action chunk
          this.pushState('path');

          return 51;
        } else {
          // TODO
          yy_.yyerror(rmCommonWS`
                                                    %include statements must occur on a line on their own and cannot occur inside an %{...%} action code block.
                                                    Its use is not permitted at this position.

                                                      Erroneous area:
                                                    ` + this.prettyPrintRange(yy_.yylloc));

          return 37;
        }

        break;

      case 3:
        /*! Conditions:: action */
        /*! Rule::       {WS}*\/\*[^]*?\*\/ */
        //yy.include_command_allowed = false; -- doesn't impact include-allowed state
        return 34;

        break;

      case 4:
        /*! Conditions:: action */
        /*! Rule::       {WS}*\/\/.* */
        yy.include_command_allowed = false;

        return 35;
        break;

      case 6:
        /*! Conditions:: action */
        /*! Rule::       \| */
        if (yy.include_command_allowed) {
          this.popState();
          this.unput(yy_.yytext);
          yy_.yytext = '';
          return 31;
        } else {
          return 33;
        }

        break;

      case 7:
        /*! Conditions:: action */
        /*! Rule::       %% */
        if (yy.include_command_allowed) {
          this.popState();
          this.unput(yy_.yytext);
          yy_.yytext = '';
          return 31;
        } else {
          return 33;
        }

        break;

      case 9:
        /*! Conditions:: action */
        /*! Rule::       \/[^\s/]*?(?:['"`{}][^\s/]*?)*\/ */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 10:
        /*! Conditions:: action */
        /*! Rule::       \/[^}{BR}]* */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 11:
        /*! Conditions:: action */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 12:
        /*! Conditions:: action */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 13:
        /*! Conditions:: action */
        /*! Rule::       `{ES2017_STRING_CONTENT}` */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 14:
        /*! Conditions:: action */
        /*! Rule::       [^{}/"'`|%\{\}{BR}{WS}]+ */
        yy.include_command_allowed = false;

        return 33;
        break;

      case 15:
        /*! Conditions:: action */
        /*! Rule::       \{ */
        yy.depth++;

        yy.include_command_allowed = false;
        return 33;
        break;

      case 16:
        /*! Conditions:: action */
        /*! Rule::       \} */
        yy.include_command_allowed = false;

        if (yy.depth <= 0) {
          yy_.yyerror(rmCommonWS`
                                                    too many closing curly braces in lexer rule action block.

                                                    Note: the action code chunk may be too complex for jison to parse
                                                    easily; we suggest you wrap the action code chunk in '%{...%}'
                                                    to help jison grok more or less complex action code chunks.

                                                      Erroneous area:
                                                    ` + this.prettyPrintRange(yy_.yylloc));

          return 30;
        } else {
          yy.depth--;
        }

        return 33;
        break;

      case 17:
        /*! Conditions:: action */
        /*! Rule::       (?:{BR}{WS}+)+(?=[^{WS}{BR}|]) */
        yy.include_command_allowed = true;

        return 36;            // keep empty lines as-is inside action code blocks.  
        break;

      case 18:
        /*! Conditions:: action */
        /*! Rule::       {BR} */
        if (yy.depth > 0) {
          yy.include_command_allowed = true;
          return 36;        // keep empty lines as-is inside action code blocks. 
        } else {
          // end of action code chunk
          this.popState();

          this.unput(yy_.yytext);
          yy_.yytext = '';
          return 31;
        }

        break;

      case 19:
        /*! Conditions:: action */
        /*! Rule::       $ */
        yy.include_command_allowed = false;

        if (yy.depth !== 0) {
          yy_.yyerror(rmCommonWS`
                                                    missing ${yy.depth} closing curly braces in lexer rule action block.

                                                    Note: the action code chunk may be too complex for jison to parse
                                                    easily; we suggest you wrap the action code chunk in '%{...%}'
                                                    to help jison grok more or less complex action code chunks.

                                                      Erroneous area:
                                                    ` + this.prettyPrintRange(yy_.yylloc));

          yy_.yytext = '';
          return 29;
        }

        this.popState();
        yy_.yytext = '';
        return 31;
        break;

      case 21:
        /*! Conditions:: conditions */
        /*! Rule::       > */
        this.popState();

        return 6;
        break;

      case 24:
        /*! Conditions:: INITIAL start_condition macro path options */
        /*! Rule::       {WS}*\/\/[^\r\n]* */
        /* skip single-line comment */
        break;

      case 25:
        /*! Conditions:: INITIAL start_condition macro path options */
        /*! Rule::       {WS}*\/\*[^]*?\*\/ */
        /* skip multi-line comment */
        break;

      case 26:
        /*! Conditions:: rules */
        /*! Rule::       {BR}+ */
        /* empty */
        break;

      case 27:
        /*! Conditions:: rules */
        /*! Rule::       {WS}+{BR}+ */
        /* empty */
        break;

      case 28:
        /*! Conditions:: rules */
        /*! Rule::       \/\/[^\r\n]* */
        /* skip single-line comment */
        break;

      case 29:
        /*! Conditions:: rules */
        /*! Rule::       \/\*[^]*?\*\/ */
        /* skip multi-line comment */
        break;

      case 30:
        /*! Conditions:: rules */
        /*! Rule::       {WS}+(?=[^{WS}{BR}|%]) */
        yy.depth = 0;

        yy.include_command_allowed = true;
        this.pushState('action');
        return 28;
        break;

      case 31:
        /*! Conditions:: rules */
        /*! Rule::       %% */
        this.popState();

        this.pushState('code');
        return 19;
        break;

      case 32:
        /*! Conditions:: rules */
        /*! Rule::       {ANY_LITERAL_CHAR}+ */
        // accept any non-regex, non-lex, non-string-delim,
        // non-escape-starter, non-space character as-is
        return 46;

        break;

      case 35:
        /*! Conditions:: options */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1], /\\"/g);

        return 49;    // value is always a string type  
        break;

      case 36:
        /*! Conditions:: options */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1], /\\'/g);

        return 49;    // value is always a string type  
        break;

      case 37:
        /*! Conditions:: options */
        /*! Rule::       `{ES2017_STRING_CONTENT}` */
        yy_.yytext = unescQuote(this.matches[1], /\\`/g);

        return 49;    // value is always a string type  
        break;

      case 39:
        /*! Conditions:: options */
        /*! Rule::       {BR}{WS}+(?=\S) */
        /* skip leading whitespace on the next line of input, when followed by more options */
        break;

      case 40:
        /*! Conditions:: options */
        /*! Rule::       {BR} */
        this.popState();

        return 48;
        break;

      case 41:
        /*! Conditions:: options */
        /*! Rule::       {WS}+ */
        /* skip whitespace */
        break;

      case 43:
        /*! Conditions:: start_condition */
        /*! Rule::       {BR}+ */
        this.popState();

        break;

      case 44:
        /*! Conditions:: start_condition */
        /*! Rule::       {WS}+ */
        /* empty */
        break;

      case 46:
        /*! Conditions:: INITIAL */
        /*! Rule::       {ID} */
        this.pushState('macro');

        return 20;
        break;

      case 47:
        /*! Conditions:: macro named_chunk */
        /*! Rule::       {BR}+ */
        this.popState();

        break;

      case 48:
        /*! Conditions:: macro */
        /*! Rule::       {ANY_LITERAL_CHAR}+ */
        // accept any non-regex, non-lex, non-string-delim,
        // non-escape-starter, non-space character as-is
        return 46;

        break;

      case 49:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       {BR}+ */
        /* empty */
        break;

      case 50:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       \s+ */
        /* empty */
        break;

      case 51:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1], /\\"/g);

        return 26;
        break;

      case 52:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1], /\\'/g);

        return 26;
        break;

      case 53:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       \[ */
        this.pushState('set');

        return 41;
        break;

      case 66:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       < */
        this.pushState('conditions');

        return 5;
        break;

      case 67:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       \/! */
        return 39;                     // treated as `(?!atom)`  

        break;

      case 68:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       \/ */
        return 14;                      // treated as `(?=atom)`  

        break;

      case 70:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       \\. */
        yy_.yytext = yy_.yytext.replace(/^\\/g, '');

        return 44;
        break;

      case 73:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %option[s]? */
        this.pushState('options');

        return 47;
        break;

      case 74:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %s\b */
        this.pushState('start_condition');

        return 21;
        break;

      case 75:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %x\b */
        this.pushState('start_condition');

        return 22;
        break;

      case 76:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %code\b */
        this.pushState('named_chunk');

        return 25;
        break;

      case 77:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %import\b */
        this.pushState('named_chunk');

        return 24;
        break;

      case 78:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %include\b */
        yy.depth = 0;

        yy.include_command_allowed = true;
        this.pushState('action');
        this.unput(yy_.yytext);
        yy_.yytext = '';
        return 28;
        break;

      case 79:
        /*! Conditions:: code */
        /*! Rule::       %include\b */
        this.pushState('path');

        return 51;
        break;

      case 80:
        /*! Conditions:: INITIAL rules code */
        /*! Rule::       %{NAME}([^\r\n]*) */
        /* ignore unrecognized decl */
        this.warn(rmCommonWS`
                                                LEX: ignoring unsupported lexer option ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

        yy_.yytext = {
          name: this.matches[1],            // {NAME}  
          value: this.matches[2].trim()       // optional value/parameters 
        };

        return 23;
        break;

      case 81:
        /*! Conditions:: rules macro named_chunk INITIAL */
        /*! Rule::       %% */
        this.pushState('rules');

        return 19;
        break;

      case 89:
        /*! Conditions:: set */
        /*! Rule::       \] */
        this.popState();

        return 42;
        break;

      case 91:
        /*! Conditions:: code */
        /*! Rule::       [^\r\n]+ */
        return 53;       // the bit of CODE just before EOF...  

        break;

      case 92:
        /*! Conditions:: path */
        /*! Rule::       {BR} */
        this.popState();

        this.unput(yy_.yytext);
        break;

      case 93:
        /*! Conditions:: path */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1]);

        this.popState();
        return 52;
        break;

      case 94:
        /*! Conditions:: path */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1]);

        this.popState();
        return 52;
        break;

      case 95:
        /*! Conditions:: path */
        /*! Rule::       {WS}+ */
        // skip whitespace in the line 
        break;

      case 96:
        /*! Conditions:: path */
        /*! Rule::       [^\s\r\n]+ */
        this.popState();

        return 52;
        break;

      case 97:
        /*! Conditions:: action */
        /*! Rule::       " */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 98:
        /*! Conditions:: action */
        /*! Rule::       ' */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 99:
        /*! Conditions:: action */
        /*! Rule::       ` */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 100:
        /*! Conditions:: options */
        /*! Rule::       " */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 101:
        /*! Conditions:: options */
        /*! Rule::       ' */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 102:
        /*! Conditions:: options */
        /*! Rule::       ` */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 103:
        /*! Conditions:: * */
        /*! Rule::       " */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 104:
        /*! Conditions:: * */
        /*! Rule::       ' */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 105:
        /*! Conditions:: * */
        /*! Rule::       ` */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 106:
        /*! Conditions:: macro rules */
        /*! Rule::       . */
        /* b0rk on bad characters */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                                unsupported lexer input encountered while lexing
                                                ${rules} (i.e. jison lex regexes).

                                                    NOTE: When you want this input to be interpreted as a LITERAL part
                                                          of a lex rule regex, you MUST enclose it in double or
                                                          single quotes.

                                                          If not, then know that this input is not accepted as a valid
                                                          regex expression here in jison-lex ${rules}.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

        break;

      case 107:
        /*! Conditions:: * */
        /*! Rule::       . */
        yy_.yyerror(rmCommonWS`
                                                unsupported lexer input: ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

        break;

      default:
        return this.simpleCaseActionClusters[yyrulenumber];
      }
    },

    simpleCaseActionClusters: {
      /*! Conditions:: action */
      /*! Rule::       {WS}+ */
      5: 36,

      /*! Conditions:: action */
      /*! Rule::       % */
      8: 33,

      /*! Conditions:: conditions */
      /*! Rule::       {NAME} */
      20: 20,

      /*! Conditions:: conditions */
      /*! Rule::       , */
      22: 8,

      /*! Conditions:: conditions */
      /*! Rule::       \* */
      23: 7,

      /*! Conditions:: options */
      /*! Rule::       {NAME} */
      33: 20,

      /*! Conditions:: options */
      /*! Rule::       = */
      34: 18,

      /*! Conditions:: options */
      /*! Rule::       [^\s\r\n]+ */
      38: 50,

      /*! Conditions:: start_condition */
      /*! Rule::       {ID} */
      42: 27,

      /*! Conditions:: named_chunk */
      /*! Rule::       {ID} */
      45: 20,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \| */
      54: 9,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \(\?: */
      55: 38,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \(\?= */
      56: 38,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \(\?! */
      57: 38,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \( */
      58: 10,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \) */
      59: 11,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \+ */
      60: 12,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \* */
      61: 7,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \? */
      62: 13,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \^ */
      63: 16,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       , */
      64: 8,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       <<EOF>> */
      65: 17,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \\([0-7]{1,3}|[rfntvsSbBwWdD\\*+()${}|[\]\/.^?]|c[A-Z]|x[0-9A-F]{2}|u[a-fA-F0-9]{4}) */
      69: 44,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \$ */
      71: 17,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \. */
      72: 15,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \{\d+(,\s*\d+|,)?\} */
      82: 45,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \{{ID}\} */
      83: 40,

      /*! Conditions:: set options */
      /*! Rule::       \{{ID}\} */
      84: 40,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \{ */
      85: 3,

      /*! Conditions:: rules macro named_chunk INITIAL */
      /*! Rule::       \} */
      86: 4,

      /*! Conditions:: set */
      /*! Rule::       (?:\\\\|\\\]|[^\]{])+ */
      87: 43,

      /*! Conditions:: set */
      /*! Rule::       \{ */
      88: 43,

      /*! Conditions:: code */
      /*! Rule::       [^\r\n]*(\r|\n)+ */
      90: 53,

      /*! Conditions:: * */
      /*! Rule::       $ */
      108: 1
    },

    rules: [
      /*   0: */  /^(?:%\{)/,
      /*   1: */  new XRegExp('^(?:%\\{([^]*?)%\\})', ''),
      /*   2: */  /^(?:%include\b)/,
      /*   3: */  new XRegExp('^(?:([^\\S\\n\\r])*\\/\\*[^]*?\\*\\/)', ''),
      /*   4: */  /^(?:([^\S\n\r])*\/\/.*)/,
      /*   5: */  /^(?:([^\S\n\r])+)/,
      /*   6: */  /^(?:\|)/,
      /*   7: */  /^(?:%%)/,
      /*   8: */  /^(?:%)/,
      /*   9: */  /^(?:\/[^\s\/]*?(?:['"`{}][^\s\/]*?)*\/)/,
      /*  10: */  /^(?:\/[^\n\r}]*)/,
      /*  11: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /*  12: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /*  13: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
      /*  14: */  /^(?:[^\s"%'\/`{-}]+)/,
      /*  15: */  /^(?:\{)/,
      /*  16: */  /^(?:\})/,
      /*  17: */  /^(?:(?:(\r\n|\n|\r)([^\S\n\r])+)+(?=[^\s|]))/,
      /*  18: */  /^(?:(\r\n|\n|\r))/,
      /*  19: */  /^(?:$)/,
      /*  20: */  new XRegExp(
        '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
        ''
      ),
      /*  21: */  /^(?:>)/,
      /*  22: */  /^(?:,)/,
      /*  23: */  /^(?:\*)/,
      /*  24: */  /^(?:([^\S\n\r])*\/\/[^\n\r]*)/,
      /*  25: */  new XRegExp('^(?:([^\\S\\n\\r])*\\/\\*[^]*?\\*\\/)', ''),
      /*  26: */  /^(?:(\r\n|\n|\r)+)/,
      /*  27: */  /^(?:([^\S\n\r])+(\r\n|\n|\r)+)/,
      /*  28: */  /^(?:\/\/[^\r\n]*)/,
      /*  29: */  new XRegExp('^(?:\\/\\*[^]*?\\*\\/)', ''),
      /*  30: */  /^(?:([^\S\n\r])+(?=[^\s%|]))/,
      /*  31: */  /^(?:%%)/,
      /*  32: */  /^(?:([^\s!"$%'-,.\/:-?\[-\^{-}])+)/,
      /*  33: */  new XRegExp(
        '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
        ''
      ),
      /*  34: */  /^(?:=)/,
      /*  35: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /*  36: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /*  37: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
      /*  38: */  /^(?:\S+)/,
      /*  39: */  /^(?:(\r\n|\n|\r)([^\S\n\r])+(?=\S))/,
      /*  40: */  /^(?:(\r\n|\n|\r))/,
      /*  41: */  /^(?:([^\S\n\r])+)/,
      /*  42: */  new XRegExp('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
      /*  43: */  /^(?:(\r\n|\n|\r)+)/,
      /*  44: */  /^(?:([^\S\n\r])+)/,
      /*  45: */  new XRegExp('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
      /*  46: */  new XRegExp('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
      /*  47: */  /^(?:(\r\n|\n|\r)+)/,
      /*  48: */  /^(?:([^\s!"$%'-,.\/:-?\[-\^{-}])+)/,
      /*  49: */  /^(?:(\r\n|\n|\r)+)/,
      /*  50: */  /^(?:\s+)/,
      /*  51: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /*  52: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /*  53: */  /^(?:\[)/,
      /*  54: */  /^(?:\|)/,
      /*  55: */  /^(?:\(\?:)/,
      /*  56: */  /^(?:\(\?=)/,
      /*  57: */  /^(?:\(\?!)/,
      /*  58: */  /^(?:\()/,
      /*  59: */  /^(?:\))/,
      /*  60: */  /^(?:\+)/,
      /*  61: */  /^(?:\*)/,
      /*  62: */  /^(?:\?)/,
      /*  63: */  /^(?:\^)/,
      /*  64: */  /^(?:,)/,
      /*  65: */  /^(?:<<EOF>>)/,
      /*  66: */  /^(?:<)/,
      /*  67: */  /^(?:\/!)/,
      /*  68: */  /^(?:\/)/,
      /*  69: */  /^(?:\\([0-7]{1,3}|[$(-+.\/?BDSW\[-\^bdfnr-tvw{-}]|c[A-Z]|x[\dA-F]{2}|u[\dA-Fa-f]{4}))/,
      /*  70: */  /^(?:\\.)/,
      /*  71: */  /^(?:\$)/,
      /*  72: */  /^(?:\.)/,
      /*  73: */  /^(?:%option[s]?)/,
      /*  74: */  /^(?:%s\b)/,
      /*  75: */  /^(?:%x\b)/,
      /*  76: */  /^(?:%code\b)/,
      /*  77: */  /^(?:%import\b)/,
      /*  78: */  /^(?:%include\b)/,
      /*  79: */  /^(?:%include\b)/,
      /*  80: */  new XRegExp(
        '^(?:%([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?)([^\\n\\r]*))',
        ''
      ),
      /*  81: */  /^(?:%%)/,
      /*  82: */  /^(?:\{\d+(,\s*\d+|,)?\})/,
      /*  83: */  new XRegExp('^(?:\\{([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\})', ''),
      /*  84: */  new XRegExp('^(?:\\{([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\})', ''),
      /*  85: */  /^(?:\{)/,
      /*  86: */  /^(?:\})/,
      /*  87: */  /^(?:(?:\\\\|\\\]|[^\]{])+)/,
      /*  88: */  /^(?:\{)/,
      /*  89: */  /^(?:\])/,
      /*  90: */  /^(?:[^\r\n]*(\r|\n)+)/,
      /*  91: */  /^(?:[^\r\n]+)/,
      /*  92: */  /^(?:(\r\n|\n|\r))/,
      /*  93: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /*  94: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /*  95: */  /^(?:([^\S\n\r])+)/,
      /*  96: */  /^(?:\S+)/,
      /*  97: */  /^(?:")/,
      /*  98: */  /^(?:')/,
      /*  99: */  /^(?:`)/,
      /* 100: */  /^(?:")/,
      /* 101: */  /^(?:')/,
      /* 102: */  /^(?:`)/,
      /* 103: */  /^(?:")/,
      /* 104: */  /^(?:')/,
      /* 105: */  /^(?:`)/,
      /* 106: */  /^(?:.)/,
      /* 107: */  /^(?:.)/,
      /* 108: */  /^(?:$)/
    ],

    conditions: {
      'rules': {
        rules: [
          0,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          80,
          81,
          82,
          83,
          85,
          86,
          103,
          104,
          105,
          106,
          107,
          108
        ],

        inclusive: true
      },

      'macro': {
        rules: [
          0,
          24,
          25,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          81,
          82,
          83,
          85,
          86,
          103,
          104,
          105,
          106,
          107,
          108
        ],

        inclusive: true
      },

      'named_chunk': {
        rules: [
          0,
          45,
          47,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          81,
          82,
          83,
          85,
          86,
          103,
          104,
          105,
          107,
          108
        ],

        inclusive: true
      },

      'code': {
        rules: [79, 80, 90, 91, 103, 104, 105, 107, 108],
        inclusive: false
      },

      'start_condition': {
        rules: [24, 25, 42, 43, 44, 103, 104, 105, 107, 108],
        inclusive: false
      },

      'options': {
        rules: [
          24,
          25,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          84,
          100,
          101,
          102,
          103,
          104,
          105,
          107,
          108
        ],

        inclusive: false
      },

      'conditions': {
        rules: [20, 21, 22, 23, 103, 104, 105, 107, 108],
        inclusive: false
      },

      'action': {
        rules: [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          97,
          98,
          99,
          103,
          104,
          105,
          107,
          108
        ],

        inclusive: false
      },

      'path': {
        rules: [24, 25, 92, 93, 94, 95, 96, 103, 104, 105, 107, 108],
        inclusive: false
      },

      'set': {
        rules: [84, 87, 88, 89, 103, 104, 105, 107, 108],
        inclusive: false
      },

      'INITIAL': {
        rules: [
          0,
          24,
          25,
          46,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          80,
          81,
          82,
          83,
          85,
          86,
          103,
          104,
          105,
          107,
          108
        ],

        inclusive: true
      }
    }
  };

  var rmCommonWS = helpers.rmCommonWS;
  var dquote = helpers.dquote;

  function unescQuote(str) {
    str = '' + str;
    var a = str.split('\\\\');

    a = a.map(function(s) {
      return s.replace(/\\'/g, '\'').replace(/\\"/g, '"');
    });

    str = a.join('\\\\');
    return str;
  }

  lexer.warn = function l_warn() {
    if (this.yy && this.yy.parser && typeof this.yy.parser.warn === 'function') {
      return this.yy.parser.warn.apply(this, arguments);
    } else {
      console.warn.apply(console, arguments);
    }
  };

  lexer.log = function l_log() {
    if (this.yy && this.yy.parser && typeof this.yy.parser.log === 'function') {
      return this.yy.parser.log.apply(this, arguments);
    } else {
      console.log.apply(console, arguments);
    }
  };

  return lexer;
}();
parser$1.lexer = lexer;

var rmCommonWS$4 = helpers.rmCommonWS;
var checkActionBlock$1 = helpers.checkActionBlock;


function encodeRE(s) {
    return s.replace(/([.*+?^${}()|\[\]\/\\])/g, '\\$1').replace(/\\\\u([a-fA-F0-9]{4})/g, '\\u$1');
}

function prepareString(s) {
    // unescape slashes
    s = s.replace(/\\\\/g, "\\");
    s = encodeRE(s);
    return s;
}

// convert string value to number or boolean value, when possible
// (and when this is more or less obviously the intent)
// otherwise produce the string itself as value.
function parseValue(v) {
    if (v === 'false') {
        return false;
    }
    if (v === 'true') {
        return true;
    }
    // http://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number
    // Note that the `v` check ensures that we do not convert `undefined`, `null` and `''` (empty string!)
    if (v && !isNaN(v)) {
        var rv = +v;
        if (isFinite(rv)) {
            return rv;
        }
    }
    return v;
}


parser$1.warn = function p_warn() {
    console.warn.apply(console, arguments);
};

parser$1.log = function p_log() {
    console.log.apply(console, arguments);
};

parser$1.pre_parse = function p_lex() {
    if (parser$1.yydebug) parser$1.log('pre_parse:', arguments);
};

parser$1.yy.pre_parse = function p_lex() {
    if (parser$1.yydebug) parser$1.log('pre_parse YY:', arguments);
};

parser$1.yy.post_lex = function p_lex() {
    if (parser$1.yydebug) parser$1.log('post_lex:', arguments);
};


function Parser$1() {
    this.yy = {};
}
Parser$1.prototype = parser$1;
parser$1.Parser = Parser$1;

function yyparse() {
    return parser$1.parse.apply(parser$1, arguments);
}



var jisonlex = {
    parser: parser$1,
    Parser: Parser$1,
    parse: yyparse,
    
};

//
// Helper library for set definitions
//
// MIT Licensed
//
//
// This code is intended to help parse regex set expressions and mix them
// together, i.e. to answer questions like this:
// 
// what is the resulting regex set expression when we mix the regex set
// `[a-z]` with the regex set `[^\s]` where with 'mix' we mean that any
// input which matches either input regex should match the resulting
// regex set. (a.k.a. Full Outer Join, see also http://www.diffen.com/difference/Inner_Join_vs_Outer_Join)
// 

const XREGEXP_UNICODE_ESCAPE_RE$1 = /^\{[A-Za-z0-9 \-\._]+\}/;              // Matches the XRegExp Unicode escape braced part, e.g. `{Number}`
const CHR_RE$1 = /^(?:[^\\]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})/;
const SET_PART_RE$1 = /^(?:[^\\\]]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})+/;
const NOTHING_SPECIAL_RE$1 = /^(?:[^\\\[\]\(\)\|^\{\}]|\\[^cxu0-9]|\\[0-9]{1,3}|\\c[A-Z]|\\x[0-9a-fA-F]{2}|\\u[0-9a-fA-F]{4}|\\u\{[0-9a-fA-F]+\})+/;
const SET_IS_SINGLE_PCODE_RE = /^\\[dDwWsS]$|^\\p\{[A-Za-z0-9 \-\._]+\}$/;

const UNICODE_BASE_PLANE_MAX_CP$1 = 65535;

// The expanded regex sets which are equivalent to the given `\\{c}` escapes:
//
// `/\s/`:
const WHITESPACE_SETSTR$1 = ' \f\n\r\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff';     
// `/\d/`:
const DIGIT_SETSTR$1 = '0-9';
// `/\w/`:
const WORDCHAR_SETSTR$1 = 'A-Za-z0-9_';





// Helper for `bitarray2set()`: convert character code to a representation string suitable for use in a regex
function i2c(i) {
    var c, x;

    switch (i) {
    case 10:
        return '\\n';

    case 13:
        return '\\r';

    case 9:
        return '\\t';

    case 8:
        return '\\b';

    case 12:
        return '\\f';

    case 11:
        return '\\v';

    case 45:        // ASCII/Unicode for '-' dash
        return '\\-';

    case 91:        // '['
        return '\\[';

    case 92:        // '\\'
        return '\\\\';

    case 93:        // ']'
        return '\\]';

    case 94:        // ']'
        return '\\^';
    }
    if (i < 32
            || i > 0xFFF0 /* Unicode Specials, also in UTF16 */
            || (i >= 0xD800 && i <= 0xDFFF) /* Unicode Supplementary Planes; we're TOAST in JavaScript as we're NOT UTF-16 but UCS-2! */
            || String.fromCharCode(i).match(/[\u2028\u2029]/) /* Code compilation via `new Function()` does not like to see these, or rather: treats them as just another form of CRLF, which breaks your generated regex code! */
        ) {
        // Detail about a detail:
        // U+2028 and U+2029 are part of the `\s` regex escape code (`\s` and `[\s]` match either of these) and when placed in a JavaScript
        // source file verbatim (without escaping it as a `\uNNNN` item) then JavaScript will interpret it as such and consequently report
        // a b0rked generated parser, as the generated code would include this regex right here.
        // Hence we MUST escape these buggers everywhere we go...
        x = i.toString(16);
        if (x.length >= 1 && i <= 0xFFFF) {
          c = '0000' + x;
          return '\\u' + c.substr(c.length - 4);
        } else {
          return '\\u{' + x + '}';
        }
    }
    return String.fromCharCode(i);
}


// Helper collection for `bitarray2set()`: we have expanded all these cached `\\p{NAME}` regex sets when creating
// this bitarray and now we should look at these expansions again to see if `bitarray2set()` can produce a
// `\\p{NAME}` shorthand to represent [part of] the bitarray:
var Pcodes_bitarray_cache = {};
var Pcodes_bitarray_cache_test_order = [];

// Helper collection for `bitarray2set()` for minifying special cases of result sets which can be represented by 
// a single regex 'escape', e.g. `\d` for digits 0-9.
var EscCode_bitarray_output_refs;

// now initialize the EscCodes_... table above:
init_EscCode_lookup_table();

function init_EscCode_lookup_table() {
    var s, bitarr, set2esc = {}, esc2bitarr = {};

    // patch global lookup tables for the time being, while we calculate their *real* content in this function:
    EscCode_bitarray_output_refs = {
        esc2bitarr: {},
        set2esc: {}
    };
    Pcodes_bitarray_cache_test_order = [];

    // `/\S':
    bitarr = [];
    set2bitarray(bitarr, '^' + WHITESPACE_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['S'] = bitarr;
    set2esc[s] = 'S';
    // set2esc['^' + s] = 's';
    Pcodes_bitarray_cache['\\S'] = bitarr;

    // `/\s':
    bitarr = [];
    set2bitarray(bitarr, WHITESPACE_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['s'] = bitarr;
    set2esc[s] = 's';
    // set2esc['^' + s] = 'S';
    Pcodes_bitarray_cache['\\s'] = bitarr;

    // `/\D':
    bitarr = [];
    set2bitarray(bitarr, '^' + DIGIT_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['D'] = bitarr;
    set2esc[s] = 'D';
    // set2esc['^' + s] = 'd';
    Pcodes_bitarray_cache['\\D'] = bitarr;

    // `/\d':
    bitarr = [];
    set2bitarray(bitarr, DIGIT_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['d'] = bitarr;
    set2esc[s] = 'd';
    // set2esc['^' + s] = 'D';
    Pcodes_bitarray_cache['\\d'] = bitarr;

    // `/\W':
    bitarr = [];
    set2bitarray(bitarr, '^' + WORDCHAR_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['W'] = bitarr;
    set2esc[s] = 'W';
    // set2esc['^' + s] = 'w';
    Pcodes_bitarray_cache['\\W'] = bitarr;

    // `/\w':
    bitarr = [];
    set2bitarray(bitarr, WORDCHAR_SETSTR$1);
    s = bitarray2set(bitarr);
    esc2bitarr['w'] = bitarr;
    set2esc[s] = 'w';
    // set2esc['^' + s] = 'W';
    Pcodes_bitarray_cache['\\w'] = bitarr;

    EscCode_bitarray_output_refs = {
        esc2bitarr: esc2bitarr,
        set2esc: set2esc
    };

    updatePcodesBitarrayCacheTestOrder();
} 

function updatePcodesBitarrayCacheTestOrder(opts) {
    var t = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);
    var l = {};
    var user_has_xregexp = opts && opts.options && opts.options.xregexp;
    var i, j, k, ba;

    // mark every character with which regex pcodes they are part of:
    for (k in Pcodes_bitarray_cache) {
        ba = Pcodes_bitarray_cache[k];

        if (!user_has_xregexp && k.indexOf('\\p{') >= 0) {
            continue;
        }

        var cnt = 0;
        for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
            if (ba[i]) {
                cnt++;
                if (!t[i]) {
                    t[i] = [k];
                } else {
                    t[i].push(k);
                }
            }
        }
        l[k] = cnt;
    }

    // now dig out the unique ones: only need one per pcode.
    // 
    // We ASSUME every \\p{NAME} 'pcode' has at least ONE character
    // in it that is ONLY matched by that particular pcode. 
    // If this assumption fails, nothing is lost, but our 'regex set
    // optimized representation' will be sub-optimal as than this pcode
    // won't be tested during optimization. 
    // 
    // Now that would be a pity, so the assumption better holds...
    // Turns out the assumption doesn't hold already for /\S/ + /\D/
    // as the second one (\D) is a pure subset of \S. So we have to
    // look for markers which match multiple escapes/pcodes for those
    // ones where a unique item isn't available...
    var lut = [];
    var done = {};
    var keys = Object.keys(Pcodes_bitarray_cache);

    for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
        k = t[i][0];
        if (t[i].length === 1 && !done[k]) {
            assert(l[k] > 0);
            lut.push([i, k]);
            done[k] = true;
        }
    }

    for (j = 0; keys[j]; j++) {
        k = keys[j];

        if (!user_has_xregexp && k.indexOf('\\p{') >= 0) {
            continue;
        }
        
        if (!done[k]) {
            assert(l[k] > 0);
            // find a minimum span character to mark this one:
            var w = Infinity;
            var rv;
            ba = Pcodes_bitarray_cache[k];
            for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
                if (ba[i]) {
                    var tl = t[i].length;
                    if (tl > 1 && tl < w) {
                        assert(l[k] > 0);
                        rv = [i, k];
                        w = tl;
                    }
                }
            }
            if (rv) {
                done[k] = true;
                lut.push(rv);
            }
        }
    }

    // order from large set to small set so that small sets don't gobble
    // characters also represented by overlapping larger set pcodes.
    // 
    // Again we assume something: that finding the large regex pcode sets
    // before the smaller, more specialized ones, will produce a more
    // optimal minification of the regex set expression. 
    // 
    // This is a guestimate/heuristic only!
    lut.sort(function (a, b) {
        var k1 = a[1];
        var k2 = b[1];
        var ld = l[k2] - l[k1];
        if (ld) {
            return ld;
        }
        // and for same-size sets, order from high to low unique identifier.
        return b[0] - a[0];
    });

    Pcodes_bitarray_cache_test_order = lut;
}






// 'Join' a regex set `[...]` into a Unicode range spanning logic array, flagging every character in the given set.
function set2bitarray(bitarr, s, opts) {
    var orig = s;
    var set_is_inverted = false;
    var bitarr_orig;

    function mark(d1, d2) {
        if (d2 == null) d2 = d1;
        for (var i = d1; i <= d2; i++) {
            bitarr[i] = true;
        }
    }

    function add2bitarray(dst, src) {
        for (var i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
            if (src[i]) {
                dst[i] = true;
            }
        }
    }

    function eval_escaped_code(s) {
        var c;
        // decode escaped code? If none, just take the character as-is
        if (s.indexOf('\\') === 0) {
            var l = s.substr(0, 2);
            switch (l) {
            case '\\c':
                c = s.charCodeAt(2) - 'A'.charCodeAt(0) + 1;
                return String.fromCharCode(c);

            case '\\x':
                s = s.substr(2);
                c = parseInt(s, 16);
                return String.fromCharCode(c);

            case '\\u':
                s = s.substr(2);
                if (s[0] === '{') {
                    s = s.substr(1, s.length - 2);
                }
                c = parseInt(s, 16);
                if (c >= 0x10000) {
                  return new Error('We do NOT support Extended Plane Unicode Codepoints (i.e. CodePoints beyond U:FFFF) in regex set expressions, e.g. \\u{' + s + '}');
                }
                return String.fromCharCode(c);

            case '\\0':
            case '\\1':
            case '\\2':
            case '\\3':
            case '\\4':
            case '\\5':
            case '\\6':
            case '\\7':
                s = s.substr(1);
                c = parseInt(s, 8);
                return String.fromCharCode(c);

            case '\\r':
                return '\r';

            case '\\n':
                return '\n';

            case '\\v':
                return '\v';

            case '\\f':
                return '\f';

            case '\\t':
                return '\t';

            case '\\b':
                return '\b';

            default:
                // just the character itself:
                return s.substr(1);
            }
        } else {
            return s;
        }
    }

    if (s && s.length) {
        var c1, c2;

        // inverted set?
        if (s[0] === '^') {
            set_is_inverted = true;
            s = s.substr(1);
            bitarr_orig = bitarr;
            bitarr = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);
        }

        // BITARR collects flags for characters set. Inversion means the complement set of character is st instead.
        // This results in an OR operations when sets are joined/chained.

        while (s.length) {
            c1 = s.match(CHR_RE$1);
            if (!c1) {
                // hit an illegal escape sequence? cope anyway!
                c1 = s[0];
            } else {
                c1 = c1[0];
                // Quick hack for XRegExp escapes inside a regex `[...]` set definition: we *could* try to keep those
                // intact but it's easier to unfold them here; this is not nice for when the grammar specifies explicit
                // XRegExp support, but alas, we'll get there when we get there... ;-)
                switch (c1) {
                case '\\p':
                    s = s.substr(c1.length);
                    c2 = s.match(XREGEXP_UNICODE_ESCAPE_RE$1);
                    if (c2) {
                        c2 = c2[0];
                        s = s.substr(c2.length);
                        // do we have this one cached already?
                        var pex = c1 + c2;
                        var ba4p = Pcodes_bitarray_cache[pex];
                        if (!ba4p) {
                            // expand escape:
                            var xr = new XRegExp('[' + pex + ']');           // TODO: case-insensitive grammar???
                            // rewrite to a standard `[...]` regex set: XRegExp will do this for us via `XRegExp.toString()`:
                            var xs = '' + xr;
                            // remove the wrapping `/.../` to get at the (possibly *combined* series of) `[...]` sets inside:
                            xs = xs.substr(1, xs.length - 2);

                            ba4p = reduceRegexToSetBitArray(xs, pex, opts);

                            Pcodes_bitarray_cache[pex] = ba4p;
                            updatePcodesBitarrayCacheTestOrder(opts);
                        }
                        // merge bitarrays:
                        add2bitarray(bitarr, ba4p);
                        continue;
                    }
                    break;

                case '\\S':
                case '\\s':
                case '\\W':
                case '\\w':
                case '\\d':
                case '\\D':
                    // these can't participate in a range, but need to be treated special:
                    s = s.substr(c1.length);
                    // check for \S, \s, \D, \d, \W, \w and expand them:
                    var ba4e = EscCode_bitarray_output_refs.esc2bitarr[c1[1]];
                    assert(ba4e);
                    add2bitarray(bitarr, ba4e);
                    continue;

                case '\\b':
                    // matches a backspace: https://developer.mozilla.org/en/docs/Web/JavaScript/Guide/Regular_Expressions#special-backspace
                    c1 = '\u0008';
                    break;
                }
            }
            var v1 = eval_escaped_code(c1);
            // propagate deferred exceptions = error reports.
            if (v1 instanceof Error) {
                return v1;
            }
            v1 = v1.charCodeAt(0);
            s = s.substr(c1.length);

            if (s[0] === '-' && s.length >= 2) {
                // we can expect a range like 'a-z':
                s = s.substr(1);
                c2 = s.match(CHR_RE$1);
                if (!c2) {
                    // hit an illegal escape sequence? cope anyway!
                    c2 = s[0];
                } else {
                    c2 = c2[0];
                }
                var v2 = eval_escaped_code(c2);
                // propagate deferred exceptions = error reports.
                if (v2 instanceof Error) {
                    return v1;
                }
                v2 = v2.charCodeAt(0);
                s = s.substr(c2.length);

                // legal ranges go UP, not /DOWN!
                if (v1 <= v2) {
                    mark(v1, v2);
                } else {
                    console.warn('INVALID CHARACTER RANGE found in regex: ', { re: orig, start: c1, start_n: v1, end: c2, end_n: v2 });
                    mark(v1);
                    mark('-'.charCodeAt(0));
                    mark(v2);
                }
                continue;
            }
            mark(v1);
        }

        // When we have marked all slots, '^' NEGATES the set, hence we flip all slots.
        // 
        // Since a regex like `[^]` should match everything(?really?), we don't need to check if the MARK
        // phase actually marked anything at all: the `^` negation will correctly flip=mark the entire
        // range then.
        if (set_is_inverted) {
            for (var i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
                if (!bitarr[i]) {
                    bitarr_orig[i] = true;
                }
            }
        }
    }
    return false;
}


// convert a simple bitarray back into a regex set `[...]` content:
function bitarray2set(l, output_inverted_variant, output_minimized) {
    // construct the inverse(?) set from the mark-set:
    //
    // Before we do that, we inject a sentinel so that our inner loops
    // below can be simple and fast:
    l[UNICODE_BASE_PLANE_MAX_CP$1 + 1] = 1;
    // now reconstruct the regex set:
    var rv = [];
    var i, j, cnt, lut, tn, tspec, match, pcode, ba4pcode, l2;
    var bitarr_is_cloned = false;
    var l_orig = l;

    if (output_inverted_variant) {
        // generate the inverted set, hence all unmarked slots are part of the output range:
        cnt = 0;
        for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
            if (!l[i]) {
                cnt++;
            }
        }
        if (cnt === UNICODE_BASE_PLANE_MAX_CP$1 + 1) {
            // When there's nothing in the output we output a special 'match-nothing' regex: `[^\S\s]`.
            // BUT... since we output the INVERTED set, we output the match-all set instead:
            return '\\S\\s';
        }
        else if (cnt === 0) {
            // When we find the entire Unicode range is in the output match set, we replace this with
            // a shorthand regex: `[\S\s]`
            // BUT... since we output the INVERTED set, we output the match-nothing set instead:
            return '^\\S\\s';
        }

        // Now see if we can replace several bits by an escape / pcode:
        if (output_minimized) {
            lut = Pcodes_bitarray_cache_test_order;
            for (tn = 0; lut[tn]; tn++) {
                tspec = lut[tn];
                // check if the uniquely identifying char is in the inverted set:
                if (!l[tspec[0]]) {
                    // check if the pcode is covered by the inverted set:
                    pcode = tspec[1];
                    ba4pcode = Pcodes_bitarray_cache[pcode];
                    match = 0;
                    for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                        if (ba4pcode[j]) {
                            if (!l[j]) {
                                // match in current inverted bitset, i.e. there's at
                                // least one 'new' bit covered by this pcode/escape:
                                match++;
                            } else if (l_orig[j]) {
                                // mismatch!
                                match = false;
                                break;
                            }
                        }
                    }

                    // We're only interested in matches which actually cover some 
                    // yet uncovered bits: `match !== 0 && match !== false`.
                    // 
                    // Apply the heuristic that the pcode/escape is only going to be used
                    // when it covers *more* characters than its own identifier's length:
                    if (match && match > pcode.length) {
                        rv.push(pcode);

                        // and nuke the bits in the array which match the given pcode:
                        // make sure these edits are visible outside this function as
                        // `l` is an INPUT parameter (~ not modified)!
                        if (!bitarr_is_cloned) {
                            l2 = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);
                            for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                                l2[j] = l[j] || ba4pcode[j];    // `!(!l[j] && !ba4pcode[j])`
                            }
                            // recreate sentinel
                            l2[UNICODE_BASE_PLANE_MAX_CP$1 + 1] = 1;
                            l = l2;
                            bitarr_is_cloned = true;
                        } else {
                            for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                                l[j] = l[j] || ba4pcode[j];
                            }
                        }
                    }
                }
            }
        }
        
        i = 0;
        while (i <= UNICODE_BASE_PLANE_MAX_CP$1) {
            // find first character not in original set:
            while (l[i]) {
                i++;
            }
            if (i >= UNICODE_BASE_PLANE_MAX_CP$1 + 1) {
                break;
            }
            // find next character not in original set:
            for (j = i + 1; !l[j]; j++) {} /* empty loop */
            // generate subset:
            rv.push(i2c(i));
            if (j - 1 > i) {
                rv.push((j - 2 > i ? '-' : '') + i2c(j - 1));
            }
            i = j;
        }
    } else {
        // generate the non-inverted set, hence all logic checks are inverted here...
        cnt = 0;
        for (i = 0; i <= UNICODE_BASE_PLANE_MAX_CP$1; i++) {
            if (l[i]) {
                cnt++;
            }
        }
        if (cnt === UNICODE_BASE_PLANE_MAX_CP$1 + 1) {
            // When we find the entire Unicode range is in the output match set, we replace this with
            // a shorthand regex: `[\S\s]`
            return '\\S\\s';
        }
        else if (cnt === 0) {
            // When there's nothing in the output we output a special 'match-nothing' regex: `[^\S\s]`.
            return '^\\S\\s';
        }

        // Now see if we can replace several bits by an escape / pcode:
        if (output_minimized) {
            lut = Pcodes_bitarray_cache_test_order;
            for (tn = 0; lut[tn]; tn++) {
                tspec = lut[tn];
                // check if the uniquely identifying char is in the set:
                if (l[tspec[0]]) {
                    // check if the pcode is covered by the set:
                    pcode = tspec[1];
                    ba4pcode = Pcodes_bitarray_cache[pcode];
                    match = 0;
                    for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                        if (ba4pcode[j]) {
                            if (l[j]) {
                                // match in current bitset, i.e. there's at
                                // least one 'new' bit covered by this pcode/escape:
                                match++;
                            } else if (!l_orig[j]) {
                                // mismatch!
                                match = false;
                                break;
                            }
                        }
                    }

                    // We're only interested in matches which actually cover some 
                    // yet uncovered bits: `match !== 0 && match !== false`.
                    // 
                    // Apply the heuristic that the pcode/escape is only going to be used
                    // when it covers *more* characters than its own identifier's length:
                    if (match && match > pcode.length) {
                        rv.push(pcode);

                        // and nuke the bits in the array which match the given pcode:
                        // make sure these edits are visible outside this function as
                        // `l` is an INPUT parameter (~ not modified)!
                        if (!bitarr_is_cloned) {
                            l2 = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);
                            for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                                l2[j] = l[j] && !ba4pcode[j];
                            }
                            // recreate sentinel
                            l2[UNICODE_BASE_PLANE_MAX_CP$1 + 1] = 1;
                            l = l2;
                            bitarr_is_cloned = true;
                        } else {
                            for (j = 0; j <= UNICODE_BASE_PLANE_MAX_CP$1; j++) {
                                l[j] = l[j] && !ba4pcode[j];
                            }
                        }
                    }
                }
            }
        }

        i = 0;
        while (i <= UNICODE_BASE_PLANE_MAX_CP$1) {
            // find first character not in original set:
            while (!l[i]) {
                i++;
            }
            if (i >= UNICODE_BASE_PLANE_MAX_CP$1 + 1) {
                break;
            }
            // find next character not in original set:
            for (j = i + 1; l[j]; j++) {} /* empty loop */
            if (j > UNICODE_BASE_PLANE_MAX_CP$1 + 1) {
                j = UNICODE_BASE_PLANE_MAX_CP$1 + 1;
            }
            // generate subset:
            rv.push(i2c(i));
            if (j - 1 > i) {
                rv.push((j - 2 > i ? '-' : '') + i2c(j - 1));
            }
            i = j;
        }
    }

    assert(rv.length);
    var s = rv.join('');
    assert(s);

    // Check if the set is better represented by one of the regex escapes:
    var esc4s = EscCode_bitarray_output_refs.set2esc[s];
    if (esc4s) {
        // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
        return '\\' + esc4s;
    }
    return s;
}





// Pretty brutal conversion of 'regex' `s` back to raw regex set content: strip outer [...] when they're there;
// ditto for inner combos of sets, i.e. `]|[` as in `[0-9]|[a-z]`.
function reduceRegexToSetBitArray(s, name, opts) {
    var orig = s;

    // propagate deferred exceptions = error reports.
    if (s instanceof Error) {
        return s;
    }

    var l = new Array(UNICODE_BASE_PLANE_MAX_CP$1 + 1);
    var internal_state = 0;
    var derr;

    while (s.length) {
        var c1 = s.match(CHR_RE$1);
        if (!c1) {
            // cope with illegal escape sequences too!
            return new Error('illegal escape sequence at start of regex part: "' + s + '" of regex "' + orig + '"');
        } else {
            c1 = c1[0];
        }
        s = s.substr(c1.length);

        switch (c1) {
        case '[':
            // this is starting a set within the regex: scan until end of set!
            var set_content = [];
            while (s.length) {
                var inner = s.match(SET_PART_RE$1);
                if (!inner) {
                    inner = s.match(CHR_RE$1);
                    if (!inner) {
                        // cope with illegal escape sequences too!
                        return new Error('illegal escape sequence at start of regex part: ' + s + '" of regex "' + orig + '"');
                    } else {
                        inner = inner[0];
                    }
                    if (inner === ']') break;
                } else {
                    inner = inner[0];
                }
                set_content.push(inner);
                s = s.substr(inner.length);
            }

            // ensure that we hit the terminating ']':
            var c2 = s.match(CHR_RE$1);
            if (!c2) {
                // cope with illegal escape sequences too!
                return new Error('regex set expression is broken in regex: "' + orig + '" --> "' + s + '"');
            } else {
                c2 = c2[0];
            }
            if (c2 !== ']') {
                return new Error('regex set expression is broken in regex: ' + orig);
            }
            s = s.substr(c2.length);

            var se = set_content.join('');
            if (!internal_state) {
                derr = set2bitarray(l, se, opts);
                // propagate deferred exceptions = error reports.
                if (derr instanceof Error) {
                    return derr;
                }

                // a set is to use like a single character in a longer literal phrase, hence input `[abc]word[def]` would thus produce output `[abc]`:
                internal_state = 1;
            }
            break;

        // Strip unescaped pipes to catch constructs like `\\r|\\n` and turn them into
        // something ready for use inside a regex set, e.g. `\\r\\n`.
        //
        // > Of course, we realize that converting more complex piped constructs this way
        // > will produce something you might not expect, e.g. `A|WORD2` which
        // > would end up as the set `[AW]` which is something else than the input
        // > entirely.
        // >
        // > However, we can only depend on the user (grammar writer) to realize this and
        // > prevent this from happening by not creating such oddities in the input grammar.
        case '|':
            // a|b --> [ab]
            internal_state = 0;
            break;

        case '(':
            // (a) --> a
            //
            // TODO - right now we treat this as 'too complex':

            // Strip off some possible outer wrappers which we know how to remove.
            // We don't worry about 'damaging' the regex as any too-complex regex will be caught
            // in the validation check at the end; our 'strippers' here would not damage useful
            // regexes anyway and them damaging the unacceptable ones is fine.
            s = s.replace(/^\((?:\?:)?(.*?)\)$/, '$1');         // (?:...) -> ...  and  (...) -> ...
            s = s.replace(/^\^?(.*?)\$?$/, '$1');               // ^...$ --> ...  (catch these both inside and outside the outer grouping, hence do the ungrouping twice: one before, once after this)
            s = s.replace(/^\((?:\?:)?(.*?)\)$/, '$1');         // (?:...) -> ...  and  (...) -> ...

            return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

        case '.':
        case '*':
        case '+':
        case '?':
            // wildcard
            //
            // TODO - right now we treat this as 'too complex':
            return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

        case '{':                        // range, e.g. `x{1,3}`, or macro?
            // TODO - right now we treat this as 'too complex':
            return new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + orig + ']"]');

        default:
            // literal character or word: take the first character only and ignore the rest, so that
            // the constructed set for `word|noun` would be `[wb]`:
            if (!internal_state) {
                derr = set2bitarray(l, c1, opts);
                // propagate deferred exceptions = error reports.
                if (derr instanceof Error) {
                    return derr;
                }

                internal_state = 2;
            }
            break;
        }
    }

    s = bitarray2set(l);

    // When this result is suitable for use in a set, than we should be able to compile
    // it in a regex; that way we can easily validate whether macro X is fit to be used
    // inside a regex set:
    try {
        var re;
        assert(s);
        assert(!(s instanceof Error));
        re = new XRegExp('[' + s + ']');
        re.test(s[0]);

        // One thing is apparently *not* caught by the RegExp compile action above: `[a[b]c]`
        // so we check for lingering UNESCAPED brackets in here as those cannot be:
        if (/[^\\][\[\]]/.exec(s)) {
            throw new Error('unescaped brackets in set data');
        }
    } catch (ex) {
        // make sure we produce a set range expression which will fail badly when it is used
        // in actual code:
        s = new Error('[macro [' + name + '] is unsuitable for use inside regex set expressions: "[' + s + ']"]: ' + ex.message);
    }

    assert(s);
    // propagate deferred exceptions = error reports.
    if (s instanceof Error) {
        return s;
    }
    return l;
}




// Convert bitarray representing, for example, `'0-9'` to regex string `[0-9]` 
// -- or in this example it can be further optimized to only `\d`!
function produceOptimizedRegex4Set(bitarr) {
    // First try to produce a minimum regex from the bitarray directly:
    var s1 = bitarray2set(bitarr, false, true);

    // and when the regex set turns out to match a single pcode/escape, then
    // use that one as-is:
    if (s1.match(SET_IS_SINGLE_PCODE_RE)) {
        // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
        return s1;
    } else {
        s1 = '[' + s1 + ']';
    }

    // Now try to produce a minimum regex from the *inverted* bitarray via negation:
    // Because we look at a negated bitset, there's no use looking for matches with
    // special cases here.
    var s2 = bitarray2set(bitarr, true, true);

    if (s2[0] === '^') {
        s2 = s2.substr(1);
        if (s2.match(SET_IS_SINGLE_PCODE_RE)) {
            // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
            return s2;
        }
    } else {
        s2 = '^' + s2;
    }
    s2 = '[' + s2 + ']';

    // Then, as some pcode/escapes still happen to deliver a LARGER regex string in the end,
    // we also check against the plain, unadulterated regex set expressions:
    // 
    // First try to produce a minimum regex from the bitarray directly:
    var s3 = bitarray2set(bitarr, false, false);

    // and when the regex set turns out to match a single pcode/escape, then
    // use that one as-is:
    if (s3.match(SET_IS_SINGLE_PCODE_RE)) {
        // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
        return s3;
    } else {
        s3 = '[' + s3 + ']';
    }

    // Now try to produce a minimum regex from the *inverted* bitarray via negation:
    // Because we look at a negated bitset, there's no use looking for matches with
    // special cases here.
    var s4 = bitarray2set(bitarr, true, false);

    if (s4[0] === '^') {
        s4 = s4.substr(1);
        if (s4.match(SET_IS_SINGLE_PCODE_RE)) {
            // When we hit a special case like this, it is always the shortest notation, hence wins on the spot!
            return s4;
        }
    } else {
        s4 = '^' + s4;
    }
    s4 = '[' + s4 + ']';

    if (s2.length < s1.length) {
        s1 = s2;
    }
    if (s3.length < s1.length) {
        s1 = s3;
    }
    if (s4.length < s1.length) {
        s1 = s4;
    }

    return s1;
}






var setmgmt = {
	XREGEXP_UNICODE_ESCAPE_RE: XREGEXP_UNICODE_ESCAPE_RE$1,
	CHR_RE: CHR_RE$1,
	SET_PART_RE: SET_PART_RE$1,
	NOTHING_SPECIAL_RE: NOTHING_SPECIAL_RE$1,
	SET_IS_SINGLE_PCODE_RE,

	UNICODE_BASE_PLANE_MAX_CP: UNICODE_BASE_PLANE_MAX_CP$1,

	WHITESPACE_SETSTR: WHITESPACE_SETSTR$1,
	DIGIT_SETSTR: DIGIT_SETSTR$1,
	WORDCHAR_SETSTR: WORDCHAR_SETSTR$1,

	set2bitarray,
	bitarray2set,
	produceOptimizedRegex4Set,
	reduceRegexToSetBitArray,
};

// Basic Lexer implemented using JavaScript regular expressions
// Zachary Carter <zach@carter.name>
// MIT Licensed

var rmCommonWS$3  = helpers.rmCommonWS;
var mkIdentifier$4 = helpers.mkIdentifier;
var code_exec$2   = helpers.exec;
// import recast from '@gerhobbelt/recast';
// import astUtils from '@gerhobbelt/ast-util';
var version$2 = '0.6.1-214';                              // require('./package.json').version;




const XREGEXP_UNICODE_ESCAPE_RE = setmgmt.XREGEXP_UNICODE_ESCAPE_RE;              // Matches the XRegExp Unicode escape braced part, e.g. `{Number}`
const CHR_RE = setmgmt.CHR_RE;
const SET_PART_RE = setmgmt.SET_PART_RE;
const NOTHING_SPECIAL_RE = setmgmt.NOTHING_SPECIAL_RE;
const UNICODE_BASE_PLANE_MAX_CP = setmgmt.UNICODE_BASE_PLANE_MAX_CP;

// WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
//
// This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
const ID_REGEX_BASE$1 = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';




// see also ./lib/cli.js
/**
@public
@nocollapse
*/
const defaultJisonLexOptions = {
    moduleType: 'commonjs',
    debug: false,
    enableDebugLogs: false,
    json: false,
    main: false,                    // CLI: not:(--main option)
    dumpSourceCodeOnFailure: true,
    throwErrorOnCompileFailure: true,

    moduleName: undefined,
    defaultModuleName: 'lexer',
    file: undefined,
    outfile: undefined,
    inputPath: undefined,
    inputFilename: undefined,
    warn_cb: undefined,             // function(msg) | true (= use Jison.Print) | false (= throw Exception)

    xregexp: false,
    lexerErrorsAreRecoverable: false,
    flex: false,
    backtrack_lexer: false,
    ranges: false,                  // track position range, i.e. start+end indexes in the input string
    trackPosition: true,            // track line+column position in the input string
    caseInsensitive: false,
    showSource: false,
    exportSourceCode: false,
    exportAST: false,
    prettyCfg: true,
    pre_lex: undefined,
    post_lex: undefined,
};


// Merge sets of options.
//
// Convert alternative jison option names to their base option.
//
// The *last* option set which overrides the default wins, where 'override' is
// defined as specifying a not-undefined value which is not equal to the
// default value.
//
// When the FIRST argument is STRING "NODEFAULT", then we MUST NOT mix the 
// default values avialable in Jison.defaultJisonOptions.
//
// Return a fresh set of options.
/** @public */
function mkStdOptions$1(/*...args*/) {
    var h = Object.prototype.hasOwnProperty;

    var opts = {};
    var args = [].concat.apply([], arguments);
    // clone defaults, so we do not modify those constants?
    if (args[0] !== "NODEFAULT") {
        args.unshift(defaultJisonLexOptions);
    } else {
        args.shift();
    }

    for (var i = 0, len = args.length; i < len; i++) {
        var o = args[i];
        if (!o) continue;

        // clone input (while camel-casing the options), so we do not modify those either.
        var o2 = {};

        for (var p in o) {
            if (typeof o[p] !== 'undefined' && h.call(o, p)) {
                o2[mkIdentifier$4(p)] = o[p];
            }
        }

        // now clean them options up:
        if (typeof o2.main !== 'undefined') {
            o2.noMain = !o2.main;
        }

        delete o2.main;

        // special check for `moduleName` to ensure we detect the 'default' moduleName entering from the CLI
        // NOT overriding the moduleName set in the grammar definition file via an `%options` entry:
        if (o2.moduleName === o2.defaultModuleName) {
            delete o2.moduleName;
        }

        // now see if we have an overriding option here:
        for (var p in o2) {
            if (h.call(o2, p)) {
                if (typeof o2[p] !== 'undefined') {
                    opts[p] = o2[p];
                }
            }
        }
    }

    return opts;
}

// set up export/output attributes of the `options` object instance
function prepExportStructures$1(options) {
    // set up the 'option' `exportSourceCode` as a hash object for returning
    // all generated source code chunks to the caller
    var exportSourceCode = options.exportSourceCode;
    if (!exportSourceCode || typeof exportSourceCode !== 'object') {
        exportSourceCode = {
            enabled: !!exportSourceCode
        };
    } else if (typeof exportSourceCode.enabled !== 'boolean') {
        exportSourceCode.enabled = true;
    }
    options.exportSourceCode = exportSourceCode;
} 

// Autodetect if the input lexer spec is in JSON or JISON
// format when the `options.json` flag is `true`.
//
// Produce the JSON lexer spec result when these are JSON formatted already as that
// would save us the trouble of doing this again, anywhere else in the JISON
// compiler/generator.
//
// Otherwise return the *parsed* lexer spec as it has
// been processed through LexParser.
function autodetectAndConvertToJSONformat$1(lexerSpec, options) {
  var chk_l = null;
  var ex1, err;

  if (typeof lexerSpec === 'string') {
    if (options.json) {
      try {
          chk_l = json5.parse(lexerSpec);

          // When JSON5-based parsing of the lexer spec succeeds, this implies the lexer spec is specified in `JSON mode`
          // *OR* there's a JSON/JSON5 format error in the input:
      } catch (e) {
          ex1 = e;
      }
    }
    if (!chk_l) {
      // // WARNING: the lexer may receive options specified in the **grammar spec file**,
      // //          hence we should mix the options to ensure the lexParser always
      // //          receives the full set!
      // //
      // // make sure all options are 'standardized' before we go and mix them together:
      // options = mkStdOptions(grammar.options, options);
      try {
          chk_l = jisonlex.parse(lexerSpec, options);
      } catch (e) {
          if (options.json) {
              err = new Error('Could not parse lexer spec in JSON AUTODETECT mode\nError: ' + ex1.message + ' (' + e.message + ')');
              err.secondary_exception = e;
              err.stack = ex1.stack;
          } else {
              err = new Error('Could not parse lexer spec\nError: ' + e.message);
              err.stack = e.stack;
          }
          throw err;
      }
    }
  } else {
    chk_l = lexerSpec;
  }

  // Save time! Don't reparse the entire lexer spec *again* inside the code generators when that's not necessary:

  return chk_l;
}


// expand macros and convert matchers to RegExp's
function prepareRules(dict, actions, caseHelper, tokens, startConditions, opts) {
    var m, i, k, rule, action, conditions;
    var active_conditions;
    assert(Array.isArray(dict.rules));
    var rules = dict.rules.slice(0);    // shallow copy of the rules array as we MAY modify it in here!        
    var newRules = [];
    var macros = {};
    var regular_rule_count = 0;
    var simple_rule_count = 0;

    // Assure all options are camelCased:
    assert(typeof opts.options['case-insensitive'] === 'undefined');

    if (!tokens) {
        tokens = {};
    }

    if (opts.options.flex && rules.length > 0) {
        rules.push(['.', 'console.log("", yytext); /* `flex` lexing mode: the last resort rule! */']);
    }

    // Depending on the location within the regex we need different expansions of the macros:
    // one expansion for when a macro is *inside* a `[...]` and another expansion when a macro
    // is anywhere else in a regex:
    if (dict.macros) {
        macros = prepareMacros(dict.macros, opts);
    }

    function tokenNumberReplacement(str, token) {
        return 'return ' + (tokens[token] || '\'' + token.replace(/'/g, '\\\'') + '\'');
    }

    // Make sure a comment does not contain any embedded '*/' end-of-comment marker
    // as that would break the generated code
    function postprocessComment(str) {
        if (Array.isArray(str)) {
            str = str.join(' ');
        }
        str = str.replace(/\*\//g, '*\\/');         // destroy any inner `*/` comment terminator sequence.
        return str;
    }

    var routingCode = ['switch(yyrulenumber) {'];

    for (i = 0; i < rules.length; i++) {
        rule = rules[i].slice(0);           // shallow copy: do not modify input rules
        m = rule[0];

        active_conditions = [];
        if (!Array.isArray(m)) {
            // implicit add to all inclusive start conditions
            for (k in startConditions) {
                if (startConditions[k].inclusive) {
                    active_conditions.push(k);
                    startConditions[k].rules.push(i);
                }
            }
        } else if (m[0] === '*') {
            // Add to ALL start conditions
            active_conditions.push('*');
            for (k in startConditions) {
                startConditions[k].rules.push(i);
            }
            rule.shift();
            m = rule[0];
        } else {
            // Add to explicit start conditions
            conditions = rule.shift();
            m = rule[0];
            for (k = 0; k < conditions.length; k++) {
                if (!startConditions.hasOwnProperty(conditions[k])) {
                    startConditions[conditions[k]] = {
                        rules: [],
                        inclusive: false
                    };
                    console.warn('Lexer Warning:', '"' + conditions[k] + '" start condition should be defined as %s or %x; assuming %x now.');
                }
                active_conditions.push(conditions[k]);
                startConditions[conditions[k]].rules.push(i);
            }
        }

        if (typeof m === 'string') {
            m = expandMacros(m, macros, opts);
            m = new XRegExp('^(?:' + m + ')', opts.options.caseInsensitive ? 'i' : '');
        }
        newRules.push(m);
        action = rule[1];
        if (typeof action === 'function') {
            // Also cope with Arrow Functions (and inline those as well?).
            // See also https://github.com/zaach/jison-lex/issues/23
            action = String(action);
            if (action.match(/^\s*function\s*\(\)\s*\{/)) {
                action = action.replace(/^\s*function\s*\(\)\s*\{/, '').replace(/\}\s*$/, '');
            } else if (action.match(/^\s*\(\)\s*=>[\s\r\n]*[^\s\r\n\{]/)) {
                // () => 'TOKEN'    --> return 'TOKEN' 
                action = action.replace(/^\s*\(\)\s*=>/, 'return ');
            } else if (action.match(/^\s*\(\)\s*=>[\s\r\n]*\{/)) {
                // () => { statements }     --> statements   (ergo: 'inline' the given function) 
                action = action.replace(/^\s*\(\)\s*=>[\s\r\n]*\{/, '').replace(/\}\s*$/, '');
            }
        }
        action = action.replace(/return\s*'((?:\\'|[^']+)+)'/g, tokenNumberReplacement);
        action = action.replace(/return\s*"((?:\\"|[^"]+)+)"/g, tokenNumberReplacement);

        var code = ['\n/*! Conditions::'];
        code.push(postprocessComment(active_conditions));
        code.push('*/', '\n/*! Rule::      ');
        code.push(postprocessComment(rule[0]));
        code.push('*/', '\n');

        // When the action is *only* a simple `return TOKEN` statement, then add it to the caseHelpers;
        // otherwise add the additional `break;` at the end.
        //
        // Note: we do NOT analyze the action block any more to see if the *last* line is a simple
        // `return NNN;` statement as there are too many shoddy idioms, e.g.
        //
        // ```
        // %{ if (cond)
        //      return TOKEN;
        // %}
        // ```
        //
        // which would then cause havoc when our action code analysis (using regexes or otherwise) was 'too simple'
        // to catch these culprits; hence we resort and stick with the most fundamental approach here:
        // always append `break;` even when it would be obvious to a human that such would be 'unreachable code'.
        var match_nr = /^return[\s\r\n]+((?:'(?:\\'|[^']+)+')|(?:"(?:\\"|[^"]+)+")|\d+)[\s\r\n]*;?$/.exec(action.trim());
        if (match_nr) {
            simple_rule_count++;
            caseHelper.push([].concat(code, i, ':', match_nr[1]).join(' ').replace(/[\n]/g, '\n  '));
        } else {
            regular_rule_count++;
            routingCode.push([].concat('case', i, ':', code, action, '\nbreak;').join(' '));
        }
    }
    if (simple_rule_count) {
        routingCode.push('default:');
        routingCode.push('  return this.simpleCaseActionClusters[yyrulenumber];');
    }
    routingCode.push('}');

    // only inject the big switch/case chunk when there's any `switch` or `default` branch to switch to:
    if (simple_rule_count + regular_rule_count > 0) {
        actions.push.apply(actions, routingCode);
    } else {
        actions.push('/* no rules ==> no rule SWITCH! */');
    }

    return {
        rules: newRules,
        macros: macros,

        regular_rule_count: regular_rule_count,
        simple_rule_count: simple_rule_count,
    };
}







// expand all macros (with maybe one exception) in the given regex: the macros may exist inside `[...]` regex sets or
// elsewhere, which requires two different treatments to expand these macros.
function reduceRegex(s, name, opts, expandAllMacrosInSet_cb, expandAllMacrosElsewhere_cb) {
    var orig = s;

    function errinfo() {
        if (name) {
            return 'macro [[' + name + ']]';
        } else {
            return 'regex [[' + orig + ']]';
        }
    }

    // propagate deferred exceptions = error reports.
    if (s instanceof Error) {
        return s;
    }

    var c1, c2;
    var rv = [];
    var derr;
    var se;

    while (s.length) {
        c1 = s.match(CHR_RE);
        if (!c1) {
            // cope with illegal escape sequences too!
            return new Error(errinfo() + ': illegal escape sequence at start of regex part: ' + s);
        } else {
            c1 = c1[0];
        }
        s = s.substr(c1.length);

        switch (c1) {
        case '[':
            // this is starting a set within the regex: scan until end of set!
            var set_content = [];
            var l = new Array(UNICODE_BASE_PLANE_MAX_CP + 1);

            while (s.length) {
                var inner = s.match(SET_PART_RE);
                if (!inner) {
                    inner = s.match(CHR_RE);
                    if (!inner) {
                        // cope with illegal escape sequences too!
                        return new Error(errinfo() + ': illegal escape sequence at start of regex part: ' + s);
                    } else {
                        inner = inner[0];
                    }
                    if (inner === ']') break;
                } else {
                    inner = inner[0];
                }
                set_content.push(inner);
                s = s.substr(inner.length);
            }

            // ensure that we hit the terminating ']':
            c2 = s.match(CHR_RE);
            if (!c2) {
                // cope with illegal escape sequences too!
                return new Error(errinfo() + ': regex set expression is broken: "' + s + '"');
            } else {
                c2 = c2[0];
            }
            if (c2 !== ']') {
                return new Error(errinfo() + ': regex set expression is broken: apparently unterminated');
            }
            s = s.substr(c2.length);

            se = set_content.join('');

            // expand any macros in here:
            if (expandAllMacrosInSet_cb) {
                se = expandAllMacrosInSet_cb(se);
                assert(se);
                if (se instanceof Error) {
                    return new Error(errinfo() + ': ' + se.message);
                }
            }

            derr = setmgmt.set2bitarray(l, se, opts);
            if (derr instanceof Error) {
                return new Error(errinfo() + ': ' + derr.message);
            }

            // find out which set expression is optimal in size:
            var s1 = setmgmt.produceOptimizedRegex4Set(l);

            // check if the source regex set potentially has any expansions (guestimate!)
            //
            // The indexOf('{') picks both XRegExp Unicode escapes and JISON lexer macros, which is perfect for us here.
            var has_expansions = (se.indexOf('{') >= 0);

            se = '[' + se + ']';

            if (!has_expansions && se.length < s1.length) {
                s1 = se;
            }
            rv.push(s1);
            break;

        // XRegExp Unicode escape, e.g. `\\p{Number}`:
        case '\\p':
            c2 = s.match(XREGEXP_UNICODE_ESCAPE_RE);
            if (c2) {
                c2 = c2[0];
                s = s.substr(c2.length);

                // nothing to expand.
                rv.push(c1 + c2);
            } else {
                // nothing to stretch this match, hence nothing to expand.
                rv.push(c1);
            }
            break;

        // Either a range expression or the start of a macro reference: `.{1,3}` or `{NAME}`.
        // Treat it as a macro reference and see if it will expand to anything:
        case '{':
            c2 = s.match(NOTHING_SPECIAL_RE);
            if (c2) {
                c2 = c2[0];
                s = s.substr(c2.length);

                var c3 = s[0];
                s = s.substr(c3.length);
                if (c3 === '}') {
                    // possibly a macro name in there... Expand if possible:
                    c2 = c1 + c2 + c3;
                    if (expandAllMacrosElsewhere_cb) {
                        c2 = expandAllMacrosElsewhere_cb(c2);
                        assert(c2);
                        if (c2 instanceof Error) {
                            return new Error(errinfo() + ': ' + c2.message);
                        }
                    }
                } else {
                    // not a well-terminated macro reference or something completely different:
                    // we do not even attempt to expand this as there's guaranteed nothing to expand
                    // in this bit.
                    c2 = c1 + c2 + c3;
                }
                rv.push(c2);
            } else {
                // nothing to stretch this match, hence nothing to expand.
                rv.push(c1);
            }
            break;

        // Recognize some other regex elements, but there's no need to understand them all.
        //
        // We are merely interested in any chunks now which do *not* include yet another regex set `[...]`
        // nor any `{MACRO}` reference:
        default:
            // non-set character or word: see how much of this there is for us and then see if there
            // are any macros still lurking inside there:
            c2 = s.match(NOTHING_SPECIAL_RE);
            if (c2) {
                c2 = c2[0];
                s = s.substr(c2.length);

                // nothing to expand.
                rv.push(c1 + c2);
            } else {
                // nothing to stretch this match, hence nothing to expand.
                rv.push(c1);
            }
            break;
        }
    }

    s = rv.join('');

    // When this result is suitable for use in a set, than we should be able to compile
    // it in a regex; that way we can easily validate whether macro X is fit to be used
    // inside a regex set:
    try {
        var re;
        re = new XRegExp(s);
        re.test(s[0]);
    } catch (ex) {
        // make sure we produce a regex expression which will fail badly when it is used
        // in actual code:
        return new Error(errinfo() + ': expands to an invalid regex: /' + s + '/');
    }

    assert(s);
    return s;
}


// expand macros within macros and cache the result
function prepareMacros(dict_macros, opts) {
    var macros = {};

    // expand a `{NAME}` macro which exists inside a `[...]` set:
    function expandMacroInSet(i) {
        var k, a, m;
        if (!macros[i]) {
            m = dict_macros[i];

            if (m.indexOf('{') >= 0) {
                // set up our own record so we can detect definition loops:
                macros[i] = {
                    in_set: false,
                    elsewhere: null,
                    raw: dict_macros[i]
                };

                for (k in dict_macros) {
                    if (dict_macros.hasOwnProperty(k) && i !== k) {
                        // it doesn't matter if the lexer recognized that the inner macro(s)
                        // were sitting inside a `[...]` set or not: the fact that they are used
                        // here in macro `i` which itself sits in a set, makes them *all* live in
                        // a set so all of them get the same treatment: set expansion style.
                        //
                        // Note: make sure we don't try to expand any XRegExp `\p{...}` or `\P{...}`
                        // macros here:
                        if (XRegExp._getUnicodeProperty(k)) {
                            // Work-around so that you can use `\p{ascii}` for a XRegExp slug, a.k.a.
                            // Unicode 'General Category' Property cf. http://unicode.org/reports/tr18/#Categories,
                            // while using `\p{ASCII}` as a *macro expansion* of the `ASCII`
                            // macro:
                            if (k.toUpperCase() !== k) {
                                m = new Error('Cannot use name "' + k + '" as a macro name as it clashes with the same XRegExp "\\p{..}" Unicode \'General Category\' Property name. Use all-uppercase macro names, e.g. name your macro "' + k.toUpperCase() + '" to work around this issue or give your offending macro a different name.');
                                break;
                            }
                        }

                        a = m.split('{' + k + '}');
                        if (a.length > 1) {
                            var x = expandMacroInSet(k);
                            assert(x);
                            if (x instanceof Error) {
                                m = x;
                                break;
                            }
                            m = a.join(x);
                        }
                    }
                }
            }

            var mba = setmgmt.reduceRegexToSetBitArray(m, i, opts);

            var s1;

            // propagate deferred exceptions = error reports.
            if (mba instanceof Error) {
                s1 = mba;
            } else {
                s1 = setmgmt.bitarray2set(mba, false);

                m = s1;
            }

            macros[i] = {
                in_set: s1,
                elsewhere: null,
                raw: dict_macros[i]
            };
        } else {
            m = macros[i].in_set;

            if (m instanceof Error) {
                // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                return new Error(m.message);
            }

            // detect definition loop:
            if (m === false) {
                return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
            }
        }

        return m;
    }

    function expandMacroElsewhere(i) {
        var k, a, m;

        if (macros[i].elsewhere == null) {
            m = dict_macros[i];

            // set up our own record so we can detect definition loops:
            macros[i].elsewhere = false;

            // the macro MAY contain other macros which MAY be inside a `[...]` set in this
            // macro or elsewhere, hence we must parse the regex:
            m = reduceRegex(m, i, opts, expandAllMacrosInSet, expandAllMacrosElsewhere);
            // propagate deferred exceptions = error reports.
            if (m instanceof Error) {
                return m;
            }

            macros[i].elsewhere = m;
        } else {
            m = macros[i].elsewhere;

            if (m instanceof Error) {
                // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                return m;
            }

            // detect definition loop:
            if (m === false) {
                return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
            }
        }

        return m;
    }

    function expandAllMacrosInSet(s) {
        var i, x;

        // process *all* the macros inside [...] set:
        if (s.indexOf('{') >= 0) {
            for (i in macros) {
                if (macros.hasOwnProperty(i)) {
                    var a = s.split('{' + i + '}');
                    if (a.length > 1) {
                        x = expandMacroInSet(i);
                        assert(x);
                        if (x instanceof Error) {
                            return new Error('failure to expand the macro [' + i + '] in set [' + s + ']: ' + x.message);
                        }
                        s = a.join(x);
                    }

                    // stop the brute-force expansion attempt when we done 'em all:
                    if (s.indexOf('{') === -1) {
                        break;
                    }
                }
            }
        }

        return s;
    }

    function expandAllMacrosElsewhere(s) {
        var i, x;

        // When we process the remaining macro occurrences in the regex
        // every macro used in a lexer rule will become its own capture group.
        //
        // Meanwhile the cached expansion will expand any submacros into
        // *NON*-capturing groups so that the backreference indexes remain as you'ld
        // expect and using macros doesn't require you to know exactly what your
        // used macro will expand into, i.e. which and how many submacros it has.
        //
        // This is a BREAKING CHANGE from vanilla jison 0.4.15!
        if (s.indexOf('{') >= 0) {
            for (i in macros) {
                if (macros.hasOwnProperty(i)) {
                    // These are all submacro expansions, hence non-capturing grouping is applied:
                    var a = s.split('{' + i + '}');
                    if (a.length > 1) {
                        x = expandMacroElsewhere(i);
                        assert(x);
                        if (x instanceof Error) {
                            return new Error('failure to expand the macro [' + i + '] in regex /' + s + '/: ' + x.message);
                        }
                        s = a.join('(?:' + x + ')');
                    }

                    // stop the brute-force expansion attempt when we done 'em all:
                    if (s.indexOf('{') === -1) {
                        break;
                    }
                }
            }
        }

        return s;
    }


    var m, i;

    if (opts.debug) console.log('\n############## RAW macros: ', dict_macros);

    // first we create the part of the dictionary which is targeting the use of macros
    // *inside* `[...]` sets; once we have completed that half of the expansions work,
    // we then go and expand the macros for when they are used elsewhere in a regex:
    // iff we encounter submacros then which are used *inside* a set, we can use that
    // first half dictionary to speed things up a bit as we can use those expansions
    // straight away!
    for (i in dict_macros) {
        if (dict_macros.hasOwnProperty(i)) {
            expandMacroInSet(i);
        }
    }

    for (i in dict_macros) {
        if (dict_macros.hasOwnProperty(i)) {
            expandMacroElsewhere(i);
        }
    }

    if (opts.debug) console.log('\n############### expanded macros: ', macros);

    return macros;
}



// expand macros in a regex; expands them recursively
function expandMacros(src, macros, opts) {
    var expansion_count = 0;

    // By the time we call this function `expandMacros` we MUST have expanded and cached all macros already!
    // Hence things should be easy in there:

    function expandAllMacrosInSet(s) {
        var i, m, x;

        // process *all* the macros inside [...] set:
        if (s.indexOf('{') >= 0) {
            for (i in macros) {
                if (macros.hasOwnProperty(i)) {
                    m = macros[i];

                    var a = s.split('{' + i + '}');
                    if (a.length > 1) {
                        x = m.in_set;

                        assert(x);
                        if (x instanceof Error) {
                            // this turns out to be an macro with 'issues' and it is used, so the 'issues' do matter: bombs away!
                            throw x;
                        }

                        // detect definition loop:
                        if (x === false) {
                            return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                        }

                        s = a.join(x);
                        expansion_count++;
                    }

                    // stop the brute-force expansion attempt when we done 'em all:
                    if (s.indexOf('{') === -1) {
                        break;
                    }
                }
            }
        }

        return s;
    }

    function expandAllMacrosElsewhere(s) {
        var i, m, x;

        // When we process the main macro occurrences in the regex
        // every macro used in a lexer rule will become its own capture group.
        //
        // Meanwhile the cached expansion will expand any submacros into
        // *NON*-capturing groups so that the backreference indexes remain as you'ld
        // expect and using macros doesn't require you to know exactly what your
        // used macro will expand into, i.e. which and how many submacros it has.
        //
        // This is a BREAKING CHANGE from vanilla jison 0.4.15!
        if (s.indexOf('{') >= 0) {
            for (i in macros) {
                if (macros.hasOwnProperty(i)) {
                    m = macros[i];

                    var a = s.split('{' + i + '}');
                    if (a.length > 1) {
                        // These are all main macro expansions, hence CAPTURING grouping is applied:
                        x = m.elsewhere;
                        assert(x);

                        // detect definition loop:
                        if (x === false) {
                            return new Error('Macro name "' + i + '" has an illegal, looping, definition, i.e. it\'s definition references itself, either directly or indirectly, via other macros.');
                        }

                        s = a.join('(' + x + ')');
                        expansion_count++;
                    }

                    // stop the brute-force expansion attempt when we done 'em all:
                    if (s.indexOf('{') === -1) {
                        break;
                    }
                }
            }
        }

        return s;
    }


    // When we process the macro occurrences in the regex
    // every macro used in a lexer rule will become its own capture group.
    //
    // Meanwhile the cached expansion will have expanded any submacros into
    // *NON*-capturing groups so that the backreference indexes remain as you'ld
    // expect and using macros doesn't require you to know exactly what your
    // used macro will expand into, i.e. which and how many submacros it has.
    //
    // This is a BREAKING CHANGE from vanilla jison 0.4.15!
    var s2 = reduceRegex(src, null, opts, expandAllMacrosInSet, expandAllMacrosElsewhere);
    // propagate deferred exceptions = error reports.
    if (s2 instanceof Error) {
        throw s2;
    }

    // only when we did expand some actual macros do we take the re-interpreted/optimized/regenerated regex from reduceRegex()
    // in order to keep our test cases simple and rules recognizable. This assumes the user can code good regexes on his own,
    // as long as no macros are involved...
    //
    // Also pick the reduced regex when there (potentially) are XRegExp extensions in the original, e.g. `\\p{Number}`,
    // unless the `xregexp` output option has been enabled.
    if (expansion_count > 0 || (src.indexOf('\\p{') >= 0 && !opts.options.xregexp)) {
        src = s2;
    } else {
        // Check if the reduced regex is smaller in size; when it is, we still go with the new one!
        if (s2.length < src.length) {
            src = s2;
        }
    }

    return src;
}

function prepareStartConditions(conditions) {
    var sc;
    var hash = {};

    for (sc in conditions) {
        if (conditions.hasOwnProperty(sc)) {
            hash[sc] = {
                rules: [], 
                inclusive: !conditions[sc]
            };
        }
    }
    return hash;
}

function buildActions(dict, tokens, opts) {
    var actions = [dict.actionInclude || '', 'var YYSTATE = YY_START;'];
    var tok;
    var toks = {};
    var caseHelper = [];

    // tokens: map/array of token numbers to token names
    for (tok in tokens) {
        var idx = parseInt(tok);
        if (idx && idx > 0) {
            toks[tokens[tok]] = idx;
        }
    }

    var gen = prepareRules(dict, actions, caseHelper, tokens && toks, opts.conditions, opts);

    var code = actions.join('\n');
    'yytext yyleng yylineno yylloc yyerror'.split(' ').forEach(function (yy) {
        code = code.replace(new RegExp('\\b(' + yy + ')\\b', 'g'), 'yy_.$1');
    });

    return {
        caseHelperInclude: '{\n' + caseHelper.join(',') + '\n}',

        actions: `function lexer__performAction(yy, yyrulenumber, YY_START) {
            var yy_ = this;

            ${code}
        }`,

        rules: gen.rules,
        macros: gen.macros,                   // propagate these for debugging/diagnostic purposes

        regular_rule_count: gen.regular_rule_count,
        simple_rule_count: gen.simple_rule_count,
    };
}

//
// NOTE: this is *almost* a copy of the JisonParserError producing code in
//       jison/lib/jison.js @ line 2304:lrGeneratorMixin.generateErrorClass
//
function generateErrorClass() {
    // --- START lexer error class ---

var prelude = `/**
 * See also:
 * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
 * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
 * with userland code which might access the derived class in a 'classic' way.
 *
 * @public
 * @constructor
 * @nocollapse
 */
function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonLexerError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) { // V8
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
} else {
    JisonLexerError.prototype = Object.create(Error.prototype);
}
JisonLexerError.prototype.constructor = JisonLexerError;
JisonLexerError.prototype.name = 'JisonLexerError';`;

    // --- END lexer error class ---

    return prelude;
}


const jisonLexerErrorDefinition = generateErrorClass();


function generateFakeXRegExpClassSrcCode() {
    return rmCommonWS$3`
        var __hacky_counter__ = 0;

        /**
         * @constructor
         * @nocollapse
         */
        function XRegExp(re, f) {
            this.re = re;
            this.flags = f;
            this._getUnicodeProperty = function (k) {};
            var fake = /./;    // WARNING: this exact 'fake' is also depended upon by the xregexp unit test!
            __hacky_counter__++;
            fake.__hacky_backy__ = __hacky_counter__;
            return fake;
        }
    `;
}



/** @constructor */
function RegExpLexer(dict, input, tokens, build_options) {
    var opts;
    var dump = false;

    function test_me(tweak_cb, description, src_exception, ex_callback) {
        opts = processGrammar(dict, tokens, build_options);
        opts.__in_rules_failure_analysis_mode__ = false;
        prepExportStructures$1(opts);
        assert(opts.options);
        if (tweak_cb) {
            tweak_cb();
        }
        var source = generateModuleBody(opts);
        try {
            // The generated code will always have the `lexer` variable declared at local scope
            // as `eval()` will use the local scope.
            //
            // The compiled code will look something like this:
            //
            // ```
            // var lexer;
            // bla bla...
            // ```
            //
            // or
            //
            // ```
            // var lexer = { bla... };
            // ```
            var testcode = [
                '// provide a local version for test purposes:',
                jisonLexerErrorDefinition,
                '',
                generateFakeXRegExpClassSrcCode(),
                '',
                source,
                '',
                'return lexer;'].join('\n');
            var lexer = code_exec$2(testcode, function generated_code_exec_wrapper_regexp_lexer(sourcecode) {
                //console.log("===============================LEXER TEST CODE\n", sourcecode, "\n=====================END====================\n");
                var lexer_f = new Function('', sourcecode);
                return lexer_f();
            }, opts.options, "lexer");

            if (!lexer) {
                throw new Error('no lexer defined *at all*?!');
            }
            if (typeof lexer.options !== 'object' || lexer.options == null) {
                throw new Error('your lexer class MUST have an .options member object or it won\'t fly!');
            }
            if (typeof lexer.setInput !== 'function') {
                throw new Error('your lexer class MUST have a .setInput function member or it won\'t fly!');
            }
            if (lexer.EOF !== 1 && lexer.ERROR !== 2) {
                throw new Error('your lexer class MUST have these constants defined: lexer.EOF = 1 and lexer.ERROR = 2 or it won\'t fly!');
            }

            // When we do NOT crash, we found/killed the problem area just before this call!
            if (src_exception && description) {
                var msg = description;
                if (typeof description === 'function') {
                    msg = description();
                }
                src_exception.message += '\n        (' + msg + ')';
            }

            // patch the pre and post handlers in there, now that we have some live code to work with:
            if (opts.options) {
                var pre = opts.options.pre_lex;
                var post = opts.options.post_lex;
                // since JSON cannot encode functions, we'll have to do it manually now:
                if (typeof pre === 'function') {
                    lexer.options.pre_lex = pre;
                }
                if (typeof post === 'function') {
                    lexer.options.post_lex = post;
                }
            }

            if (opts.options.showSource) {
                if (typeof opts.options.showSource === 'function') {
                    opts.options.showSource(lexer, source, opts);
                } else {
                    console.log("\nGenerated lexer sourcecode:\n----------------------------------------\n", source, "\n----------------------------------------\n");
                }
            }
            return lexer;
        } catch (ex) {
            // if (src_exception) {
            //     src_exception.message += '\n        (' + description + ': ' + ex.message + ')';
            // }

            if (ex_callback) {
                ex_callback(ex);
            } else if (dump) {
                console.log('source code:\n', source);
            }
            return false;
        }
    }

    /** @constructor */
    var lexer = test_me(null, null, null, function (ex) {
        // When we get an exception here, it means some part of the user-specified lexer is botched.
        //
        // Now we go and try to narrow down the problem area/category:
        assert(opts.options);
        assert(opts.options.xregexp !== undefined);
        var orig_xregexp_opt = !!opts.options.xregexp;
        if (!test_me(function () {
            assert(opts.options.xregexp !== undefined);
            opts.options.xregexp = false;
            opts.showSource = false;
        }, 'When you have specified %option xregexp, you must also properly IMPORT the XRegExp library in the generated lexer.', ex, null)) {
            if (!test_me(function () {
                // restore xregexp option setting: the trouble wasn't caused by the xregexp flag i.c.w. incorrect XRegExp library importing!
                opts.options.xregexp = orig_xregexp_opt;

                opts.conditions = [];
                opts.showSource = false;
            }, function () {
                assert(Array.isArray(opts.rules));
                return (opts.rules.length > 0 ?
                    'One or more of your lexer state names are possibly botched?' :
                    'Your custom lexer is somehow botched.'
                );
            }, ex, null)) {
                var rulesSpecSize;
                if (!test_me(function () {
                    // store the parsed rule set size so we can use that info in case
                    // this attempt also fails:
                    assert(Array.isArray(opts.rules));
                    rulesSpecSize = opts.rules.length; 

                    // opts.conditions = [];
                    opts.rules = [];
                    opts.showSource = false;
                    opts.__in_rules_failure_analysis_mode__ = true;
                }, 'One or more of your lexer rules are possibly botched?', ex, null)) {
                    // kill each rule action block, one at a time and test again after each 'edit':
                    var rv = false;
                    for (var i = 0, len = rulesSpecSize; i < len; i++) {
                        var lastEditedRuleSpec;
                        rv = test_me(function () {
                            assert(Array.isArray(opts.rules));
                            assert(opts.rules.length === rulesSpecSize);

                            // opts.conditions = [];
                            // opts.rules = [];
                            // opts.__in_rules_failure_analysis_mode__ = true;
                            
                            // nuke all rules' actions up to and including rule numero `i`:
                            for (var j = 0; j <= i; j++) {
                                // rules, when parsed, have 2 or 3 elements: [conditions, handle, action];
                                // now we want to edit the *action* part:
                                var rule = opts.rules[j];
                                assert(Array.isArray(rule));
                                assert(rule.length === 2 || rule.length === 3);
                                rule.pop();
                                rule.push('{ /* nada */ }');
                                lastEditedRuleSpec = rule;
                            }
                        }, function () {
                            return 'Your lexer rule "' + lastEditedRuleSpec[0] + '" action code block is botched?';
                        }, ex, null);
                        if (rv) {
                            break;
                        }
                    }
                    if (!rv) {
                        test_me(function () {
                            opts.conditions = [];
                            opts.rules = [];
                            opts.performAction = 'null';
                            // opts.options = {};
                            // opts.caseHelperInclude = '{}';
                            opts.showSource = false;
                            opts.__in_rules_failure_analysis_mode__ = true;

                            dump = false;
                        }, 'One or more of your lexer rule action code block(s) are possibly botched?', ex, null);
                    }
                }
            }
        }
        throw ex;
    });

    lexer.setInput(input);

    /** @public */
    lexer.generate = function () {
        return generateFromOpts(opts);
    };
    /** @public */
    lexer.generateModule = function () {
        return generateModule(opts);
    };
    /** @public */
    lexer.generateCommonJSModule = function () {
        return generateCommonJSModule(opts);
    };
    /** @public */
    lexer.generateESModule = function () {
        return generateESModule(opts);
    };
    /** @public */
    lexer.generateAMDModule = function () {
        return generateAMDModule(opts);
    };

    // internal APIs to aid testing:
    /** @public */
    lexer.getExpandedMacros = function () {
        return opts.macros;
    };

    return lexer;
}

// code stripping performance test for very simple grammar:
//
// - removing backtracking parser code branches:                    730K -> 750K rounds
// - removing all location info tracking: yylineno, yylloc, etc.:   750K -> 900K rounds
// - no `yyleng`:                                                   900K -> 905K rounds
// - no `this.done` as we cannot have a NULL `_input` anymore:      905K -> 930K rounds
// - `simpleCaseActionClusters` as array instead of hash object:    930K -> 940K rounds
// - lexers which have only return stmts, i.e. only a
//   `simpleCaseActionClusters` lookup table to produce
//   lexer tokens: *inline* the `performAction` call:               940K -> 950K rounds
// - given all the above, you can *inline* what's left of
//   `lexer_next()`:                                                950K -> 955K rounds (? this stuff becomes hard to measure; inaccuracy abounds!)
//
// Total gain when we forget about very minor (and tough to nail) *inlining* `lexer_next()` gains:
//
//     730 -> 950  ~ 30% performance gain.
//

// As a function can be reproduced in source-code form by any JavaScript engine, we're going to wrap this chunk
// of code in a function so that we can easily get it including it comments, etc.:
/**
@public
@nocollapse
*/
function getRegExpLexerPrototype() {
    // --- START lexer kernel ---
return `{
    EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup

    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use

    done: false,                                /// INTERNAL USE ONLY
    _backtrack: false,                          /// INTERNAL USE ONLY
    _input: '',                                 /// INTERNAL USE ONLY
    _more: false,                               /// INTERNAL USE ONLY
    _signaled_error_token: false,               /// INTERNAL USE ONLY

    conditionStack: [],                         /// INTERNAL USE ONLY; managed via \`pushState()\`, \`popState()\`, \`topState()\` and \`stateStackSize()\`

    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. \`match\` is identical to \`yytext\` except that this one still contains the matched input string after \`lexer.performAction()\` has been invoked, where userland code MAY have changed/replaced the \`yytext\` value entirely!
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the \`lex()\` API.
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (\`yytext\`)
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for \`parseError\`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
        msg = '' + msg;

        // heuristic to determine if the error message already contains a (partial) source code dump
        // as produced by either \`showPosition()\` or \`prettyPrintRange()\`:
        if (show_input_position == undefined) {
            show_input_position = !(msg.indexOf('\\n') > 0 && msg.indexOf('^') > 0);
        }
        if (this.yylloc && show_input_position) {
            if (typeof this.prettyPrintRange === 'function') {
                var pretty_src = this.prettyPrintRange(this.yylloc);

                if (!/\\n\\s*$/.test(msg)) {
                    msg += '\\n';
                }
                msg += '\\n  Erroneous area:\\n' + this.prettyPrintRange(this.yylloc);          
            } else if (typeof this.showPosition === 'function') {
                var pos_str = this.showPosition();
                if (pos_str) {
                    if (msg.length && msg[msg.length - 1] !== '\\n' && pos_str[0] !== '\\n') {
                        msg += '\\n' + pos_str;
                    } else {
                        msg += pos_str;
                    }
                }
            }
        }
        /** @constructor */
        var pei = {
            errStr: msg,
            recoverable: !!recoverable,
            text: this.match,           // This one MAY be empty; userland code should use the \`upcomingInput\` API to obtain more text which follows the 'lexer cursor position'...
            token: null,
            line: this.yylineno,
            loc: this.yylloc,
            yy: this.yy,
            lexer: this,

            /**
             * and make sure the error info doesn't stay due to potential
             * ref cycle via userland code manipulations.
             * These would otherwise all be memory leak opportunities!
             * 
             * Note that only array and object references are nuked as those
             * constitute the set of elements which can produce a cyclic ref.
             * The rest of the members is kept intact as they are harmless.
             * 
             * @public
             * @this {LexErrorInfo}
             */
            destroy: function destructLexErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     * 
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
        if (!ExceptionClass) {
            ExceptionClass = this.JisonLexerError;
        }
        if (this.yy) {
            if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
                return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } else if (typeof this.yy.parseError === 'function') {
                return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
            } 
        }
        throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements \`yyerror(str, ...args)\` functionality for use inside lexer actions.
     * 
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str /*, ...args */) {
        var lineno_msg = '';
        if (this.yylloc) {
            lineno_msg = ' on line ' + (this.yylineno + 1);
        }
        var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': ' + str, this.options.lexerErrorsAreRecoverable);

        // Add any extra args to the hash under the name \`extra_error_attributes\`:
        var args = Array.prototype.slice.call(arguments, 1);
        if (args.length) {
            p.extra_error_attributes = args;
        }

        return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     * 
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
        // prevent lingering circular references from causing memory leaks:
        this.setInput('', {});

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;
        }

        return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     * 
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
        this.yytext = '';
        this.yyleng = 0;
        this.match = '';
        // - DO NOT reset \`this.matched\`
        this.matches = false;
        this._more = false;
        this._backtrack = false;

        var col = (this.yylloc ? this.yylloc.last_column : 0);
        this.yylloc = {
            first_line: this.yylineno + 1,
            first_column: col,
            last_line: this.yylineno + 1,
            last_column: col,

            range: [this.offset, this.offset]
        };
    },

    /**
     * resets the lexer, sets new input
     * 
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
        this.yy = yy || this.yy || {};

        // also check if we've fully initialized the lexer instance,
        // including expansion work to be done to go from a loaded
        // lexer to a usable lexer:
        if (!this.__decompressed) {
          // step 1: decompress the regex list:
          var rules = this.rules;
          for (var i = 0, len = rules.length; i < len; i++) {
            var rule_re = rules[i];

            // compression: is the RE an xref to another RE slot in the rules[] table?
            if (typeof rule_re === 'number') {
              rules[i] = rules[rule_re];
            }
          }

          // step 2: unfold the conditions[] set to make these ready for use:
          var conditions = this.conditions;
          for (var k in conditions) {
            var spec = conditions[k];

            var rule_ids = spec.rules;

            var len = rule_ids.length;
            var rule_regexes = new Array(len + 1);            // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in \`lexer_next()\` fast and simple!
            var rule_new_ids = new Array(len + 1);

            for (var i = 0; i < len; i++) {
              var idx = rule_ids[i];
              var rule_re = rules[idx];
              rule_regexes[i + 1] = rule_re;
              rule_new_ids[i + 1] = idx;
            }

            spec.rules = rule_new_ids;
            spec.__rule_regexes = rule_regexes;
            spec.__rule_count = len;
          }

          this.__decompressed = true;
        }

        this._input = input || '';
        this.clear();
        this._signaled_error_token = false;
        this.done = false;
        this.yylineno = 0;
        this.matched = '';
        this.conditionStack = ['INITIAL'];
        this.__currentRuleSet__ = null;
        this.yylloc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [0, 0]
        };
        this.offset = 0;
        return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse, 
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the \`unput()\` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current \`yyloc\` cursor location or any history. 
     * 
     * Use this API to help implement C-preprocessor-like
     * \`#include\` statements, etc.
     * 
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The \`cpsArg\` argument value is passed to the callback
     * as-is.
     *
     * \`callback\` interface: 
     * \`function callback(input, cpsArg)\`
     * 
     * - \`input\` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - \`cpsArg\` is \`cpsArg\` passed into this API.
     * 
     * The \`this\` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API. 
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the \`"" + retval\`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html 
     * -- that way any returned object's \`toValue()\` and \`toString()\`
     * methods will be invoked in a proper/desirable order.)
     * 
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
        var rv = callback.call(this, this._input, cpsArg);
        if (typeof rv !== 'string') {
            if (rv) {
                this._input = '' + rv; 
            }
            // else: keep \`this._input\` as is. 
        } else {
            this._input = rv; 
        }
        return this;
    },

    /**
     * consumes and returns one char from the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
        if (!this._input) {
            //this.done = true;    -- don't set \`done\` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
            return null;
        }
        var ch = this._input[0];
        this.yytext += ch;
        this.yyleng++;
        this.offset++;
        this.match += ch;
        this.matched += ch;
        // Count the linenumber up when we hit the LF (or a stand-alone CR).
        // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
        // and we advance immediately past the LF as well, returning both together as if
        // it was all a single 'character' only.
        var slice_len = 1;
        var lines = false;
        if (ch === '\\n') {
            lines = true;
        } else if (ch === '\\r') {
            lines = true;
            var ch2 = this._input[1];
            if (ch2 === '\\n') {
                slice_len++;
                ch += ch2;
                this.yytext += ch2;
                this.yyleng++;
                this.offset++;
                this.match += ch2;
                this.matched += ch2;
                this.yylloc.range[1]++;
            }
        }
        if (lines) {
            this.yylineno++;
            this.yylloc.last_line++;
            this.yylloc.last_column = 0;
        } else {
            this.yylloc.last_column++;
        }
        this.yylloc.range[1]++;

        this._input = this._input.slice(slice_len);
        return ch;
    },

    /**
     * unshifts one char (or an entire string) into the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
        var len = ch.length;
        var lines = ch.split(/(?:\\r\\n?|\\n)/g);

        this._input = ch + this._input;
        this.yytext = this.yytext.substr(0, this.yytext.length - len);
        this.yyleng = this.yytext.length;
        this.offset -= len;
        this.match = this.match.substr(0, this.match.length - len);
        this.matched = this.matched.substr(0, this.matched.length - len);

        if (lines.length > 1) {
            this.yylineno -= lines.length - 1;

            this.yylloc.last_line = this.yylineno + 1;

            // Get last entirely matched line into the \`pre_lines[]\` array's
            // last index slot; we don't mind when other previously 
            // matched lines end up in the array too. 
            var pre = this.match;
            var pre_lines = pre.split(/(?:\\r\\n?|\\n)/g);
            if (pre_lines.length === 1) {
                pre = this.matched;
                pre_lines = pre.split(/(?:\\r\\n?|\\n)/g);
            }
            this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
        } else {
            this.yylloc.last_column -= len;
        }

        this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;

        this.done = false;
        return this;
    },

    /**
     * cache matched text and append it on next action
     * 
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
        this._more = true;
        return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     * 
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
        if (this.options.backtrack_lexer) {
            this._backtrack = true;
        } else {
            // when the \`parseError()\` call returns, we MUST ensure that the error is registered.
            // We accomplish this by signaling an 'error' token to be produced for the current
            // \`.lex()\` run.
            var lineno_msg = '';
            if (this.yylloc) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
            }
            var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).', false);
            this._signaled_error_token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
        }
        return this;
    },

    /**
     * retain first n characters of the match
     * 
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
        return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     * 
     * Limit the returned string length to \`maxSize\` (default: 20).
     * 
     * Limit the returned string to the \`maxLines\` number of lines of
     * input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     * 
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
        var past = this.matched.substring(0, this.matched.length - this.match.length);
        if (maxSize < 0)
            maxSize = past.length;
        else if (!maxSize)
            maxSize = 20;
        if (maxLines < 0)
            maxLines = past.length;         // can't ever have more input lines than this!
        else if (!maxLines)
            maxLines = 1;
        // \`substr\` anticipation: treat \\r\\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        past = past.substr(-maxSize * 2 - 2);
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        var a = past.replace(/\\r\\n|\\r/g, '\\n').split('\\n');
        a = a.slice(-maxLines);
        past = a.join('\\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis prefix...
        if (past.length > maxSize) {
            past = '...' + past.substr(-maxSize);
        }
        return past;
    },

    /**
     * return (part of the) upcoming input, i.e. for error messages.
     * 
     * Limit the returned string length to \`maxSize\` (default: 20).
     * 
     * Limit the returned string to the \`maxLines\` number of lines of input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input 
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block. 
     * >
     * 
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
        var next = this.match;
        if (maxSize < 0)
            maxSize = next.length + this._input.length;
        else if (!maxSize)
            maxSize = 20;
        if (maxLines < 0)
            maxLines = maxSize;         // can't ever have more input lines than this!
        else if (!maxLines)
            maxLines = 1;
        // \`substring\` anticipation: treat \\r\\n as a single character and take a little
        // more than necessary so that we can still properly check against maxSize
        // after we've transformed and limited the newLines in here:
        if (next.length < maxSize * 2 + 2) {
            next += this._input.substring(0, maxSize * 2 + 2);  // substring is faster on Chrome/V8
        }
        // now that we have a significantly reduced string to process, transform the newlines
        // and chop them, then limit them:
        var a = next.replace(/\\r\\n|\\r/g, '\\n').split('\\n');
        a = a.slice(0, maxLines);
        next = a.join('\\n');
        // When, after limiting to maxLines, we still have too much to return,
        // do add an ellipsis postfix...
        if (next.length > maxSize) {
            next = next.substring(0, maxSize) + '...';
        }
        return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     * 
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
        var pre = this.pastInput(maxPrefix).replace(/\\s/g, ' ');
        var c = new Array(pre.length + 1).join('-');
        return pre + this.upcomingInput(maxPostfix).replace(/\\s/g, ' ') + '\\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given \`actual\` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the \`preceding\` and \`following\` locations, IFF those are available,
     * and reconstruct the \`actual\` location info from those.
     * If this fails, the heuristic is to take the \`current\` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: \`deriveLocationInfo()\` ALWAYS produces a location info object *copy* of \`actual\`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     * 
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
        var loc = {
            first_line: 1,
            first_column: 0,
            last_line: 1,
            last_column: 0,

            range: [0, 0]
        };
        if (actual) {
            loc.first_line = actual.first_line | 0;
            loc.last_line = actual.last_line | 0;
            loc.first_column = actual.first_column | 0;
            loc.last_column = actual.last_column | 0;

            if (actual.range) {
                loc.range[0] = actual.range[0] | 0; 
                loc.range[1] = actual.range[1] | 0;
            } 
        }
        if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
            // plan B: heuristic using preceding and following:
            if (loc.first_line <= 0 && preceding) {
                loc.first_line = preceding.last_line | 0;
                loc.first_column = preceding.last_column | 0;

                if (preceding.range) {
                    loc.range[0] = actual.range[1] | 0; 
                } 
            }

            if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
                loc.last_line = following.first_line | 0;
                loc.last_column = following.first_column | 0;

                if (following.range) {
                    loc.range[1] = actual.range[0] | 0; 
                } 
            }

            // plan C?: see if the 'current' location is useful/sane too:
            if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
                loc.first_line = current.first_line | 0;
                loc.first_column = current.first_column | 0;

                if (current.range) {
                    loc.range[0] = current.range[0] | 0; 
                } 
            }

            if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
                loc.last_line = current.last_line | 0;
                loc.last_column = current.last_column | 0;

                if (current.range) {
                    loc.range[1] = current.range[1] | 0; 
                } 
            }
        }
        // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
        // or plan D heuristics to produce a 'sensible' last_line value:
        if (loc.last_line <= 0) {
            if (loc.first_line <= 0) {
                loc.first_line = this.yylloc.first_line;
                loc.last_line = this.yylloc.last_line;
                loc.first_column = this.yylloc.first_column;
                loc.last_column = this.yylloc.last_column;

                loc.range[0] = this.yylloc.range[0];
                loc.range[1] = this.yylloc.range[1];
            } else {
                loc.last_line = this.yylloc.last_line;
                loc.last_column = this.yylloc.last_column;

                loc.range[1] = this.yylloc.range[1];
            }
        }
        if (loc.first_line <= 0) {
            loc.first_line = loc.last_line;
            loc.first_column = 0; // loc.last_column;

            loc.range[1] = loc.range[0];
        }
        if (loc.first_column < 0) {
            loc.first_column = 0;
        }
        if (loc.last_column < 0) {
            loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
        }
        return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced 
     * by the given location info range, plus a few lines of context.
     * 
     * This function pretty-prints the indicated section of the input, with line numbers 
     * and everything!
     * 
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     * 
     * - \`loc\` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by \`^\`
     *   characters below each character in the entire input range.
     * 
     * - \`context_loc\` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by \`loc\`. This can help provide context for the displayed
     *   error, etc.
     * 
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     * 
     * - \`context_loc2\` is another *optional* location info object, which serves
     *   a similar purpose to \`context_loc\`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     * 
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     * 
     * Special Notes:
     * 
     * - when the \`loc\`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   \`...continued...\` message will be printed between them.
     * 
     *   This serves the purpose of not printing a huge amount of text when the \`loc\`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     * 
     * - this function can display lines of input which whave not yet been lexed.
     *   \`prettyPrintRange()\` can access the entire input!
     * 
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
        loc = this.deriveLocationInfo(loc, context_loc, context_loc2);        
        const CONTEXT = 3;
        const CONTEXT_TAIL = 1;
        const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
        var input = this.matched + this._input;
        var lines = input.split('\\n');
        var l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
        var l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
        var lineno_display_width = (1 + Math.log10(l1 | 1) | 0);
        var ws_prefix = new Array(lineno_display_width).join(' ');
        var nonempty_line_indexes = [];
        var rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
            var lno = index + l0;
            var lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
            var rv = lno_pfx + ': ' + line;
            var errpfx = (new Array(lineno_display_width + 1)).join('^');
            var offset = 2 + 1;
            var len = 0;

            if (lno === loc.first_line) {
              offset += loc.first_column;

              len = Math.max(
                2,
                ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
              );
            } else if (lno === loc.last_line) {
              len = Math.max(2, loc.last_column + 1);
            } else if (lno > loc.first_line && lno < loc.last_line) {
              len = Math.max(2, line.length + 1);
            }

            if (len) {
              var lead = new Array(offset).join('.');
              var mark = new Array(len).join('^');
              rv += '\\n' + errpfx + lead + mark;

              if (line.trim().length > 0) {
                nonempty_line_indexes.push(index);
              }
            }

            rv = rv.replace(/\\t/g, ' ');
            return rv;
        });

        // now make sure we don't print an overly large amount of error area: limit it 
        // to the top and bottom line count:
        if (nonempty_line_indexes.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
            var clip_start = nonempty_line_indexes[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
            var clip_end = nonempty_line_indexes[nonempty_line_indexes.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;

            var intermediate_line = (new Array(lineno_display_width + 1)).join(' ') +     '  (...continued...)';
            intermediate_line += '\\n' + (new Array(lineno_display_width + 1)).join('-') + '  (---------------)';
            rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
        }
        return rv.join('\\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input \`yylloc\` location object.
     * 
     * Set \`display_range_too\` to TRUE to include the string character index position(s)
     * in the description if the \`yylloc.range\` is available.
     * 
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
        var l1 = yylloc.first_line;
        var l2 = yylloc.last_line;
        var c1 = yylloc.first_column;
        var c2 = yylloc.last_column;
        var dl = l2 - l1;
        var dc = c2 - c1;
        var rv;
        if (dl === 0) {
            rv = 'line ' + l1 + ', ';
            if (dc <= 1) {
                rv += 'column ' + c1;
            } else {
                rv += 'columns ' + c1 + ' .. ' + c2;
            }
        } else {
            rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
        }
        if (yylloc.range && display_range_too) {
            var r1 = yylloc.range[0];
            var r2 = yylloc.range[1] - 1;
            if (r2 <= r1) {
                rv += ' {String Offset: ' + r1 + '}';
            } else {
                rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
            }
        }
        return rv;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     * 
     * \`match\` is supposed to be an array coming out of a regex match, i.e. \`match[0]\`
     * contains the actually matched text string.
     * 
     * Also move the input cursor forward and update the match collectors:
     * 
     * - \`yytext\`
     * - \`yyleng\`
     * - \`match\`
     * - \`matches\`
     * - \`yylloc\`
     * - \`offset\`
     * 
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
        var token,
            lines,
            backup,
            match_str,
            match_str_len;

        if (this.options.backtrack_lexer) {
            // save context
            backup = {
                yylineno: this.yylineno,
                yylloc: {
                    first_line: this.yylloc.first_line,
                    last_line: this.yylloc.last_line,
                    first_column: this.yylloc.first_column,
                    last_column: this.yylloc.last_column,

                    range: this.yylloc.range.slice(0)
                },
                yytext: this.yytext,
                match: this.match,
                matches: this.matches,
                matched: this.matched,
                yyleng: this.yyleng,
                offset: this.offset,
                _more: this._more,
                _input: this._input,
                //_signaled_error_token: this._signaled_error_token,
                yy: this.yy,
                conditionStack: this.conditionStack.slice(0),
                done: this.done
            };
        }

        match_str = match[0];
        match_str_len = match_str.length;
        // if (match_str.indexOf('\\n') !== -1 || match_str.indexOf('\\r') !== -1) {
            lines = match_str.split(/(?:\\r\\n?|\\n)/g);
            if (lines.length > 1) {
                this.yylineno += lines.length - 1;

                this.yylloc.last_line = this.yylineno + 1;
                this.yylloc.last_column = lines[lines.length - 1].length;
            } else {
                this.yylloc.last_column += match_str_len;
            }
        // }
        this.yytext += match_str;
        this.match += match_str;
        this.matched += match_str;
        this.matches = match;
        this.yyleng = this.yytext.length;
        this.yylloc.range[1] += match_str_len;

        // previous lex rules MAY have invoked the \`more()\` API rather than producing a token:
        // those rules will already have moved this \`offset\` forward matching their match lengths,
        // hence we must only add our own match length now:
        this.offset += match_str_len;
        this._more = false;
        this._backtrack = false;
        this._input = this._input.slice(match_str_len);

        // calling this method:
        //
        //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
        token = this.performAction.call(this, this.yy, indexed_rule, this.conditionStack[this.conditionStack.length - 1] /* = YY_START */);
        // otherwise, when the action codes are all simple return token statements:
        //token = this.simpleCaseActionClusters[indexed_rule];

        if (this.done && this._input) {
            this.done = false;
        }
        if (token) {
            return token;
        } else if (this._backtrack) {
            // recover context
            for (var k in backup) {
                this[k] = backup[k];
            }
            this.__currentRuleSet__ = null;
            return false; // rule action called reject() implying the next rule should be tested instead.
        } else if (this._signaled_error_token) {
            // produce one 'error' token as \`.parseError()\` in \`reject()\`
            // did not guarantee a failure signal by throwing an exception!
            token = this._signaled_error_token;
            this._signaled_error_token = false;
            return token;
        }
        return false;
    },

    /**
     * return next match in input
     * 
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
        if (this.done) {
            this.clear();
            return this.EOF;
        }
        if (!this._input) {
            this.done = true;
        }

        var token,
            match,
            tempMatch,
            index;
        if (!this._more) {
            this.clear();
        }
        var spec = this.__currentRuleSet__;
        if (!spec) {
            // Update the ruleset cache as we apparently encountered a state change or just started lexing.
            // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
            // invoke the \`lex()\` token-producing API and related APIs, hence caching the set for direct access helps
            // speed up those activities a tiny bit.
            spec = this.__currentRuleSet__ = this._currentRules();
            // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
            // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
            if (!spec || !spec.rules) {
                var lineno_msg = '';
                if (this.options.trackPosition) {
                    lineno_msg = ' on line ' + (this.yylineno + 1);
                }
                var p = this.constructLexErrorInfo('Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!', false);
                // produce one 'error' token until this situation has been resolved, most probably by parse termination!
                return (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            }
        }

        var rule_ids = spec.rules;
        var regexes = spec.__rule_regexes;
        var len = spec.__rule_count;

        // Note: the arrays are 1-based, while \`len\` itself is a valid index,
        // hence the non-standard less-or-equal check in the next loop condition!
        for (var i = 1; i <= len; i++) {
            tempMatch = this._input.match(regexes[i]);
            if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
                match = tempMatch;
                index = i;
                if (this.options.backtrack_lexer) {
                    token = this.test_match(tempMatch, rule_ids[i]);
                    if (token !== false) {
                        return token;
                    } else if (this._backtrack) {
                        match = undefined;
                        continue; // rule action called reject() implying a rule MISmatch.
                    } else {
                        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
                        return false;
                    }
                } else if (!this.options.flex) {
                    break;
                }
            }
        }
        if (match) {
            token = this.test_match(match, rule_ids[index]);
            if (token !== false) {
                return token;
            }
            // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
            return false;
        }
        if (!this._input) {
            this.done = true;
            this.clear();
            return this.EOF;
        } else {
            var lineno_msg = '';
            if (this.options.trackPosition) {
                lineno_msg = ' on line ' + (this.yylineno + 1);
            }
            var p = this.constructLexErrorInfo('Lexical error' + lineno_msg + ': Unrecognized text.', this.options.lexerErrorsAreRecoverable);

            var pendingInput = this._input;
            var activeCondition = this.topState();
            var conditionStackDepth = this.conditionStack.length;

            token = (this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR);
            if (token === this.ERROR) {
                // we can try to recover from a lexer error that \`parseError()\` did not 'recover' for us
                // by moving forward at least one character at a time IFF the (user-specified?) \`parseError()\`
                // has not consumed/modified any pending input or changed state in the error handler:
                if (!this.matches && 
                    // and make sure the input has been modified/consumed ...
                    pendingInput === this._input &&
                    // ...or the lexer state has been modified significantly enough
                    // to merit a non-consuming error handling action right now.
                    activeCondition === this.topState() && 
                    conditionStackDepth === this.conditionStack.length
                ) {
                    this.input();
                }
            }
            return token;
        }
    },

    /**
     * return next match that has a token
     * 
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
        var r;
        // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
        if (typeof this.pre_lex === 'function') {
            r = this.pre_lex.call(this, 0);
        }
        if (typeof this.options.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.pre_lex.call(this, r) || r;
        }
        if (this.yy && typeof this.yy.pre_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.pre_lex.call(this, r) || r;
        }

        while (!r) {
            r = this.next();
        }

        if (this.yy && typeof this.yy.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.yy.post_lex.call(this, r) || r;
        }
        if (typeof this.options.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.options.post_lex.call(this, r) || r;
        }
        if (typeof this.post_lex === 'function') {
            // (also account for a userdef function which does not return any value: keep the token as is)
            r = this.post_lex.call(this, r) || r;
        }
        return r;
    },

    /**
     * return next match that has a token. Identical to the \`lex()\` API but does not invoke any of the 
     * \`pre_lex()\` nor any of the \`post_lex()\` callbacks.
     * 
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
        var r;

        while (!r) {
            r = this.next();
        }

        return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     * 
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
        var rv = {
            fastLex: !(
                typeof this.pre_lex === 'function' ||
                typeof this.options.pre_lex === 'function' ||
                (this.yy && typeof this.yy.pre_lex === 'function') ||
                (this.yy && typeof this.yy.post_lex === 'function') ||
                typeof this.options.post_lex === 'function' ||
                typeof this.post_lex === 'function'
            ) && typeof this.fastLex === 'function',
        };
        return rv;
    },


    /**
     * backwards compatible alias for \`pushState()\`;
     * the latter is symmetrical with \`popState()\` and we advise to use
     * those APIs in any modern lexer code, rather than \`begin()\`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
        return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     * 
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
        this.conditionStack.push(condition);
        this.__currentRuleSet__ = null;
        return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
        var n = this.conditionStack.length - 1;
        if (n > 0) {
            this.__currentRuleSet__ = null; 
            return this.conditionStack.pop();
        } else {
            return this.conditionStack[0];
        }
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     * 
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
        n = this.conditionStack.length - 1 - Math.abs(n || 0);
        if (n >= 0) {
            return this.conditionStack[n];
        } else {
            return 'INITIAL';
        }
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     * 
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
        if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
            return this.conditions[this.conditionStack[this.conditionStack.length - 1]];
        } else {
            return this.conditions['INITIAL'];
        }
    },

    /**
     * return the number of states currently on the stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
        return this.conditionStack.length;
    }
}`;
    // --- END lexer kernel ---
}

RegExpLexer.prototype = (new Function(rmCommonWS$3`
    return ${getRegExpLexerPrototype()};
`))();


// The lexer code stripper, driven by optimization analysis settings and
// lexer options, which cannot be changed at run-time.
function stripUnusedLexerCode(src, opt) {
    //   uses yyleng: ..................... ${opt.lexerActionsUseYYLENG}
    //   uses yylineno: ................... ${opt.lexerActionsUseYYLINENO}
    //   uses yytext: ..................... ${opt.lexerActionsUseYYTEXT}
    //   uses yylloc: ..................... ${opt.lexerActionsUseYYLOC}
    //   uses ParseError API: ............. ${opt.lexerActionsUseParseError}
    //   uses location tracking & editing:  ${opt.lexerActionsUseLocationTracking}
    //   uses more() API: ................. ${opt.lexerActionsUseMore}
    //   uses unput() API: ................ ${opt.lexerActionsUseUnput}
    //   uses reject() API: ............... ${opt.lexerActionsUseReject}
    //   uses less() API: ................. ${opt.lexerActionsUseLess}
    //   uses display APIs pastInput(), upcomingInput(), showPosition():
    //        ............................. ${opt.lexerActionsUseDisplayAPIs}
    //   uses describeYYLLOC() API: ....... ${opt.lexerActionsUseDescribeYYLOC}

    var ast = helpers.parseCodeChunkToAST(src, opt);
    var new_src = helpers.prettyPrintAST(ast, opt);

new_src = new_src.replace(/\/\*\s*JISON-LEX-ANALYTICS-REPORT\s*\*\//g, rmCommonWS$3`
        // Code Generator Information Report
        // ---------------------------------
        //
        // Options:
        //
        //   backtracking: .................... ${opt.options.backtrack_lexer}
        //   location.ranges: ................. ${opt.options.ranges}
        //   location line+column tracking: ... ${opt.options.trackPosition}
        //
        //
        // Forwarded Parser Analysis flags:
        //
        //   uses yyleng: ..................... ${opt.parseActionsUseYYLENG}
        //   uses yylineno: ................... ${opt.parseActionsUseYYLINENO}
        //   uses yytext: ..................... ${opt.parseActionsUseYYTEXT}
        //   uses yylloc: ..................... ${opt.parseActionsUseYYLOC}
        //   uses lexer values: ............... ${opt.parseActionsUseValueTracking} / ${opt.parseActionsUseValueAssignment}
        //   location tracking: ............... ${opt.parseActionsUseLocationTracking}
        //   location assignment: ............. ${opt.parseActionsUseLocationAssignment}
        //
        //
        // Lexer Analysis flags:
        //
        //   uses yyleng: ..................... ${opt.lexerActionsUseYYLENG}
        //   uses yylineno: ................... ${opt.lexerActionsUseYYLINENO}
        //   uses yytext: ..................... ${opt.lexerActionsUseYYTEXT}
        //   uses yylloc: ..................... ${opt.lexerActionsUseYYLOC}
        //   uses ParseError API: ............. ${opt.lexerActionsUseParseError}
        //   uses yyerror: .................... ${opt.lexerActionsUseYYERROR}
        //   uses location tracking & editing:  ${opt.lexerActionsUseLocationTracking}
        //   uses more() API: ................. ${opt.lexerActionsUseMore}
        //   uses unput() API: ................ ${opt.lexerActionsUseUnput}
        //   uses reject() API: ............... ${opt.lexerActionsUseReject}
        //   uses less() API: ................. ${opt.lexerActionsUseLess}
        //   uses display APIs pastInput(), upcomingInput(), showPosition():
        //        ............................. ${opt.lexerActionsUseDisplayAPIs}
        //   uses describeYYLLOC() API: ....... ${opt.lexerActionsUseDescribeYYLOC}
        //
        // --------- END OF REPORT -----------

    `);

    return new_src;
}





// generate lexer source from a grammar
/**  @public */
function generate(dict, tokens, build_options) {
    var opt = processGrammar(dict, tokens, build_options);

    return generateFromOpts(opt);
}

// process the grammar and build final data structures and functions
/**  @public */
function processGrammar(dict, tokens, build_options) {
    build_options = build_options || {};
    var opts = {
        // include the knowledge passed through `build_options` about which lexer
        // features will actually be *used* by the environment (which in 99.9%
        // of cases is a jison *parser*):
        //
        // (this stuff comes straight from the jison Optimization Analysis.)
        //
        parseActionsUseYYLENG: build_options.parseActionsUseYYLENG,
        parseActionsUseYYLINENO: build_options.parseActionsUseYYLINENO,
        parseActionsUseYYTEXT: build_options.parseActionsUseYYTEXT,
        parseActionsUseYYLOC: build_options.parseActionsUseYYLOC,
        parseActionsUseParseError: build_options.parseActionsUseParseError,
        parseActionsUseYYERROR: build_options.parseActionsUseYYERROR,
        parseActionsUseYYERROK: build_options.parseActionsUseYYERROK,
        parseActionsUseYYRECOVERING: build_options.parseActionsUseYYRECOVERING,
        parseActionsUseYYCLEARIN: build_options.parseActionsUseYYCLEARIN,
        parseActionsUseValueTracking: build_options.parseActionsUseValueTracking,
        parseActionsUseValueAssignment: build_options.parseActionsUseValueAssignment,
        parseActionsUseLocationTracking: build_options.parseActionsUseLocationTracking,
        parseActionsUseLocationAssignment: build_options.parseActionsUseLocationAssignment,
        parseActionsUseYYSTACK: build_options.parseActionsUseYYSTACK,
        parseActionsUseYYSSTACK: build_options.parseActionsUseYYSSTACK,
        parseActionsUseYYSTACKPOINTER: build_options.parseActionsUseYYSTACKPOINTER,
        parseActionsUseYYRULELENGTH: build_options.parseActionsUseYYRULELENGTH,
        parserHasErrorRecovery: build_options.parserHasErrorRecovery,
        parserHasErrorReporting: build_options.parserHasErrorReporting,

        lexerActionsUseYYLENG: '???',
        lexerActionsUseYYLINENO: '???',
        lexerActionsUseYYTEXT: '???',
        lexerActionsUseYYLOC: '???',
        lexerActionsUseParseError: '???',
        lexerActionsUseYYERROR: '???',
        lexerActionsUseLocationTracking: '???',
        lexerActionsUseMore: '???',
        lexerActionsUseUnput: '???',
        lexerActionsUseReject: '???',
        lexerActionsUseLess: '???',
        lexerActionsUseDisplayAPIs: '???',
        lexerActionsUseDescribeYYLOC: '???',
    };

    dict = autodetectAndConvertToJSONformat$1(dict, build_options) || {};

    // Feed the possibly reprocessed 'dictionary' above back to the caller
    // (for use by our error diagnostic assistance code)
    opts.lex_rule_dictionary = dict;

    // Always provide the lexer with an options object, even if it's empty!
    // Make sure to camelCase all options:
    opts.options = mkStdOptions$1(build_options, dict.options);

    opts.moduleType = opts.options.moduleType;
    opts.moduleName = opts.options.moduleName;

    opts.conditions = prepareStartConditions(dict.startConditions);
    opts.conditions.INITIAL = {
        rules: [],
        inclusive: true
    };

    // only produce rule action code blocks when there are any rules at all;
    // a "custom lexer" has ZERO rules and must be defined entirely in 
    // other code blocks: 
    var code = (dict.rules ? buildActions(dict, tokens, opts) : {});
    opts.performAction = code.actions;
    opts.caseHelperInclude = code.caseHelperInclude;
    opts.rules = code.rules || [];
    opts.macros = code.macros;

    opts.regular_rule_count = code.regular_rule_count;
    opts.simple_rule_count = code.simple_rule_count;

    opts.conditionStack = ['INITIAL'];

    opts.actionInclude = (dict.actionInclude || '');
    opts.moduleInclude = (opts.moduleInclude || '') + (dict.moduleInclude || '').trim();

    return opts;
}

// Assemble the final source from the processed grammar
/**  @public */
function generateFromOpts(opt) {
    var code = '';

    switch (opt.moduleType) {
    case 'js':
        code = generateModule(opt);
        break;
    case 'amd':
        code = generateAMDModule(opt);
        break;
    case 'es':
        code = generateESModule(opt);
        break;
    case 'commonjs':
    default:
        code = generateCommonJSModule(opt);
        break;
    }

    return code;
}

function generateRegexesInitTableCode(opt) {
    var a = opt.rules;
    var print_xregexp = opt.options && opt.options.xregexp;
    var id_display_width = (1 + Math.log10(a.length | 1) | 0);
    var ws_prefix = new Array(id_display_width).join(' ');
    var b = a.map(function generateXRegExpInitCode(re, idx) {
        var idx_str = (ws_prefix + idx).substr(-id_display_width);

        if (re instanceof XRegExp) {
            // When we don't need the special XRegExp sauce at run-time, we do with the original
            // JavaScript RegExp instance a.k.a. 'native regex':
            if (re.xregexp.isNative || !print_xregexp) {
                return `/* ${idx_str}: */  ${re}`;
            }
            // And make sure to escape the regex to make it suitable for placement inside a *string*
            // as it is passed as a string argument to the XRegExp constructor here.
            var re_src = re.xregexp.source.replace(/[\\"]/g, '\\$&');
            return `/* ${idx_str}: */  new XRegExp("${re_src}", "${re.xregexp.flags}")`;
        } else {
            return `/* ${idx_str}: */  ${re}`;
        }
    });
    return b.join(',\n');
}

function generateModuleBody(opt) {
    // make the JSON output look more like JavaScript:
    function cleanupJSON(str) {
        str = str.replace(/  "rules": \[/g, '  rules: [');
        str = str.replace(/  "inclusive": /g, '  inclusive: ');
        return str;
    }

    function produceOptions(opts) {
        var obj = {};
        var do_not_pass = {
          debug: !opts.debug,     // do not include this item when it is FALSE as there's no debug tracing built into the generated grammar anyway!
          enableDebugLogs: 1,
          json: 1,
          _: 1,
          noMain: 1,
          dumpSourceCodeOnFailure: 1,
          throwErrorOnCompileFailure: 1,
          reportStats: 1,
          file: 1,
          outfile: 1,
          inputPath: 1,
          inputFilename: 1,
          defaultModuleName: 1,
          moduleName: 1,
          moduleType: 1,
          lexerErrorsAreRecoverable: 0,
          flex: 0,
          backtrack_lexer: 0,
          caseInsensitive: 0,
          showSource: 1,
          exportAST: 1,
          exportAllTables: 1,
          exportSourceCode: 1,
          prettyCfg: 1,
          parseActionsUseYYLENG: 1,
          parseActionsUseYYLINENO: 1,
          parseActionsUseYYTEXT: 1,
          parseActionsUseYYLOC: 1,
          parseActionsUseParseError: 1,
          parseActionsUseYYERROR: 1,
          parseActionsUseYYRECOVERING: 1,
          parseActionsUseYYERROK: 1,
          parseActionsUseYYCLEARIN: 1,
          parseActionsUseValueTracking: 1,
          parseActionsUseValueAssignment: 1,
          parseActionsUseLocationTracking: 1,
          parseActionsUseLocationAssignment: 1,
          parseActionsUseYYSTACK: 1,
          parseActionsUseYYSSTACK: 1,
          parseActionsUseYYSTACKPOINTER: 1,
          parseActionsUseYYRULELENGTH: 1,
          parserHasErrorRecovery: 1,
          parserHasErrorReporting: 1,
          lexerActionsUseYYLENG: 1,
          lexerActionsUseYYLINENO: 1,
          lexerActionsUseYYTEXT: 1,
          lexerActionsUseYYLOC: 1,
          lexerActionsUseParseError: 1,
          lexerActionsUseYYERROR: 1,
          lexerActionsUseLocationTracking: 1,
          lexerActionsUseMore: 1,
          lexerActionsUseUnput: 1,
          lexerActionsUseReject: 1,
          lexerActionsUseLess: 1,
          lexerActionsUseDisplayAPIs: 1,
          lexerActionsUseDescribeYYLOC: 1,
        };
        for (var k in opts) {
            if (!do_not_pass[k] && opts[k] != null && opts[k] !== false) {
                // make sure numeric values are encoded as numeric, the rest as boolean/string.
                if (typeof opts[k] === 'string') {
                    var f = parseFloat(opts[k]);
                    if (f == opts[k]) {
                        obj[k] = f;
                        continue;
                    }
                }
                obj[k] = opts[k];
            }
        }

        // And now some options which should receive some special processing:
        var pre = obj.pre_lex;
        var post = obj.post_lex;
        // since JSON cannot encode functions, we'll have to do it manually at run-time, i.e. later on:
        if (pre) {
            obj.pre_lex = true;
        }
        if (post) {
            obj.post_lex = true;
        }

        var js = JSON.stringify(obj, null, 2);

        js = js.replace(new XRegExp(`  "(${ID_REGEX_BASE$1})": `, 'g'), '  $1: ');
        js = js.replace(/^( +)pre_lex: true(,)?$/gm, function (m, ls, tc) {
            return ls + 'pre_lex: ' + String(pre) + (tc || '');
        });
        js = js.replace(/^( +)post_lex: true(,)?$/gm, function (m, ls, tc) {
            return ls + 'post_lex: ' + String(post) + (tc || '');
        });
        return js;
    }


    var out;
    if (opt.rules.length > 0 || opt.__in_rules_failure_analysis_mode__) {
        // we don't mind that the `test_me()` code above will have this `lexer` variable re-defined:
        // JavaScript is fine with that.
        var code = [rmCommonWS$3`
            var lexer = {
            `, '/*JISON-LEX-ANALYTICS-REPORT*/' /* slot #1: placeholder for analysis report further below */
        ];

        // get the RegExpLexer.prototype in source code form:
        var protosrc = getRegExpLexerPrototype();
        // and strip off the surrounding bits we don't want:
        protosrc = protosrc
        .replace(/^[\s\r\n]*\{/, '')
        .replace(/\s*\}[\s\r\n]*$/, '')
        .trim();
        code.push(protosrc + ',\n');

        assert(opt.options);
        // Assure all options are camelCased:
        assert(typeof opt.options['case-insensitive'] === 'undefined');

        code.push('    options: ' + produceOptions(opt.options));
  
/*
        function isEmpty(code) {
            switch (typeof code) {
            case 'undefined':
            case 'null':
                return true;

            case 'string':

            } 
        }
*/        
        
        var performActionCode = String(opt.performAction);
        var simpleCaseActionClustersCode = String(opt.caseHelperInclude);
        var rulesCode = generateRegexesInitTableCode(opt);
        var conditionsCode = cleanupJSON(JSON.stringify(opt.conditions, null, 2));
        code.push(rmCommonWS$3`,
            JisonLexerError: JisonLexerError,
            performAction: ${performActionCode},
            simpleCaseActionClusters: ${simpleCaseActionClustersCode},
            rules: [
                ${rulesCode}
            ],
            conditions: ${conditionsCode}
        };
        `);

        opt.is_custom_lexer = false;

        out = code.join('');
    } else {
        // We're clearly looking at a custom lexer here as there's no lexer rules at all.
        //
        // We are re-purposing the `%{...%}` `actionInclude` code block here as it serves no purpose otherwise.
        //
        // Meanwhile we make sure we have the `lexer` variable declared in *local scope* no matter
        // what crazy stuff (or lack thereof) the userland code is pulling in the `actionInclude` chunk.
        out = 'var lexer;\n';

        assert(opt.regular_rule_count === 0);
        assert(opt.simple_rule_count === 0);
        opt.is_custom_lexer = true;

        if (opt.actionInclude) {
            out += opt.actionInclude + (!opt.actionInclude.match(/;[\s\r\n]*$/) ? ';' : '') + '\n';
        }
    }

    // The output of this function is guaranteed to read something like this:
    //
    // ```
    // var lexer;
    //
    // bla bla bla bla ... lotsa bla bla;
    // ```
    //
    // and that should work nicely as an `eval()`-able piece of source code.
    return out;
}

function generateGenericHeaderComment() {
    var out = rmCommonWS$3`
    /* lexer generated by jison-lex ${version$2} */

    /*
     * Returns a Lexer object of the following structure:
     *
     *  Lexer: {
     *    yy: {}     The so-called "shared state" or rather the *source* of it;
     *               the real "shared state" \`yy\` passed around to
     *               the rule actions, etc. is a direct reference!
     *
     *               This "shared context" object was passed to the lexer by way of 
     *               the \`lexer.setInput(str, yy)\` API before you may use it.
     *
     *               This "shared context" object is passed to the lexer action code in \`performAction()\`
     *               so userland code in the lexer actions may communicate with the outside world 
     *               and/or other lexer rules' actions in more or less complex ways.
     *
     *  }
     *
     *  Lexer.prototype: {
     *    EOF: 1,
     *    ERROR: 2,
     *
     *    yy:        The overall "shared context" object reference.
     *
     *    JisonLexerError: function(msg, hash),
     *
     *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
     *
     *               The function parameters and \`this\` have the following value/meaning:
     *               - \`this\`    : reference to the \`lexer\` instance. 
     *                               \`yy_\` is an alias for \`this\` lexer instance reference used internally.
     *
     *               - \`yy\`      : a reference to the \`yy\` "shared state" object which was passed to the lexer
     *                             by way of the \`lexer.setInput(str, yy)\` API before.
     *
     *                             Note:
     *                             The extra arguments you specified in the \`%parse-param\` statement in your
     *                             **parser** grammar definition file are passed to the lexer via this object
     *                             reference as member variables.
     *
     *               - \`yyrulenumber\`   : index of the matched lexer rule (regex), used internally.
     *
     *               - \`YY_START\`: the current lexer "start condition" state.
     *
     *    parseError: function(str, hash, ExceptionClass),
     *
     *    constructLexErrorInfo: function(error_message, is_recoverable),
     *               Helper function.
     *               Produces a new errorInfo \'hash object\' which can be passed into \`parseError()\`.
     *               See it\'s use in this lexer kernel in many places; example usage:
     *
     *                   var infoObj = lexer.constructParseErrorInfo(\'fail!\', true);
     *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
     *
     *    options: { ... lexer %options ... },
     *
     *    lex: function(),
     *               Produce one token of lexed input, which was passed in earlier via the \`lexer.setInput()\` API.
     *               You MAY use the additional \`args...\` parameters as per \`%parse-param\` spec of the **lexer** grammar:
     *               these extra \`args...\` are added verbatim to the \`yy\` object reference as member variables.
     *
     *               WARNING:
     *               Lexer's additional \`args...\` parameters (via lexer's \`%parse-param\`) MAY conflict with
     *               any attributes already added to \`yy\` by the **parser** or the jison run-time; 
     *               when such a collision is detected an exception is thrown to prevent the generated run-time 
     *               from silently accepting this confusing and potentially hazardous situation! 
     *
     *    cleanupAfterLex: function(do_not_nuke_errorinfos),
     *               Helper function.
     *
     *               This helper API is invoked when the **parse process** has completed: it is the responsibility
     *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired. 
     *
     *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
     *
     *    setInput: function(input, [yy]),
     *
     *
     *    input: function(),
     *
     *
     *    unput: function(str),
     *
     *
     *    more: function(),
     *
     *
     *    reject: function(),
     *
     *
     *    less: function(n),
     *
     *
     *    pastInput: function(n),
     *
     *
     *    upcomingInput: function(n),
     *
     *
     *    showPosition: function(),
     *
     *
     *    test_match: function(regex_match_array, rule_index),
     *
     *
     *    next: function(),
     *
     *
     *    begin: function(condition),
     *
     *
     *    pushState: function(condition),
     *
     *
     *    popState: function(),
     *
     *
     *    topState: function(),
     *
     *
     *    _currentRules: function(),
     *
     *
     *    stateStackSize: function(),
     *
     *
     *    performAction: function(yy, yy_, yyrulenumber, YY_START),
     *
     *
     *    rules: [...],
     *
     *
     *    conditions: {associative list: name ==> set},
     *  }
     *
     *
     *  token location info (\`yylloc\`): {
     *    first_line: n,
     *    last_line: n,
     *    first_column: n,
     *    last_column: n,
     *    range: [start_number, end_number]
     *               (where the numbers are indexes into the input string, zero-based)
     *  }
     *
     * ---
     *
     * The \`parseError\` function receives a \'hash\' object with these members for lexer errors:
     *
     *  {
     *    text:        (matched text)
     *    token:       (the produced terminal token, if any)
     *    token_id:    (the produced terminal token numeric ID, if any)
     *    line:        (yylineno)
     *    loc:         (yylloc)
     *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
     *                  available for this particular error)
     *    yy:          (object: the current parser internal "shared state" \`yy\`
     *                  as is also available in the rule actions; this can be used,
     *                  for instance, for advanced error analysis and reporting)
     *    lexer:       (reference to the current lexer instance used by the parser)
     *  }
     *
     * while \`this\` will reference the current lexer instance.
     *
     * When \`parseError\` is invoked by the lexer, the default implementation will
     * attempt to invoke \`yy.parser.parseError()\`; when this callback is not provided
     * it will try to invoke \`yy.parseError()\` instead. When that callback is also not
     * provided, a \`JisonLexerError\` exception will be thrown containing the error
     * message and \`hash\`, as constructed by the \`constructLexErrorInfo()\` API.
     *
     * Note that the lexer\'s \`JisonLexerError\` error class is passed via the
     * \`ExceptionClass\` argument, which is invoked to construct the exception
     * instance to be thrown, so technically \`parseError\` will throw the object
     * produced by the \`new ExceptionClass(str, hash)\` JavaScript expression.
     *
     * ---
     *
     * You can specify lexer options by setting / modifying the \`.options\` object of your Lexer instance.
     * These options are available:
     *
     * (Options are permanent.)
     *  
     *  yy: {
     *      parseError: function(str, hash, ExceptionClass)
     *                 optional: overrides the default \`parseError\` function.
     *  }
     *
     *  lexer.options: {
     *      pre_lex:  function()
     *                 optional: is invoked before the lexer is invoked to produce another token.
     *                 \`this\` refers to the Lexer object.
     *      post_lex: function(token) { return token; }
     *                 optional: is invoked when the lexer has produced a token \`token\`;
     *                 this function can override the returned token value by returning another.
     *                 When it does not return any (truthy) value, the lexer will return
     *                 the original \`token\`.
     *                 \`this\` refers to the Lexer object.
     *
     * WARNING: the next set of options are not meant to be changed. They echo the abilities of
     * the lexer as per when it was compiled!
     *
     *      ranges: boolean
     *                 optional: \`true\` ==> token location info will include a .range[] member.
     *      flex: boolean
     *                 optional: \`true\` ==> flex-like lexing behaviour where the rules are tested
     *                 exhaustively to find the longest match.
     *      backtrack_lexer: boolean
     *                 optional: \`true\` ==> lexer regexes are tested in order and for invoked;
     *                 the lexer terminates the scan when a token is returned by the action code.
     *      xregexp: boolean
     *                 optional: \`true\` ==> lexer rule regexes are "extended regex format" requiring the
     *                 \`XRegExp\` library. When this %option has not been specified at compile time, all lexer
     *                 rule regexes have been written as standard JavaScript RegExp expressions.
     *  }
     */
     `;

    return out;
}

function prepareOptions(opt) {
    opt = opt || {};

    // check for illegal identifier
    if (!opt.moduleName || !opt.moduleName.match(/^[a-zA-Z_$][a-zA-Z0-9_$\.]*$/)) {
        if (opt.moduleName) {
            var msg = 'WARNING: The specified moduleName "' + opt.moduleName + '" is illegal (only characters [a-zA-Z0-9_$] and "." dot are accepted); using the default moduleName "lexer" instead.';
            if (typeof opt.warn_cb === 'function') {
                opt.warn_cb(msg);
            } else {
                // do not treat as warning; barf hairball instead so that this oddity gets noticed right away!
                throw new Error(msg);
            }
        }
        opt.moduleName = 'lexer';
    }

    prepExportStructures$1(opt);

    return opt;
}

function generateModule(opt) {
    opt = prepareOptions(opt);

    var out = [
        generateGenericHeaderComment(),
        '',
        'var ' + opt.moduleName + ' = (function () {',
        jisonLexerErrorDefinition,
        '',
        generateModuleBody(opt),
        '',
        (opt.moduleInclude ? opt.moduleInclude + ';' : ''),
        '',
        'return lexer;',
        '})();'
    ];

    var src = out.join('\n') + '\n';
    src = stripUnusedLexerCode(src, opt);
    opt.exportSourceCode.all = src;   
    return src;
}

function generateAMDModule(opt) {
    opt = prepareOptions(opt);

    var out = [
        generateGenericHeaderComment(),
        '',
        'define([], function () {',
        jisonLexerErrorDefinition,
        '',
        generateModuleBody(opt),
        '',
        (opt.moduleInclude ? opt.moduleInclude + ';' : ''),
        '',
        'return lexer;',
        '});'
    ];

    var src = out.join('\n') + '\n';
    src = stripUnusedLexerCode(src, opt);
    opt.exportSourceCode.all = src;   
    return src;
}

function generateESModule(opt) {
    opt = prepareOptions(opt);

    var out = [
        generateGenericHeaderComment(),
        '',
        'var lexer = (function () {',
        jisonLexerErrorDefinition,
        '',
        generateModuleBody(opt),
        '',
        (opt.moduleInclude ? opt.moduleInclude + ';' : ''),
        '',
        'return lexer;',
        '})();',
        '',
        'function yylex() {',
        '    return lexer.lex.apply(lexer, arguments);',
        '}',
        rmCommonWS$3`
            export {
                lexer,
                yylex as lex
            };
        `
    ];

    var src = out.join('\n') + '\n';
    src = stripUnusedLexerCode(src, opt);
    opt.exportSourceCode.all = src;   
    return src;
}

function generateCommonJSModule(opt) {
    opt = prepareOptions(opt);

    var out = [
        generateGenericHeaderComment(),
        '',
        'var ' + opt.moduleName + ' = (function () {',
        jisonLexerErrorDefinition,
        '',
        generateModuleBody(opt),
        '',
        (opt.moduleInclude ? opt.moduleInclude + ';' : ''),
        '',
        'return lexer;',
        '})();',
        '',
        'if (typeof require !== \'undefined\' && typeof exports !== \'undefined\') {',
        '  exports.lexer = ' + opt.moduleName + ';',
        '  exports.lex = function () {',
        '    return ' + opt.moduleName + '.lex.apply(lexer, arguments);',
        '  };',
        '}'
    ];

    var src = out.join('\n') + '\n';
    src = stripUnusedLexerCode(src, opt);
    opt.exportSourceCode.all = src;   
    return src;
}

RegExpLexer.generate = generate;

RegExpLexer.version = version$2;
RegExpLexer.defaultJisonLexOptions = defaultJisonLexOptions;
RegExpLexer.mkStdOptions = mkStdOptions$1;
RegExpLexer.camelCase = helpers.camelCase;
RegExpLexer.mkIdentifier = mkIdentifier$4;
RegExpLexer.autodetectAndConvertToJSONformat = autodetectAndConvertToJSONformat$1;

/* parser generated by jison 0.6.1-214 */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `quoteName()` to reference this function
 *               at the end of the `parse()`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `yyval` internal object, which has members (`$` and `_$`)
 *                             to store/reference the rule value `$$` and location info `@$`.
 *
 *                 One important thing to note about `this` a.k.a. `yyval`: every *reduce* action gets
 *                 to see the same object via the `this` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use `yyval` a.k.a. `this` for storing you own semi-permanent data.
 *
 *                 `this.yy` is a direct reference to the `yy` shared state object.
 *
 *                 `%parse-param`-specified additional `parse()` arguments have been added to this `yy`
 *                 object at `parse()` start and are therefore available to the action code via the
 *                 same named `yy.xxxx` attributes (where `xxxx` represents a identifier name from
 *                 the %parse-param` list.
 *
 *               - `yytext`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, `yytext` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - `yyleng`  : ditto as `yytext`, only now for the lexer.yyleng value.
 *
 *               - `yylineno`: ditto as `yytext`, only now for the lexer.yylineno value.
 *
 *               - `yyloc`   : ditto as `yytext`, only now for the lexer.yylloc lexer token location info.
 *
 *                               WARNING: since jison 0.4.18-186 this entry may be NULL/UNDEFINED instead
 *                               of an empty object when no suitable location info can be provided.
 *
 *               - `yystate` : the current parser state number, used internally for dispatching and
 *                               executing the action code chunk matching the rule currently being reduced.
 *
 *               - `yysp`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. `##$ === ##0 === yysp`, while `##1` is the stack index for all things
 *                 related to the first rule term, just like you have `$1`, `@1` and `#1`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - `yyrulelength`: the current rule's term count, i.e. the number of entries occupied on the stack.
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *               - `yyvstack`: reference to the parser value stack. Also accessed via the `$1` etc.
 *                             constructs.
 *
 *               - `yylstack`: reference to the parser token location stack. Also accessed via
 *                             the `@1` etc. constructs.
 *
 *                             WARNING: since jison 0.4.18-186 this array MAY contain slots which are
 *                             UNDEFINED rather than an empty (location) object, when the lexer/parser
 *                             action code did not provide a suitable location info object when such a
 *                             slot was filled!
 *
 *               - `yystack` : reference to the parser token id stack. Also accessed via the
 *                             `#1` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any `#n` reference to
 *                 its numeric token id value, hence that code wouldn't need the `yystack` but *you* might
 *                 want access this array for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - `yysstack`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in `yystate`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - `...`     : the extra arguments you specified in the `%parse-param` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - `state`  --> hash table
 *               - `symbol` --> action (number or array)
 *
 *                 If the `action` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO `state`
 *
 *                 If the `action` is a number, it is the GOTO `state`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   var infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   var retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic `parseError` handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `parseError()` to reference this function
 *               at the end of the `parse()`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given `input` and return the parsed value (or `true` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of this grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Parser's additional `args...` parameters (via `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *               The lexer MAY add its own set of additional parameters (via the `%parse-param` line in
 *               the lexer section of the grammar spec): these will be inserted in the `yy` shared state
 *               object and any collision with those will be reported by the lexer via a thrown exception.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API is invoked at the end of the `parse()` call, unless an exception was thrown
 *               and `%options no-try-catch` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the `post_parse` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    yyMergeLocationInfo: function(first_index, last_index, first_yylloc, last_yylloc, dont_look_back),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API can be invoked to calculate a spanning `yylloc` location info object.
 *
 *               Note: %epsilon rules MAY specify no `first_index` and `first_yylloc`, in which case
 *               this function will attempt to obtain a suitable location marker by inspecting the location stack
 *               backwards.
 *
 *               For more info see the documentation comment further below, immediately above this function's
 *               implementation.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" `yy` once
 *                             received via a call to the `.setInput(input, yy)` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the `collect_expected_token_set()`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal `$$` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while `this` will reference the current parser instance.
 *
 * When `parseError` is invoked by the lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When `parseError` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the `expected` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the `.yy` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy)
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`.
 *  Parser.post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`. When it does not return any value,
 *                 the parser will return the original `retval`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy)
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of `lex()`) but immediately after the invocation of
 *                 `parser.pre_parse()`).
 *      post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 `retval` contains the return value to be produced by `Parser.parse()`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 `retval`.
 *                 This function is invoked immediately before `parser.post_parse()`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *      quoteName: function(name),
 *                 optional: overrides the default `quoteName` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this `%option` has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError$2(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError$2.prototype, Error.prototype);
} else {
    JisonParserError$2.prototype = Object.create(Error.prototype);
}
JisonParserError$2.prototype.constructor = JisonParserError$2;
JisonParserError$2.prototype.name = 'JisonParserError';



        // helper: reconstruct the productions[] table
        function bp$2(s) {
            var rv = [];
            var p = s.pop;
            var r = s.rule;
            for (var i = 0, l = p.length; i < l; i++) {
                rv.push([
                    p[i],
                    r[i]
                ]);
            }
            return rv;
        }
    




        // helper: reconstruct the 'goto' table
        function bt$2(s) {
            var rv = [];
            var d = s.len;
            var y = s.symbol;
            var t = s.type;
            var a = s.state;
            var m = s.mode;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var n = d[i];
                var q = {};
                for (var j = 0; j < n; j++) {
                    var z = y.shift();
                    switch (t.shift()) {
                    case 2:
                        q[z] = [
                            m.shift(),
                            g.shift()
                        ];
                        break;

                    case 0:
                        q[z] = a.shift();
                        break;

                    default:
                        // type === 1: accept
                        q[z] = [
                            3
                        ];
                    }
                }
                rv.push(q);
            }
            return rv;
        }
    


        // helper: runlength encoding with increment step: code, length: step (default step = 0)
        // `this` references an array
        function s$2(c, l, a) {
            a = a || 0;
            for (var i = 0; i < l; i++) {
                this.push(c);
                c += a;
            }
        }

        // helper: duplicate sequence from *relative* offset and length.
        // `this` references an array
        function c$2(i, l) {
            i = this.length - i;
            for (l += i; i < l; i++) {
                this.push(this[i]);
            }
        }

        // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
        function u$2(a) {
            var rv = [];
            for (var i = 0, l = a.length; i < l; i++) {
                var e = a[i];
                // Is this entry a helper function?
                if (typeof e === 'function') {
                    i++;
                    e.apply(rv, a[i]);
                } else {
                    rv.push(e);
                }
            }
            return rv;
        }
    

var parser$3 = {
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   default action mode: ............. classic,merge
    //   try..catch: ...................... true
    //   default resolve on conflict: ..... true
    //   on-demand look-ahead: ............ false
    //   error recovery token skip maximum: 3
    //   yyerror in parse actions is: ..... NOT recoverable,
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. NOT recoverable,
    //   debug grammar/output: ............ false
    //   has partial LR conflict upgrade:   true
    //   rudimentary token-stack support:   false
    //   parser table compression mode: ... 2
    //   export debug tables: ............. false
    //   export *all* tables: ............. false
    //   module type: ..................... es
    //   parser engine type: .............. lalr
    //   output main() in the module: ..... true
    //   has user-specified main(): ....... false
    //   has user-specified require()/import modules for main():
    //   .................................. false
    //   number of expected conflicts: .... 0
    //
    //
    // Parser Analysis flags:
    //
    //   no significant actions (parser is a language matcher only):
    //   .................................. false
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses ParseError API: ............. false
    //   uses YYERROR: .................... false
    //   uses YYRECOVERING: ............... false
    //   uses YYERROK: .................... false
    //   uses YYCLEARIN: .................. false
    //   tracks rule values: .............. true
    //   assigns rule values: ............. true
    //   uses location tracking: .......... false
    //   assigns location: ................ false
    //   uses yystack: .................... false
    //   uses yysstack: ................... false
    //   uses yysp: ....................... true
    //   uses yyrulelength: ............... false
    //   uses yyMergeLocationInfo API: .... false
    //   has error recovery: .............. false
    //   has error reporting: ............. false
    //
    // --------- END OF REPORT -----------

trace: function no_op_trace() {},
JisonParserError: JisonParserError$2,
yy: {},
options: {
  type: "lalr",
  hasPartialLrUpgradeOnConflict: true,
  errorRecoveryTokenDiscardCount: 3
},
symbols_: {
  "$accept": 0,
  "$end": 1,
  "(": 4,
  ")": 5,
  "*": 6,
  "+": 8,
  "?": 7,
  "ALIAS": 9,
  "EOF": 1,
  "SYMBOL": 10,
  "error": 2,
  "expression": 16,
  "handle": 13,
  "handle_list": 12,
  "production": 11,
  "rule": 14,
  "suffix": 17,
  "suffixed_expression": 15,
  "|": 3
},
terminals_: {
  1: "EOF",
  2: "error",
  3: "|",
  4: "(",
  5: ")",
  6: "*",
  7: "?",
  8: "+",
  9: "ALIAS",
  10: "SYMBOL"
},
TERROR: 2,
EOF: 1,

// internals: defined here so the object *structure* doesn't get modified by parse() et al,
// thus helping JIT compilers like Chrome V8.
originalQuoteName: null,
originalParseError: null,
cleanupAfterParse: null,
constructParseErrorInfo: null,
yyMergeLocationInfo: null,

__reentrant_call_depth: 0, // INTERNAL USE ONLY
__error_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
__error_recovery_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

// APIs which will be set up depending on user action code analysis:
//yyRecovering: 0,
//yyErrOk: 0,
//yyClearIn: 0,

// Helper APIs
// -----------

// Helper function which can be overridden by user code later on: put suitable quotes around
// literal IDs in a description string.
quoteName: function parser_quoteName(id_str) {
    return '"' + id_str + '"';
},

// Return the name of the given symbol (terminal or non-terminal) as a string, when available.
//
// Return NULL when the symbol is unknown to the parser.
getSymbolName: function parser_getSymbolName(symbol) {
    if (this.terminals_[symbol]) {
        return this.terminals_[symbol];
    }

    // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
    //
    // An example of this may be where a rule's action code contains a call like this:
    //
    //      parser.getSymbolName(#$)
    //
    // to obtain a human-readable name of the current grammar rule.
    var s = this.symbols_;
    for (var key in s) {
        if (s[key] === symbol) {
            return key;
        }
    }
    return null;
},

// Return a more-or-less human-readable description of the given symbol, when available,
// or the symbol itself, serving as its own 'description' for lack of something better to serve up.
//
// Return NULL when the symbol is unknown to the parser.
describeSymbol: function parser_describeSymbol(symbol) {
    if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
        return this.terminal_descriptions_[symbol];
    } else if (symbol === this.EOF) {
        return 'end of input';
    }
    var id = this.getSymbolName(symbol);
    if (id) {
        return this.quoteName(id);
    }
    return null;
},

// Produce a (more or less) human-readable list of expected tokens at the point of failure.
//
// The produced list may contain token or token set descriptions instead of the tokens
// themselves to help turning this output into something that easier to read by humans
// unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
// expected terminals and nonterminals is produced.
//
// The returned list (array) will not contain any duplicate entries.
collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
    var TERROR = this.TERROR;
    var tokenset = [];
    var check = {};
    // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
    // If so, use that one instead of the less palatable token set.
    if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
        return [this.state_descriptions_[state]];
    }
    for (var p in this.table[state]) {
        p = +p;
        if (p !== TERROR) {
            var d = do_not_describe ? p : this.describeSymbol(p);
            if (d && !check[d]) {
                tokenset.push(d);
                check[d] = true; // Mark this token description as already mentioned to prevent outputting duplicate entries.
            }
        }
    }
    return tokenset;
},
productions_: bp$2({
  pop: u$2([
  11,
  12,
  12,
  13,
  13,
  14,
  14,
  15,
  15,
  16,
  16,
  s$2,
  [17, 4]
]),
  rule: u$2([
  2,
  1,
  3,
  0,
  1,
  1,
  2,
  3,
  c$2,
  [8, 6],
  1
])
}),
performAction: function parser__PerformAction(yystate /* action[1] */, yysp, yyvstack) {

          /* this == yyval */

          // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
          var yy = this.yy;
          var yyparser = yy.parser;
          var yylexer = yy.lexer;

          

          switch (yystate) {
case 0:
    /*! Production::    $accept : production $end */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,-,-,-,-):
    this.$ = yyvstack[yysp - 1];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,-,-,-,-)
    break;

case 1:
    /*! Production::    production : handle EOF */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,-,-,-,-):
    this.$ = yyvstack[yysp - 1];
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,-,-,-,-)
    
    
    return yyvstack[yysp - 1];
    break;

case 2:
    /*! Production::    handle_list : handle */
case 6:
    /*! Production::    rule : suffixed_expression */

    this.$ = [yyvstack[yysp]];
    break;

case 3:
    /*! Production::    handle_list : handle_list "|" handle */

    yyvstack[yysp - 2].push(yyvstack[yysp]);
    this.$ = yyvstack[yysp - 2];
    break;

case 4:
    /*! Production::    handle : %epsilon */

    this.$ = [];
    break;

case 5:
    /*! Production::    handle : rule */
case 13:
    /*! Production::    suffix : "*" */
case 14:
    /*! Production::    suffix : "?" */
case 15:
    /*! Production::    suffix : "+" */

    this.$ = yyvstack[yysp];
    break;

case 7:
    /*! Production::    rule : rule suffixed_expression */

    yyvstack[yysp - 1].push(yyvstack[yysp]);
    this.$ = yyvstack[yysp - 1];
    break;

case 8:
    /*! Production::    suffixed_expression : expression suffix ALIAS */

    this.$ = ['xalias', yyvstack[yysp - 1], yyvstack[yysp - 2], yyvstack[yysp]];
    break;

case 9:
    /*! Production::    suffixed_expression : expression suffix */

    if (yyvstack[yysp]) {
      this.$ = [yyvstack[yysp], yyvstack[yysp - 1]];
    } else {
      this.$ = yyvstack[yysp - 1];
    }
    break;

case 10:
    /*! Production::    expression : SYMBOL */

    this.$ = ['symbol', yyvstack[yysp]];
    break;

case 11:
    /*! Production::    expression : "(" handle_list ")" */

    this.$ = ['()', yyvstack[yysp - 1]];
    break;

case 12:
    /*! Production::    suffix : %epsilon */

    this.$ = undefined;
    break;

}
},
table: bt$2({
  len: u$2([
  8,
  1,
  1,
  7,
  0,
  10,
  0,
  9,
  0,
  0,
  6,
  s$2,
  [0, 3],
  2,
  s$2,
  [0, 3],
  8,
  0
]),
  symbol: u$2([
  1,
  4,
  10,
  11,
  s$2,
  [13, 4, 1],
  s$2,
  [1, 3],
  3,
  4,
  5,
  10,
  c$2,
  [9, 3],
  s$2,
  [3, 8, 1],
  17,
  c$2,
  [16, 4],
  s$2,
  [12, 5, 1],
  c$2,
  [19, 4],
  9,
  10,
  3,
  5,
  c$2,
  [17, 4],
  c$2,
  [16, 4]
]),
  type: u$2([
  s$2,
  [2, 3],
  s$2,
  [0, 5],
  1,
  s$2,
  [2, 6],
  0,
  0,
  s$2,
  [2, 9],
  c$2,
  [10, 5],
  s$2,
  [0, 5],
  s$2,
  [2, 12],
  s$2,
  [0, 4]
]),
  state: u$2([
  s$2,
  [1, 5, 1],
  9,
  5,
  10,
  14,
  15,
  c$2,
  [8, 3],
  19,
  c$2,
  [4, 3]
]),
  mode: u$2([
  2,
  s$2,
  [1, 3],
  2,
  2,
  1,
  2,
  c$2,
  [5, 3],
  c$2,
  [7, 3],
  c$2,
  [12, 4],
  c$2,
  [13, 9],
  c$2,
  [15, 3],
  c$2,
  [5, 4]
]),
  goto: u$2([
  4,
  7,
  6,
  8,
  5,
  5,
  7,
  5,
  6,
  s$2,
  [12, 4],
  11,
  12,
  13,
  12,
  12,
  4,
  7,
  4,
  6,
  s$2,
  [9, 4],
  16,
  9,
  18,
  17,
  c$2,
  [12, 4]
])
}),
defaultActions: {
  4: 6,
  6: 10,
  8: 1,
  9: 7,
  11: 13,
  12: 14,
  13: 15,
  15: 2,
  16: 8,
  17: 11,
  19: 3
},
parseError: function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable) {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
},
parse: function parse(input) {
    var self = this;
    var stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
    var sstack = new Array(128);        // state stack: stores states (column storage)

    var vstack = new Array(128);        // semantic value stack

    var table = this.table;
    var sp = 0;                         // 'stack pointer': index into the stacks


    


    var symbol = 0;



    var TERROR = this.TERROR;
    var EOF = this.EOF;
    var ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    var NO_ACTION = [0, 20 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

    var lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    var sharedState_yy = {
        parseError: undefined,
        quoteName: undefined,
        lexer: undefined,
        parser: undefined,
        pre_parse: undefined,
        post_parse: undefined,
        pre_lex: undefined,
        post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly in both ES5 and ES6 modes!
    };

    this.yyGetSharedState = function yyGetSharedState() {
        return sharedState_yy;
    };








    function shallow_copy_noclobber(dst, src) {
        for (var k in src) {
            if (typeof dst[k] === 'undefined' && Object.prototype.hasOwnProperty.call(src, k)) {
                dst[k] = src[k];
            }
        }
    }

    // copy state
    shallow_copy_noclobber(sharedState_yy, this.yy);

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;






    // Does the shared state override the default `parseError` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default `quoteName` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = function quoteNameAlt(id_str) {
            return sharedState_yy.quoteName.call(this, id_str);
        };
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a `finally { ... }` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `sharedState`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        var rv;

        if (invoke_post_methods) {
            var hash;

            if (sharedState_yy.post_parse || this.post_parse) {
                // create an error hash info instance: we re-use this API in a **non-error situation**
                // as this one delivers all parser internals ready for access by userland code.
                hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
            }

            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }

            // cleanup:
            if (hash && hash.destroy) {
                hash.destroy();
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;

        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;


        }

        return resultValue;
    };






































































































































    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        var pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: lexer.yytext,
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,

            expected: expected,
            recoverable: recoverable,
            state: state,
            action: action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,

            stack_pointer: sp,
            yy: sharedState_yy,
            lexer: lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };













    function stdLex() {
        var token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    function fastLex() {
        var token = lexer.fastLex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    var lex = stdLex;


    var state, action, r, t;
    var yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    var p;
    var yyrulelen;
    var this_production;
    var newState;
    var retval = false;


    try {
        this.__reentrant_call_depth++;

        lexer.setInput(input, sharedState_yy);

        // NOTE: we *assume* no lexer pre/post handlers are set up *after* 
        // this initial `setInput()` call: hence we can now check and decide
        // whether we'll go with the standard, slower, lex() API or the
        // `fast_lex()` one:
        if (typeof lexer.canIUse === 'function') {
            var lexerInfo = lexer.canIUse();
            if (lexerInfo.fastLex && typeof fastLex === 'function') {
                lex = fastLex;
            }
        } 



        vstack[sp] = null;
        sstack[sp] = 0;
        stack[sp] = 0;
        ++sp;





        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single `==` condition below covers both these `===` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];











                // handle parse error
                if (!action) {
                    var errStr;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    // Report error
                    if (typeof lexer.yylineno === 'number') {
                        errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                    } else {
                        errStr = 'Parse error: ';
                    }
                    if (typeof lexer.showPosition === 'function') {
                        errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                    }
                    if (expected.length) {
                        errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                    } else {
                        errStr += 'Unexpected ' + errSymbolDescr;
                    }
                    // we cannot recover from the error!
                    p = this.constructParseErrorInfo(errStr, null, expected, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }


            }










            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                r = this.parseError(p.errStr, p, this.JisonParserError);
                if (typeof r !== 'undefined') {
                    retval = r;
                }
                break;

            // shift:
            case 1:
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;

                sstack[sp] = newState; // push state

                ++sp;
                symbol = 0;




                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:




                continue;

            // reduce:
            case 2:



                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                yyrulelen = this_production[1];










                r = this.performAction.call(yyval, newState, sp - 1, vstack);

                if (typeof r !== 'undefined') {
                    retval = r;
                    break;
                }

                // pop off stack
                sp -= yyrulelen;

                // don't overwrite the `symbol` variable: use a local var to speed things up:
                var ntsymbol = this_production[0];    // push nonterminal (reduce)
                stack[sp] = ntsymbol;
                vstack[sp] = yyval.$;

                // goto new state = table[STATE][NONTERMINAL]
                newState = table[sstack[sp - 1]][ntsymbol];
                sstack[sp] = newState;
                ++sp;









                continue;

            // accept:
            case 3:
                if (sp !== -2) {
                    retval = true;
                    // Return the `$accept` rule's `$$` result, if available.
                    //
                    // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                    // default, action):
                    //
                    //     $accept: <startSymbol> $end
                    //                  %{ $$ = $1; @$ = @1; %}
                    //
                    // which, combined with the parse kernel's `$accept` state behaviour coded below,
                    // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                    // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                    //
                    // In code:
                    //
                    //                  %{
                    //                      @$ = @1;            // if location tracking support is included
                    //                      if (typeof $1 !== 'undefined')
                    //                          return $1;
                    //                      else
                    //                          return true;           // the default parse result if the rule actions don't produce anything
                    //                  %}
                    sp--;
                    if (typeof vstack[sp] !== 'undefined') {
                        retval = vstack[sp];
                    }
                }
                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        }
        else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }
        else {
            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;
    }   // /finally

    return retval;
}
};
parser$3.originalParseError = parser$3.parseError;
parser$3.originalQuoteName = parser$3.quoteName;
/* lexer generated by jison-lex 0.6.1-214 */

/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a direct reference!
 *
 *               This "shared context" object was passed to the lexer by way of 
 *               the `lexer.setInput(str, yy)` API before you may use it.
 *
 *               This "shared context" object is passed to the lexer action code in `performAction()`
 *               so userland code in the lexer actions may communicate with the outside world 
 *               and/or other lexer rules' actions in more or less complex ways.
 *
 *  }
 *
 *  Lexer.prototype: {
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    yy:        The overall "shared context" object reference.
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance. 
 *                               `yy_` is an alias for `this` lexer instance reference used internally.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *                             Note:
 *                             The extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file are passed to the lexer via this object
 *                             reference as member variables.
 *
 *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function(),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the **parser** or the jison run-time; 
 *               when such a collision is detected an exception is thrown to prevent the generated run-time 
 *               from silently accepting this confusing and potentially hazardous situation! 
 *
 *    cleanupAfterLex: function(do_not_nuke_errorinfos),
 *               Helper function.
 *
 *               This helper API is invoked when the **parse process** has completed: it is the responsibility
 *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired. 
 *
 *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *    setInput: function(input, [yy]),
 *
 *
 *    input: function(),
 *
 *
 *    unput: function(str),
 *
 *
 *    more: function(),
 *
 *
 *    reject: function(),
 *
 *
 *    less: function(n),
 *
 *
 *    pastInput: function(n),
 *
 *
 *    upcomingInput: function(n),
 *
 *
 *    showPosition: function(),
 *
 *
 *    test_match: function(regex_match_array, rule_index),
 *
 *
 *    next: function(),
 *
 *
 *    begin: function(condition),
 *
 *
 *    pushState: function(condition),
 *
 *
 *    popState: function(),
 *
 *
 *    topState: function(),
 *
 *
 *    _currentRules: function(),
 *
 *
 *    stateStackSize: function(),
 *
 *
 *    performAction: function(yy, yy_, yyrulenumber, YY_START),
 *
 *
 *    rules: [...],
 *
 *
 *    conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *  
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


var lexer$2 = function() {
  /**
   * See also:
   * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
   * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
   * with userland code which might access the derived class in a 'classic' way.
   *
   * @public
   * @constructor
   * @nocollapse
   */
  function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
      enumerable: false,
      writable: false,
      value: 'JisonLexerError'
    });

    if (msg == null)
      msg = '???';

    Object.defineProperty(this, 'message', {
      enumerable: false,
      writable: true,
      value: msg
    });

    this.hash = hash;
    var stacktrace;

    if (hash && hash.exception instanceof Error) {
      var ex2 = hash.exception;
      this.message = ex2.message || msg;
      stacktrace = ex2.stack;
    }

    if (!stacktrace) {
      if (Error.hasOwnProperty('captureStackTrace')) {
        // V8
        Error.captureStackTrace(this, this.constructor);
      } else {
        stacktrace = new Error(msg).stack;
      }
    }

    if (stacktrace) {
      Object.defineProperty(this, 'stack', {
        enumerable: false,
        writable: false,
        value: stacktrace
      });
    }
  }

  if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
  } else {
    JisonLexerError.prototype = Object.create(Error.prototype);
  }

  JisonLexerError.prototype.constructor = JisonLexerError;
  JisonLexerError.prototype.name = 'JisonLexerError';

  var lexer = {
    
// Code Generator Information Report
// ---------------------------------
//
// Options:
//
//   backtracking: .................... false
//   location.ranges: ................. true
//   location line+column tracking: ... true
//
//
// Forwarded Parser Analysis flags:
//
//   uses yyleng: ..................... false
//   uses yylineno: ................... false
//   uses yytext: ..................... false
//   uses yylloc: ..................... false
//   uses lexer values: ............... true / true
//   location tracking: ............... false
//   location assignment: ............. false
//
//
// Lexer Analysis flags:
//
//   uses yyleng: ..................... ???
//   uses yylineno: ................... ???
//   uses yytext: ..................... ???
//   uses yylloc: ..................... ???
//   uses ParseError API: ............. ???
//   uses yyerror: .................... ???
//   uses location tracking & editing:  ???
//   uses more() API: ................. ???
//   uses unput() API: ................ ???
//   uses reject() API: ............... ???
//   uses less() API: ................. ???
//   uses display APIs pastInput(), upcomingInput(), showPosition():
//        ............................. ???
//   uses describeYYLLOC() API: ....... ???
//
// --------- END OF REPORT -----------

EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state  

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup  
    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use  
    done: false,                                /// INTERNAL USE ONLY  
    _backtrack: false,                          /// INTERNAL USE ONLY  
    _input: '',                                 /// INTERNAL USE ONLY  
    _more: false,                               /// INTERNAL USE ONLY  
    _signaled_error_token: false,               /// INTERNAL USE ONLY  
    conditionStack: [],                         /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`  
    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!  
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far  
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt  
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.  
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far  
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)  
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located  
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction  

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
      msg = '' + msg;

      // heuristic to determine if the error message already contains a (partial) source code dump
      // as produced by either `showPosition()` or `prettyPrintRange()`:
      if (show_input_position == undefined) {
        show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
      }

      if (this.yylloc && show_input_position) {
        if (typeof this.prettyPrintRange === 'function') {
          var pretty_src = this.prettyPrintRange(this.yylloc);

          if (!/\n\s*$/.test(msg)) {
            msg += '\n';
          }

          msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
        } else if (typeof this.showPosition === 'function') {
          var pos_str = this.showPosition();

          if (pos_str) {
            if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
              msg += '\n' + pos_str;
            } else {
              msg += pos_str;
            }
          }
        }
      }

      /** @constructor */
      var pei = {
        errStr: msg,
        recoverable: !!recoverable,
        text: this.match,           // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...  
        token: null,
        line: this.yylineno,
        loc: this.yylloc,
        yy: this.yy,
        lexer: this,

        /**
         * and make sure the error info doesn't stay due to potential
         * ref cycle via userland code manipulations.
         * These would otherwise all be memory leak opportunities!
         * 
         * Note that only array and object references are nuked as those
         * constitute the set of elements which can produce a cyclic ref.
         * The rest of the members is kept intact as they are harmless.
         * 
         * @public
         * @this {LexErrorInfo}
         */
        destroy: function destructLexErrorInfo() {
          // remove cyclic references added to error info:
          // info.yy = null;
          // info.lexer = null;
          // ...
          var rec = !!this.recoverable;

          for (var key in this) {
            if (this.hasOwnProperty(key) && typeof key === 'object') {
              this[key] = undefined;
            }
          }

          this.recoverable = rec;
        }
      };

      // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
      this.__error_infos.push(pei);

      return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     * 
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
      if (!ExceptionClass) {
        ExceptionClass = this.JisonLexerError;
      }

      if (this.yy) {
        if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
          return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        } else if (typeof this.yy.parseError === 'function') {
          return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        }
      }

      throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
     * 
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str /*, ...args */) {
      var lineno_msg = '';

      if (this.yylloc) {
        lineno_msg = ' on line ' + (this.yylineno + 1);
      }

      var p = this.constructLexErrorInfo(
        'Lexical error' + lineno_msg + ': ' + str,
        this.options.lexerErrorsAreRecoverable
      );

      // Add any extra args to the hash under the name `extra_error_attributes`:
      var args = Array.prototype.slice.call(arguments, 1);

      if (args.length) {
        p.extra_error_attributes = args;
      }

      return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     * 
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
      // prevent lingering circular references from causing memory leaks:
      this.setInput('', {});

      // nuke the error hash info instances created during this run.
      // Userland code must COPY any data/references
      // in the error hash instance(s) it is more permanently interested in.
      if (!do_not_nuke_errorinfos) {
        for (var i = this.__error_infos.length - 1; i >= 0; i--) {
          var el = this.__error_infos[i];

          if (el && typeof el.destroy === 'function') {
            el.destroy();
          }
        }

        this.__error_infos.length = 0;
      }

      return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     * 
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
      this.yytext = '';
      this.yyleng = 0;
      this.match = '';

      // - DO NOT reset `this.matched`
      this.matches = false;

      this._more = false;
      this._backtrack = false;
      var col = (this.yylloc ? this.yylloc.last_column : 0);

      this.yylloc = {
        first_line: this.yylineno + 1,
        first_column: col,
        last_line: this.yylineno + 1,
        last_column: col,
        range: [this.offset, this.offset]
      };
    },

    /**
     * resets the lexer, sets new input
     * 
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
      this.yy = yy || this.yy || {};

      // also check if we've fully initialized the lexer instance,
      // including expansion work to be done to go from a loaded
      // lexer to a usable lexer:
      if (!this.__decompressed) {
        // step 1: decompress the regex list:
        var rules = this.rules;

        for (var i = 0, len = rules.length; i < len; i++) {
          var rule_re = rules[i];

          // compression: is the RE an xref to another RE slot in the rules[] table?
          if (typeof rule_re === 'number') {
            rules[i] = rules[rule_re];
          }
        }

        // step 2: unfold the conditions[] set to make these ready for use:
        var conditions = this.conditions;

        for (var k in conditions) {
          var spec = conditions[k];
          var rule_ids = spec.rules;
          var len = rule_ids.length;
          var rule_regexes = new Array(len + 1);             // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple! 
          var rule_new_ids = new Array(len + 1);

          for (var i = 0; i < len; i++) {
            var idx = rule_ids[i];
            var rule_re = rules[idx];
            rule_regexes[i + 1] = rule_re;
            rule_new_ids[i + 1] = idx;
          }

          spec.rules = rule_new_ids;
          spec.__rule_regexes = rule_regexes;
          spec.__rule_count = len;
        }

        this.__decompressed = true;
      }

      this._input = input || '';
      this.clear();
      this._signaled_error_token = false;
      this.done = false;
      this.yylineno = 0;
      this.matched = '';
      this.conditionStack = ['INITIAL'];
      this.__currentRuleSet__ = null;

      this.yylloc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      this.offset = 0;
      return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse, 
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the `unput()` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current `yyloc` cursor location or any history. 
     * 
     * Use this API to help implement C-preprocessor-like
     * `#include` statements, etc.
     * 
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The `cpsArg` argument value is passed to the callback
     * as-is.
     *
     * `callback` interface: 
     * `function callback(input, cpsArg)`
     * 
     * - `input` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - `cpsArg` is `cpsArg` passed into this API.
     * 
     * The `this` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API. 
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the `"" + retval`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html 
     * -- that way any returned object's `toValue()` and `toString()`
     * methods will be invoked in a proper/desirable order.)
     * 
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
      var rv = callback.call(this, this._input, cpsArg);

      if (typeof rv !== 'string') {
        if (rv) {
          this._input = '' + rv;
        } 
        // else: keep `this._input` as is.  
      } else {
        this._input = rv;
      }

      return this;
    },

    /**
     * consumes and returns one char from the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
      if (!this._input) {
        //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
        return null;
      }

      var ch = this._input[0];
      this.yytext += ch;
      this.yyleng++;
      this.offset++;
      this.match += ch;
      this.matched += ch;

      // Count the linenumber up when we hit the LF (or a stand-alone CR).
      // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
      // and we advance immediately past the LF as well, returning both together as if
      // it was all a single 'character' only.
      var slice_len = 1;

      var lines = false;

      if (ch === '\n') {
        lines = true;
      } else if (ch === '\r') {
        lines = true;
        var ch2 = this._input[1];

        if (ch2 === '\n') {
          slice_len++;
          ch += ch2;
          this.yytext += ch2;
          this.yyleng++;
          this.offset++;
          this.match += ch2;
          this.matched += ch2;
          this.yylloc.range[1]++;
        }
      }

      if (lines) {
        this.yylineno++;
        this.yylloc.last_line++;
        this.yylloc.last_column = 0;
      } else {
        this.yylloc.last_column++;
      }

      this.yylloc.range[1]++;
      this._input = this._input.slice(slice_len);
      return ch;
    },

    /**
     * unshifts one char (or an entire string) into the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
      var len = ch.length;
      var lines = ch.split(/(?:\r\n?|\n)/g);
      this._input = ch + this._input;
      this.yytext = this.yytext.substr(0, this.yytext.length - len);
      this.yyleng = this.yytext.length;
      this.offset -= len;
      this.match = this.match.substr(0, this.match.length - len);
      this.matched = this.matched.substr(0, this.matched.length - len);

      if (lines.length > 1) {
        this.yylineno -= lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;

        // Get last entirely matched line into the `pre_lines[]` array's
        // last index slot; we don't mind when other previously 
        // matched lines end up in the array too. 
        var pre = this.match;

        var pre_lines = pre.split(/(?:\r\n?|\n)/g);

        if (pre_lines.length === 1) {
          pre = this.matched;
          pre_lines = pre.split(/(?:\r\n?|\n)/g);
        }

        this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
      } else {
        this.yylloc.last_column -= len;
      }

      this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
      this.done = false;
      return this;
    },

    /**
     * cache matched text and append it on next action
     * 
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
      this._more = true;
      return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     * 
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
      if (this.options.backtrack_lexer) {
        this._backtrack = true;
      } else {
        // when the `parseError()` call returns, we MUST ensure that the error is registered.
        // We accomplish this by signaling an 'error' token to be produced for the current
        // `.lex()` run.
        var lineno_msg = '';

        if (this.yylloc) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
          false
        );

        this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
      }

      return this;
    },

    /**
     * retain first n characters of the match
     * 
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
      return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of
     * input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     * 
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
      var past = this.matched.substring(0, this.matched.length - this.match.length);

      if (maxSize < 0)
        maxSize = past.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = past.length;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substr` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      past = past.substr(-maxSize * 2 - 2);

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = past.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(-maxLines);
      past = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis prefix...
      if (past.length > maxSize) {
        past = '...' + past.substr(-maxSize);
      }

      return past;
    },

    /**
     * return (part of the) upcoming input, i.e. for error messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input 
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block. 
     * >
     * 
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
      var next = this.match;

      if (maxSize < 0)
        maxSize = next.length + this._input.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = maxSize;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substring` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      if (next.length < maxSize * 2 + 2) {
        next += this._input.substring(0, maxSize * 2 + 2);   // substring is faster on Chrome/V8 
      }

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = next.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(0, maxLines);
      next = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis postfix...
      if (next.length > maxSize) {
        next = next.substring(0, maxSize) + '...';
      }

      return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     * 
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
      var pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
      var c = new Array(pre.length + 1).join('-');
      return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the `preceding` and `following` locations, IFF those are available,
     * and reconstruct the `actual` location info from those.
     * If this fails, the heuristic is to take the `current` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     * 
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
      var loc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      if (actual) {
        loc.first_line = actual.first_line | 0;
        loc.last_line = actual.last_line | 0;
        loc.first_column = actual.first_column | 0;
        loc.last_column = actual.last_column | 0;

        if (actual.range) {
          loc.range[0] = actual.range[0] | 0;
          loc.range[1] = actual.range[1] | 0;
        }
      }

      if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
        // plan B: heuristic using preceding and following:
        if (loc.first_line <= 0 && preceding) {
          loc.first_line = preceding.last_line | 0;
          loc.first_column = preceding.last_column | 0;

          if (preceding.range) {
            loc.range[0] = actual.range[1] | 0;
          }
        }

        if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
          loc.last_line = following.first_line | 0;
          loc.last_column = following.first_column | 0;

          if (following.range) {
            loc.range[1] = actual.range[0] | 0;
          }
        }

        // plan C?: see if the 'current' location is useful/sane too:
        if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
          loc.first_line = current.first_line | 0;
          loc.first_column = current.first_column | 0;

          if (current.range) {
            loc.range[0] = current.range[0] | 0;
          }
        }

        if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
          loc.last_line = current.last_line | 0;
          loc.last_column = current.last_column | 0;

          if (current.range) {
            loc.range[1] = current.range[1] | 0;
          }
        }
      }

      // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
      // or plan D heuristics to produce a 'sensible' last_line value:
      if (loc.last_line <= 0) {
        if (loc.first_line <= 0) {
          loc.first_line = this.yylloc.first_line;
          loc.last_line = this.yylloc.last_line;
          loc.first_column = this.yylloc.first_column;
          loc.last_column = this.yylloc.last_column;
          loc.range[0] = this.yylloc.range[0];
          loc.range[1] = this.yylloc.range[1];
        } else {
          loc.last_line = this.yylloc.last_line;
          loc.last_column = this.yylloc.last_column;
          loc.range[1] = this.yylloc.range[1];
        }
      }

      if (loc.first_line <= 0) {
        loc.first_line = loc.last_line;
        loc.first_column = 0;  // loc.last_column; 
        loc.range[1] = loc.range[0];
      }

      if (loc.first_column < 0) {
        loc.first_column = 0;
      }

      if (loc.last_column < 0) {
        loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
      }

      return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced 
     * by the given location info range, plus a few lines of context.
     * 
     * This function pretty-prints the indicated section of the input, with line numbers 
     * and everything!
     * 
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     * 
     * - `loc` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by `^`
     *   characters below each character in the entire input range.
     * 
     * - `context_loc` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by `loc`. This can help provide context for the displayed
     *   error, etc.
     * 
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     * 
     * - `context_loc2` is another *optional* location info object, which serves
     *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     * 
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     * 
     * Special Notes:
     * 
     * - when the `loc`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   `...continued...` message will be printed between them.
     * 
     *   This serves the purpose of not printing a huge amount of text when the `loc`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     * 
     * - this function can display lines of input which whave not yet been lexed.
     *   `prettyPrintRange()` can access the entire input!
     * 
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
      loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
      const CONTEXT = 3;
      const CONTEXT_TAIL = 1;
      const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
      var input = this.matched + this._input;
      var lines = input.split('\n');
      var l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
      var l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
      var lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
      var ws_prefix = new Array(lineno_display_width).join(' ');
      var nonempty_line_indexes = [];

      var rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
        var lno = index + l0;
        var lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
        var rv = lno_pfx + ': ' + line;
        var errpfx = new Array(lineno_display_width + 1).join('^');
        var offset = 2 + 1;
        var len = 0;

        if (lno === loc.first_line) {
          offset += loc.first_column;

          len = Math.max(
            2,
            ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
          );
        } else if (lno === loc.last_line) {
          len = Math.max(2, loc.last_column + 1);
        } else if (lno > loc.first_line && lno < loc.last_line) {
          len = Math.max(2, line.length + 1);
        }

        if (len) {
          var lead = new Array(offset).join('.');
          var mark = new Array(len).join('^');
          rv += '\n' + errpfx + lead + mark;

          if (line.trim().length > 0) {
            nonempty_line_indexes.push(index);
          }
        }

        rv = rv.replace(/\t/g, ' ');
        return rv;
      });

      // now make sure we don't print an overly large amount of error area: limit it 
      // to the top and bottom line count:
      if (nonempty_line_indexes.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
        var clip_start = nonempty_line_indexes[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
        var clip_end = nonempty_line_indexes[nonempty_line_indexes.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
        var intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';
        intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
        rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
      }

      return rv.join('\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input `yylloc` location object.
     * 
     * Set `display_range_too` to TRUE to include the string character index position(s)
     * in the description if the `yylloc.range` is available.
     * 
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
      var l1 = yylloc.first_line;
      var l2 = yylloc.last_line;
      var c1 = yylloc.first_column;
      var c2 = yylloc.last_column;
      var dl = l2 - l1;
      var dc = c2 - c1;
      var rv;

      if (dl === 0) {
        rv = 'line ' + l1 + ', ';

        if (dc <= 1) {
          rv += 'column ' + c1;
        } else {
          rv += 'columns ' + c1 + ' .. ' + c2;
        }
      } else {
        rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
      }

      if (yylloc.range && display_range_too) {
        var r1 = yylloc.range[0];
        var r2 = yylloc.range[1] - 1;

        if (r2 <= r1) {
          rv += ' {String Offset: ' + r1 + '}';
        } else {
          rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
        }
      }

      return rv;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     * 
     * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
     * contains the actually matched text string.
     * 
     * Also move the input cursor forward and update the match collectors:
     * 
     * - `yytext`
     * - `yyleng`
     * - `match`
     * - `matches`
     * - `yylloc`
     * - `offset`
     * 
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
      var token, lines, backup, match_str, match_str_len;

      if (this.options.backtrack_lexer) {
        // save context
        backup = {
          yylineno: this.yylineno,

          yylloc: {
            first_line: this.yylloc.first_line,
            last_line: this.yylloc.last_line,
            first_column: this.yylloc.first_column,
            last_column: this.yylloc.last_column,
            range: this.yylloc.range.slice(0)
          },

          yytext: this.yytext,
          match: this.match,
          matches: this.matches,
          matched: this.matched,
          yyleng: this.yyleng,
          offset: this.offset,
          _more: this._more,
          _input: this._input,

          //_signaled_error_token: this._signaled_error_token,
          yy: this.yy,

          conditionStack: this.conditionStack.slice(0),
          done: this.done
        };
      }

      match_str = match[0];
      match_str_len = match_str.length;

      // if (match_str.indexOf('\n') !== -1 || match_str.indexOf('\r') !== -1) {
      lines = match_str.split(/(?:\r\n?|\n)/g);

      if (lines.length > 1) {
        this.yylineno += lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;
        this.yylloc.last_column = lines[lines.length - 1].length;
      } else {
        this.yylloc.last_column += match_str_len;
      }

      // }
      this.yytext += match_str;

      this.match += match_str;
      this.matched += match_str;
      this.matches = match;
      this.yyleng = this.yytext.length;
      this.yylloc.range[1] += match_str_len;

      // previous lex rules MAY have invoked the `more()` API rather than producing a token:
      // those rules will already have moved this `offset` forward matching their match lengths,
      // hence we must only add our own match length now:
      this.offset += match_str_len;

      this._more = false;
      this._backtrack = false;
      this._input = this._input.slice(match_str_len);

      // calling this method:
      //
      //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
      token = this.performAction.call(
        this,
        this.yy,
        indexed_rule,
        this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
      );

      // otherwise, when the action codes are all simple return token statements:
      //token = this.simpleCaseActionClusters[indexed_rule];

      if (this.done && this._input) {
        this.done = false;
      }

      if (token) {
        return token;
      } else if (this._backtrack) {
        // recover context
        for (var k in backup) {
          this[k] = backup[k];
        }

        this.__currentRuleSet__ = null;
        return false;  // rule action called reject() implying the next rule should be tested instead. 
      } else if (this._signaled_error_token) {
        // produce one 'error' token as `.parseError()` in `reject()`
        // did not guarantee a failure signal by throwing an exception!
        token = this._signaled_error_token;

        this._signaled_error_token = false;
        return token;
      }

      return false;
    },

    /**
     * return next match in input
     * 
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
      if (this.done) {
        this.clear();
        return this.EOF;
      }

      if (!this._input) {
        this.done = true;
      }

      var token, match, tempMatch, index;

      if (!this._more) {
        this.clear();
      }

      var spec = this.__currentRuleSet__;

      if (!spec) {
        // Update the ruleset cache as we apparently encountered a state change or just started lexing.
        // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
        // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
        // speed up those activities a tiny bit.
        spec = this.__currentRuleSet__ = this._currentRules();

        // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
        // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
        if (!spec || !spec.rules) {
          var lineno_msg = '';

          if (this.options.trackPosition) {
            lineno_msg = ' on line ' + (this.yylineno + 1);
          }

          var p = this.constructLexErrorInfo(
            'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
            false
          );

          // produce one 'error' token until this situation has been resolved, most probably by parse termination!
          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        }
      }

      var rule_ids = spec.rules;
      var regexes = spec.__rule_regexes;
      var len = spec.__rule_count;

      // Note: the arrays are 1-based, while `len` itself is a valid index,
      // hence the non-standard less-or-equal check in the next loop condition!
      for (var i = 1; i <= len; i++) {
        tempMatch = this._input.match(regexes[i]);

        if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
          match = tempMatch;
          index = i;

          if (this.options.backtrack_lexer) {
            token = this.test_match(tempMatch, rule_ids[i]);

            if (token !== false) {
              return token;
            } else if (this._backtrack) {
              match = undefined;
              continue;  // rule action called reject() implying a rule MISmatch. 
            } else {
              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          } else if (!this.options.flex) {
            break;
          }
        }
      }

      if (match) {
        token = this.test_match(match, rule_ids[index]);

        if (token !== false) {
          return token;
        }

        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
        return false;
      }

      if (!this._input) {
        this.done = true;
        this.clear();
        return this.EOF;
      } else {
        var lineno_msg = '';

        if (this.options.trackPosition) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': Unrecognized text.',
          this.options.lexerErrorsAreRecoverable
        );

        var pendingInput = this._input;
        var activeCondition = this.topState();
        var conditionStackDepth = this.conditionStack.length;
        token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

        if (token === this.ERROR) {
          // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
          // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
          // has not consumed/modified any pending input or changed state in the error handler:
          if (!this.matches && // and make sure the input has been modified/consumed ...
          pendingInput === this._input && // ...or the lexer state has been modified significantly enough
          // to merit a non-consuming error handling action right now.
          activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
            this.input();
          }
        }

        return token;
      }
    },

    /**
     * return next match that has a token
     * 
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
      var r;

      // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
      if (typeof this.pre_lex === 'function') {
        r = this.pre_lex.call(this, 0);
      }

      if (typeof this.options.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.pre_lex.call(this, r) || r;
      }

      if (this.yy && typeof this.yy.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.pre_lex.call(this, r) || r;
      }

      while (!r) {
        r = this.next();
      }

      if (this.yy && typeof this.yy.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.post_lex.call(this, r) || r;
      }

      if (typeof this.options.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.post_lex.call(this, r) || r;
      }

      if (typeof this.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.post_lex.call(this, r) || r;
      }

      return r;
    },

    /**
     * return next match that has a token. Identical to the `lex()` API but does not invoke any of the 
     * `pre_lex()` nor any of the `post_lex()` callbacks.
     * 
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
      var r;

      while (!r) {
        r = this.next();
      }

      return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     * 
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
      var rv = {
        fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
      };

      return rv;
    },

    /**
     * backwards compatible alias for `pushState()`;
     * the latter is symmetrical with `popState()` and we advise to use
     * those APIs in any modern lexer code, rather than `begin()`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
      return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     * 
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
      this.conditionStack.push(condition);
      this.__currentRuleSet__ = null;
      return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
      var n = this.conditionStack.length - 1;

      if (n > 0) {
        this.__currentRuleSet__ = null;
        return this.conditionStack.pop();
      } else {
        return this.conditionStack[0];
      }
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     * 
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
      n = this.conditionStack.length - 1 - Math.abs(n || 0);

      if (n >= 0) {
        return this.conditionStack[n];
      } else {
        return 'INITIAL';
      }
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     * 
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
      if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
        return this.conditions[this.conditionStack[this.conditionStack.length - 1]];
      } else {
        return this.conditions['INITIAL'];
      }
    },

    /**
     * return the number of states currently on the stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
      return this.conditionStack.length;
    },

    options: {
      xregexp: true,
      ranges: true,
      trackPosition: true,
      easy_keyword_rules: true
    },

    JisonLexerError: JisonLexerError,

    performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
      var yy_ = this;
      switch (yyrulenumber) {
      case 0:
        /*! Conditions:: INITIAL */
        /*! Rule::       \s+ */
        /* skip whitespace */
        break;

      case 3:
        /*! Conditions:: INITIAL */
        /*! Rule::       \[{ID}\] */
        yy_.yytext = this.matches[1];

        return 9;
        break;

      default:
        return this.simpleCaseActionClusters[yyrulenumber];
      }
    },

    simpleCaseActionClusters: {
      /*! Conditions:: INITIAL */
      /*! Rule::       {ID} */
      1: 10,

      /*! Conditions:: INITIAL */
      /*! Rule::       \$end\b */
      2: 10,

      /*! Conditions:: INITIAL */
      /*! Rule::       '{QUOTED_STRING_CONTENT}' */
      4: 10,

      /*! Conditions:: INITIAL */
      /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
      5: 10,

      /*! Conditions:: INITIAL */
      /*! Rule::       \. */
      6: 10,

      /*! Conditions:: INITIAL */
      /*! Rule::       \( */
      7: 4,

      /*! Conditions:: INITIAL */
      /*! Rule::       \) */
      8: 5,

      /*! Conditions:: INITIAL */
      /*! Rule::       \* */
      9: 6,

      /*! Conditions:: INITIAL */
      /*! Rule::       \? */
      10: 7,

      /*! Conditions:: INITIAL */
      /*! Rule::       \| */
      11: 3,

      /*! Conditions:: INITIAL */
      /*! Rule::       \+ */
      12: 8,

      /*! Conditions:: INITIAL */
      /*! Rule::       $ */
      13: 1
    },

    rules: [
      /*  0: */  /^(?:\s+)/,
      /*  1: */  new XRegExp('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
      /*  2: */  /^(?:\$end\b)/,
      /*  3: */  new XRegExp('^(?:\\[([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\])', ''),
      /*  4: */  /^(?:'((?:\\'|\\[^']|[^'\\])*)')/,
      /*  5: */  /^(?:"((?:\\"|\\[^"]|[^"\\])*)")/,
      /*  6: */  /^(?:\.)/,
      /*  7: */  /^(?:\()/,
      /*  8: */  /^(?:\))/,
      /*  9: */  /^(?:\*)/,
      /* 10: */  /^(?:\?)/,
      /* 11: */  /^(?:\|)/,
      /* 12: */  /^(?:\+)/,
      /* 13: */  /^(?:$)/
    ],

    conditions: {
      'INITIAL': {
        rules: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13],
        inclusive: true
      }
    }
  };

  return lexer;
}();
parser$3.lexer = lexer$2;




function Parser$3() {
    this.yy = {};
}
Parser$3.prototype = parser$3;
parser$3.Parser = Parser$3;

function yyparse$2() {
    return parser$3.parse.apply(parser$3, arguments);
}



var parser$4 = {
    parser: parser$3,
    Parser: Parser$3,
    parse: yyparse$2,
    
};

//import assert from 'assert';

var devDebug$1 = 0;

// WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
//
// This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
const ID_REGEX_BASE$2 = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';

// produce a unique production symbol.
// Use this to produce rule productions from transformed EBNF which are
// guaranteed not to collide with previously generated / already existing
// rules (~ symbols).
function generateUniqueSymbol(id, postfix, opts) {
    var sym = id + postfix;
    if (opts.grammar[sym]) {
        var i = 2;              // the first occurrence won't have a number, this is already a collision, so start numbering at *2*.
        do {
            sym = id + postfix + i;
            i++;
        } while (opts.grammar[sym]);
    }
    return sym;
}

function generatePushAction(handle, offset) {
    var terms = handle.terms;
    var rv = [];

    for (var i = 0, len = terms.length; i < len; i++) {
        rv.push('$' + (i + offset));
    }
    rv = rv.join(', ');
    // and make sure we contain a term series unambiguously, i.e. anything more complex than
    // a single term inside an EBNF check is produced as an array so we can differentiate
    // between */+/? EBNF operator results and groups of tokens per individual match.
    if (len > 1) {
        rv = '[' + rv + ']';
    }
    return rv;
}

function transformExpression(e, opts, emit) {
    var type = e[0],
        value = e[1],
        name = false,
        has_transformed = 0;
    var list, n;

    if (type === 'xalias') {
        type = e[1];
        value = e[2];
        name = e[3];
        if (type) {
            e = e.slice(1);
        } else {
            e = value;
            type = e[0];
            value = e[1];
        }
        if (devDebug$1 > 3) console.log('xalias: ', e, type, value, name);
    }

    if (type === 'symbol') {
        n = e[1];
        if (devDebug$1 > 2) console.log('symbol EMIT: ', n + (name ? '[' + name + ']' : ''));
        emit(n + (name ? '[' + name + ']' : ''));
    } else if (type === '+') {
        if (!name) {
            name = generateUniqueSymbol(opts.production, '_repetition_plus', opts);
        }
        if (devDebug$1 > 2) console.log('+ EMIT name: ', name);
        emit(name);

        has_transformed = 1;

        opts = optsForProduction(name, opts.grammar);
        list = transformExpressionList([value], opts);
        opts.grammar[name] = [
            [
                list.fragment,
                '$$ = [' + generatePushAction(list, 1) + '];'
            ],
            [
                name + ' ' + list.fragment,
                '$1.push(' + generatePushAction(list, 2) + ');\n$$ = $1;'
            ]
        ];
    } else if (type === '*') {
        if (!name) {
            name = generateUniqueSymbol(opts.production, '_repetition', opts);
        }
        if (devDebug$1 > 2) console.log('* EMIT name: ', name);
        emit(name);

        has_transformed = 1;

        opts = optsForProduction(name, opts.grammar);
        list = transformExpressionList([value], opts);
        opts.grammar[name] = [
            [
                '',
                '$$ = [];'
            ],
            [
                name + ' ' + list.fragment,
                '$1.push(' + generatePushAction(list, 2) + ');\n$$ = $1;'
            ]
        ];
    } else if (type === '?') {
        if (!name) {
            name = generateUniqueSymbol(opts.production, '_option', opts);
        }
        if (devDebug$1 > 2) console.log('? EMIT name: ', name);
        emit(name);

        has_transformed = 1;

        opts = optsForProduction(name, opts.grammar);
        list = transformExpressionList([value], opts);
        // you want to be able to check if 0 or 1 occurrences were recognized: since jison
        // by default *copies* the lexer token value, i.e. `$$ = $1` is the (optional) default action,
        // we will need to set the action up explicitly in case of the 0-count match:
        // `$$ = undefined`.
        //
        // Note that we MUST return an array as the
        // '1 occurrence' match CAN carry multiple terms, e.g. in constructs like
        // `(T T T)?`, which would otherwise be unrecognizable from the `T*` construct.
        opts.grammar[name] = [
            [
                '',
                '$$ = undefined;'
            ],
            [
                list.fragment,
                '$$ = ' + generatePushAction(list, 1) + ';'
            ]
        ];
    } else if (type === '()') {
        if (value.length === 1 && !name) {
            list = transformExpressionList(value[0], opts);
            if (list.first_transformed_term_index) {
                has_transformed = list.first_transformed_term_index;
            }
            if (devDebug$1 > 2) console.log('group EMIT len=1: ', list);
            emit(list);
        } else {
            if (!name) {
                name = generateUniqueSymbol(opts.production, '_group', opts);
            }
            if (devDebug$1 > 2) console.log('group EMIT name: ', name);
            emit(name);

            has_transformed = 1;

            opts = optsForProduction(name, opts.grammar);
            opts.grammar[name] = value.map(function (handle) {
                var list = transformExpressionList(handle, opts);
                return [
                    list.fragment,
                    '$$ = ' + generatePushAction(list, 1) + ';'
                ];
            });
        }
    }

    return has_transformed;
}

function transformExpressionList(list, opts) {
    var first_transformed_term_index = false;
    var terms = list.reduce(function (tot, e) {
        var ci = tot.length;

        var has_transformed = transformExpression(e, opts, function (name) {
            if (name.terms) {
                tot.push.apply(tot, name.terms);
            } else {
                tot.push(name);
            }
        });

        if (has_transformed) {
            first_transformed_term_index = ci + has_transformed;
        }
        return tot;
    }, []);

    return {
        fragment: terms.join(' '),
        terms: terms,
        first_transformed_term_index: first_transformed_term_index              // 1-based index
    };
}

function optsForProduction(id, grammar) {
    return {
        production: id,
        grammar: grammar
    };
}

function transformProduction(id, production, grammar) {
    var transform_opts = optsForProduction(id, grammar);
    return production.map(function (handle) {
        var action = null,
            opts = null;
        var i, len, n;

        if (typeof handle !== 'string') {
            action = handle[1];
            opts = handle[2];
            handle = handle[0];
        }
        var expressions = parser$4.parse(handle);

        if (devDebug$1 > 1) console.log('\n================\nEBNF transform expressions:\n ', handle, opts, JSON.stringify(expressions, null, 2));

        var list = transformExpressionList(expressions, transform_opts);

        var ret = [list.fragment];
        if (action) {
            // make sure the action doesn't address any inner items.
            if (list.first_transformed_term_index) {
                var rhs = list.fragment;
                // seek out all names and aliases; strip out literal tokens first as those cannot serve as $names:
                var alist = list.terms; // rhs.replace(/'[^']+'/g, '~').replace(/"[^"]+"/g, '~').split(' ');
                // we also know at which index the first transformation occurred:
                if (devDebug$1 > 2) console.log('alist ~ rhs rule terms: ', alist, rhs);

                var alias_re = new XRegExp(`\\[${ID_REGEX_BASE$2}\\]`);
                var term_re = new XRegExp(`^${ID_REGEX_BASE$2}$`);
                // and collect the PERMITTED aliases: the names of the terms and all the remaining aliases
                var good_aliases = {};
                var alias_cnt = {};
                var donotalias = {};

                // WARNING: this replicates the knowledge/code of jison.js::addName()
                var addName = function addNameEBNF(s, i) {
                    var base = s.replace(/[0-9]+$/, '');
                    var dna = donotalias[base];

                    if (good_aliases[s]) {
                        alias_cnt[s]++;
                        if (!dna) {
                            good_aliases[s + alias_cnt[s]] = i + 1;
                            alias_cnt[s + alias_cnt[s]] = 1;
                        }
                    } else {
                        good_aliases[s] = i + 1;
                        alias_cnt[s] = 1;
                        if (!dna) {
                            good_aliases[s + alias_cnt[s]] = i + 1;
                            alias_cnt[s + alias_cnt[s]] = 1;
                        }
                    }
                };

                // WARNING: this replicates the knowledge/code of jison.js::markBasename()
                var markBasename = function markBasenameEBNF(s) {
                    if (/[0-9]$/.test(s)) {
                        s = s.replace(/[0-9]+$/, '');
                        donotalias[s] = true;
                    }
                };

                // mark both regular and aliased names, e.g., `id[alias1]` and `id1`
                //
                // WARNING: this replicates the knowledge/code of jison.js::markBasename()+addName() usage
                for (i = 0, len = alist.length; i < len; i++) {
                    var term = alist[i];
                    var alias = term.match(alias_re);
                    if (alias) {
                        markBasename(alias[0].substr(1, alias[0].length - 2));
                        term = term.replace(alias_re, '');
                    }
                    if (term.match(term_re)) {
                        markBasename(term);
                    }
                }
                // then check & register both regular and aliased names, e.g., `id[alias1]` and `id1`
                for (i = 0, len = alist.length; i < len; i++) {
                    var term = alist[i];
                    var alias = term.match(alias_re);
                    if (alias) {
                        addName(alias[0].substr(1, alias[0].length - 2), i);
                        term = term.replace(alias_re, '');
                    }
                    if (term.match(term_re)) {
                        addName(term, i);
                    }
                }
                if (devDebug$1 > 2) console.log('good_aliases: ', {
                    donotalias: donotalias,
                    good_aliases: good_aliases,
                    alias_cnt: alias_cnt,
                });

                // now scan the action for all named and numeric semantic values ($nonterminal / $1 / @1, ##1, ...)
                //
                // Note that `#name` are straight **static** symbol translations, which are okay as they don't
                // require access to the parse stack: `#n` references can be resolved completely 
                // at grammar compile time.
                //
                var nameref_re = new XRegExp(`(?:[$@]|##)${ID_REGEX_BASE$2}`, 'g');
                var named_spots = nameref_re.exec(action);
                var numbered_spots = action.match(/(?:[$@]|##)[0-9]+\b/g);
                var max_term_index = list.terms.length;
                if (devDebug$1 > 2) console.log('ACTION named_spots: ', named_spots);
                if (devDebug$1 > 2) console.log('ACTION numbered_spots: ', numbered_spots);

                // loop through the XRegExp alias regex matches in `action`
                while (named_spots) {
                    n = named_spots[0].replace(/^(?:[$@]|##)/, '');
                    if (!good_aliases[n]) {
                        throw new Error('The action block references the named alias "' + n + '" ' +
                                        'which is not available in production "' + handle + '"; ' +
                                        'it probably got removed by the EBNF rule rewrite process.\n' +
                                        'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                        'only the outer-most EBNF group alias will remain available at all times ' +
                                        'due to the EBNF-to-BNF rewrite process.');
                    }

                    if (alias_cnt[n] !== 1) {
                        throw new Error('The action block references the ambiguous named alias or term reference "' + n + '" ' +
                                        'which is mentioned ' + alias_cnt[n] + ' times in production "' + handle + '", implicit and explicit aliases included.\n' +
                                        'You should either provide unambiguous = uniquely named aliases for these terms or use numeric index references (e.g. `$3`) as a stop-gap in your action code.\n' +
                                        'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                        'only the outer-most EBNF group alias will remain available at all times ' +
                                        'due to the EBNF-to-BNF rewrite process.');
                    }
                    //assert(good_aliases[n] <= max_term_index, 'max term index');

                    named_spots = nameref_re.exec(action);
                }
                if (numbered_spots) {
                    for (i = 0, len = numbered_spots.length; i < len; i++) {
                        n = parseInt(numbered_spots[i].replace(/^(?:[$@]|##)/, ''));
                        if (n > max_term_index) {
                            /* @const */ var n_suffixes = [ 'st', 'nd', 'rd', 'th' ];
                            throw new Error('The action block references the ' + n + n_suffixes[Math.max(0, Math.min(3, n - 1))] + ' term, ' +
                                            'which is not available in production "' + handle + '"; ' +
                                            'Be reminded that you cannot reference sub-elements within EBNF */+/? groups, ' +
                                            'only the outer-most EBNF group alias will remain available at all times ' +
                                            'due to the EBNF-to-BNF rewrite process.');
                        }
                    }
                }
            }
            ret.push(action);
        }
        if (opts) {
            ret.push(opts);
        }
        if (devDebug$1 > 1) console.log('\n\nEBNF tx result:\n ', JSON.stringify(list, null, 2), JSON.stringify(ret, null, 2));

        if (ret.length === 1) {
            return ret[0];
        } else {
            return ret;
        }
    });
}

var ref_list;
var ref_names;

// create a deep copy of the input, so we will keep the input constant.
function deepClone(from, sub) {
    if (sub == null) {
        ref_list = [];
        ref_names = [];
        sub = 'root';
    }
    if (typeof from === 'function') return from;
    if (from == null || typeof from !== 'object') return from;
    if (from.constructor !== Object && from.constructor !== Array) {
        return from;
    }

    for (var i = 0, len = ref_list.length; i < len; i++) {
        if (ref_list[i] === from) {
            throw new Error('[Circular/Xref:' + ref_names[i] + ']');   // circular or cross reference
        }
    }
    ref_list.push(from);
    ref_names.push(sub);
    sub += '.';

    var to = new from.constructor();
    for (var name in from) {
        to[name] = deepClone(from[name], sub + name);
    }
    return to;
}

function transformGrammar(grammar) {
    grammar = deepClone(grammar);

    Object.keys(grammar).forEach(function transformGrammarForKey(id) {
        grammar[id] = transformProduction(id, grammar[id], grammar);
    });

    return grammar;
}

function transform(ebnf) {
    if (devDebug$1 > 0) console.log('EBNF:\n ', JSON.stringify(ebnf, null, 2));
    var rv = transformGrammar(ebnf);
    if (devDebug$1 > 0) console.log('\n\nEBNF after transformation:\n ', JSON.stringify(rv, null, 2));

    return rv;
}

// hack:
var assert$2;

/* parser generated by jison 0.6.1-214 */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `quoteName()` to reference this function
 *               at the end of the `parse()`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `yyval` internal object, which has members (`$` and `_$`)
 *                             to store/reference the rule value `$$` and location info `@$`.
 *
 *                 One important thing to note about `this` a.k.a. `yyval`: every *reduce* action gets
 *                 to see the same object via the `this` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use `yyval` a.k.a. `this` for storing you own semi-permanent data.
 *
 *                 `this.yy` is a direct reference to the `yy` shared state object.
 *
 *                 `%parse-param`-specified additional `parse()` arguments have been added to this `yy`
 *                 object at `parse()` start and are therefore available to the action code via the
 *                 same named `yy.xxxx` attributes (where `xxxx` represents a identifier name from
 *                 the %parse-param` list.
 *
 *               - `yytext`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, `yytext` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - `yyleng`  : ditto as `yytext`, only now for the lexer.yyleng value.
 *
 *               - `yylineno`: ditto as `yytext`, only now for the lexer.yylineno value.
 *
 *               - `yyloc`   : ditto as `yytext`, only now for the lexer.yylloc lexer token location info.
 *
 *                               WARNING: since jison 0.4.18-186 this entry may be NULL/UNDEFINED instead
 *                               of an empty object when no suitable location info can be provided.
 *
 *               - `yystate` : the current parser state number, used internally for dispatching and
 *                               executing the action code chunk matching the rule currently being reduced.
 *
 *               - `yysp`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. `##$ === ##0 === yysp`, while `##1` is the stack index for all things
 *                 related to the first rule term, just like you have `$1`, `@1` and `#1`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - `yyrulelength`: the current rule's term count, i.e. the number of entries occupied on the stack.
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *               - `yyvstack`: reference to the parser value stack. Also accessed via the `$1` etc.
 *                             constructs.
 *
 *               - `yylstack`: reference to the parser token location stack. Also accessed via
 *                             the `@1` etc. constructs.
 *
 *                             WARNING: since jison 0.4.18-186 this array MAY contain slots which are
 *                             UNDEFINED rather than an empty (location) object, when the lexer/parser
 *                             action code did not provide a suitable location info object when such a
 *                             slot was filled!
 *
 *               - `yystack` : reference to the parser token id stack. Also accessed via the
 *                             `#1` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any `#n` reference to
 *                 its numeric token id value, hence that code wouldn't need the `yystack` but *you* might
 *                 want access this array for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - `yysstack`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in `yystate`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - `...`     : the extra arguments you specified in the `%parse-param` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - `state`  --> hash table
 *               - `symbol` --> action (number or array)
 *
 *                 If the `action` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO `state`
 *
 *                 If the `action` is a number, it is the GOTO `state`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   var infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   var retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic `parseError` handler provided by JISON.
 *               `cleanupAfterParse()` will clean up and reset `parseError()` to reference this function
 *               at the end of the `parse()`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given `input` and return the parsed value (or `true` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of this grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Parser's additional `args...` parameters (via `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *               The lexer MAY add its own set of additional parameters (via the `%parse-param` line in
 *               the lexer section of the grammar spec): these will be inserted in the `yy` shared state
 *               object and any collision with those will be reported by the lexer via a thrown exception.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API is invoked at the end of the `parse()` call, unless an exception was thrown
 *               and `%options no-try-catch` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the `post_parse` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    yyMergeLocationInfo: function(first_index, last_index, first_yylloc, last_yylloc, dont_look_back),
 *               Helper function **which will be set up during the first invocation of the `parse()` method**.
 *               This helper API can be invoked to calculate a spanning `yylloc` location info object.
 *
 *               Note: %epsilon rules MAY specify no `first_index` and `first_yylloc`, in which case
 *               this function will attempt to obtain a suitable location marker by inspecting the location stack
 *               backwards.
 *
 *               For more info see the documentation comment further below, immediately above this function's
 *               implementation.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" `yy` once
 *                             received via a call to the `.setInput(input, yy)` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the `collect_expected_token_set()`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal `$$` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while `this` will reference the current parser instance.
 *
 * When `parseError` is invoked by the lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When `parseError` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, `this` will still reference the related *parser*
 * instance, while these additional `hash` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the `expected` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the `.yy` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy)
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`.
 *  Parser.post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last `%%`. When it does not return any value,
 *                 the parser will return the original `retval`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy)
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of `lex()`) but immediately after the invocation of
 *                 `parser.pre_parse()`).
 *      post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 `retval` contains the return value to be produced by `Parser.parse()`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 `retval`.
 *                 This function is invoked immediately before `parser.post_parse()`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *      quoteName: function(name),
 *                 optional: overrides the default `quoteName` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this `%option` has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError$1(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError$1.prototype, Error.prototype);
} else {
    JisonParserError$1.prototype = Object.create(Error.prototype);
}
JisonParserError$1.prototype.constructor = JisonParserError$1;
JisonParserError$1.prototype.name = 'JisonParserError';



        // helper: reconstruct the productions[] table
        function bp$1(s) {
            var rv = [];
            var p = s.pop;
            var r = s.rule;
            for (var i = 0, l = p.length; i < l; i++) {
                rv.push([
                    p[i],
                    r[i]
                ]);
            }
            return rv;
        }
    


        // helper: reconstruct the defaultActions[] table
        function bda$1(s) {
            var rv = {};
            var d = s.idx;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var j = d[i];
                rv[j] = g[i];
            }
            return rv;
        }
    


        // helper: reconstruct the 'goto' table
        function bt$1(s) {
            var rv = [];
            var d = s.len;
            var y = s.symbol;
            var t = s.type;
            var a = s.state;
            var m = s.mode;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var n = d[i];
                var q = {};
                for (var j = 0; j < n; j++) {
                    var z = y.shift();
                    switch (t.shift()) {
                    case 2:
                        q[z] = [
                            m.shift(),
                            g.shift()
                        ];
                        break;

                    case 0:
                        q[z] = a.shift();
                        break;

                    default:
                        // type === 1: accept
                        q[z] = [
                            3
                        ];
                    }
                }
                rv.push(q);
            }
            return rv;
        }
    


        // helper: runlength encoding with increment step: code, length: step (default step = 0)
        // `this` references an array
        function s$1(c, l, a) {
            a = a || 0;
            for (var i = 0; i < l; i++) {
                this.push(c);
                c += a;
            }
        }

        // helper: duplicate sequence from *relative* offset and length.
        // `this` references an array
        function c$1(i, l) {
            i = this.length - i;
            for (l += i; i < l; i++) {
                this.push(this[i]);
            }
        }

        // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
        function u$1(a) {
            var rv = [];
            for (var i = 0, l = a.length; i < l; i++) {
                var e = a[i];
                // Is this entry a helper function?
                if (typeof e === 'function') {
                    i++;
                    e.apply(rv, a[i]);
                } else {
                    rv.push(e);
                }
            }
            return rv;
        }
    

var parser$2 = {
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   default action mode: ............. classic,merge
    //   try..catch: ...................... true
    //   default resolve on conflict: ..... true
    //   on-demand look-ahead: ............ false
    //   error recovery token skip maximum: 3
    //   yyerror in parse actions is: ..... NOT recoverable,
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. NOT recoverable,
    //   debug grammar/output: ............ false
    //   has partial LR conflict upgrade:   true
    //   rudimentary token-stack support:   false
    //   parser table compression mode: ... 2
    //   export debug tables: ............. false
    //   export *all* tables: ............. false
    //   module type: ..................... es
    //   parser engine type: .............. lalr
    //   output main() in the module: ..... true
    //   has user-specified main(): ....... false
    //   has user-specified require()/import modules for main():
    //   .................................. false
    //   number of expected conflicts: .... 0
    //
    //
    // Parser Analysis flags:
    //
    //   no significant actions (parser is a language matcher only):
    //   .................................. false
    //   uses yyleng: ..................... false
    //   uses yylineno: ................... false
    //   uses yytext: ..................... false
    //   uses yylloc: ..................... false
    //   uses ParseError API: ............. false
    //   uses YYERROR: .................... true
    //   uses YYRECOVERING: ............... false
    //   uses YYERROK: .................... false
    //   uses YYCLEARIN: .................. false
    //   tracks rule values: .............. true
    //   assigns rule values: ............. true
    //   uses location tracking: .......... true
    //   assigns location: ................ true
    //   uses yystack: .................... false
    //   uses yysstack: ................... false
    //   uses yysp: ....................... true
    //   uses yyrulelength: ............... false
    //   uses yyMergeLocationInfo API: .... true
    //   has error recovery: .............. true
    //   has error reporting: ............. true
    //
    // --------- END OF REPORT -----------

trace: function no_op_trace() {},
JisonParserError: JisonParserError$1,
yy: {},
options: {
  type: "lalr",
  hasPartialLrUpgradeOnConflict: true,
  errorRecoveryTokenDiscardCount: 3
},
symbols_: {
  "$accept": 0,
  "$end": 1,
  "%%": 14,
  "(": 7,
  ")": 8,
  "*": 9,
  "+": 11,
  ":": 5,
  ";": 4,
  "=": 3,
  "?": 10,
  "ACTION": 15,
  "ACTION_BODY": 43,
  "ALIAS": 39,
  "ARROW_ACTION": 42,
  "CODE": 46,
  "DEBUG": 19,
  "EBNF": 20,
  "EOF": 1,
  "EOF_ID": 40,
  "EPSILON": 38,
  "ID": 24,
  "IMPORT": 22,
  "INCLUDE": 44,
  "INIT_CODE": 23,
  "INTEGER": 37,
  "LEFT": 33,
  "LEX_BLOCK": 17,
  "NAME": 25,
  "NONASSOC": 35,
  "OPTIONS": 27,
  "OPTIONS_END": 28,
  "OPTION_STRING_VALUE": 29,
  "OPTION_VALUE": 30,
  "PARSER_TYPE": 32,
  "PARSE_PARAM": 31,
  "PATH": 45,
  "PREC": 41,
  "RIGHT": 34,
  "START": 16,
  "STRING": 26,
  "TOKEN": 18,
  "TOKEN_TYPE": 36,
  "UNKNOWN_DECL": 21,
  "action": 85,
  "action_body": 86,
  "action_comments_body": 87,
  "action_ne": 84,
  "associativity": 61,
  "declaration": 51,
  "declaration_list": 50,
  "error": 2,
  "expression": 79,
  "extra_parser_module_code": 88,
  "full_token_definitions": 63,
  "grammar": 69,
  "handle": 76,
  "handle_action": 75,
  "handle_list": 74,
  "handle_sublist": 77,
  "id": 83,
  "id_list": 68,
  "import_name": 53,
  "import_path": 54,
  "include_macro_code": 89,
  "init_code_name": 52,
  "module_code_chunk": 90,
  "one_full_token": 64,
  "operator": 60,
  "option": 57,
  "option_list": 56,
  "optional_action_header_block": 49,
  "optional_end_block": 48,
  "optional_module_code_chunk": 91,
  "optional_production_description": 73,
  "optional_token_type": 65,
  "options": 55,
  "parse_params": 58,
  "parser_type": 59,
  "prec": 81,
  "production": 71,
  "production_id": 72,
  "production_list": 70,
  "spec": 47,
  "suffix": 80,
  "suffixed_expression": 78,
  "symbol": 82,
  "token_description": 67,
  "token_list": 62,
  "token_value": 66,
  "{": 12,
  "|": 6,
  "}": 13
},
terminals_: {
  1: "EOF",
  2: "error",
  3: "=",
  4: ";",
  5: ":",
  6: "|",
  7: "(",
  8: ")",
  9: "*",
  10: "?",
  11: "+",
  12: "{",
  13: "}",
  14: "%%",
  15: "ACTION",
  16: "START",
  17: "LEX_BLOCK",
  18: "TOKEN",
  19: "DEBUG",
  20: "EBNF",
  21: "UNKNOWN_DECL",
  22: "IMPORT",
  23: "INIT_CODE",
  24: "ID",
  25: "NAME",
  26: "STRING",
  27: "OPTIONS",
  28: "OPTIONS_END",
  29: "OPTION_STRING_VALUE",
  30: "OPTION_VALUE",
  31: "PARSE_PARAM",
  32: "PARSER_TYPE",
  33: "LEFT",
  34: "RIGHT",
  35: "NONASSOC",
  36: "TOKEN_TYPE",
  37: "INTEGER",
  38: "EPSILON",
  39: "ALIAS",
  40: "EOF_ID",
  41: "PREC",
  42: "ARROW_ACTION",
  43: "ACTION_BODY",
  44: "INCLUDE",
  45: "PATH",
  46: "CODE"
},
TERROR: 2,
EOF: 1,

// internals: defined here so the object *structure* doesn't get modified by parse() et al,
// thus helping JIT compilers like Chrome V8.
originalQuoteName: null,
originalParseError: null,
cleanupAfterParse: null,
constructParseErrorInfo: null,
yyMergeLocationInfo: null,

__reentrant_call_depth: 0, // INTERNAL USE ONLY
__error_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
__error_recovery_infos: [], // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

// APIs which will be set up depending on user action code analysis:
//yyRecovering: 0,
//yyErrOk: 0,
//yyClearIn: 0,

// Helper APIs
// -----------

// Helper function which can be overridden by user code later on: put suitable quotes around
// literal IDs in a description string.
quoteName: function parser_quoteName(id_str) {
    return '"' + id_str + '"';
},

// Return the name of the given symbol (terminal or non-terminal) as a string, when available.
//
// Return NULL when the symbol is unknown to the parser.
getSymbolName: function parser_getSymbolName(symbol) {
    if (this.terminals_[symbol]) {
        return this.terminals_[symbol];
    }

    // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
    //
    // An example of this may be where a rule's action code contains a call like this:
    //
    //      parser.getSymbolName(#$)
    //
    // to obtain a human-readable name of the current grammar rule.
    var s = this.symbols_;
    for (var key in s) {
        if (s[key] === symbol) {
            return key;
        }
    }
    return null;
},

// Return a more-or-less human-readable description of the given symbol, when available,
// or the symbol itself, serving as its own 'description' for lack of something better to serve up.
//
// Return NULL when the symbol is unknown to the parser.
describeSymbol: function parser_describeSymbol(symbol) {
    if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
        return this.terminal_descriptions_[symbol];
    } else if (symbol === this.EOF) {
        return 'end of input';
    }
    var id = this.getSymbolName(symbol);
    if (id) {
        return this.quoteName(id);
    }
    return null;
},

// Produce a (more or less) human-readable list of expected tokens at the point of failure.
//
// The produced list may contain token or token set descriptions instead of the tokens
// themselves to help turning this output into something that easier to read by humans
// unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
// expected terminals and nonterminals is produced.
//
// The returned list (array) will not contain any duplicate entries.
collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
    var TERROR = this.TERROR;
    var tokenset = [];
    var check = {};
    // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
    // If so, use that one instead of the less palatable token set.
    if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
        return [this.state_descriptions_[state]];
    }
    for (var p in this.table[state]) {
        p = +p;
        if (p !== TERROR) {
            var d = do_not_describe ? p : this.describeSymbol(p);
            if (d && !check[d]) {
                tokenset.push(d);
                check[d] = true; // Mark this token description as already mentioned to prevent outputting duplicate entries.
            }
        }
    }
    return tokenset;
},
productions_: bp$1({
  pop: u$1([
  s$1,
  [47, 3],
  48,
  48,
  s$1,
  [49, 3],
  s$1,
  [50, 3],
  s$1,
  [51, 20],
  s$1,
  [52, 3],
  53,
  53,
  54,
  54,
  s$1,
  [55, 3],
  56,
  56,
  s$1,
  [57, 6],
  58,
  58,
  59,
  59,
  60,
  60,
  s$1,
  [61, 3],
  62,
  62,
  63,
  63,
  s$1,
  [64, 3],
  65,
  s$1,
  [65, 4, 1],
  68,
  69,
  70,
  70,
  s$1,
  [71, 3],
  72,
  72,
  73,
  73,
  s$1,
  [74, 4],
  s$1,
  [75, 3],
  76,
  76,
  77,
  77,
  78,
  78,
  s$1,
  [79, 5],
  s$1,
  [80, 4],
  s$1,
  [81, 3],
  82,
  82,
  83,
  s$1,
  [84, 4],
  s$1,
  [85, 3],
  s$1,
  [86, 5],
  87,
  87,
  88,
  88,
  89,
  89,
  s$1,
  [90, 3],
  91,
  91
]),
  rule: u$1([
  5,
  5,
  3,
  0,
  2,
  0,
  s$1,
  [2, 3],
  c$1,
  [4, 3],
  1,
  1,
  c$1,
  [3, 3],
  s$1,
  [1, 6],
  s$1,
  [3, 5],
  s$1,
  [2, 3],
  c$1,
  [15, 9],
  c$1,
  [11, 4],
  c$1,
  [20, 7],
  s$1,
  [2, 4],
  s$1,
  [1, 3],
  2,
  1,
  2,
  2,
  c$1,
  [15, 3],
  0,
  c$1,
  [11, 7],
  c$1,
  [36, 4],
  3,
  3,
  1,
  0,
  3,
  c$1,
  [39, 4],
  c$1,
  [80, 4],
  c$1,
  [9, 3],
  c$1,
  [39, 4],
  3,
  3,
  c$1,
  [34, 5],
  c$1,
  [40, 5],
  c$1,
  [32, 3],
  s$1,
  [1, 3],
  0,
  0,
  1,
  5,
  4,
  4,
  c$1,
  [53, 3],
  c$1,
  [85, 4],
  c$1,
  [35, 3],
  0
])
}),
performAction: function parser__PerformAction(yyloc, yystate /* action[1] */, yysp, yyvstack, yylstack) {

          /* this == yyval */

          // the JS engine itself can go and remove these statements when `yy` turns out to be unused in any action code!
          var yy = this.yy;
          var yyparser = yy.parser;
          var yylexer = yy.lexer;

          

          switch (yystate) {
case 0:
    /*! Production::    $accept : spec $end */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yylstack[yysp - 1];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    break;

case 1:
    /*! Production::    spec : declaration_list "%%" grammar optional_end_block EOF */

    // default action (generated by JISON mode classic/merge :: 5,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
    // END of default action (generated by JISON mode classic/merge :: 5,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 4];
    if (yyvstack[yysp - 1].trim() !== '') {
        yy.addDeclaration(this.$, { include: yyvstack[yysp - 1] });
    }
    return extend(this.$, yyvstack[yysp - 2]);
    break;

case 2:
    /*! Production::    spec : declaration_list "%%" grammar error EOF */

    // default action (generated by JISON mode classic/merge :: 5,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 4];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
    // END of default action (generated by JISON mode classic/merge :: 5,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Maybe you did not correctly separate trailing code from the grammar rule set with a '%%' marker on an otherwise empty line?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
    break;

case 3:
    /*! Production::    spec : declaration_list error EOF */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Maybe you did not correctly separate the parse 'header section' (token definitions, options, lexer spec, etc.) from the grammar rule set with a '%%' on an otherwise empty line?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
    break;

case 4:
    /*! Production::    optional_end_block : %epsilon */
case 100:
    /*! Production::    suffix : %epsilon */
case 116:
    /*! Production::    action : %epsilon */
case 117:
    /*! Production::    action_body : %epsilon */
case 132:
    /*! Production::    optional_module_code_chunk : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '';
    break;

case 5:
    /*! Production::    optional_end_block : "%%" extra_parser_module_code */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            The extra parser module code section (a.k.a. 'epilogue') does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = yyvstack[yysp];
    break;

case 6:
    /*! Production::    optional_action_header_block : %epsilon */
case 10:
    /*! Production::    declaration_list : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {};
    break;

case 7:
    /*! Production::    optional_action_header_block : optional_action_header_block ACTION */
case 8:
    /*! Production::    optional_action_header_block : optional_action_header_block include_macro_code */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            action header code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    yy.addDeclaration(this.$, { actionInclude: yyvstack[yysp] });
    break;

case 9:
    /*! Production::    declaration_list : declaration_list declaration */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1]; yy.addDeclaration(this.$, yyvstack[yysp]);
    break;

case 11:
    /*! Production::    declaration_list : declaration_list error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        declaration list error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 12:
    /*! Production::    declaration : START id */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {start: yyvstack[yysp]};
    break;

case 13:
    /*! Production::    declaration : LEX_BLOCK */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {lex: {text: yyvstack[yysp], position: yylstack[yysp]}};
    break;

case 14:
    /*! Production::    declaration : operator */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {operator: yyvstack[yysp]};
    break;

case 15:
    /*! Production::    declaration : TOKEN full_token_definitions */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {token_list: yyvstack[yysp]};
    break;

case 16:
    /*! Production::    declaration : ACTION */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            action code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = {include: yyvstack[yysp]};
    break;

case 17:
    /*! Production::    declaration : include_macro_code */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            action header code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp])}
        `);
    }
    this.$ = {include: yyvstack[yysp]};
    break;

case 18:
    /*! Production::    declaration : parse_params */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {parseParams: yyvstack[yysp]};
    break;

case 19:
    /*! Production::    declaration : parser_type */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {parserType: yyvstack[yysp]};
    break;

case 20:
    /*! Production::    declaration : options */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {options: yyvstack[yysp]};
    break;

case 21:
    /*! Production::    declaration : DEBUG */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {options: [['debug', true]]};
    break;

case 22:
    /*! Production::    declaration : EBNF */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    ebnf = true; 
    this.$ = {options: [['ebnf', true]]};
    break;

case 23:
    /*! Production::    declaration : UNKNOWN_DECL */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {unknownDecl: yyvstack[yysp]};
    break;

case 24:
    /*! Production::    declaration : IMPORT import_name import_path */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {imports: {name: yyvstack[yysp - 1], path: yyvstack[yysp]}};
    break;

case 25:
    /*! Production::    declaration : IMPORT import_name error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        You did not specify a legal file path for the '%import' initialization code statement, which must have the format:
    
            %import qualifier_name file_path
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 26:
    /*! Production::    declaration : IMPORT error import_path */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Each '%import'-ed initialization code section must be qualified by a name, e.g. 'required' before the import path itself:
    
            %import qualifier_name file_path
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
    break;

case 27:
    /*! Production::    declaration : INIT_CODE init_code_name action_ne */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            %code "${$init_code_name}" initialization section action code block does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
        `);
    }
    this.$ = {
        initCode: {
            qualifier: yyvstack[yysp - 1],
            include: yyvstack[yysp]
        }
    };
    break;

case 28:
    /*! Production::    declaration : INIT_CODE error action_ne */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Each '%code' initialization code section must be qualified by a name, e.g. 'required' before the action code itself:
    
            %code qualifier_name {action code}
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2], yylstack[yysp])}
    `);
    break;

case 29:
    /*! Production::    declaration : START error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %start token error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 30:
    /*! Production::    declaration : TOKEN error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %token definition list error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 31:
    /*! Production::    declaration : IMPORT error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %import name or source filename missing maybe?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 32:
    /*! Production::    init_code_name : ID */
case 33:
    /*! Production::    init_code_name : NAME */
case 34:
    /*! Production::    init_code_name : STRING */
case 35:
    /*! Production::    import_name : ID */
case 36:
    /*! Production::    import_name : STRING */
case 37:
    /*! Production::    import_path : ID */
case 38:
    /*! Production::    import_path : STRING */
case 67:
    /*! Production::    optional_token_type : TOKEN_TYPE */
case 68:
    /*! Production::    token_value : INTEGER */
case 69:
    /*! Production::    token_description : STRING */
case 80:
    /*! Production::    optional_production_description : STRING */
case 95:
    /*! Production::    expression : ID */
case 101:
    /*! Production::    suffix : "*" */
case 102:
    /*! Production::    suffix : "?" */
case 103:
    /*! Production::    suffix : "+" */
case 107:
    /*! Production::    symbol : id */
case 108:
    /*! Production::    symbol : STRING */
case 109:
    /*! Production::    id : ID */
case 112:
    /*! Production::    action_ne : ACTION */
case 113:
    /*! Production::    action_ne : include_macro_code */
case 114:
    /*! Production::    action : action_ne */
case 118:
    /*! Production::    action_body : action_comments_body */
case 122:
    /*! Production::    action_comments_body : ACTION_BODY */
case 124:
    /*! Production::    extra_parser_module_code : optional_module_code_chunk */
case 128:
    /*! Production::    module_code_chunk : CODE */
case 131:
    /*! Production::    optional_module_code_chunk : module_code_chunk */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp];
    break;

case 39:
    /*! Production::    options : OPTIONS option_list OPTIONS_END */
case 110:
    /*! Production::    action_ne : "{" action_body "}" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    break;

case 40:
    /*! Production::    options : OPTIONS error OPTIONS_END */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %options ill defined / error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2], yylstack[yysp])}
    `);
    break;

case 41:
    /*! Production::    options : OPTIONS error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %options don't seem terminated?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 42:
    /*! Production::    option_list : option_list option */
case 59:
    /*! Production::    token_list : token_list symbol */
case 70:
    /*! Production::    id_list : id_list id */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1]; this.$.push(yyvstack[yysp]);
    break;

case 43:
    /*! Production::    option_list : option */
case 60:
    /*! Production::    token_list : symbol */
case 71:
    /*! Production::    id_list : id */
case 83:
    /*! Production::    handle_list : handle_action */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp]];
    break;

case 44:
    /*! Production::    option : NAME */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp], true];
    break;

case 45:
    /*! Production::    option : NAME "=" OPTION_STRING_VALUE */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 2], yyvstack[yysp]];
    break;

case 46:
    /*! Production::    option : NAME "=" OPTION_VALUE */
case 47:
    /*! Production::    option : NAME "=" NAME */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 2], parseValue$1(yyvstack[yysp])];
    break;

case 48:
    /*! Production::    option : NAME "=" error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        named %option value error for ${yyvstack[yysp - 2]}?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 49:
    /*! Production::    option : NAME error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        named %option value assignment error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 50:
    /*! Production::    parse_params : PARSE_PARAM token_list */
case 52:
    /*! Production::    parser_type : PARSER_TYPE symbol */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp];
    break;

case 51:
    /*! Production::    parse_params : PARSE_PARAM error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %parse-params declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 53:
    /*! Production::    parser_type : PARSER_TYPE error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %parser-type declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 54:
    /*! Production::    operator : associativity token_list */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 1]]; this.$.push.apply(this.$, yyvstack[yysp]);
    break;

case 55:
    /*! Production::    operator : associativity error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        operator token list error in an associativity statement?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 56:
    /*! Production::    associativity : LEFT */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = 'left';
    break;

case 57:
    /*! Production::    associativity : RIGHT */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = 'right';
    break;

case 58:
    /*! Production::    associativity : NONASSOC */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = 'nonassoc';
    break;

case 61:
    /*! Production::    full_token_definitions : optional_token_type id_list */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var rv = [];
    var lst = yyvstack[yysp];
    for (var i = 0, len = lst.length; i < len; i++) {
        var id = lst[i];
        var m = {id: id};
        if (yyvstack[yysp - 1]) {
            m.type = yyvstack[yysp - 1];
        }
        rv.push(m);
    }
    this.$ = rv;
    break;

case 62:
    /*! Production::    full_token_definitions : optional_token_type one_full_token */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var m = yyvstack[yysp];
    if (yyvstack[yysp - 1]) {
        m.type = yyvstack[yysp - 1];
    }
    this.$ = [m];
    break;

case 63:
    /*! Production::    one_full_token : id token_value token_description */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
        id: yyvstack[yysp - 2],
        value: yyvstack[yysp - 1],
        description: yyvstack[yysp]
    };
    break;

case 64:
    /*! Production::    one_full_token : id token_description */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
        id: yyvstack[yysp - 1],
        description: yyvstack[yysp]
    };
    break;

case 65:
    /*! Production::    one_full_token : id token_value */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {
        id: yyvstack[yysp - 1],
        value: yyvstack[yysp]
    };
    break;

case 66:
    /*! Production::    optional_token_type : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = false;
    break;

case 72:
    /*! Production::    grammar : optional_action_header_block production_list */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    this.$.grammar = yyvstack[yysp];
    break;

case 73:
    /*! Production::    production_list : production_list production */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    if (yyvstack[yysp][0] in this.$) {
        this.$[yyvstack[yysp][0]] = this.$[yyvstack[yysp][0]].concat(yyvstack[yysp][1]);
    } else {
        this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
    }
    break;

case 74:
    /*! Production::    production_list : production */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = {}; this.$[yyvstack[yysp][0]] = yyvstack[yysp][1];
    break;

case 75:
    /*! Production::    production : production_id handle_list ";" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp - 2], yyvstack[yysp - 1]];
    break;

case 76:
    /*! Production::    production : production_id error ";" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        rule production declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp - 1], yylstack[yysp - 2])}
    `);
    break;

case 77:
    /*! Production::    production : production_id error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        rule production declaration error: did you terminate the rule production set with a semicolon?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 78:
    /*! Production::    production_id : id optional_production_description ":" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2];
    
    // TODO: carry rule description support into the parser generator...
    break;

case 79:
    /*! Production::    production_id : id optional_production_description error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        rule id should be followed by a colon, but that one seems missing?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 81:
    /*! Production::    optional_production_description : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-):
    this.$ = undefined;
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,-,-,LT,LA,-,-)
    break;

case 82:
    /*! Production::    handle_list : handle_list "|" handle_action */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2];
    this.$.push(yyvstack[yysp]);
    break;

case 84:
    /*! Production::    handle_list : handle_list "|" error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        rule alternative production declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 85:
    /*! Production::    handle_list : handle_list ":" error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        multiple alternative rule productions should be separated by a '|' pipe character, not a ':' colon!
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 86:
    /*! Production::    handle_action : handle prec action */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [(yyvstack[yysp - 2].length ? yyvstack[yysp - 2].join(' ') : '')];
    if (yyvstack[yysp]) {
        var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$5`
                production rule action code block does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
            `);
        }
        this.$.push(yyvstack[yysp]);
    }
    if (yyvstack[yysp - 1]) {
        if (yyvstack[yysp - 2].length === 0) {
            yyparser.yyError(rmCommonWS$5`
                You cannot specify a precedence override for an epsilon (a.k.a. empty) rule!
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp - 2], yylstack[yysp - 3], yylstack[yysp] /* @handle is very probably NULL! We need this one for some decent location info! */)}
            `);
        }
        this.$.push(yyvstack[yysp - 1]);
    }
    if (this.$.length === 1) {
        this.$ = this.$[0];
    }
    break;

case 87:
    /*! Production::    handle_action : EPSILON action */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [''];
    if (yyvstack[yysp]) {
        var rv = checkActionBlock$2(yyvstack[yysp], yylstack[yysp]);
        if (rv) {
            yyparser.yyError(rmCommonWS$5`
                epsilon production rule action code block does not compile: ${rv}
    
                  Erroneous area:
                ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
            `);
        }
        this.$.push(yyvstack[yysp]);
    }
    if (this.$.length === 1) {
        this.$ = this.$[0];
    }
    break;

case 88:
    /*! Production::    handle_action : EPSILON error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %epsilon rule action declaration error?
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 89:
    /*! Production::    handle : handle suffixed_expression */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1];
    this.$.push(yyvstack[yysp]);
    break;

case 90:
    /*! Production::    handle : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [];
    break;

case 91:
    /*! Production::    handle_sublist : handle_sublist "|" handle */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2];
    this.$.push(yyvstack[yysp].join(' '));
    break;

case 92:
    /*! Production::    handle_sublist : handle */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = [yyvstack[yysp].join(' ')];
    break;

case 93:
    /*! Production::    suffixed_expression : expression suffix ALIAS */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + "[" + yyvstack[yysp] + "]";
    break;

case 94:
    /*! Production::    suffixed_expression : expression suffix */
case 123:
    /*! Production::    action_comments_body : action_comments_body ACTION_BODY */
case 129:
    /*! Production::    module_code_chunk : module_code_chunk CODE */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 96:
    /*! Production::    expression : EOF_ID */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '$end';
    break;

case 97:
    /*! Production::    expression : STRING */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    // Re-encode the string *anyway* as it will
    // be made part of the rule rhs a.k.a. production (type: *string*) again and we want
    // to be able to handle all tokens, including *significant space*
    // encoded as literal tokens in a grammar such as this: `rule: A ' ' B`.
    this.$ = dquote$2(yyvstack[yysp]);
    break;

case 98:
    /*! Production::    expression : "(" handle_sublist ")" */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '(' + yyvstack[yysp - 1].join(' | ') + ')';
    break;

case 99:
    /*! Production::    expression : "(" handle_sublist error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Seems you did not correctly bracket a grammar rule sublist in '( ... )' brackets.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 104:
    /*! Production::    prec : PREC symbol */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = { prec: yyvstack[yysp] };
    break;

case 105:
    /*! Production::    prec : PREC error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        %prec precedence override declaration error?
    
          Erroneous precedence declaration:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
    `);
    break;

case 106:
    /*! Production::    prec : %epsilon */

    // default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
    // END of default action (generated by JISON mode classic/merge :: 0,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = null;
    break;

case 111:
    /*! Production::    action_ne : "{" action_body error */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 2];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Seems you did not correctly bracket a parser rule action block in curly braces: '{ ... }'.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 115:
    /*! Production::    action : ARROW_ACTION */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = '$$ = ' + yyvstack[yysp];
    break;

case 119:
    /*! Production::    action_body : action_body "{" action_body "}" action_comments_body */

    // default action (generated by JISON mode classic/merge :: 5,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 4, yysp);
    // END of default action (generated by JISON mode classic/merge :: 5,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 4] + yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 120:
    /*! Production::    action_body : action_body "{" action_body "}" */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 3] + yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 121:
    /*! Production::    action_body : action_body "{" action_body error */

    // default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 3];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 3, yysp);
    // END of default action (generated by JISON mode classic/merge :: 4,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
        Seems you did not correctly match curly braces '{ ... }' in a parser rule action block.
    
          Erroneous area:
        ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 2])}
    `);
    break;

case 125:
    /*! Production::    extra_parser_module_code : optional_module_code_chunk include_macro_code extra_parser_module_code */

    // default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 2, yysp);
    // END of default action (generated by JISON mode classic/merge :: 3,VT,VA,VU,-,LT,LA,-,-)
    
    
    this.$ = yyvstack[yysp - 2] + yyvstack[yysp - 1] + yyvstack[yysp];
    break;

case 126:
    /*! Production::    include_macro_code : INCLUDE PATH */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-):
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,VU,-,LT,LA,-,-)
    
    
    var fileContent = fs.readFileSync(yyvstack[yysp], { encoding: 'utf-8' });
    var rv = checkActionBlock$2(fileContent);
    if (rv) {
        yyparser.yyError(rmCommonWS$5`
            included action code file "${$PATH}" does not compile: ${rv}
    
              Erroneous area:
            ${yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1])}
        `);
    }
    // And no, we don't support nested '%include':
    this.$ = '\n// Included by Jison: ' + yyvstack[yysp] + ':\n\n' + fileContent + '\n\n// End Of Include by Jison: ' + yyvstack[yysp] + '\n\n';
    break;

case 127:
    /*! Production::    include_macro_code : INCLUDE error */

    // default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp - 1];
    this._$ = yyparser.yyMergeLocationInfo(yysp - 1, yysp);
    // END of default action (generated by JISON mode classic/merge :: 2,VT,VA,-,-,LT,LA,-,-)
    
    
    yyparser.yyError(rmCommonWS$5`
    %include MUST be followed by a valid file path.
    
      Erroneous path:
    ` + yylexer.prettyPrintRange(yylstack[yysp], yylstack[yysp - 1]));
    break;

case 130:
    /*! Production::    module_code_chunk : error */

    // default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-):
    this.$ = yyvstack[yysp];
    this._$ = yylstack[yysp];
    // END of default action (generated by JISON mode classic/merge :: 1,VT,VA,-,-,LT,LA,-,-)
    
    
    // TODO ...
    yyparser.yyError(rmCommonWS$5`
        module code declaration error?
    
          Erroneous area:
        ` + yylexer.prettyPrintRange(yylstack[yysp]));
    break;

case 164:       // === NO_ACTION[1] :: ensures that anyone (but us) using this new state will fail dramatically!
                // error recovery reduction action (action generated by jison,
                // using the user-specified `%code error_recovery_reduction` %{...%}
                // code chunk below.

                
                break;
            
}
},
table: bt$1({
  len: u$1([
  20,
  1,
  25,
  5,
  19,
  18,
  3,
  18,
  18,
  5,
  s$1,
  [18, 8],
  4,
  5,
  6,
  2,
  s$1,
  [6, 4, -1],
  3,
  3,
  4,
  8,
  1,
  18,
  18,
  26,
  c$1,
  [18, 3],
  1,
  4,
  21,
  3,
  3,
  5,
  5,
  s$1,
  [3, 3],
  22,
  18,
  20,
  25,
  25,
  24,
  24,
  22,
  s$1,
  [18, 3],
  3,
  19,
  2,
  4,
  1,
  1,
  7,
  7,
  c$1,
  [40, 3],
  17,
  4,
  20,
  18,
  23,
  s$1,
  [18, 6],
  6,
  21,
  21,
  18,
  20,
  18,
  2,
  18,
  4,
  2,
  s$1,
  [1, 3],
  s$1,
  [3, 4],
  4,
  3,
  5,
  3,
  15,
  11,
  2,
  2,
  19,
  20,
  18,
  c$1,
  [104, 3],
  4,
  4,
  s$1,
  [2, 4],
  7,
  3,
  4,
  16,
  1,
  4,
  10,
  14,
  c$1,
  [122, 3],
  18,
  18,
  9,
  s$1,
  [3, 4],
  14,
  14,
  18,
  21,
  21,
  6,
  4,
  c$1,
  [50, 5],
  7,
  7,
  s$1,
  [15, 4],
  3,
  9,
  3,
  14,
  18,
  18,
  8,
  5,
  3,
  9,
  4
]),
  symbol: u$1([
  2,
  s$1,
  [14, 10, 1],
  27,
  s$1,
  [31, 5, 1],
  44,
  47,
  50,
  1,
  c$1,
  [21, 18],
  51,
  55,
  s$1,
  [58, 4, 1],
  89,
  15,
  24,
  44,
  49,
  69,
  c$1,
  [31, 19],
  c$1,
  [18, 19],
  24,
  83,
  c$1,
  [39, 38],
  36,
  63,
  65,
  c$1,
  [41, 37],
  c$1,
  [18, 108],
  24,
  26,
  53,
  2,
  24,
  25,
  26,
  52,
  c$1,
  [9, 3],
  62,
  82,
  83,
  2,
  45,
  c$1,
  [8, 7],
  24,
  26,
  c$1,
  [5, 3],
  25,
  56,
  57,
  c$1,
  [9, 3],
  c$1,
  [3, 6],
  c$1,
  [266, 3],
  48,
  c$1,
  [275, 3],
  70,
  71,
  72,
  83,
  89,
  c$1,
  [278, 38],
  4,
  5,
  6,
  12,
  s$1,
  [14, 11, 1],
  26,
  c$1,
  [24, 6],
  37,
  42,
  c$1,
  [152, 37],
  24,
  64,
  68,
  83,
  24,
  c$1,
  [119, 3],
  54,
  c$1,
  [27, 11],
  c$1,
  [67, 8],
  44,
  54,
  c$1,
  [147, 6],
  12,
  15,
  44,
  84,
  89,
  c$1,
  [5, 8],
  c$1,
  [3, 6],
  c$1,
  [46, 20],
  c$1,
  [201, 3],
  c$1,
  [113, 28],
  c$1,
  [40, 9],
  c$1,
  [177, 23],
  c$1,
  [176, 3],
  c$1,
  [25, 24],
  1,
  c$1,
  [26, 4],
  c$1,
  [25, 11],
  c$1,
  [73, 7],
  46,
  c$1,
  [24, 24],
  c$1,
  [158, 51],
  c$1,
  [18, 25],
  25,
  28,
  57,
  c$1,
  [21, 12],
  28,
  c$1,
  [22, 8],
  2,
  3,
  25,
  28,
  s$1,
  [1, 3],
  2,
  44,
  46,
  88,
  90,
  91,
  c$1,
  [425, 3],
  24,
  c$1,
  [433, 3],
  c$1,
  [440, 3],
  c$1,
  [3, 3],
  c$1,
  [13, 4],
  c$1,
  [153, 4],
  7,
  12,
  15,
  24,
  26,
  38,
  40,
  41,
  42,
  44,
  74,
  75,
  76,
  2,
  5,
  26,
  73,
  c$1,
  [151, 12],
  c$1,
  [94, 7],
  c$1,
  [307, 38],
  37,
  44,
  66,
  67,
  c$1,
  [685, 109],
  12,
  13,
  43,
  86,
  87,
  c$1,
  [349, 14],
  c$1,
  [445, 11],
  c$1,
  [84, 46],
  c$1,
  [504, 10],
  c$1,
  [348, 19],
  c$1,
  [58, 19],
  25,
  29,
  30,
  c$1,
  [346, 5],
  1,
  44,
  89,
  1,
  c$1,
  [483, 3],
  c$1,
  [3, 6],
  c$1,
  [339, 3],
  c$1,
  [121, 3],
  c$1,
  [496, 3],
  c$1,
  [8, 5],
  c$1,
  [349, 8],
  c$1,
  [348, 4],
  78,
  79,
  81,
  c$1,
  [568, 5],
  15,
  42,
  44,
  84,
  85,
  89,
  2,
  5,
  2,
  5,
  c$1,
  [359, 19],
  c$1,
  [19, 11],
  c$1,
  [142, 8],
  c$1,
  [337, 30],
  c$1,
  [180, 26],
  c$1,
  [284, 3],
  c$1,
  [287, 4],
  c$1,
  [4, 4],
  25,
  28,
  25,
  28,
  c$1,
  [4, 4],
  c$1,
  [517, 8],
  c$1,
  [168, 6],
  c$1,
  [507, 14],
  c$1,
  [506, 3],
  c$1,
  [189, 7],
  c$1,
  [162, 8],
  s$1,
  [4, 5, 1],
  c$1,
  [190, 8],
  c$1,
  [1024, 6],
  s$1,
  [4, 9, 1],
  c$1,
  [22, 3],
  s$1,
  [39, 4, 1],
  44,
  80,
  c$1,
  [19, 18],
  c$1,
  [18, 37],
  c$1,
  [16, 3],
  c$1,
  [88, 3],
  76,
  77,
  c$1,
  [292, 6],
  c$1,
  [3, 6],
  c$1,
  [144, 14],
  c$1,
  [14, 15],
  c$1,
  [480, 39],
  c$1,
  [21, 21],
  c$1,
  [549, 6],
  c$1,
  [6, 3],
  1,
  c$1,
  [111, 12],
  c$1,
  [234, 7],
  c$1,
  [7, 7],
  c$1,
  [238, 10],
  c$1,
  [179, 11],
  c$1,
  [15, 40],
  6,
  8,
  c$1,
  [209, 7],
  78,
  79,
  c$1,
  [374, 4],
  c$1,
  [313, 14],
  c$1,
  [271, 43],
  c$1,
  [164, 4],
  c$1,
  [169, 4],
  c$1,
  [78, 12],
  43
]),
  type: u$1([
  s$1,
  [2, 18],
  0,
  0,
  1,
  c$1,
  [21, 20],
  s$1,
  [0, 5],
  c$1,
  [10, 5],
  s$1,
  [2, 39],
  c$1,
  [40, 41],
  c$1,
  [41, 40],
  s$1,
  [2, 108],
  c$1,
  [148, 5],
  c$1,
  [239, 6],
  c$1,
  [159, 6],
  c$1,
  [253, 10],
  c$1,
  [176, 14],
  c$1,
  [36, 7],
  c$1,
  [197, 102],
  c$1,
  [103, 7],
  c$1,
  [108, 21],
  c$1,
  [21, 10],
  c$1,
  [423, 36],
  c$1,
  [373, 149],
  c$1,
  [158, 67],
  c$1,
  [57, 32],
  c$1,
  [322, 8],
  c$1,
  [98, 26],
  c$1,
  [489, 7],
  c$1,
  [721, 173],
  c$1,
  [462, 131],
  c$1,
  [130, 37],
  c$1,
  [375, 11],
  c$1,
  [818, 45],
  c$1,
  [223, 79],
  c$1,
  [124, 24],
  c$1,
  [986, 15],
  c$1,
  [38, 19],
  c$1,
  [57, 20],
  c$1,
  [157, 62],
  c$1,
  [443, 106],
  c$1,
  [106, 103],
  c$1,
  [103, 62],
  c$1,
  [1248, 16],
  c$1,
  [78, 6]
]),
  state: u$1([
  1,
  2,
  5,
  14,
  12,
  13,
  8,
  20,
  11,
  29,
  28,
  31,
  34,
  36,
  38,
  42,
  47,
  49,
  50,
  54,
  49,
  50,
  56,
  50,
  58,
  60,
  62,
  65,
  68,
  69,
  70,
  67,
  72,
  71,
  73,
  74,
  78,
  79,
  82,
  83,
  82,
  84,
  50,
  84,
  50,
  86,
  92,
  94,
  93,
  97,
  69,
  70,
  98,
  100,
  101,
  103,
  105,
  106,
  107,
  110,
  111,
  117,
  124,
  126,
  123,
  133,
  131,
  82,
  137,
  142,
  94,
  93,
  143,
  101,
  133,
  146,
  82,
  147,
  50,
  149,
  154,
  153,
  155,
  111,
  124,
  126,
  162,
  163,
  124,
  126
]),
  mode: u$1([
  s$1,
  [2, 18],
  s$1,
  [1, 18],
  c$1,
  [21, 4],
  s$1,
  [2, 36],
  c$1,
  [42, 5],
  c$1,
  [38, 34],
  c$1,
  [77, 38],
  s$1,
  [2, 108],
  s$1,
  [1, 20],
  c$1,
  [30, 15],
  c$1,
  [134, 100],
  c$1,
  [106, 4],
  c$1,
  [335, 26],
  c$1,
  [151, 16],
  c$1,
  [376, 48],
  c$1,
  [347, 120],
  c$1,
  [63, 75],
  c$1,
  [13, 9],
  c$1,
  [23, 4],
  c$1,
  [4, 3],
  c$1,
  [587, 6],
  c$1,
  [427, 12],
  c$1,
  [9, 15],
  c$1,
  [335, 13],
  c$1,
  [389, 39],
  c$1,
  [45, 43],
  c$1,
  [509, 77],
  c$1,
  [762, 121],
  c$1,
  [129, 9],
  c$1,
  [756, 14],
  c$1,
  [334, 14],
  c$1,
  [41, 6],
  c$1,
  [367, 5],
  c$1,
  [784, 37],
  c$1,
  [208, 63],
  c$1,
  [1142, 20],
  c$1,
  [1081, 10],
  c$1,
  [487, 14],
  c$1,
  [22, 9],
  c$1,
  [151, 17],
  c$1,
  [221, 10],
  c$1,
  [803, 156],
  c$1,
  [318, 61],
  c$1,
  [216, 50],
  c$1,
  [457, 7],
  c$1,
  [455, 38],
  c$1,
  [123, 34],
  c$1,
  [1206, 8],
  1
]),
  goto: u$1([
  s$1,
  [10, 18],
  4,
  3,
  10,
  6,
  7,
  9,
  s$1,
  [15, 5, 1],
  24,
  22,
  23,
  25,
  26,
  27,
  21,
  s$1,
  [6, 3],
  30,
  s$1,
  [11, 18],
  s$1,
  [9, 18],
  32,
  33,
  s$1,
  [13, 18],
  s$1,
  [14, 18],
  35,
  66,
  37,
  s$1,
  [16, 18],
  s$1,
  [17, 18],
  s$1,
  [18, 18],
  s$1,
  [19, 18],
  s$1,
  [20, 18],
  s$1,
  [21, 18],
  s$1,
  [22, 18],
  s$1,
  [23, 18],
  39,
  40,
  41,
  s$1,
  [43, 4, 1],
  48,
  33,
  51,
  53,
  52,
  55,
  33,
  51,
  57,
  33,
  51,
  59,
  61,
  s$1,
  [56, 3],
  s$1,
  [57, 3],
  s$1,
  [58, 3],
  4,
  63,
  64,
  66,
  33,
  21,
  3,
  s$1,
  [12, 18],
  s$1,
  [29, 18],
  s$1,
  [109, 26],
  s$1,
  [15, 18],
  s$1,
  [30, 18],
  33,
  67,
  75,
  76,
  77,
  s$1,
  [31, 11],
  c$1,
  [13, 9],
  s$1,
  [35, 3],
  s$1,
  [36, 3],
  80,
  81,
  21,
  c$1,
  [3, 3],
  s$1,
  [32, 3],
  s$1,
  [33, 3],
  s$1,
  [34, 3],
  s$1,
  [54, 11],
  33,
  51,
  s$1,
  [54, 7],
  s$1,
  [55, 18],
  s$1,
  [60, 20],
  s$1,
  [107, 25],
  s$1,
  [108, 25],
  s$1,
  [126, 24],
  s$1,
  [127, 24],
  s$1,
  [50, 11],
  33,
  51,
  s$1,
  [50, 7],
  s$1,
  [51, 18],
  s$1,
  [52, 18],
  s$1,
  [53, 18],
  61,
  85,
  s$1,
  [41, 12],
  87,
  s$1,
  [41, 6],
  43,
  43,
  89,
  88,
  44,
  44,
  90,
  91,
  132,
  96,
  132,
  95,
  s$1,
  [72, 3],
  33,
  s$1,
  [7, 3],
  s$1,
  [8, 3],
  s$1,
  [74, 4],
  99,
  s$1,
  [90, 8],
  102,
  s$1,
  [90, 4],
  81,
  81,
  104,
  s$1,
  [61, 11],
  33,
  s$1,
  [61, 7],
  s$1,
  [62, 18],
  s$1,
  [71, 12],
  109,
  s$1,
  [71, 6],
  108,
  71,
  s$1,
  [24, 18],
  s$1,
  [25, 18],
  s$1,
  [37, 18],
  s$1,
  [38, 18],
  s$1,
  [26, 18],
  s$1,
  [27, 18],
  s$1,
  [117, 3],
  s$1,
  [112, 22],
  s$1,
  [113, 21],
  s$1,
  [28, 18],
  s$1,
  [59, 20],
  s$1,
  [39, 18],
  42,
  42,
  s$1,
  [40, 18],
  116,
  115,
  113,
  114,
  49,
  49,
  1,
  2,
  5,
  124,
  21,
  131,
  131,
  118,
  s$1,
  [128, 3],
  s$1,
  [130, 3],
  s$1,
  [73, 4],
  119,
  121,
  120,
  77,
  77,
  122,
  77,
  77,
  s$1,
  [83, 3],
  s$1,
  [106, 3],
  130,
  106,
  106,
  127,
  129,
  128,
  125,
  106,
  106,
  132,
  s$1,
  [116, 3],
  80,
  81,
  134,
  21,
  136,
  135,
  80,
  80,
  s$1,
  [70, 19],
  s$1,
  [65, 11],
  109,
  s$1,
  [65, 7],
  s$1,
  [64, 18],
  s$1,
  [68, 19],
  s$1,
  [69, 18],
  139,
  140,
  138,
  s$1,
  [118, 3],
  141,
  s$1,
  [122, 4],
  45,
  45,
  46,
  46,
  47,
  47,
  48,
  48,
  c$1,
  [494, 4],
  s$1,
  [129, 3],
  s$1,
  [75, 4],
  144,
  c$1,
  [487, 13],
  145,
  s$1,
  [76, 4],
  c$1,
  [153, 7],
  s$1,
  [89, 14],
  148,
  33,
  51,
  s$1,
  [100, 6],
  150,
  151,
  152,
  s$1,
  [100, 9],
  s$1,
  [95, 18],
  s$1,
  [96, 18],
  s$1,
  [97, 18],
  s$1,
  [90, 7],
  s$1,
  [87, 3],
  s$1,
  [88, 3],
  s$1,
  [114, 3],
  s$1,
  [115, 3],
  s$1,
  [78, 14],
  s$1,
  [79, 14],
  s$1,
  [63, 18],
  s$1,
  [110, 21],
  s$1,
  [111, 21],
  c$1,
  [526, 4],
  s$1,
  [123, 4],
  125,
  s$1,
  [82, 3],
  s$1,
  [84, 3],
  s$1,
  [85, 3],
  s$1,
  [86, 3],
  s$1,
  [104, 7],
  s$1,
  [105, 7],
  s$1,
  [94, 10],
  156,
  s$1,
  [94, 4],
  s$1,
  [101, 15],
  s$1,
  [102, 15],
  s$1,
  [103, 15],
  158,
  159,
  157,
  92,
  92,
  130,
  92,
  c$1,
  [465, 3],
  161,
  140,
  160,
  s$1,
  [93, 14],
  s$1,
  [98, 18],
  s$1,
  [99, 18],
  s$1,
  [90, 7],
  s$1,
  [120, 3],
  112,
  s$1,
  [121, 3],
  91,
  91,
  130,
  91,
  c$1,
  [74, 3],
  s$1,
  [119, 3],
  141
])
}),
defaultActions: bda$1({
  idx: u$1([
  0,
  3,
  5,
  7,
  8,
  s$1,
  [10, 8, 1],
  25,
  26,
  27,
  s$1,
  [30, 6, 1],
  37,
  40,
  41,
  44,
  45,
  46,
  s$1,
  [48, 6, 1],
  55,
  56,
  57,
  60,
  66,
  67,
  68,
  72,
  s$1,
  [74, 6, 1],
  s$1,
  [81, 7, 1],
  s$1,
  [89, 4, 1],
  95,
  96,
  97,
  100,
  104,
  105,
  107,
  108,
  109,
  s$1,
  [112, 5, 1],
  118,
  119,
  122,
  124,
  s$1,
  [127, 13, 1],
  s$1,
  [141, 8, 1],
  150,
  151,
  152,
  s$1,
  [156, 4, 1],
  161
]),
  goto: u$1([
  10,
  6,
  9,
  13,
  14,
  s$1,
  [16, 8, 1],
  56,
  57,
  58,
  3,
  12,
  29,
  109,
  15,
  30,
  67,
  35,
  36,
  32,
  33,
  34,
  55,
  60,
  107,
  108,
  126,
  127,
  51,
  52,
  53,
  43,
  7,
  8,
  74,
  62,
  24,
  25,
  37,
  38,
  26,
  27,
  112,
  113,
  28,
  59,
  39,
  42,
  40,
  49,
  1,
  2,
  5,
  128,
  130,
  73,
  83,
  80,
  70,
  64,
  68,
  69,
  122,
  s$1,
  [45, 4, 1],
  129,
  75,
  76,
  89,
  95,
  96,
  97,
  90,
  87,
  88,
  114,
  115,
  78,
  79,
  63,
  110,
  111,
  123,
  125,
  82,
  84,
  85,
  86,
  104,
  105,
  101,
  102,
  103,
  93,
  98,
  99,
  90,
  121
])
}),
parseError: function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable) {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
},
parse: function parse(input) {
    var self = this;
    var stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
    var sstack = new Array(128);        // state stack: stores states (column storage)

    var vstack = new Array(128);        // semantic value stack
    var lstack = new Array(128);        // location stack
    var table = this.table;
    var sp = 0;                         // 'stack pointer': index into the stacks
    var yyloc;

    


    var symbol = 0;
    var preErrorSymbol = 0;
    var lastEofErrorStateDepth = Infinity;
    var recoveringErrorInfo = null;
    var recovering = 0;                 // (only used when the grammar contains error recovery rules)
    var TERROR = this.TERROR;
    var EOF = this.EOF;
    var ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    var NO_ACTION = [0, 164 /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

    var lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    var sharedState_yy = {
        parseError: undefined,
        quoteName: undefined,
        lexer: undefined,
        parser: undefined,
        pre_parse: undefined,
        post_parse: undefined,
        pre_lex: undefined,
        post_lex: undefined      // WARNING: must be written this way for the code expanders to work correctly in both ES5 and ES6 modes!
    };

    var ASSERT;
    if (typeof assert$2 !== 'function') {
        ASSERT = function JisonAssert(cond, msg) {
            if (!cond) {
                throw new Error('assertion failed: ' + (msg || '***'));
            }
        };
    } else {
        ASSERT = assert$2;
    }

    this.yyGetSharedState = function yyGetSharedState() {
        return sharedState_yy;
    };


    this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
        return recoveringErrorInfo;
    };


    // shallow clone objects, straight copy of simple `src` values
    // e.g. `lexer.yytext` MAY be a complex value object,
    // rather than a simple string/value.
    function shallow_copy(src) {
        if (typeof src === 'object') {
            var dst = {};
            for (var k in src) {
                if (Object.prototype.hasOwnProperty.call(src, k)) {
                    dst[k] = src[k];
                }
            }
            return dst;
        }
        return src;
    }
    function shallow_copy_noclobber(dst, src) {
        for (var k in src) {
            if (typeof dst[k] === 'undefined' && Object.prototype.hasOwnProperty.call(src, k)) {
                dst[k] = src[k];
            }
        }
    }
    function copy_yylloc(loc) {
        var rv = shallow_copy(loc);
        if (rv && rv.range) {
            rv.range = rv.range.slice(0);
        }
        return rv;
    }

    // copy state
    shallow_copy_noclobber(sharedState_yy, this.yy);

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;





    // *Always* setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions as it is paramount
    // to have *their* closure match ours -- if we only set them up once,
    // any subsequent `parse()` runs will fail in very obscure ways when
    // these functions are invoked in the user action code block(s) as
    // their closure will still refer to the `parse()` instance which set
    // them up. Hence we MUST set them up at the start of every `parse()` run!
    if (this.yyError) {
        this.yyError = function yyError(str /*, ...args */) {











            var error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
            var expected = this.collect_expected_token_set(state);
            var hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
            // append to the old one?
            if (recoveringErrorInfo) {
                var esp = recoveringErrorInfo.info_stack_pointer;

                recoveringErrorInfo.symbol_stack[esp] = symbol;
                var v = this.shallowCopyErrorInfo(hash);
                v.yyError = true;
                v.errorRuleDepth = error_rule_depth;
                v.recovering = recovering;
                // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                recoveringErrorInfo.value_stack[esp] = v;
                recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                ++esp;
                recoveringErrorInfo.info_stack_pointer = esp;
            } else {
                recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                recoveringErrorInfo.yyError = true;
                recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                recoveringErrorInfo.recovering = recovering;
            }


            // Add any extra args to the hash under the name `extra_error_attributes`:
            var args = Array.prototype.slice.call(arguments, 1);
            if (args.length) {
                hash.extra_error_attributes = args;
            }

            var r = this.parseError(str, hash, this.JisonParserError);
            return r;
        };
    }







    // Does the shared state override the default `parseError` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default `quoteName` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = function quoteNameAlt(id_str) {
            return sharedState_yy.quoteName.call(this, id_str);
        };
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the `%options no-try-catch` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a `finally { ... }` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `sharedState`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        var rv;

        if (invoke_post_methods) {
            var hash;

            if (sharedState_yy.post_parse || this.post_parse) {
                // create an error hash info instance: we re-use this API in a **non-error situation**
                // as this one delivers all parser internals ready for access by userland code.
                hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
            }

            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }

            // cleanup:
            if (hash && hash.destroy) {
                hash.destroy();
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;
        lstack.length = 0;
        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;


            for (var i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                var el = this.__error_recovery_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_recovery_infos.length = 0;

            // `recoveringErrorInfo` is also part of the `__error_recovery_infos` array,
            // hence has been destroyed already: no need to do that *twice*.
            if (recoveringErrorInfo) {
                recoveringErrorInfo = undefined;
            }


        }

        return resultValue;
    };

    // merge yylloc info into a new yylloc instance.
    //
    // `first_index` and `last_index` MAY be UNDEFINED/NULL or these are indexes into the `lstack[]` location stack array.
    //
    // `first_yylloc` and `last_yylloc` MAY be UNDEFINED/NULL or explicit (custom or regular) `yylloc` instances, in which
    // case these override the corresponding first/last indexes.
    //
    // `dont_look_back` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
    // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
    // yylloc info.
    //
    // Note: epsilon rule's yylloc situation is detected by passing both `first_index` and `first_yylloc` as UNDEFINED/NULL.
    this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
        var i1 = first_index | 0,
            i2 = last_index | 0;
        var l1 = first_yylloc,
            l2 = last_yylloc;
        var rv;

        // rules:
        // - first/last yylloc entries override first/last indexes

        if (!l1) {
            if (first_index != null) {
                for (var i = i1; i <= i2; i++) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
        }

        if (!l2) {
            if (last_index != null) {
                for (var i = i2; i >= i1; i--) {
                    l2 = lstack[i];
                    if (l2) {
                        break;
                    }
                }
            }
        }

        // - detect if an epsilon rule is being processed and act accordingly:
        if (!l1 && first_index == null) {
            // epsilon rule span merger. With optional look-ahead in l2.
            if (!dont_look_back) {
                for (var i = (i1 || sp) - 1; i >= 0; i--) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
            if (!l1) {
                if (!l2) {
                    // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                    // without look-ahead and no preceding terms and/or `dont_look_back` set:
                    // in that case we ca do nothing but return NULL/UNDEFINED:
                    return undefined;
                } else {
                    // shallow-copy L2: after all, we MAY be looking
                    // at unconventional yylloc info objects...
                    rv = shallow_copy(l2);
                    if (rv.range) {
                        // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                        rv.range = rv.range.slice(0);
                    }
                    return rv;
                }
            } else {
                // shallow-copy L1, then adjust first col/row 1 column past the end.
                rv = shallow_copy(l1);
                rv.first_line = rv.last_line;
                rv.first_column = rv.last_column;
                if (rv.range) {
                    // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                    rv.range = rv.range.slice(0);
                    rv.range[0] = rv.range[1];
                }

                if (l2) {
                    // shallow-mixin L2, then adjust last col/row accordingly.
                    shallow_copy_noclobber(rv, l2);
                    rv.last_line = l2.last_line;
                    rv.last_column = l2.last_column;
                    if (rv.range && l2.range) {
                        rv.range[1] = l2.range[1];
                    }
                }
                return rv;
            }
        }

        if (!l1) {
            l1 = l2;
            l2 = null;
        }
        if (!l1) {
            return undefined;
        }

        // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
        // at unconventional yylloc info objects...
        rv = shallow_copy(l1);

        // first_line: ...,
        // first_column: ...,
        // last_line: ...,
        // last_column: ...,
        if (rv.range) {
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            rv.range = rv.range.slice(0);
        }

        if (l2) {
            shallow_copy_noclobber(rv, l2);
            rv.last_line = l2.last_line;
            rv.last_column = l2.last_column;
            if (rv.range && l2.range) {
                rv.range[1] = l2.range[1];
            }
        }

        return rv;
    };

    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your `lexer`, `sharedState`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        var pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: lexer.yytext,
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,
            loc: copy_yylloc(lexer.yylloc),
            expected: expected,
            recoverable: recoverable,
            state: state,
            action: action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,
            location_stack: lstack,
            stack_pointer: sp,
            yy: sharedState_yy,
            lexer: lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };

    // clone some parts of the (possibly enhanced!) errorInfo object
    // to give them some persistence.
    this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
        var rv = shallow_copy(p);

        // remove the large parts which can only cause cyclic references
        // and are otherwise available from the parser kernel anyway.
        delete rv.sharedState_yy;
        delete rv.parser;
        delete rv.lexer;

        // lexer.yytext MAY be a complex value object, rather than a simple string/value:
        rv.value = shallow_copy(rv.value);

        // yylloc info:
        rv.loc = copy_yylloc(rv.loc);

        // the 'expected' set won't be modified, so no need to clone it:
        //rv.expected = rv.expected.slice(0);

        //symbol stack is a simple array:
        rv.symbol_stack = rv.symbol_stack.slice(0);
        // ditto for state stack:
        rv.state_stack = rv.state_stack.slice(0);
        // clone the yylloc's in the location stack?:
        rv.location_stack = rv.location_stack.map(copy_yylloc);
        // and the value stack may carry both simple and complex values:
        // shallow-copy the latter.
        rv.value_stack = rv.value_stack.map(shallow_copy);

        // and we don't bother with the sharedState_yy reference:
        //delete rv.yy;

        // now we prepare for tracking the COMBINE actions
        // in the error recovery code path:
        //
        // as we want to keep the maximum error info context, we
        // *scan* the state stack to find the first *empty* slot.
        // This position will surely be AT OR ABOVE the current
        // stack pointer, but we want to keep the 'used but discarded'
        // part of the parse stacks *intact* as those slots carry
        // error context that may be useful when you want to produce
        // very detailed error diagnostic reports.
        //
        // ### Purpose of each stack pointer:
        //
        // - stack_pointer: points at the top of the parse stack
        //                  **as it existed at the time of the error
        //                  occurrence, i.e. at the time the stack
        //                  snapshot was taken and copied into the
        //                  errorInfo object.**
        // - base_pointer:  the bottom of the **empty part** of the
        //                  stack, i.e. **the start of the rest of
        //                  the stack space /above/ the existing
        //                  parse stack. This section will be filled
        //                  by the error recovery process as it
        //                  travels the parse state machine to
        //                  arrive at the resolving error recovery rule.**
        // - info_stack_pointer:
        //                  this stack pointer points to the **top of
        //                  the error ecovery tracking stack space**, i.e.
        //                  this stack pointer takes up the role of
        //                  the `stack_pointer` for the error recovery
        //                  process. Any mutations in the **parse stack**
        //                  are **copy-appended** to this part of the
        //                  stack space, keeping the bottom part of the
        //                  stack (the 'snapshot' part where the parse
        //                  state at the time of error occurrence was kept)
        //                  intact.
        // - root_failure_pointer:
        //                  copy of the `stack_pointer`...
        //
        for (var i = rv.stack_pointer; typeof rv.state_stack[i] !== 'undefined'; i++) {
            // empty
        }
        rv.base_pointer = i;
        rv.info_stack_pointer = i;

        rv.root_failure_pointer = rv.stack_pointer;

        // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
        this.__error_recovery_infos.push(rv);

        return rv;
    };

    function stdLex() {
        var token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    function fastLex() {
        var token = lexer.fastLex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    var lex = stdLex;


    var state, action, r, t;
    var yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    var p;
    var yyrulelen;
    var this_production;
    var newState;
    var retval = false;


    // Return the rule stack depth where the nearest error rule can be found.
    // Return -1 when no error recovery rule was found.
    function locateNearestErrorRecoveryRule(state) {
        var stack_probe = sp - 1;
        var depth = 0;

        // try to recover from error
        while (stack_probe >= 0) {
            // check for error recovery rule in this state









            var t = table[state][TERROR] || NO_ACTION;
            if (t[0]) {
                // We need to make sure we're not cycling forever:
                // once we hit EOF, even when we `yyerrok()` an error, we must
                // prevent the core from running forever,
                // e.g. when parent rules are still expecting certain input to
                // follow after this, for example when you handle an error inside a set
                // of braces which are matched by a parent rule in your grammar.
                //
                // Hence we require that every error handling/recovery attempt
                // *after we've hit EOF* has a diminishing state stack: this means
                // we will ultimately have unwound the state stack entirely and thus
                // terminate the parse in a controlled fashion even when we have
                // very complex error/recovery code interplay in the core + user
                // action code blocks:









                if (symbol === EOF) {
                    if (lastEofErrorStateDepth > sp - 1 - depth) {
                        lastEofErrorStateDepth = sp - 1 - depth;
                    } else {









                        --stack_probe; // popStack(1): [symbol, action]
                        state = sstack[stack_probe];
                        ++depth;
                        continue;
                    }
                }
                return depth;
            }
            if (state === 0 /* $accept rule */ || stack_probe < 1) {









                return -1; // No suitable error recovery rule available.
            }
            --stack_probe; // popStack(1): [symbol, action]
            state = sstack[stack_probe];
            ++depth;
        }









        return -1; // No suitable error recovery rule available.
    }


    try {
        this.__reentrant_call_depth++;

        lexer.setInput(input, sharedState_yy);

        // NOTE: we *assume* no lexer pre/post handlers are set up *after* 
        // this initial `setInput()` call: hence we can now check and decide
        // whether we'll go with the standard, slower, lex() API or the
        // `fast_lex()` one:
        if (typeof lexer.canIUse === 'function') {
            var lexerInfo = lexer.canIUse();
            if (lexerInfo.fastLex && typeof fastLex === 'function') {
                lex = fastLex;
            }
        } 

        yyloc = lexer.yylloc;
        lstack[sp] = yyloc;
        vstack[sp] = null;
        sstack[sp] = 0;
        stack[sp] = 0;
        ++sp;





        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single `==` condition below covers both these `===` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];











                // handle parse error
                if (!action) {
                    // first see if there's any chance at hitting an error recovery rule:
                    var error_rule_depth = locateNearestErrorRecoveryRule(state);
                    var errStr = null;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    if (!recovering) {
                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                        } else {
                            errStr = 'Parse error: ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                        // DO NOT cleanup the old one before we start the new error info track:
                        // the old one will *linger* on the error stack and stay alive until we 
                        // invoke the parser's cleanup API!
                        recoveringErrorInfo = this.shallowCopyErrorInfo(p);

                        r = this.parseError(p.errStr, p, this.JisonParserError);









                        // Protect against overly blunt userland `parseError` code which *sets*
                        // the `recoverable` flag without properly checking first:
                        // we always terminate the parse when there's no recovery rule available anyhow!
                        if (!p.recoverable || error_rule_depth < 0) {
                            if (typeof r !== 'undefined') {
                                retval = r;
                            }
                            break;
                        } else {
                            // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                        }
                    }










                    var esp = recoveringErrorInfo.info_stack_pointer;

                    // just recovered from another error
                    if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                        // SHIFT current lookahead and grab another
                        recoveringErrorInfo.symbol_stack[esp] = symbol;
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(lexer.yytext);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                        recoveringErrorInfo.state_stack[esp] = newState; // push state
                        ++esp;

                        // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                        yyloc = lexer.yylloc;

                        preErrorSymbol = 0;
                        symbol = lex();









                    }

                    // try to recover from error
                    if (error_rule_depth < 0) {
                        ASSERT(recovering > 0, "line 897");
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                        // while we are still busy recovering from another error:
                        var po = this.__error_infos[this.__error_infos.length - 1];

                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                        } else {
                            errStr = 'Parsing halted while starting to recover from another error';
                        }

                        if (po) {
                            errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                        } else {
                            errStr += ': ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\n' + lexer.showPosition(79 - 10, 10) + '\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, false);
                        if (po) {
                            p.extra_error_attributes = po;
                        }

                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }

                    preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                    symbol = TERROR;            // insert generic error symbol as new lookahead

                    const EXTRA_STACK_SAMPLE_DEPTH = 3;

                    // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                    recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                    if (errStr) {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            errStr: errStr,
                            errorSymbolDescr: errSymbolDescr,
                            expectedStr: expected,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };









                    } else {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                    }
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    yyval.$ = recoveringErrorInfo;
                    yyval._$ = undefined;

                    yyrulelen = error_rule_depth;









                    r = this.performAction.call(yyval, yyloc, NO_ACTION[1], sp - 1, vstack, lstack);

                    if (typeof r !== 'undefined') {
                        retval = r;
                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // and move the top entries + discarded part of the parse stacks onto the error info stack:
                    for (var idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                        recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(vstack[idx]);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lstack[idx]);
                        recoveringErrorInfo.state_stack[esp] = sstack[idx];
                    }

                    recoveringErrorInfo.symbol_stack[esp] = TERROR;
                    recoveringErrorInfo.value_stack[esp] = shallow_copy(yyval.$);
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(yyval._$);

                    // goto new state = table[STATE][NONTERMINAL]
                    newState = sstack[sp - 1];

                    if (this.defaultActions[newState]) {
                        recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                    } else {
                        t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                        recoveringErrorInfo.state_stack[esp] = t[1];
                    }

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    // allow N (default: 3) real symbols to be shifted before reporting a new error
                    recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;










                    // Now duplicate the standard parse machine here, at least its initial
                    // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                    // as we wish to push something special then!
                    //
                    // Run the state machine in this copy of the parser state machine
                    // until we *either* consume the error symbol (and its related information)
                    // *or* we run into another error while recovering from this one
                    // *or* we execute a `reduce` action which outputs a final parse
                    // result (yes, that MAY happen!).
                    //
                    // We stay in this secondary parse loop until we have completed
                    // the *error recovery phase* as the main parse loop (further below)
                    // is optimized for regular parse operation and DOES NOT cope with
                    // error recovery *at all*.
                    //
                    // We call the secondary parse loop just below the "slow parse loop",
                    // while the main parse loop, which is an almost-duplicate of this one,
                    // yet optimized for regular parse operation, is called the "fast
                    // parse loop".
                    //
                    // Compare this to `bison` & (vanilla) `jison`, both of which have
                    // only a single parse loop, which handles everything. Our goal is
                    // to eke out every drop of performance in the main parse loop...

                    ASSERT(recoveringErrorInfo, "line 1049");
                    ASSERT(symbol === TERROR, "line 1050");
                    ASSERT(!action, "line 1051");
                    var errorSymbolFromParser = true;
                    for (;;) {
                        // retrieve state number from top of stack
                        state = newState;               // sstack[sp - 1];

                        // use default actions if available
                        if (this.defaultActions[state]) {
                            action = 2;
                            newState = this.defaultActions[state];
                        } else {
                            // The single `==` condition below covers both these `===` comparisons in a single
                            // operation:
                            //
                            //     if (symbol === null || typeof symbol === 'undefined') ...
                            if (!symbol) {
                                symbol = lex();
                                // **Warning: Edge Case**: the *lexer* may produce
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided `yyvalue`
                                // and `yylloc`:
                                errorSymbolFromParser = false;
                            }
                            // read action for current state and first input
                            t = (table[state] && table[state][symbol]) || NO_ACTION;
                            newState = t[1];
                            action = t[0];










                            // encountered another parse error? If so, break out to main loop
                            // and take it from there!
                            if (!action) {










                                ASSERT(recoveringErrorInfo, "line 1087");

                                // Prep state variables so that upon breaking out of
                                // this "slow parse loop" and hitting the `continue;`
                                // statement in the outer "fast parse loop" we redo
                                // the exact same state table lookup as the one above
                                // so that the outer=main loop will also correctly
                                // detect the 'parse error' state (`!action`) we have
                                // just encountered above.
                                newState = state;
                                break;
                            }
                        }










                        switch (action) {
                        // catch misc. parse failures:
                        default:
                            // this shouldn't happen, unless resolve defaults are off
                            //
                            // SILENTLY SIGNAL that the outer "fast parse loop" should
                            // take care of this internal error condition:
                            // prevent useless code duplication now/here.
                            break;

                        // shift:
                        case 1:
                            stack[sp] = symbol;
                            // ### Note/Warning ###
                            //
                            // The *lexer* may also produce TERROR tokens on its own,
                            // so we specifically test for the TERROR we did set up
                            // in the error recovery logic further above!
                            if (symbol === TERROR && errorSymbolFromParser) {
                                // Push a special value onto the stack when we're
                                // shifting the `error` symbol that is related to the
                                // error we're recovering from.
                                ASSERT(recoveringErrorInfo, "line 1131");
                                vstack[sp] = recoveringErrorInfo;
                                lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                            } else {
                                ASSERT(symbol !== 0, "line 1135");
                                ASSERT(preErrorSymbol === 0, "line 1136");
                                vstack[sp] = lexer.yytext;
                                lstack[sp] = copy_yylloc(lexer.yylloc);
                            }
                            sstack[sp] = newState; // push state

                            ++sp;
                            symbol = 0;
                            // **Warning: Edge Case**: the *lexer* may have produced
                            // TERROR tokens of its own volition: *those* TERROR
                            // tokens should be treated like *regular tokens*
                            // i.e. tokens which have a lexer-provided `yyvalue`
                            // and `yylloc`:
                            errorSymbolFromParser = false;
                            if (!preErrorSymbol) { // normal execution / no error
                                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                                yyloc = lexer.yylloc;

                                if (recovering > 0) {
                                    recovering--;









                                }
                            } else {
                                // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                ASSERT(recovering > 0, "line 1163");
                                symbol = preErrorSymbol;
                                preErrorSymbol = 0;









                                // read action for current state and first input
                                t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                if (!t[0] || symbol === TERROR) {
                                    // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                    // (simple) stuff might have been missing before the token which caused the error we're
                                    // recovering from now...
                                    //
                                    // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                    // recovery, for then this we would we idling (cycling) on the error forever.
                                    // Yes, this does not take into account the possibility that the *lexer* may have
                                    // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!









                                    symbol = 0;
                                }
                            }

                            // once we have pushed the special ERROR token value,
                            // we REMAIN in this inner, "slow parse loop" until
                            // the entire error recovery phase has completed.
                            //
                            // ### Note About Edge Case ###
                            //
                            // Userland action code MAY already have 'reset' the
                            // error recovery phase marker `recovering` to ZERO(0)
                            // while the error symbol hasn't been shifted onto
                            // the stack yet. Hence we only exit this "slow parse loop"
                            // when *both* conditions are met!
                            ASSERT(preErrorSymbol === 0, "line 1194");
                            if (recovering === 0) {
                                break;
                            }
                            continue;

                        // reduce:
                        case 2:
                            this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                            yyrulelen = this_production[1];










                            r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                            if (typeof r !== 'undefined') {
                                // signal end of error recovery loop AND end of outer parse loop
                                action = 3;
                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                                retval = r;
                                break;
                            }

                            // pop off stack
                            sp -= yyrulelen;

                            // don't overwrite the `symbol` variable: use a local var to speed things up:
                            var ntsymbol = this_production[0];    // push nonterminal (reduce)
                            stack[sp] = ntsymbol;
                            vstack[sp] = yyval.$;
                            lstack[sp] = yyval._$;
                            // goto new state = table[STATE][NONTERMINAL]
                            newState = table[sstack[sp - 1]][ntsymbol];
                            sstack[sp] = newState;
                            ++sp;









                            continue;

                        // accept:
                        case 3:
                            retval = true;
                            // Return the `$accept` rule's `$$` result, if available.
                            //
                            // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                            // default, action):
                            //
                            //     $accept: <startSymbol> $end
                            //                  %{ $$ = $1; @$ = @1; %}
                            //
                            // which, combined with the parse kernel's `$accept` state behaviour coded below,
                            // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                            // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                            //
                            // In code:
                            //
                            //                  %{
                            //                      @$ = @1;            // if location tracking support is included
                            //                      if (typeof $1 !== 'undefined')
                            //                          return $1;
                            //                      else
                            //                          return true;           // the default parse result if the rule actions don't produce anything
                            //                  %}
                            sp--;
                            if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                retval = vstack[sp];
                            }
                            sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up `retval` parser return value.
                            break;
                        }

                        // break out of loop: we accept or fail with error
                        break;
                    }

                    // should we also break out of the regular/outer parse loop,
                    // i.e. did the parser already produce a parse result in here?!
                    // *or* did we hit an unsupported parse state, to be handled
                    // in the `switch/default` code further below?
                    ASSERT(action !== 2, "line 1272");
                    if (!action || action === 1) {
                        continue;
                    }
                }


            }










            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                r = this.parseError(p.errStr, p, this.JisonParserError);
                if (typeof r !== 'undefined') {
                    retval = r;
                }
                break;

            // shift:
            case 1:
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;
                lstack[sp] = copy_yylloc(lexer.yylloc);
                sstack[sp] = newState; // push state

                ++sp;
                symbol = 0;

                ASSERT(preErrorSymbol === 0, "line 1352");         // normal execution / no error
                ASSERT(recovering === 0, "line 1353");             // normal execution / no error

                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:



                yyloc = lexer.yylloc;
                continue;

            // reduce:
            case 2:
                ASSERT(preErrorSymbol === 0, "line 1364");         // normal execution / no error
                ASSERT(recovering === 0, "line 1365");             // normal execution / no error

                this_production = this.productions_[newState - 1];  // `this.productions_[]` is zero-based indexed while states start from 1 upwards...
                yyrulelen = this_production[1];










                r = this.performAction.call(yyval, yyloc, newState, sp - 1, vstack, lstack);

                if (typeof r !== 'undefined') {
                    retval = r;
                    break;
                }

                // pop off stack
                sp -= yyrulelen;

                // don't overwrite the `symbol` variable: use a local var to speed things up:
                var ntsymbol = this_production[0];    // push nonterminal (reduce)
                stack[sp] = ntsymbol;
                vstack[sp] = yyval.$;
                lstack[sp] = yyval._$;
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[sstack[sp - 1]][ntsymbol];
                sstack[sp] = newState;
                ++sp;









                continue;

            // accept:
            case 3:
                if (sp !== -2) {
                    retval = true;
                    // Return the `$accept` rule's `$$` result, if available.
                    //
                    // Also note that JISON always adds this top-most `$accept` rule (with implicit,
                    // default, action):
                    //
                    //     $accept: <startSymbol> $end
                    //                  %{ $$ = $1; @$ = @1; %}
                    //
                    // which, combined with the parse kernel's `$accept` state behaviour coded below,
                    // will produce the `$$` value output of the <startSymbol> rule as the parse result,
                    // IFF that result is *not* `undefined`. (See also the parser kernel code.)
                    //
                    // In code:
                    //
                    //                  %{
                    //                      @$ = @1;            // if location tracking support is included
                    //                      if (typeof $1 !== 'undefined')
                    //                          return $1;
                    //                      else
                    //                          return true;           // the default parse result if the rule actions don't produce anything
                    //                  %}
                    sp--;
                    if (typeof vstack[sp] !== 'undefined') {
                        retval = vstack[sp];
                    }
                }
                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        }
        else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }
        else {
            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;
    }   // /finally

    return retval;
},
yyError: 1
};
parser$2.originalParseError = parser$2.parseError;
parser$2.originalQuoteName = parser$2.quoteName;
/* lexer generated by jison-lex 0.6.1-214 */

/*
 * Returns a Lexer object of the following structure:
 *
 *  Lexer: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" `yy` passed around to
 *               the rule actions, etc. is a direct reference!
 *
 *               This "shared context" object was passed to the lexer by way of 
 *               the `lexer.setInput(str, yy)` API before you may use it.
 *
 *               This "shared context" object is passed to the lexer action code in `performAction()`
 *               so userland code in the lexer actions may communicate with the outside world 
 *               and/or other lexer rules' actions in more or less complex ways.
 *
 *  }
 *
 *  Lexer.prototype: {
 *    EOF: 1,
 *    ERROR: 2,
 *
 *    yy:        The overall "shared context" object reference.
 *
 *    JisonLexerError: function(msg, hash),
 *
 *    performAction: function lexer__performAction(yy, yyrulenumber, YY_START),
 *
 *               The function parameters and `this` have the following value/meaning:
 *               - `this`    : reference to the `lexer` instance. 
 *                               `yy_` is an alias for `this` lexer instance reference used internally.
 *
 *               - `yy`      : a reference to the `yy` "shared state" object which was passed to the lexer
 *                             by way of the `lexer.setInput(str, yy)` API before.
 *
 *                             Note:
 *                             The extra arguments you specified in the `%parse-param` statement in your
 *                             **parser** grammar definition file are passed to the lexer via this object
 *                             reference as member variables.
 *
 *               - `yyrulenumber`   : index of the matched lexer rule (regex), used internally.
 *
 *               - `YY_START`: the current lexer "start condition" state.
 *
 *    parseError: function(str, hash, ExceptionClass),
 *
 *    constructLexErrorInfo: function(error_message, is_recoverable),
 *               Helper function.
 *               Produces a new errorInfo 'hash object' which can be passed into `parseError()`.
 *               See it's use in this lexer kernel in many places; example usage:
 *
 *                   var infoObj = lexer.constructParseErrorInfo('fail!', true);
 *                   var retVal = lexer.parseError(infoObj.errStr, infoObj, lexer.JisonLexerError);
 *
 *    options: { ... lexer %options ... },
 *
 *    lex: function(),
 *               Produce one token of lexed input, which was passed in earlier via the `lexer.setInput()` API.
 *               You MAY use the additional `args...` parameters as per `%parse-param` spec of the **lexer** grammar:
 *               these extra `args...` are added verbatim to the `yy` object reference as member variables.
 *
 *               WARNING:
 *               Lexer's additional `args...` parameters (via lexer's `%parse-param`) MAY conflict with
 *               any attributes already added to `yy` by the **parser** or the jison run-time; 
 *               when such a collision is detected an exception is thrown to prevent the generated run-time 
 *               from silently accepting this confusing and potentially hazardous situation! 
 *
 *    cleanupAfterLex: function(do_not_nuke_errorinfos),
 *               Helper function.
 *
 *               This helper API is invoked when the **parse process** has completed: it is the responsibility
 *               of the **parser** (or the calling userland code) to invoke this method once cleanup is desired. 
 *
 *               This helper may be invoked by user code to ensure the internal lexer gets properly garbage collected.
 *
 *    setInput: function(input, [yy]),
 *
 *
 *    input: function(),
 *
 *
 *    unput: function(str),
 *
 *
 *    more: function(),
 *
 *
 *    reject: function(),
 *
 *
 *    less: function(n),
 *
 *
 *    pastInput: function(n),
 *
 *
 *    upcomingInput: function(n),
 *
 *
 *    showPosition: function(),
 *
 *
 *    test_match: function(regex_match_array, rule_index),
 *
 *
 *    next: function(),
 *
 *
 *    begin: function(condition),
 *
 *
 *    pushState: function(condition),
 *
 *
 *    popState: function(),
 *
 *
 *    topState: function(),
 *
 *
 *    _currentRules: function(),
 *
 *
 *    stateStackSize: function(),
 *
 *
 *    performAction: function(yy, yy_, yyrulenumber, YY_START),
 *
 *
 *    rules: [...],
 *
 *
 *    conditions: {associative list: name ==> set},
 *  }
 *
 *
 *  token location info (`yylloc`): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The `parseError` function receives a 'hash' object with these members for lexer errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    yy:          (object: the current parser internal "shared state" `yy`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *  }
 *
 * while `this` will reference the current lexer instance.
 *
 * When `parseError` is invoked by the lexer, the default implementation will
 * attempt to invoke `yy.parser.parseError()`; when this callback is not provided
 * it will try to invoke `yy.parseError()` instead. When that callback is also not
 * provided, a `JisonLexerError` exception will be thrown containing the error
 * message and `hash`, as constructed by the `constructLexErrorInfo()` API.
 *
 * Note that the lexer's `JisonLexerError` error class is passed via the
 * `ExceptionClass` argument, which is invoked to construct the exception
 * instance to be thrown, so technically `parseError` will throw the object
 * produced by the `new ExceptionClass(str, hash)` JavaScript expression.
 *
 * ---
 *
 * You can specify lexer options by setting / modifying the `.options` object of your Lexer instance.
 * These options are available:
 *
 * (Options are permanent.)
 *  
 *  yy: {
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default `parseError` function.
 *  }
 *
 *  lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 `this` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token `token`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original `token`.
 *                 `this` refers to the Lexer object.
 *
 * WARNING: the next set of options are not meant to be changed. They echo the abilities of
 * the lexer as per when it was compiled!
 *
 *      ranges: boolean
 *                 optional: `true` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: `true` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: `true` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: `true` ==> lexer rule regexes are "extended regex format" requiring the
 *                 `XRegExp` library. When this %option has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */


var lexer$1 = function() {
  /**
   * See also:
   * http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
   * but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
   * with userland code which might access the derived class in a 'classic' way.
   *
   * @public
   * @constructor
   * @nocollapse
   */
  function JisonLexerError(msg, hash) {
    Object.defineProperty(this, 'name', {
      enumerable: false,
      writable: false,
      value: 'JisonLexerError'
    });

    if (msg == null)
      msg = '???';

    Object.defineProperty(this, 'message', {
      enumerable: false,
      writable: true,
      value: msg
    });

    this.hash = hash;
    var stacktrace;

    if (hash && hash.exception instanceof Error) {
      var ex2 = hash.exception;
      this.message = ex2.message || msg;
      stacktrace = ex2.stack;
    }

    if (!stacktrace) {
      if (Error.hasOwnProperty('captureStackTrace')) {
        // V8
        Error.captureStackTrace(this, this.constructor);
      } else {
        stacktrace = new Error(msg).stack;
      }
    }

    if (stacktrace) {
      Object.defineProperty(this, 'stack', {
        enumerable: false,
        writable: false,
        value: stacktrace
      });
    }
  }

  if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonLexerError.prototype, Error.prototype);
  } else {
    JisonLexerError.prototype = Object.create(Error.prototype);
  }

  JisonLexerError.prototype.constructor = JisonLexerError;
  JisonLexerError.prototype.name = 'JisonLexerError';

  var lexer = {
    
// Code Generator Information Report
// ---------------------------------
//
// Options:
//
//   backtracking: .................... false
//   location.ranges: ................. true
//   location line+column tracking: ... true
//
//
// Forwarded Parser Analysis flags:
//
//   uses yyleng: ..................... false
//   uses yylineno: ................... false
//   uses yytext: ..................... false
//   uses yylloc: ..................... false
//   uses lexer values: ............... true / true
//   location tracking: ............... true
//   location assignment: ............. true
//
//
// Lexer Analysis flags:
//
//   uses yyleng: ..................... ???
//   uses yylineno: ................... ???
//   uses yytext: ..................... ???
//   uses yylloc: ..................... ???
//   uses ParseError API: ............. ???
//   uses yyerror: .................... ???
//   uses location tracking & editing:  ???
//   uses more() API: ................. ???
//   uses unput() API: ................ ???
//   uses reject() API: ............... ???
//   uses less() API: ................. ???
//   uses display APIs pastInput(), upcomingInput(), showPosition():
//        ............................. ???
//   uses describeYYLLOC() API: ....... ???
//
// --------- END OF REPORT -----------

EOF: 1,
    ERROR: 2,

    // JisonLexerError: JisonLexerError,        /// <-- injected by the code generator

    // options: {},                             /// <-- injected by the code generator

    // yy: ...,                                 /// <-- injected by setInput()

    __currentRuleSet__: null,                   /// INTERNAL USE ONLY: internal rule set cache for the current lexer state  

    __error_infos: [],                          /// INTERNAL USE ONLY: the set of lexErrorInfo objects created since the last cleanup  
    __decompressed: false,                      /// INTERNAL USE ONLY: mark whether the lexer instance has been 'unfolded' completely and is now ready for use  
    done: false,                                /// INTERNAL USE ONLY  
    _backtrack: false,                          /// INTERNAL USE ONLY  
    _input: '',                                 /// INTERNAL USE ONLY  
    _more: false,                               /// INTERNAL USE ONLY  
    _signaled_error_token: false,               /// INTERNAL USE ONLY  
    conditionStack: [],                         /// INTERNAL USE ONLY; managed via `pushState()`, `popState()`, `topState()` and `stateStackSize()`  
    match: '',                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction. `match` is identical to `yytext` except that this one still contains the matched input string after `lexer.performAction()` has been invoked, where userland code MAY have changed/replaced the `yytext` value entirely!  
    matched: '',                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks entire input which has been matched so far  
    matches: false,                             /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks RE match result for last (successful) match attempt  
    yytext: '',                                 /// ADVANCED USE ONLY: tracks input which has been matched so far for the lexer token under construction; this value is transferred to the parser as the 'token value' when the parser consumes the lexer token produced through a call to the `lex()` API.  
    offset: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks the 'cursor position' in the input string, i.e. the number of characters matched so far  
    yyleng: 0,                                  /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: length of matched input for the token under construction (`yytext`)  
    yylineno: 0,                                /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: 'line number' at which the token under construction is located  
    yylloc: null,                               /// READ-ONLY EXTERNAL ACCESS - ADVANCED USE ONLY: tracks location info (lines + columns) for the token under construction  

    /**
     * INTERNAL USE: construct a suitable error info hash object instance for `parseError`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    constructLexErrorInfo: function lexer_constructLexErrorInfo(msg, recoverable, show_input_position) {
      msg = '' + msg;

      // heuristic to determine if the error message already contains a (partial) source code dump
      // as produced by either `showPosition()` or `prettyPrintRange()`:
      if (show_input_position == undefined) {
        show_input_position = !(msg.indexOf('\n') > 0 && msg.indexOf('^') > 0);
      }

      if (this.yylloc && show_input_position) {
        if (typeof this.prettyPrintRange === 'function') {
          var pretty_src = this.prettyPrintRange(this.yylloc);

          if (!/\n\s*$/.test(msg)) {
            msg += '\n';
          }

          msg += '\n  Erroneous area:\n' + this.prettyPrintRange(this.yylloc);
        } else if (typeof this.showPosition === 'function') {
          var pos_str = this.showPosition();

          if (pos_str) {
            if (msg.length && msg[msg.length - 1] !== '\n' && pos_str[0] !== '\n') {
              msg += '\n' + pos_str;
            } else {
              msg += pos_str;
            }
          }
        }
      }

      /** @constructor */
      var pei = {
        errStr: msg,
        recoverable: !!recoverable,
        text: this.match,           // This one MAY be empty; userland code should use the `upcomingInput` API to obtain more text which follows the 'lexer cursor position'...  
        token: null,
        line: this.yylineno,
        loc: this.yylloc,
        yy: this.yy,
        lexer: this,

        /**
         * and make sure the error info doesn't stay due to potential
         * ref cycle via userland code manipulations.
         * These would otherwise all be memory leak opportunities!
         * 
         * Note that only array and object references are nuked as those
         * constitute the set of elements which can produce a cyclic ref.
         * The rest of the members is kept intact as they are harmless.
         * 
         * @public
         * @this {LexErrorInfo}
         */
        destroy: function destructLexErrorInfo() {
          // remove cyclic references added to error info:
          // info.yy = null;
          // info.lexer = null;
          // ...
          var rec = !!this.recoverable;

          for (var key in this) {
            if (this.hasOwnProperty(key) && typeof key === 'object') {
              this[key] = undefined;
            }
          }

          this.recoverable = rec;
        }
      };

      // track this instance so we can `destroy()` it once we deem it superfluous and ready for garbage collection!
      this.__error_infos.push(pei);

      return pei;
    },

    /**
     * handler which is invoked when a lexer error occurs.
     * 
     * @public
     * @this {RegExpLexer}
     */
    parseError: function lexer_parseError(str, hash, ExceptionClass) {
      if (!ExceptionClass) {
        ExceptionClass = this.JisonLexerError;
      }

      if (this.yy) {
        if (this.yy.parser && typeof this.yy.parser.parseError === 'function') {
          return this.yy.parser.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        } else if (typeof this.yy.parseError === 'function') {
          return this.yy.parseError.call(this, str, hash, ExceptionClass) || this.ERROR;
        }
      }

      throw new ExceptionClass(str, hash);
    },

    /**
     * method which implements `yyerror(str, ...args)` functionality for use inside lexer actions.
     * 
     * @public
     * @this {RegExpLexer}
     */
    yyerror: function yyError(str /*, ...args */) {
      var lineno_msg = '';

      if (this.yylloc) {
        lineno_msg = ' on line ' + (this.yylineno + 1);
      }

      var p = this.constructLexErrorInfo(
        'Lexical error' + lineno_msg + ': ' + str,
        this.options.lexerErrorsAreRecoverable
      );

      // Add any extra args to the hash under the name `extra_error_attributes`:
      var args = Array.prototype.slice.call(arguments, 1);

      if (args.length) {
        p.extra_error_attributes = args;
      }

      return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
    },

    /**
     * final cleanup function for when we have completed lexing the input;
     * make it an API so that external code can use this one once userland
     * code has decided it's time to destroy any lingering lexer error
     * hash object instances and the like: this function helps to clean
     * up these constructs, which *may* carry cyclic references which would
     * otherwise prevent the instances from being properly and timely
     * garbage-collected, i.e. this function helps prevent memory leaks!
     * 
     * @public
     * @this {RegExpLexer}
     */
    cleanupAfterLex: function lexer_cleanupAfterLex(do_not_nuke_errorinfos) {
      // prevent lingering circular references from causing memory leaks:
      this.setInput('', {});

      // nuke the error hash info instances created during this run.
      // Userland code must COPY any data/references
      // in the error hash instance(s) it is more permanently interested in.
      if (!do_not_nuke_errorinfos) {
        for (var i = this.__error_infos.length - 1; i >= 0; i--) {
          var el = this.__error_infos[i];

          if (el && typeof el.destroy === 'function') {
            el.destroy();
          }
        }

        this.__error_infos.length = 0;
      }

      return this;
    },

    /**
     * clear the lexer token context; intended for internal use only
     * 
     * @public
     * @this {RegExpLexer}
     */
    clear: function lexer_clear() {
      this.yytext = '';
      this.yyleng = 0;
      this.match = '';

      // - DO NOT reset `this.matched`
      this.matches = false;

      this._more = false;
      this._backtrack = false;
      var col = (this.yylloc ? this.yylloc.last_column : 0);

      this.yylloc = {
        first_line: this.yylineno + 1,
        first_column: col,
        last_line: this.yylineno + 1,
        last_column: col,
        range: [this.offset, this.offset]
      };
    },

    /**
     * resets the lexer, sets new input
     * 
     * @public
     * @this {RegExpLexer}
     */
    setInput: function lexer_setInput(input, yy) {
      this.yy = yy || this.yy || {};

      // also check if we've fully initialized the lexer instance,
      // including expansion work to be done to go from a loaded
      // lexer to a usable lexer:
      if (!this.__decompressed) {
        // step 1: decompress the regex list:
        var rules = this.rules;

        for (var i = 0, len = rules.length; i < len; i++) {
          var rule_re = rules[i];

          // compression: is the RE an xref to another RE slot in the rules[] table?
          if (typeof rule_re === 'number') {
            rules[i] = rules[rule_re];
          }
        }

        // step 2: unfold the conditions[] set to make these ready for use:
        var conditions = this.conditions;

        for (var k in conditions) {
          var spec = conditions[k];
          var rule_ids = spec.rules;
          var len = rule_ids.length;
          var rule_regexes = new Array(len + 1);             // slot 0 is unused; we use a 1-based index approach here to keep the hottest code in `lexer_next()` fast and simple! 
          var rule_new_ids = new Array(len + 1);

          for (var i = 0; i < len; i++) {
            var idx = rule_ids[i];
            var rule_re = rules[idx];
            rule_regexes[i + 1] = rule_re;
            rule_new_ids[i + 1] = idx;
          }

          spec.rules = rule_new_ids;
          spec.__rule_regexes = rule_regexes;
          spec.__rule_count = len;
        }

        this.__decompressed = true;
      }

      this._input = input || '';
      this.clear();
      this._signaled_error_token = false;
      this.done = false;
      this.yylineno = 0;
      this.matched = '';
      this.conditionStack = ['INITIAL'];
      this.__currentRuleSet__ = null;

      this.yylloc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      this.offset = 0;
      return this;
    },

    /**
     * edit the remaining input via user-specified callback.
     * This can be used to forward-adjust the input-to-parse, 
     * e.g. inserting macro expansions and alike in the
     * input which has yet to be lexed.
     * The behaviour of this API contrasts the `unput()` et al
     * APIs as those act on the *consumed* input, while this
     * one allows one to manipulate the future, without impacting
     * the current `yyloc` cursor location or any history. 
     * 
     * Use this API to help implement C-preprocessor-like
     * `#include` statements, etc.
     * 
     * The provided callback must be synchronous and is
     * expected to return the edited input (string).
     *
     * The `cpsArg` argument value is passed to the callback
     * as-is.
     *
     * `callback` interface: 
     * `function callback(input, cpsArg)`
     * 
     * - `input` will carry the remaining-input-to-lex string
     *   from the lexer.
     * - `cpsArg` is `cpsArg` passed into this API.
     * 
     * The `this` reference for the callback will be set to
     * reference this lexer instance so that userland code
     * in the callback can easily and quickly access any lexer
     * API. 
     *
     * When the callback returns a non-string-type falsey value,
     * we assume the callback did not edit the input and we
     * will using the input as-is.
     *
     * When the callback returns a non-string-type value, it
     * is converted to a string for lexing via the `"" + retval`
     * operation. (See also why: http://2ality.com/2012/03/converting-to-string.html 
     * -- that way any returned object's `toValue()` and `toString()`
     * methods will be invoked in a proper/desirable order.)
     * 
     * @public
     * @this {RegExpLexer}
     */
    editRemainingInput: function lexer_editRemainingInput(callback, cpsArg) {
      var rv = callback.call(this, this._input, cpsArg);

      if (typeof rv !== 'string') {
        if (rv) {
          this._input = '' + rv;
        } 
        // else: keep `this._input` as is.  
      } else {
        this._input = rv;
      }

      return this;
    },

    /**
     * consumes and returns one char from the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    input: function lexer_input() {
      if (!this._input) {
        //this.done = true;    -- don't set `done` as we want the lex()/next() API to be able to produce one custom EOF token match after this anyhow. (lexer can match special <<EOF>> tokens and perform user action code for a <<EOF>> match, but only does so *once*)
        return null;
      }

      var ch = this._input[0];
      this.yytext += ch;
      this.yyleng++;
      this.offset++;
      this.match += ch;
      this.matched += ch;

      // Count the linenumber up when we hit the LF (or a stand-alone CR).
      // On CRLF, the linenumber is incremented when you fetch the CR or the CRLF combo
      // and we advance immediately past the LF as well, returning both together as if
      // it was all a single 'character' only.
      var slice_len = 1;

      var lines = false;

      if (ch === '\n') {
        lines = true;
      } else if (ch === '\r') {
        lines = true;
        var ch2 = this._input[1];

        if (ch2 === '\n') {
          slice_len++;
          ch += ch2;
          this.yytext += ch2;
          this.yyleng++;
          this.offset++;
          this.match += ch2;
          this.matched += ch2;
          this.yylloc.range[1]++;
        }
      }

      if (lines) {
        this.yylineno++;
        this.yylloc.last_line++;
        this.yylloc.last_column = 0;
      } else {
        this.yylloc.last_column++;
      }

      this.yylloc.range[1]++;
      this._input = this._input.slice(slice_len);
      return ch;
    },

    /**
     * unshifts one char (or an entire string) into the input
     * 
     * @public
     * @this {RegExpLexer}
     */
    unput: function lexer_unput(ch) {
      var len = ch.length;
      var lines = ch.split(/(?:\r\n?|\n)/g);
      this._input = ch + this._input;
      this.yytext = this.yytext.substr(0, this.yytext.length - len);
      this.yyleng = this.yytext.length;
      this.offset -= len;
      this.match = this.match.substr(0, this.match.length - len);
      this.matched = this.matched.substr(0, this.matched.length - len);

      if (lines.length > 1) {
        this.yylineno -= lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;

        // Get last entirely matched line into the `pre_lines[]` array's
        // last index slot; we don't mind when other previously 
        // matched lines end up in the array too. 
        var pre = this.match;

        var pre_lines = pre.split(/(?:\r\n?|\n)/g);

        if (pre_lines.length === 1) {
          pre = this.matched;
          pre_lines = pre.split(/(?:\r\n?|\n)/g);
        }

        this.yylloc.last_column = pre_lines[pre_lines.length - 1].length;
      } else {
        this.yylloc.last_column -= len;
      }

      this.yylloc.range[1] = this.yylloc.range[0] + this.yyleng;
      this.done = false;
      return this;
    },

    /**
     * cache matched text and append it on next action
     * 
     * @public
     * @this {RegExpLexer}
     */
    more: function lexer_more() {
      this._more = true;
      return this;
    },

    /**
     * signal the lexer that this rule fails to match the input, so the
     * next matching rule (regex) should be tested instead.
     * 
     * @public
     * @this {RegExpLexer}
     */
    reject: function lexer_reject() {
      if (this.options.backtrack_lexer) {
        this._backtrack = true;
      } else {
        // when the `parseError()` call returns, we MUST ensure that the error is registered.
        // We accomplish this by signaling an 'error' token to be produced for the current
        // `.lex()` run.
        var lineno_msg = '';

        if (this.yylloc) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': You can only invoke reject() in the lexer when the lexer is of the backtracking persuasion (options.backtrack_lexer = true).',
          false
        );

        this._signaled_error_token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
      }

      return this;
    },

    /**
     * retain first n characters of the match
     * 
     * @public
     * @this {RegExpLexer}
     */
    less: function lexer_less(n) {
      return this.unput(this.match.slice(n));
    },

    /**
     * return (part of the) already matched input, i.e. for error
     * messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of
     * input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     * 
     * @public
     * @this {RegExpLexer}
     */
    pastInput: function lexer_pastInput(maxSize, maxLines) {
      var past = this.matched.substring(0, this.matched.length - this.match.length);

      if (maxSize < 0)
        maxSize = past.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = past.length;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substr` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      past = past.substr(-maxSize * 2 - 2);

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = past.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(-maxLines);
      past = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis prefix...
      if (past.length > maxSize) {
        past = '...' + past.substr(-maxSize);
      }

      return past;
    },

    /**
     * return (part of the) upcoming input, i.e. for error messages.
     * 
     * Limit the returned string length to `maxSize` (default: 20).
     * 
     * Limit the returned string to the `maxLines` number of lines of input (default: 1).
     * 
     * Negative limit values equal *unlimited*.
     *
     * > ### NOTE ###
     * >
     * > *"upcoming input"* is defined as the whole of the both
     * > the *currently lexed* input, together with any remaining input
     * > following that. *"currently lexed"* input is the input 
     * > already recognized by the lexer but not yet returned with
     * > the lexer token. This happens when you are invoking this API
     * > from inside any lexer rule action code block. 
     * >
     * 
     * @public
     * @this {RegExpLexer}
     */
    upcomingInput: function lexer_upcomingInput(maxSize, maxLines) {
      var next = this.match;

      if (maxSize < 0)
        maxSize = next.length + this._input.length;
      else if (!maxSize)
        maxSize = 20;

      if (maxLines < 0)
        maxLines = maxSize;          // can't ever have more input lines than this! 
      else if (!maxLines)
        maxLines = 1;

      // `substring` anticipation: treat \r\n as a single character and take a little
      // more than necessary so that we can still properly check against maxSize
      // after we've transformed and limited the newLines in here:
      if (next.length < maxSize * 2 + 2) {
        next += this._input.substring(0, maxSize * 2 + 2);   // substring is faster on Chrome/V8 
      }

      // now that we have a significantly reduced string to process, transform the newlines
      // and chop them, then limit them:
      var a = next.replace(/\r\n|\r/g, '\n').split('\n');

      a = a.slice(0, maxLines);
      next = a.join('\n');

      // When, after limiting to maxLines, we still have too much to return,
      // do add an ellipsis postfix...
      if (next.length > maxSize) {
        next = next.substring(0, maxSize) + '...';
      }

      return next;
    },

    /**
     * return a string which displays the character position where the
     * lexing error occurred, i.e. for error messages
     * 
     * @public
     * @this {RegExpLexer}
     */
    showPosition: function lexer_showPosition(maxPrefix, maxPostfix) {
      var pre = this.pastInput(maxPrefix).replace(/\s/g, ' ');
      var c = new Array(pre.length + 1).join('-');
      return pre + this.upcomingInput(maxPostfix).replace(/\s/g, ' ') + '\n' + c + '^';
    },

    /**
     * return an YYLLOC info object derived off the given context (actual, preceding, following, current).
     * Use this method when the given `actual` location is not guaranteed to exist (i.e. when
     * it MAY be NULL) and you MUST have a valid location info object anyway:
     * then we take the given context of the `preceding` and `following` locations, IFF those are available,
     * and reconstruct the `actual` location info from those.
     * If this fails, the heuristic is to take the `current` location, IFF available.
     * If this fails as well, we assume the sought location is at/around the current lexer position
     * and then produce that one as a response. DO NOTE that these heuristic/derived location info
     * values MAY be inaccurate!
     *
     * NOTE: `deriveLocationInfo()` ALWAYS produces a location info object *copy* of `actual`, not just
     * a *reference* hence all input location objects can be assumed to be 'constant' (function has no side-effects).
     * 
     * @public
     * @this {RegExpLexer}
     */
    deriveLocationInfo: function lexer_deriveYYLLOC(actual, preceding, following, current) {
      var loc = {
        first_line: 1,
        first_column: 0,
        last_line: 1,
        last_column: 0,
        range: [0, 0]
      };

      if (actual) {
        loc.first_line = actual.first_line | 0;
        loc.last_line = actual.last_line | 0;
        loc.first_column = actual.first_column | 0;
        loc.last_column = actual.last_column | 0;

        if (actual.range) {
          loc.range[0] = actual.range[0] | 0;
          loc.range[1] = actual.range[1] | 0;
        }
      }

      if (loc.first_line <= 0 || loc.last_line < loc.first_line) {
        // plan B: heuristic using preceding and following:
        if (loc.first_line <= 0 && preceding) {
          loc.first_line = preceding.last_line | 0;
          loc.first_column = preceding.last_column | 0;

          if (preceding.range) {
            loc.range[0] = actual.range[1] | 0;
          }
        }

        if ((loc.last_line <= 0 || loc.last_line < loc.first_line) && following) {
          loc.last_line = following.first_line | 0;
          loc.last_column = following.first_column | 0;

          if (following.range) {
            loc.range[1] = actual.range[0] | 0;
          }
        }

        // plan C?: see if the 'current' location is useful/sane too:
        if (loc.first_line <= 0 && current && (loc.last_line <= 0 || current.last_line <= loc.last_line)) {
          loc.first_line = current.first_line | 0;
          loc.first_column = current.first_column | 0;

          if (current.range) {
            loc.range[0] = current.range[0] | 0;
          }
        }

        if (loc.last_line <= 0 && current && (loc.first_line <= 0 || current.first_line >= loc.first_line)) {
          loc.last_line = current.last_line | 0;
          loc.last_column = current.last_column | 0;

          if (current.range) {
            loc.range[1] = current.range[1] | 0;
          }
        }
      }

      // sanitize: fix last_line BEFORE we fix first_line as we use the 'raw' value of the latter
      // or plan D heuristics to produce a 'sensible' last_line value:
      if (loc.last_line <= 0) {
        if (loc.first_line <= 0) {
          loc.first_line = this.yylloc.first_line;
          loc.last_line = this.yylloc.last_line;
          loc.first_column = this.yylloc.first_column;
          loc.last_column = this.yylloc.last_column;
          loc.range[0] = this.yylloc.range[0];
          loc.range[1] = this.yylloc.range[1];
        } else {
          loc.last_line = this.yylloc.last_line;
          loc.last_column = this.yylloc.last_column;
          loc.range[1] = this.yylloc.range[1];
        }
      }

      if (loc.first_line <= 0) {
        loc.first_line = loc.last_line;
        loc.first_column = 0;  // loc.last_column; 
        loc.range[1] = loc.range[0];
      }

      if (loc.first_column < 0) {
        loc.first_column = 0;
      }

      if (loc.last_column < 0) {
        loc.last_column = (loc.first_column > 0 ? loc.first_column : 80);
      }

      return loc;
    },

    /**
     * return a string which displays the lines & columns of input which are referenced 
     * by the given location info range, plus a few lines of context.
     * 
     * This function pretty-prints the indicated section of the input, with line numbers 
     * and everything!
     * 
     * This function is very useful to provide highly readable error reports, while
     * the location range may be specified in various flexible ways:
     * 
     * - `loc` is the location info object which references the area which should be
     *   displayed and 'marked up': these lines & columns of text are marked up by `^`
     *   characters below each character in the entire input range.
     * 
     * - `context_loc` is the *optional* location info object which instructs this
     *   pretty-printer how much *leading* context should be displayed alongside
     *   the area referenced by `loc`. This can help provide context for the displayed
     *   error, etc.
     * 
     *   When this location info is not provided, a default context of 3 lines is
     *   used.
     * 
     * - `context_loc2` is another *optional* location info object, which serves
     *   a similar purpose to `context_loc`: it specifies the amount of *trailing*
     *   context lines to display in the pretty-print output.
     * 
     *   When this location info is not provided, a default context of 1 line only is
     *   used.
     * 
     * Special Notes:
     * 
     * - when the `loc`-indicated range is very large (about 5 lines or more), then
     *   only the first and last few lines of this block are printed while a
     *   `...continued...` message will be printed between them.
     * 
     *   This serves the purpose of not printing a huge amount of text when the `loc`
     *   range happens to be huge: this way a manageable & readable output results
     *   for arbitrary large ranges.
     * 
     * - this function can display lines of input which whave not yet been lexed.
     *   `prettyPrintRange()` can access the entire input!
     * 
     * @public
     * @this {RegExpLexer}
     */
    prettyPrintRange: function lexer_prettyPrintRange(loc, context_loc, context_loc2) {
      loc = this.deriveLocationInfo(loc, context_loc, context_loc2);
      const CONTEXT = 3;
      const CONTEXT_TAIL = 1;
      const MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT = 2;
      var input = this.matched + this._input;
      var lines = input.split('\n');
      var l0 = Math.max(1, (context_loc ? context_loc.first_line : loc.first_line - CONTEXT));
      var l1 = Math.max(1, (context_loc2 ? context_loc2.last_line : loc.last_line + CONTEXT_TAIL));
      var lineno_display_width = 1 + Math.log10(l1 | 1) | 0;
      var ws_prefix = new Array(lineno_display_width).join(' ');
      var nonempty_line_indexes = [];

      var rv = lines.slice(l0 - 1, l1 + 1).map(function injectLineNumber(line, index) {
        var lno = index + l0;
        var lno_pfx = (ws_prefix + lno).substr(-lineno_display_width);
        var rv = lno_pfx + ': ' + line;
        var errpfx = new Array(lineno_display_width + 1).join('^');
        var offset = 2 + 1;
        var len = 0;

        if (lno === loc.first_line) {
          offset += loc.first_column;

          len = Math.max(
            2,
            ((lno === loc.last_line ? loc.last_column : line.length)) - loc.first_column + 1
          );
        } else if (lno === loc.last_line) {
          len = Math.max(2, loc.last_column + 1);
        } else if (lno > loc.first_line && lno < loc.last_line) {
          len = Math.max(2, line.length + 1);
        }

        if (len) {
          var lead = new Array(offset).join('.');
          var mark = new Array(len).join('^');
          rv += '\n' + errpfx + lead + mark;

          if (line.trim().length > 0) {
            nonempty_line_indexes.push(index);
          }
        }

        rv = rv.replace(/\t/g, ' ');
        return rv;
      });

      // now make sure we don't print an overly large amount of error area: limit it 
      // to the top and bottom line count:
      if (nonempty_line_indexes.length > 2 * MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT) {
        var clip_start = nonempty_line_indexes[MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT - 1] + 1;
        var clip_end = nonempty_line_indexes[nonempty_line_indexes.length - MINIMUM_VISIBLE_NONEMPTY_LINE_COUNT] - 1;
        var intermediate_line = new Array(lineno_display_width + 1).join(' ') + '  (...continued...)';
        intermediate_line += '\n' + new Array(lineno_display_width + 1).join('-') + '  (---------------)';
        rv.splice(clip_start, clip_end - clip_start + 1, intermediate_line);
      }

      return rv.join('\n');
    },

    /**
     * helper function, used to produce a human readable description as a string, given
     * the input `yylloc` location object.
     * 
     * Set `display_range_too` to TRUE to include the string character index position(s)
     * in the description if the `yylloc.range` is available.
     * 
     * @public
     * @this {RegExpLexer}
     */
    describeYYLLOC: function lexer_describe_yylloc(yylloc, display_range_too) {
      var l1 = yylloc.first_line;
      var l2 = yylloc.last_line;
      var c1 = yylloc.first_column;
      var c2 = yylloc.last_column;
      var dl = l2 - l1;
      var dc = c2 - c1;
      var rv;

      if (dl === 0) {
        rv = 'line ' + l1 + ', ';

        if (dc <= 1) {
          rv += 'column ' + c1;
        } else {
          rv += 'columns ' + c1 + ' .. ' + c2;
        }
      } else {
        rv = 'lines ' + l1 + '(column ' + c1 + ') .. ' + l2 + '(column ' + c2 + ')';
      }

      if (yylloc.range && display_range_too) {
        var r1 = yylloc.range[0];
        var r2 = yylloc.range[1] - 1;

        if (r2 <= r1) {
          rv += ' {String Offset: ' + r1 + '}';
        } else {
          rv += ' {String Offset range: ' + r1 + ' .. ' + r2 + '}';
        }
      }

      return rv;
    },

    /**
     * test the lexed token: return FALSE when not a match, otherwise return token.
     * 
     * `match` is supposed to be an array coming out of a regex match, i.e. `match[0]`
     * contains the actually matched text string.
     * 
     * Also move the input cursor forward and update the match collectors:
     * 
     * - `yytext`
     * - `yyleng`
     * - `match`
     * - `matches`
     * - `yylloc`
     * - `offset`
     * 
     * @public
     * @this {RegExpLexer}
     */
    test_match: function lexer_test_match(match, indexed_rule) {
      var token, lines, backup, match_str, match_str_len;

      if (this.options.backtrack_lexer) {
        // save context
        backup = {
          yylineno: this.yylineno,

          yylloc: {
            first_line: this.yylloc.first_line,
            last_line: this.yylloc.last_line,
            first_column: this.yylloc.first_column,
            last_column: this.yylloc.last_column,
            range: this.yylloc.range.slice(0)
          },

          yytext: this.yytext,
          match: this.match,
          matches: this.matches,
          matched: this.matched,
          yyleng: this.yyleng,
          offset: this.offset,
          _more: this._more,
          _input: this._input,

          //_signaled_error_token: this._signaled_error_token,
          yy: this.yy,

          conditionStack: this.conditionStack.slice(0),
          done: this.done
        };
      }

      match_str = match[0];
      match_str_len = match_str.length;

      // if (match_str.indexOf('\n') !== -1 || match_str.indexOf('\r') !== -1) {
      lines = match_str.split(/(?:\r\n?|\n)/g);

      if (lines.length > 1) {
        this.yylineno += lines.length - 1;
        this.yylloc.last_line = this.yylineno + 1;
        this.yylloc.last_column = lines[lines.length - 1].length;
      } else {
        this.yylloc.last_column += match_str_len;
      }

      // }
      this.yytext += match_str;

      this.match += match_str;
      this.matched += match_str;
      this.matches = match;
      this.yyleng = this.yytext.length;
      this.yylloc.range[1] += match_str_len;

      // previous lex rules MAY have invoked the `more()` API rather than producing a token:
      // those rules will already have moved this `offset` forward matching their match lengths,
      // hence we must only add our own match length now:
      this.offset += match_str_len;

      this._more = false;
      this._backtrack = false;
      this._input = this._input.slice(match_str_len);

      // calling this method:
      //
      //   function lexer__performAction(yy, yyrulenumber, YY_START) {...}
      token = this.performAction.call(
        this,
        this.yy,
        indexed_rule,
        this.conditionStack[this.conditionStack.length - 1] /* = YY_START */
      );

      // otherwise, when the action codes are all simple return token statements:
      //token = this.simpleCaseActionClusters[indexed_rule];

      if (this.done && this._input) {
        this.done = false;
      }

      if (token) {
        return token;
      } else if (this._backtrack) {
        // recover context
        for (var k in backup) {
          this[k] = backup[k];
        }

        this.__currentRuleSet__ = null;
        return false;  // rule action called reject() implying the next rule should be tested instead. 
      } else if (this._signaled_error_token) {
        // produce one 'error' token as `.parseError()` in `reject()`
        // did not guarantee a failure signal by throwing an exception!
        token = this._signaled_error_token;

        this._signaled_error_token = false;
        return token;
      }

      return false;
    },

    /**
     * return next match in input
     * 
     * @public
     * @this {RegExpLexer}
     */
    next: function lexer_next() {
      if (this.done) {
        this.clear();
        return this.EOF;
      }

      if (!this._input) {
        this.done = true;
      }

      var token, match, tempMatch, index;

      if (!this._more) {
        this.clear();
      }

      var spec = this.__currentRuleSet__;

      if (!spec) {
        // Update the ruleset cache as we apparently encountered a state change or just started lexing.
        // The cache is set up for fast lookup -- we assume a lexer will switch states much less often than it will
        // invoke the `lex()` token-producing API and related APIs, hence caching the set for direct access helps
        // speed up those activities a tiny bit.
        spec = this.__currentRuleSet__ = this._currentRules();

        // Check whether a *sane* condition has been pushed before: this makes the lexer robust against
        // user-programmer bugs such as https://github.com/zaach/jison-lex/issues/19
        if (!spec || !spec.rules) {
          var lineno_msg = '';

          if (this.options.trackPosition) {
            lineno_msg = ' on line ' + (this.yylineno + 1);
          }

          var p = this.constructLexErrorInfo(
            'Internal lexer engine error' + lineno_msg + ': The lex grammar programmer pushed a non-existing condition name "' + this.topState() + '"; this is a fatal error and should be reported to the application programmer team!',
            false
          );

          // produce one 'error' token until this situation has been resolved, most probably by parse termination!
          return this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;
        }
      }

      var rule_ids = spec.rules;
      var regexes = spec.__rule_regexes;
      var len = spec.__rule_count;

      // Note: the arrays are 1-based, while `len` itself is a valid index,
      // hence the non-standard less-or-equal check in the next loop condition!
      for (var i = 1; i <= len; i++) {
        tempMatch = this._input.match(regexes[i]);

        if (tempMatch && (!match || tempMatch[0].length > match[0].length)) {
          match = tempMatch;
          index = i;

          if (this.options.backtrack_lexer) {
            token = this.test_match(tempMatch, rule_ids[i]);

            if (token !== false) {
              return token;
            } else if (this._backtrack) {
              match = undefined;
              continue;  // rule action called reject() implying a rule MISmatch. 
            } else {
              // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
              return false;
            }
          } else if (!this.options.flex) {
            break;
          }
        }
      }

      if (match) {
        token = this.test_match(match, rule_ids[index]);

        if (token !== false) {
          return token;
        }

        // else: this is a lexer rule which consumes input without producing a token (e.g. whitespace)
        return false;
      }

      if (!this._input) {
        this.done = true;
        this.clear();
        return this.EOF;
      } else {
        var lineno_msg = '';

        if (this.options.trackPosition) {
          lineno_msg = ' on line ' + (this.yylineno + 1);
        }

        var p = this.constructLexErrorInfo(
          'Lexical error' + lineno_msg + ': Unrecognized text.',
          this.options.lexerErrorsAreRecoverable
        );

        var pendingInput = this._input;
        var activeCondition = this.topState();
        var conditionStackDepth = this.conditionStack.length;
        token = this.parseError(p.errStr, p, this.JisonLexerError) || this.ERROR;

        if (token === this.ERROR) {
          // we can try to recover from a lexer error that `parseError()` did not 'recover' for us
          // by moving forward at least one character at a time IFF the (user-specified?) `parseError()`
          // has not consumed/modified any pending input or changed state in the error handler:
          if (!this.matches && // and make sure the input has been modified/consumed ...
          pendingInput === this._input && // ...or the lexer state has been modified significantly enough
          // to merit a non-consuming error handling action right now.
          activeCondition === this.topState() && conditionStackDepth === this.conditionStack.length) {
            this.input();
          }
        }

        return token;
      }
    },

    /**
     * return next match that has a token
     * 
     * @public
     * @this {RegExpLexer}
     */
    lex: function lexer_lex() {
      var r;

      // allow the PRE/POST handlers set/modify the return token for maximum flexibility of the generated lexer:
      if (typeof this.pre_lex === 'function') {
        r = this.pre_lex.call(this, 0);
      }

      if (typeof this.options.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.pre_lex.call(this, r) || r;
      }

      if (this.yy && typeof this.yy.pre_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.pre_lex.call(this, r) || r;
      }

      while (!r) {
        r = this.next();
      }

      if (this.yy && typeof this.yy.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.yy.post_lex.call(this, r) || r;
      }

      if (typeof this.options.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.options.post_lex.call(this, r) || r;
      }

      if (typeof this.post_lex === 'function') {
        // (also account for a userdef function which does not return any value: keep the token as is)
        r = this.post_lex.call(this, r) || r;
      }

      return r;
    },

    /**
     * return next match that has a token. Identical to the `lex()` API but does not invoke any of the 
     * `pre_lex()` nor any of the `post_lex()` callbacks.
     * 
     * @public
     * @this {RegExpLexer}
     */
    fastLex: function lexer_fastLex() {
      var r;

      while (!r) {
        r = this.next();
      }

      return r;
    },

    /**
     * return info about the lexer state that can help a parser or other lexer API user to use the
     * most efficient means available. This API is provided to aid run-time performance for larger
     * systems which employ this lexer.
     * 
     * @public
     * @this {RegExpLexer}
     */
    canIUse: function lexer_canIUse() {
      var rv = {
        fastLex: !(typeof this.pre_lex === 'function' || typeof this.options.pre_lex === 'function' || this.yy && typeof this.yy.pre_lex === 'function' || this.yy && typeof this.yy.post_lex === 'function' || typeof this.options.post_lex === 'function' || typeof this.post_lex === 'function') && typeof this.fastLex === 'function'
      };

      return rv;
    },

    /**
     * backwards compatible alias for `pushState()`;
     * the latter is symmetrical with `popState()` and we advise to use
     * those APIs in any modern lexer code, rather than `begin()`.
     * 
     * @public
     * @this {RegExpLexer}
     */
    begin: function lexer_begin(condition) {
      return this.pushState(condition);
    },

    /**
     * activates a new lexer condition state (pushes the new lexer
     * condition state onto the condition stack)
     * 
     * @public
     * @this {RegExpLexer}
     */
    pushState: function lexer_pushState(condition) {
      this.conditionStack.push(condition);
      this.__currentRuleSet__ = null;
      return this;
    },

    /**
     * pop the previously active lexer condition state off the condition
     * stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    popState: function lexer_popState() {
      var n = this.conditionStack.length - 1;

      if (n > 0) {
        this.__currentRuleSet__ = null;
        return this.conditionStack.pop();
      } else {
        return this.conditionStack[0];
      }
    },

    /**
     * return the currently active lexer condition state; when an index
     * argument is provided it produces the N-th previous condition state,
     * if available
     * 
     * @public
     * @this {RegExpLexer}
     */
    topState: function lexer_topState(n) {
      n = this.conditionStack.length - 1 - Math.abs(n || 0);

      if (n >= 0) {
        return this.conditionStack[n];
      } else {
        return 'INITIAL';
      }
    },

    /**
     * (internal) determine the lexer rule set which is active for the
     * currently active lexer condition state
     * 
     * @public
     * @this {RegExpLexer}
     */
    _currentRules: function lexer__currentRules() {
      if (this.conditionStack.length && this.conditionStack[this.conditionStack.length - 1]) {
        return this.conditions[this.conditionStack[this.conditionStack.length - 1]];
      } else {
        return this.conditions['INITIAL'];
      }
    },

    /**
     * return the number of states currently on the stack
     * 
     * @public
     * @this {RegExpLexer}
     */
    stateStackSize: function lexer_stateStackSize() {
      return this.conditionStack.length;
    },

    options: {
      xregexp: true,
      ranges: true,
      trackPosition: true,
      parseActionsUseYYMERGELOCATIONINFO: true,
      easy_keyword_rules: true
    },

    JisonLexerError: JisonLexerError,

    performAction: function lexer__performAction(yy, yyrulenumber, YY_START) {
      var yy_ = this;
      switch (yyrulenumber) {
      case 2:
        /*! Conditions:: action */
        /*! Rule::       \/[^ /]*?['"{}][^ ]*?\/ */
        return 43;  // regexp with braces or quotes (and no spaces)  

        break;

      case 7:
        /*! Conditions:: action */
        /*! Rule::       \{ */
        yy.depth++;

        return 12;
        break;

      case 8:
        /*! Conditions:: action */
        /*! Rule::       \} */
        if (yy.depth === 0) {
          this.popState();
        } else {
          yy.depth--;
        }

        return 13;
        break;

      case 9:
        /*! Conditions:: token */
        /*! Rule::       {BR} */
        this.popState();

        break;

      case 10:
        /*! Conditions:: token */
        /*! Rule::       %% */
        this.popState();

        break;

      case 11:
        /*! Conditions:: token */
        /*! Rule::       ; */
        this.popState();

        break;

      case 12:
        /*! Conditions:: bnf ebnf */
        /*! Rule::       %% */
        this.pushState('code');

        return 14;
        break;

      case 25:
        /*! Conditions:: options */
        /*! Rule::       = */
        this.pushState('option_values');

        return 3;
        break;

      case 26:
        /*! Conditions:: option_values */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1], /\\"/g);

        this.popState();
        return 29;    // value is always a string type  
        break;

      case 27:
        /*! Conditions:: option_values */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1], /\\'/g);

        this.popState();
        return 29;    // value is always a string type  
        break;

      case 28:
        /*! Conditions:: option_values */
        /*! Rule::       `{ES2017_STRING_CONTENT}` */
        yy_.yytext = unescQuote(this.matches[1], /\\`/g);

        this.popState();
        return 29;    // value is always a string type  
        break;

      case 29:
        /*! Conditions:: INITIAL ebnf bnf token path options option_values */
        /*! Rule::       \/\/[^\r\n]* */
        /* skip single-line comment */
        break;

      case 30:
        /*! Conditions:: INITIAL ebnf bnf token path options option_values */
        /*! Rule::       \/\*[^]*?\*\/ */
        /* skip multi-line comment */
        break;

      case 31:
        /*! Conditions:: option_values */
        /*! Rule::       [^\s\r\n]+ */
        this.popState();

        return 30;
        break;

      case 32:
        /*! Conditions:: options */
        /*! Rule::       {BR}{WS}+(?=\S) */
        /* skip leading whitespace on the next line of input, when followed by more options */
        break;

      case 33:
        /*! Conditions:: options */
        /*! Rule::       {BR} */
        this.popState();

        return 28;
        break;

      case 34:
        /*! Conditions:: options option_values */
        /*! Rule::       {WS}+ */
        /* skip whitespace */
        break;

      case 35:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       {WS}+ */
        /* skip whitespace */
        break;

      case 36:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       {BR}+ */
        /* skip newlines */
        break;

      case 37:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       \[{ID}\] */
        yy_.yytext = this.matches[1];

        return 39;
        break;

      case 42:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1], /\\"/g);

        return 26;
        break;

      case 43:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1], /\\'/g);

        return 26;
        break;

      case 48:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %% */
        this.pushState((yy.ebnf ? 'ebnf' : 'bnf'));

        return 14;
        break;

      case 49:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %ebnf\b */
        yy.ebnf = true;

        return 20;
        break;

      case 57:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %token\b */
        this.pushState('token');

        return 18;
        break;

      case 59:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %option[s]? */
        this.pushState('options');

        return 27;
        break;

      case 60:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %lex{LEX_CONTENT}\/lex\b */
        // remove the %lex../lex wrapper and return the pure lex section:
        yy_.yytext = this.matches[1];

        return 17;
        break;

      case 63:
        /*! Conditions:: INITIAL ebnf bnf code */
        /*! Rule::       %include\b */
        this.pushState('path');

        return 44;
        break;

      case 64:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %{NAME}([^\r\n]*) */
        /* ignore unrecognized decl */
        this.warn(rmCommonWS`
                                                EBNF: ignoring unsupported parser option ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.

                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

        yy_.yytext = [
          this.matches[1],            // {NAME}  
          this.matches[2].trim()       // optional value/parameters 
        ];

        return 21;
        break;

      case 65:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       <{ID}> */
        yy_.yytext = this.matches[1];

        return 36;
        break;

      case 66:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       \{\{([^]*?)\}\} */
        yy_.yytext = this.matches[1].replace(/\}\\\}/g, '}}');   // unescape any literal '}\}' that exists within the action code block 

        return 15;
        break;

      case 67:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       %\{([^]*?)%\} */
        yy_.yytext = this.matches[1].replace(/%\\\}/g, '%}');    // unescape any literal '%\}' that exists within the action code block 

        return 15;
        break;

      case 68:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       \{ */
        yy.depth = 0;

        this.pushState('action');
        return 12;
        break;

      case 69:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       ->.* */
        yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 2).trim();

        return 42;
        break;

      case 70:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       →.* */
        yy_.yytext = yy_.yytext.substr(1, yy_.yyleng - 1).trim();

        return 42;
        break;

      case 71:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       =>.* */
        yy_.yytext = yy_.yytext.substr(2, yy_.yyleng - 2).trim();

        return 42;
        break;

      case 72:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       {HEX_NUMBER} */
        yy_.yytext = parseInt(yy_.yytext, 16);

        return 37;
        break;

      case 73:
        /*! Conditions:: token bnf ebnf INITIAL */
        /*! Rule::       {DECIMAL_NUMBER}(?![xX0-9a-fA-F]) */
        yy_.yytext = parseInt(yy_.yytext, 10);

        return 37;
        break;

      case 75:
        /*! Conditions:: code */
        /*! Rule::       [^\r\n]+ */
        return 46;       // the bit of CODE just before EOF...  

        break;

      case 76:
        /*! Conditions:: path */
        /*! Rule::       {BR} */
        this.popState();

        this.unput(yy_.yytext);
        break;

      case 77:
        /*! Conditions:: path */
        /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
        yy_.yytext = unescQuote(this.matches[1]);

        this.popState();
        return 45;
        break;

      case 78:
        /*! Conditions:: path */
        /*! Rule::       '{QUOTED_STRING_CONTENT}' */
        yy_.yytext = unescQuote(this.matches[1]);

        this.popState();
        return 45;
        break;

      case 79:
        /*! Conditions:: path */
        /*! Rule::       {WS}+ */
        // skip whitespace in the line 
        break;

      case 80:
        /*! Conditions:: path */
        /*! Rule::       [^\s\r\n]+ */
        this.popState();

        return 45;
        break;

      case 81:
        /*! Conditions:: action */
        /*! Rule::       " */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 82:
        /*! Conditions:: action */
        /*! Rule::       ' */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 83:
        /*! Conditions:: action */
        /*! Rule::       ` */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in lexer rule action block.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 84:
        /*! Conditions:: option_values */
        /*! Rule::       " */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 85:
        /*! Conditions:: option_values */
        /*! Rule::       ' */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 86:
        /*! Conditions:: option_values */
        /*! Rule::       ` */
        yy_.yyerror(rmCommonWS`
                                            unterminated string constant in %options entry.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 87:
        /*! Conditions:: * */
        /*! Rule::       " */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 88:
        /*! Conditions:: * */
        /*! Rule::       ' */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 89:
        /*! Conditions:: * */
        /*! Rule::       ` */
        var rules = (this.topState() === 'macro' ? 'macro\'s' : this.topState());

        yy_.yyerror(rmCommonWS`
                                            unterminated string constant  encountered while lexing
                                            ${rules}.

                                              Erroneous area:
                                            ` + this.prettyPrintRange(yy_.yylloc));

        return 2;
        break;

      case 90:
        /*! Conditions:: * */
        /*! Rule::       . */
        /* b0rk on bad characters */
        yy_.yyerror(rmCommonWS`
                                                unsupported parser input: ${dquote(yy_.yytext)}
                                                while lexing in ${dquote(this.topState())} state.
                                                
                                                  Erroneous area:
                                                ` + this.prettyPrintRange(yy_.yylloc));

        break;

      default:
        return this.simpleCaseActionClusters[yyrulenumber];
      }
    },

    simpleCaseActionClusters: {
      /*! Conditions:: action */
      /*! Rule::       \/\*[^]*?\*\/ */
      0: 43,

      /*! Conditions:: action */
      /*! Rule::       \/\/[^\r\n]* */
      1: 43,

      /*! Conditions:: action */
      /*! Rule::       "{DOUBLEQUOTED_STRING_CONTENT}" */
      3: 43,

      /*! Conditions:: action */
      /*! Rule::       '{QUOTED_STRING_CONTENT}' */
      4: 43,

      /*! Conditions:: action */
      /*! Rule::       [/"'][^{}/"']+ */
      5: 43,

      /*! Conditions:: action */
      /*! Rule::       [^{}/"']+ */
      6: 43,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       %empty\b */
      13: 38,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       %epsilon\b */
      14: 38,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       \u0190 */
      15: 38,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       \u025B */
      16: 38,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       \u03B5 */
      17: 38,

      /*! Conditions:: bnf ebnf */
      /*! Rule::       \u03F5 */
      18: 38,

      /*! Conditions:: ebnf */
      /*! Rule::       \( */
      19: 7,

      /*! Conditions:: ebnf */
      /*! Rule::       \) */
      20: 8,

      /*! Conditions:: ebnf */
      /*! Rule::       \* */
      21: 9,

      /*! Conditions:: ebnf */
      /*! Rule::       \? */
      22: 10,

      /*! Conditions:: ebnf */
      /*! Rule::       \+ */
      23: 11,

      /*! Conditions:: options */
      /*! Rule::       {NAME} */
      24: 25,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       {ID} */
      38: 24,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       {NAME} */
      39: 25,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       \$end\b */
      40: 40,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       \$eof\b */
      41: 40,

      /*! Conditions:: token */
      /*! Rule::       [^\s\r\n]+ */
      44: 'TOKEN_WORD',

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       : */
      45: 5,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       ; */
      46: 4,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       \| */
      47: 6,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %debug\b */
      50: 19,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %parser-type\b */
      51: 32,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %prec\b */
      52: 41,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %start\b */
      53: 16,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %left\b */
      54: 33,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %right\b */
      55: 34,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %nonassoc\b */
      56: 35,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %parse-param[s]? */
      58: 31,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %code\b */
      61: 23,

      /*! Conditions:: token bnf ebnf INITIAL */
      /*! Rule::       %import\b */
      62: 22,

      /*! Conditions:: code */
      /*! Rule::       [^\r\n]*(\r|\n)+ */
      74: 46,

      /*! Conditions:: * */
      /*! Rule::       $ */
      91: 1
    },

    rules: [
      /*  0: */  new XRegExp('^(?:\\/\\*[^]*?\\*\\/)', ''),
      /*  1: */  /^(?:\/\/[^\r\n]*)/,
      /*  2: */  /^(?:\/[^ \/]*?['"{}][^ ]*?\/)/,
      /*  3: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /*  4: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /*  5: */  /^(?:[\/"'][^{}\/"']+)/,
      /*  6: */  /^(?:[^{}\/"']+)/,
      /*  7: */  /^(?:\{)/,
      /*  8: */  /^(?:\})/,
      /*  9: */  /^(?:(\r\n|\n|\r))/,
      /* 10: */  /^(?:%%)/,
      /* 11: */  /^(?:;)/,
      /* 12: */  /^(?:%%)/,
      /* 13: */  /^(?:%empty\b)/,
      /* 14: */  /^(?:%epsilon\b)/,
      /* 15: */  /^(?:\u0190)/,
      /* 16: */  /^(?:\u025B)/,
      /* 17: */  /^(?:\u03B5)/,
      /* 18: */  /^(?:\u03F5)/,
      /* 19: */  /^(?:\()/,
      /* 20: */  /^(?:\))/,
      /* 21: */  /^(?:\*)/,
      /* 22: */  /^(?:\?)/,
      /* 23: */  /^(?:\+)/,
      /* 24: */  new XRegExp(
        '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
        ''
      ),
      /* 25: */  /^(?:=)/,
      /* 26: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /* 27: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /* 28: */  /^(?:`((?:\\`|\\[^`]|[^\\`])*)`)/,
      /* 29: */  /^(?:\/\/[^\r\n]*)/,
      /* 30: */  new XRegExp('^(?:\\/\\*[^]*?\\*\\/)', ''),
      /* 31: */  /^(?:\S+)/,
      /* 32: */  /^(?:(\r\n|\n|\r)([^\S\n\r])+(?=\S))/,
      /* 33: */  /^(?:(\r\n|\n|\r))/,
      /* 34: */  /^(?:([^\S\n\r])+)/,
      /* 35: */  /^(?:([^\S\n\r])+)/,
      /* 36: */  /^(?:(\r\n|\n|\r)+)/,
      /* 37: */  new XRegExp('^(?:\\[([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)\\])', ''),
      /* 38: */  new XRegExp('^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*))', ''),
      /* 39: */  new XRegExp(
        '^(?:([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?))',
        ''
      ),
      /* 40: */  /^(?:\$end\b)/,
      /* 41: */  /^(?:\$eof\b)/,
      /* 42: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /* 43: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /* 44: */  /^(?:\S+)/,
      /* 45: */  /^(?::)/,
      /* 46: */  /^(?:;)/,
      /* 47: */  /^(?:\|)/,
      /* 48: */  /^(?:%%)/,
      /* 49: */  /^(?:%ebnf\b)/,
      /* 50: */  /^(?:%debug\b)/,
      /* 51: */  /^(?:%parser-type\b)/,
      /* 52: */  /^(?:%prec\b)/,
      /* 53: */  /^(?:%start\b)/,
      /* 54: */  /^(?:%left\b)/,
      /* 55: */  /^(?:%right\b)/,
      /* 56: */  /^(?:%nonassoc\b)/,
      /* 57: */  /^(?:%token\b)/,
      /* 58: */  /^(?:%parse-param[s]?)/,
      /* 59: */  /^(?:%option[s]?)/,
      /* 60: */  new XRegExp(
        '^(?:%lex((?:[^\\S\\n\\r])*(?:(?:\\r\\n|\\n|\\r)[^]*?)?(?:\\r\\n|\\n|\\r)(?:[^\\S\\n\\r])*)\\/lex\\b)',
        ''
      ),
      /* 61: */  /^(?:%code\b)/,
      /* 62: */  /^(?:%import\b)/,
      /* 63: */  /^(?:%include\b)/,
      /* 64: */  new XRegExp(
        '^(?:%([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}\\-_]*(?:[\\p{Alphabetic}\\p{Number}_]))?)([^\\n\\r]*))',
        ''
      ),
      /* 65: */  new XRegExp('^(?:<([\\p{Alphabetic}_](?:[\\p{Alphabetic}\\p{Number}_])*)>)', ''),
      /* 66: */  new XRegExp('^(?:\\{\\{([^]*?)\\}\\})', ''),
      /* 67: */  new XRegExp('^(?:%\\{([^]*?)%\\})', ''),
      /* 68: */  /^(?:\{)/,
      /* 69: */  /^(?:->.*)/,
      /* 70: */  /^(?:→.*)/,
      /* 71: */  /^(?:=>.*)/,
      /* 72: */  /^(?:(0[Xx][\dA-Fa-f]+))/,
      /* 73: */  /^(?:([1-9]\d*)(?![\dA-FXa-fx]))/,
      /* 74: */  /^(?:[^\r\n]*(\r|\n)+)/,
      /* 75: */  /^(?:[^\r\n]+)/,
      /* 76: */  /^(?:(\r\n|\n|\r))/,
      /* 77: */  /^(?:"((?:\\"|\\[^"]|[^\n\r"\\])*)")/,
      /* 78: */  /^(?:'((?:\\'|\\[^']|[^\n\r'\\])*)')/,
      /* 79: */  /^(?:([^\S\n\r])+)/,
      /* 80: */  /^(?:\S+)/,
      /* 81: */  /^(?:")/,
      /* 82: */  /^(?:')/,
      /* 83: */  /^(?:`)/,
      /* 84: */  /^(?:")/,
      /* 85: */  /^(?:')/,
      /* 86: */  /^(?:`)/,
      /* 87: */  /^(?:")/,
      /* 88: */  /^(?:')/,
      /* 89: */  /^(?:`)/,
      /* 90: */  /^(?:.)/,
      /* 91: */  /^(?:$)/
    ],

    conditions: {
      'action': {
        rules: [0, 1, 2, 3, 4, 5, 6, 7, 8, 81, 82, 83, 87, 88, 89, 90, 91],
        inclusive: false
      },

      'code': {
        rules: [63, 74, 75, 87, 88, 89, 90, 91],
        inclusive: false
      },

      'path': {
        rules: [29, 30, 76, 77, 78, 79, 80, 87, 88, 89, 90, 91],
        inclusive: false
      },

      'options': {
        rules: [24, 25, 29, 30, 32, 33, 34, 87, 88, 89, 90, 91],
        inclusive: false
      },

      'option_values': {
        rules: [26, 27, 28, 29, 30, 31, 34, 84, 85, 86, 87, 88, 89, 90, 91],
        inclusive: false
      },

      'token': {
        rules: [
          9,
          10,
          11,
          29,
          30,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          87,
          88,
          89,
          90,
          91
        ],

        inclusive: true
      },

      'bnf': {
        rules: [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          29,
          30,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          87,
          88,
          89,
          90,
          91
        ],

        inclusive: true
      },

      'ebnf': {
        rules: [
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          29,
          30,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          87,
          88,
          89,
          90,
          91
        ],

        inclusive: true
      },

      'INITIAL': {
        rules: [
          29,
          30,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          87,
          88,
          89,
          90,
          91
        ],

        inclusive: true
      }
    }
  };

  var rmCommonWS = helpers.rmCommonWS;
  var dquote = helpers.dquote;

  function unescQuote(str) {
    str = '' + str;
    var a = str.split('\\\\');

    a = a.map(function(s) {
      return s.replace(/\\'/g, '\'').replace(/\\"/g, '"');
    });

    str = a.join('\\\\');
    return str;
  }

  lexer.warn = function l_warn() {
    if (this.yy && this.yy.parser && typeof this.yy.parser.warn === 'function') {
      return this.yy.parser.warn.apply(this, arguments);
    } else {
      console.warn.apply(console, arguments);
    }
  };

  lexer.log = function l_log() {
    if (this.yy && this.yy.parser && typeof this.yy.parser.log === 'function') {
      return this.yy.parser.log.apply(this, arguments);
    } else {
      console.log.apply(console, arguments);
    }
  };

  return lexer;
}();
parser$2.lexer = lexer$1;

var ebnf = false;



var rmCommonWS$5 = helpers.rmCommonWS;
var dquote$2 = helpers.dquote;
var checkActionBlock$2 = helpers.checkActionBlock;


// transform ebnf to bnf if necessary
function extend(json, grammar) {
    if (ebnf) {
        json.ebnf = grammar.grammar;        // keep the original source EBNF around for possible pretty-printing & AST exports.
        json.bnf = transform(grammar.grammar);
    }
    else {
        json.bnf = grammar.grammar;
    }
    if (grammar.actionInclude) {
        json.actionInclude = grammar.actionInclude;
    }
    return json;
}

// convert string value to number or boolean value, when possible
// (and when this is more or less obviously the intent)
// otherwise produce the string itself as value.
function parseValue$1(v) {
    if (v === 'false') {
        return false;
    }
    if (v === 'true') {
        return true;
    }
    // http://stackoverflow.com/questions/175739/is-there-a-built-in-way-in-javascript-to-check-if-a-string-is-a-valid-number
    // Note that the `v` check ensures that we do not convert `undefined`, `null` and `''` (empty string!)
    if (v && !isNaN(v)) {
        var rv = +v;
        if (isFinite(rv)) {
            return rv;
        }
    }
    return v;
}


parser$2.warn = function p_warn() {
    console.warn.apply(console, arguments);
};

parser$2.log = function p_log() {
    console.log.apply(console, arguments);
};


function Parser$2() {
    this.yy = {};
}
Parser$2.prototype = parser$2;
parser$2.Parser = Parser$2;

function yyparse$1() {
    return parser$2.parse.apply(parser$2, arguments);
}



var bnf = {
    parser: parser$2,
    Parser: Parser$2,
    parse: yyparse$1,
    
};

var version$3 = '0.6.1-214';                              // require('./package.json').version;

function parse(grammar) {
    return bnf.parser.parse(grammar);
}

// adds a declaration to the grammar
bnf.parser.yy.addDeclaration = function bnfAddDeclaration(grammar, decl) {
    if (decl.start) {
        grammar.start = decl.start;
    } else if (decl.lex) {
        grammar.lex = parseLex(decl.lex.text, decl.lex.position);
    } else if (decl.operator) {
        if (!grammar.operators) grammar.operators = [];
        grammar.operators.push(decl.operator);
    } else if (decl.token) {
        if (!grammar.extra_tokens) grammar.extra_tokens = [];
        grammar.extra_tokens.push(decl.token);
    } else if (decl.token_list) {
        if (!grammar.extra_tokens) grammar.extra_tokens = [];
        decl.token_list.forEach(function (tok) {
            grammar.extra_tokens.push(tok);
        });
    } else if (decl.parseParams) {
        if (!grammar.parseParams) grammar.parseParams = [];
        grammar.parseParams = grammar.parseParams.concat(decl.parseParams);
    } else if (decl.parserType) {
        if (!grammar.options) grammar.options = {};
        grammar.options.type = decl.parserType;
    } else if (decl.include) {
        if (!grammar.moduleInclude) grammar.moduleInclude = '';
        grammar.moduleInclude += decl.include;
    } else if (decl.options) {
        if (!grammar.options) grammar.options = {};
        // last occurrence of `%options` wins:
        for (var i = 0; i < decl.options.length; i++) {
            grammar.options[decl.options[i][0]] = decl.options[i][1];
        }
    } else if (decl.unknownDecl) {
        if (!grammar.unknownDecls) grammar.unknownDecls = [];
        grammar.unknownDecls.push(decl.unknownDecl);
    } else if (decl.imports) {
        if (!grammar.imports) grammar.imports = [];
        grammar.imports.push(decl.imports);
    } else if (decl.actionInclude) {
        if (!grammar.actionInclude) {
            grammar.actionInclude = '';
        }
        grammar.actionInclude += decl.actionInclude;
    } else if (decl.initCode) {
        if (!grammar.moduleInit) {
            grammar.moduleInit = [];
        }
        grammar.moduleInit.push(decl.initCode);       // {qualifier: <name>, include: <source code chunk>}
    }
};

// parse an embedded lex section
function parseLex(text, position) {
    text = text.replace(/(?:^%lex)|(?:\/lex$)/g, '');
    // We want the lex input to start at the given 'position', if any,
    // so that error reports will produce a line number and character index
    // which matches the original input file:
    position = position || {};
    position.range = position.range || [];
    var l = position.first_line | 0;
    var c = position.range[0] | 0;
    var prelude = '';
    if (l > 1) {
        prelude += (new Array(l)).join('\n');
        c -= prelude.length;
    }
    if (c > 3) {
        prelude = '// ' + (new Array(c - 3)).join('.') + prelude;
    }
    return jisonlex.parse(prelude + text);
}

const ebnf_parser = {
    transform
};

var ebnfParser = {
    parse,

    transform,

    // assistant exports for debugging/testing:
    bnf_parser: bnf,
    ebnf_parser,
    bnf_lexer: jisonlex,

    version: version$3,
};

// import Lexer from '../../packages/jison-lex';
// import ebnfParser from '../../packages/ebnf-parser';
// import lexParser from '../../packages/lex-parser';
// import XRegExp from '@gerhobbelt/xregexp';
// import recast from '@gerhobbelt/recast';
// import astUtils from '@gerhobbelt/ast-util';
// import prettier from '@gerhobbelt/prettier-miscellaneous';
var rmCommonWS$6 = helpers.rmCommonWS;
/**
 * Output the `raw` input (JSON format or plain STRING containing JSON-formatted data)
 * as JISON source file format in the returned string.
 *
 * @returns a string containing the file contents of an input-equivalent JISON parser/lexer source file.
 * @public
 */
function grammarPrinter(raw, options) {
    if (typeof raw !== 'object') {
        raw = json5.parse(raw);
    }
    options = options || {};
    options.showLexer = (options.showLexer !== undefined ? !!options.showLexer : true);
    options.showParser = (options.showParser !== undefined ? !!options.showParser : true);
    switch (String(options.format).toLowerCase()) {
    default:
    case 'jison':
        options.format = 'jison';
        break;

    case 'json5':
        options.format = 'json5';
        break;
        
    case '.y':
    case '.yacc':
        options.format = 'jison';
        options.showLexer = false;
        options.showParser = true;
        break;
        
    case '.l':
    case '.lex':
        options.format = 'jison';
        options.showLexer = true;
        options.showParser = false;
        break;
    }
    
    function makeIndent(num) {
        return (new Array(num + 1)).join(' ');
    }

    function padRight(str, num) {
        return str + (new Array(Math.max(0, num - str.length) + 1)).join(' ');
    }

    function indentAction(src, num) {
        // It's dangerous to indent an action code chunk as it MAY contain **template strings**
        // which MAY get corrupted that way as their actual content would change then!

        // construct fake nesting levels to arrive at the intended start indent value: `num`
        var nesting_levels = num / 2;
        var pre = '// **PRE**',
            post = '// **POST**';
        for ( ; nesting_levels > 0; nesting_levels--) {
            pre = 'function x() {\n' + pre;
            post += '\n}';
        }
        src = '\n' + pre + '\n' + src + '\n' + post + '\n';        

        var ast = helpers.parseCodeChunkToAST(src);
        var new_src = helpers.prettyPrintAST(ast);

        var start = new_src.indexOf('// **PRE**');
        var end = new_src.lastIndexOf('// **POST**');
        new_src = new_src
        .substring(start + 10, end)
        .trim();

        return new_src;
    }

    function isEmptyObj(obj) {
        var keys = obj && typeof obj === 'object' && Object.keys(obj);
        return keys && keys.length === 0;
    }

    function isEmptyArr(arr) {
        if (arr && arr instanceof Array) {
            for (var i = 0, len = arr.length; i < len; i++) {
                if (arr[i] !== undefined) {
                    return false;
                }
            }
            return true;
        }
        return false;
    }

    // Copied from Crokford's implementation of JSON
    // See https://github.com/douglascrockford/JSON-js/blob/e39db4b7e6249f04a195e7dd0840e610cc9e941e/json2.js#L195
    // Begin
    var escapable = /[\\\"\x00-\x1f\x7f-\x9f\u00ad\u0600-\u0604\u070f\u17b4\u17b5\u200c-\u200f\u2028-\u202f\u2060-\u206f\ufeff\ufff0-\uffff]/g,
        meta = { // table of character substitutions
        '\b': '\\b',
        '\t': '\\t',
        '\n': '\\n',
        '\f': '\\f',
        '\r': '\\r',
        '"' : '\\"',
        '\\': '\\\\'
    };

    function escapeString(string) {
        // If the string contains no control characters, no quote characters, and no
        // backslash characters, then we can safely slap some quotes around it.
        // Otherwise we must also replace the offending characters with safe escape
        // sequences.
        escapable.lastIndex = 0;
        return escapable.test(string) ? '"' + string.replace(escapable, function (a) {
            var c = meta[a];
            return typeof c === 'string' ?
                c :
                '\\u' + ('0000' + a.charCodeAt(0).toString(16)).slice(-4);
        }) + '"' : '"' + string + '"';
    }

    var ref_list;
    var ref_names;

    // create a deep copy of the input, so we can delete the parts we converted and dump the remainder
    // so that we always output the entire thing, even when we don't know all the details about the
    // actual input:
    function deepClone(from, sub) {
        if (sub == null) {
            ref_list = [];
            ref_names = [];
            sub = 'root';
        }
        if (typeof from === 'function') return '[Function]';
        if (from == null || typeof from !== 'object') return from;
        if (from.constructor !== Object && from.constructor !== Array) {
            return from;
        }

        for (var i = 0, len = ref_list.length; i < len; i++) {
            if (ref_list[i] === from) {
                return '[Circular/Xref:' + ref_names[i] + ']';   // circular or cross reference
            }
        }
        ref_list.push(from);
        ref_names.push(sub);
        sub += '.';

        var to = new from.constructor();
        for (var name in from) {
            to[name] = deepClone(from[name], sub + name);
        }
        return to;
    }


    var originalInput = raw;
    raw = deepClone(raw);

    var lex_out_str = '';
    if (raw.lex) {
        var lex_pre = [];
        var lex_rules = [];
        var lex_post = [];
        var key, src;

        src = raw.lex.macros;
        delete raw.lex.macros;
        if (src && !isEmptyObj(src)) {
            lex_pre.push(rmCommonWS$6`
                // macros:
            `);

            var keylen = 0;
            for (key in src) {
                keylen = Math.max(keylen, key.length);
            }
            console.log('macros keylen:', keylen);
            keylen = ((keylen / 4) | 0) * 4 + 4;
            console.log('macros keylen B:', keylen);
            for (key in src) {
                lex_pre.push(padRight(key, keylen) + src[key]);
            }

            lex_pre.push(rmCommonWS$6`
                // END of the lexer macros.
            `);
        }

        src = raw.lex.unknownDecls;
        delete raw.lex.unknownDecls;
        if (src && !isEmptyObj(src)) {
            lex_pre.push(rmCommonWS$6`
                // unknown declarations:
            `);

            for (var i = 0, len = src.length; i < len; i++) {
                var entry = src[i];
                var key = entry[0];
                var value = entry[1];

                lex_pre.push('%' + key + ' ' + value);
            }

            lex_pre.push(rmCommonWS$6`
                // END of unknown declarations.
            `);
        }

        src = raw.lex.options;
        delete raw.lex.options;
        if (src && !isEmptyObj(src)) {
            lex_pre.push(rmCommonWS$6`
                // options:
            `);

            for (key in src) {
                var value = src[key];
                if (value) {
                    lex_pre.push('%options ' + key + '=' + value);
                }
                else {
                    lex_pre.push('%options ' + key);
                }
            }
        }

        src = raw.lex.startConditions;
        delete raw.lex.startConditions;
        if (src && !isEmptyObj(src)) {
            for (key in src) {
                var value = src[key];

                lex_pre.push((value ? '%x ' : '%s ') + key);
            }
        }

        src = raw.lex.actionInclude;
        delete raw.lex.actionInclude;
        if (src && src.trim()) {
            lex_pre.push('%{\n' + indentAction(src.trim(), 4) + '\n%}');
        }

        src = raw.lex.rules;
        delete raw.lex.rules;
        if (src) {
            for (var i = 0, len = src.length; i < len; i++) {
                var entry = src[i];
                key = entry[0];
                var action = indentAction(entry[1], 4);

                var actionHasLF = /[\r\n]/.test(action);
                console.log('indented action:', {
                    entry: entry[1],
                    action,
                    actionHasLF
                });
                if (key.length <= 12) {
                    if (!actionHasLF) {
                        lex_rules.push(padRight(key, 16) + indentAction(action, 16));
                    }
                    else {
                        lex_rules.push(padRight(key, 16) + '%' + indentAction('{ ' + action + ' }', 16) + '%');
                    }
                }
                else {
                    if (!actionHasLF) {
                        lex_rules.push(key, makeIndent(16) + indentAction(action, 16));
                    }
                    else {
                        lex_rules.push(key, makeIndent(16) + '%' + indentAction('{ ' + action + ' }', 16) + '%');
                    }
                }
            }
        }

        src = raw.lex.moduleInclude;
        delete raw.lex.moduleInclude;
        if (src && src.trim()) {
            lex_post.push(indentAction(src.trim(), 0));
        }

        var out = '';

        if (!isEmptyObj(raw.lex)) {
            // dump the remainder as a comment:
            var rem = json5.stringify(raw.lex, null, 2);
            out += rmCommonWS$6`
                /*
                 * Lexer stuff that's unknown to the JISON prettyPrint service:
                 *
                 * ${rem.replace(/\*\//g, '*\\/')}
                 */
                
            `;
        }
        delete raw.lex;

        out += lex_pre.join('\n') + '\n\n';
        out += rmCommonWS$6`

            %%

        ` + lex_rules.join('\n') + '\n\n';
        if (lex_post.length > 0) {
            out += rmCommonWS$6`

                %%

            ` + lex_post.join('\n') + '\n\n';
        }
        lex_out_str = out;
    }

    var grammar_pre = [];
    var grammar_mid = [];
    var ebnf_rules = [];
    var bnf_rules = [];
    var grammar_post = [];
    var key, src;

    var fmtprod = function fmtprod(rule, prodset) {
        var backup = deepClone(prodset);

        rule += prodset[0] ? prodset[0] : '%epsilon';
        var prec = null;
        var lead = rule.split(/\r\n\|\n|\r/).pop();
        delete prodset[0];

        if (prodset.length === 3 && typeof prodset[2] === 'object') {
            prec = '%prec ' + prodset[2].prec;
            if (lead.length < 12) {
                rule += makeIndent(12 - lead.length);
            } 
            rule += '  ' + prec;

            delete prodset[2].prec;
            if (isEmptyObj(prodset[2])) {
                delete prodset[2];
            }
        }
        else if (prodset.length === 2 && typeof prodset[1] === 'object') {
            prec = '%prec ' + prodset[1].prec;
            if (lead.length < 12) {
                rule += makeIndent(12 - lead.length);
            } 
            rule += '  ' + prec;

            delete prodset[1].prec;
            if (isEmptyObj(prodset[1])) {
                delete prodset[1];
            }
        }
        if (typeof prodset[1] === 'string') {
            var action = prodset[1];
            if (lead.length < 12 - 1) {
                rule += makeIndent(12 - lead.length) + indentAction('{ ' + action + ' }', 12); 
            }
            else {
                rule += '\n' + makeIndent(12) + indentAction('{ ' + action + ' }', 12); 
            }
            delete prodset[1];
        }

        if (isEmptyArr(prodset)) {
            prodset.length = 0;
        }
        else {
            prodset = backup;
        }
        return rule;
    };

    var grammarfmt = function grammarfmt(src) {
        var key;
        var dst = [];

        for (key in src) {
            var prodset = src[key];
            var rule;
            console.log('format one rule:', {
                key, 
                prodset
            });

            if (typeof prodset === 'string') {
                rule = fmtprod(key + ' : ', [prodset]) + ';'; 
                delete src[key];
            }
            else if (prodset instanceof Array) {
                if (prodset.length === 1) {
                    if (typeof prodset[0] === 'string') {
                        rule = fmtprod(key + ' : ', [prodset]) + ';';
                        delete src[key];
                    }
                    else if (prodset[0] instanceof Array) {
                        rule = fmtprod(key + ' : ', prodset[0]);
                        rule += '\n    ;';
                        if (prodset[0].length === 0) {
                            delete src[key];
                        }
                    }
                    else {
                        rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[0];
                    }
                }
                else if (prodset.length > 1) {
                    if (typeof prodset[0] === 'string') {
                        rule = fmtprod(key + '\n    : ', [prodset[0]]);
                        delete prodset[0];
                    }
                    else if (prodset[0] instanceof Array) {
                        rule = fmtprod(key + '\n    : ', prodset[0]);
                        if (prodset[0].length === 0) {
                            delete prodset[0];
                        }
                    }
                    else {
                        rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[0];
                    }
                    for (var i = 1, len = prodset.length; i < len; i++) {
                        if (typeof prodset[i] === 'string') {
                            rule += fmtprod('\n    | ', [prodset[i]]);
                            delete prodset[i];
                        } 
                        else if (prodset[i] instanceof Array) {
                            rule += fmtprod('\n    | ', prodset[i]);
                            if (prodset[i].length === 0) {
                                delete prodset[i];
                            }
                        } 
                        else {
                            rule += '\n    | **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset[i];
                        }
                    }
                    rule += '\n    ;';

                    if (isEmptyArr(prodset)) {
                        delete src[key];
                    }
                }
            }
            else {
                rule = key + '\n    : **ERRONEOUS PRODUCTION** (see the dump for more): ' + prodset;
            }
            dst.push(rule);
        }

        return dst;
    };

    src = raw.ebnf;
    if (src) {
        ebnf_rules = grammarfmt(src);

        if (isEmptyObj(src)) {
            delete raw.ebnf;
        }
    }

    src = raw.bnf;
    //delete raw.bnf;
    if (src) {
        bnf_rules = grammarfmt(src);

        if (isEmptyObj(src)) {
            delete raw.bnf;
        }
    }

    src = raw.unknownDecls;
    delete raw.unknownDecls;
    if (src && !isEmptyObj(src)) {
        lex_pre.push(rmCommonWS$6`
            // unknown declarations:
        `);

        for (var i = 0, len = src.length; i < len; i++) {
            var entry = src[i];
            var key = entry[0];
            var value = entry[1];

            lex_pre.push('%' + key + ' ' + value);
        }

        lex_pre.push(rmCommonWS$6`
            // END of unknown declarations.
        `);
    }

    //src = raw.lex;
    //delete raw.lex;
    //if (src) {
    if (lex_out_str.trim() && options.showLexer) {
        grammar_pre.push(rmCommonWS$6`
            // ============================== START lexer section =========================== 
            
            %lex
            
            ${lex_out_str}

            /lex

            // ============================== END lexer section =============================

        `);
    }

    src = raw.options;
    delete raw.options;
    if (src && !isEmptyObj(src)) {
        var a = [];
        for (key in src) {
            var value = src[key];
            switch (key) {
            default:
                if (value !== true) {
                    a.push('options', '%options ' + key + '=' + value);
                }
                else {
                    a.push('options', '%options ' + key);
                }
                break;

            case 'ebnf':
                if (value) {
                    a.push(key, '%ebnf');
                }
                break;

            case 'type':
                if (value) {
                    a.push(key, '%parser-type ' + value);
                }
                break;

            case 'debug':
                if (typeof value !== 'boolean') {
                    a.push(key, '%debug ' + value);
                }
                else if (value) {
                    a.push(key, '%debug');
                }
                break;
            }
        }
        var type = null;
        for (var i = 0, len = a.length; i < len; i += 2) {
            var t = a[i];
            var line = a[i + 1];
            if (t !== type) {
                type = t;
                grammar_pre.push('');
            }
            grammar_pre.push(line);
        }
        grammar_pre.push('');
    }

    src = raw.imports;
    if (src) {
        var clean = true;
        for (var i = 0, len = src.length; i < len; i++) {
            var entry = src[i];

            grammar_pre.push('%import ' + entry.name + '  ' + entry.path);
            delete entry.name;
            delete entry.path;
            if (isEmptyObj(entry)) {
                delete src[i];
            }
            else {
                clean = false;
            } 
        }
        if (clean) {
            delete raw.imports;
        }
    }

    src = raw.moduleInit;
    if (src) {
        var clean = true;
        for (var i = 0, len = src.length; i < len; i++) {
            var entry = src[i];

            grammar_pre.push('%code ' + entry.qualifier + '  ' + entry.include);
            delete entry.qualifier;
            delete entry.include;
            if (isEmptyObj(entry)) {
                delete src[i];
            }
            else {
                clean = false;
            } 
        }
        if (clean) {
            delete raw.moduleInit;
        }
    }

    src = raw.operators;
    if (src) {
        var clean = true;
        for (var i = 0, len = src.length; i < len; i++) {
            var entry = src[i];
            var tokens = entry[1];
            var line = '%' + entry[0] + ' ';

            for (var t = 0, tlen = tokens.length; t < tlen; t++) {
                line += ' ' + tokens[t];
            }

            grammar_pre.push(line);

            if (entry.length === 2) {
                delete src[i];
            }
            else {
                clean = false;
            }
        }
        if (clean) {
            delete raw.operators;
        }
    }

    src = raw.extra_tokens;
    if (src) {
        var clean = true;
        for (var i = 0, len = src.length; i < len; i++) {
            var entry = src[i];
            var line = '%token ' + entry.id;
            
            if (entry.type) {
                line += ' <' + entry.type + '>';
                delete entry.type;
            }
            if (entry.value) {
                line += ' ' + entry.value;
                delete entry.value;
            }
            if (entry.description) {
                line += ' ' + escapeString(entry.description);
                delete entry.description;
            }

            grammar_pre.push(line);

            delete entry.id;
            if (isEmptyObj(entry)) {
                delete src[i];
            }
            else {
                clean = false;
            }
        }
        if (clean) {
            delete raw.extra_tokens;
        }
    }

    src = raw.parseParams;
    delete raw.parseParams;
    if (src) {
        grammar_pre.push('%parse-param ' + src.join(' '));
    }

    src = raw.start;
    delete raw.start;
    if (src) {
        grammar_pre.push('%start ' + src);
    }

    src = raw.moduleInclude;
    delete raw.moduleInclude;
    if (src && src.trim()) {
        grammar_post.push(indentAction(src.trim(), 0));
    }

    src = raw.actionInclude;
    delete raw.actionInclude;
    if (src && src.trim()) {
        grammar_mid.push('%{\n' + indentAction(src.trim(), 4) + '\n%}');
    }

    var out = '';

    if (!isEmptyObj(raw)) {
        // dump the remainder as a comment:
        var rem = json5.stringify(raw, null, 2);
        out += rmCommonWS$6`
            /*
             * Parser stuff that's unknown to the JISON prettyPrint service:
             *
             * ${rem.replace(/\*\//g, '*\\/')}
             */
            
        `;
        // delete raw;
    }

    if (!options.showParser) {
        out += lex_out_str;
    }
    else {
        out += grammar_pre.join('\n') + '\n\n';
        out += rmCommonWS$6`

            %%

        `;
        if (grammar_mid.length > 0) {
            out += grammar_mid.join('\n') + '\n\n';
        }
        if (ebnf_rules.length > 0) {
            if (bnf_rules.length > 0) {
                // dump the original EBNF grammar as source and dump the BNF derivative as COMMENT:
                var bnf_deriv = bnf_rules.join('\n\n');
                var a = bnf_deriv.split(/\r\n|\n|\r/).map(function (line) {
                    return '// ' + line;
                });

                out += rmCommonWS$6`
                    //
                    // JISON says:
                    //
                    // This is a EBNF grammar. The resulting **BNF** grammar has been
                    // reproduced here for your convenience:
                    //
                    // ---------------------------- START ---------------------------
                    ${a.join('\n')}
                    // ---------------------------- END OF BNF grammar --------------
                    //


                `;
            }
            out += ebnf_rules.join('\n\n') + '\n\n';
        }
        else if (bnf_rules.length > 0) {
            out += bnf_rules.join('\n\n') + '\n\n';
        }

        if (grammar_post.length > 0) {
            out += rmCommonWS$6`

                %%

            ` + grammar_post.join('\n') + '\n\n';
        }
    }

    if (options.format === 'json5') {
        var a = out.split(/\r\n|\n|\r/).map(function (line) {
            return '// ' + line;
        });

        out = rmCommonWS$6`
            //
            // JISON says:
            //
            // The JISON ${options.showParser ? 'grammar' : 'lexer'} has been
            // reproduced here for your convenience:
            //
            // ---------------------------- START ---------------------------
            ${a.join('\n')}
            // ---------------------------- END -----------------------------
            //

        `;

        // process the original input once again: this time via JSON5
        raw = deepClone(originalInput);

        if (!options.showLexer) {
            delete raw.lex;
            out += JSON5.stringify(raw, null, 2);
        }
        else if (!options.showParser) {
            out += JSON5.stringify(raw.lex, null, 2);
        }
    }

    return out;
}

// Jison, an LR(0), SLR(1), LARL(1), LR(1) Parser Generator
// Zachary Carter <zach@carter.name>
// MIT Licensed

var rmCommonWS$1 = helpers.rmCommonWS;
var mkIdentifier$1  = helpers.mkIdentifier;
var code_exec  = helpers.exec;
var version$1 = '0.6.1-214';

var devDebug = 0;

// WARNING: this regex MUST match the regex for `ID` in ebnf-parser::bnf.l jison language lexer spec! (`ID = [{ALPHA}]{ALNUM}*`)
//
// This is the base XRegExp ID regex used in many places; this should match the ID macro definition in the EBNF/BNF parser et al as well!
const ID_REGEX_BASE = '[\\p{Alphabetic}_][\\p{Alphabetic}_\\p{Number}]*';

var Jison = {
    version: version$1
};

// see also ./lib/cli.js
const defaultJisonOptions = {
    moduleType: 'commonjs',
    debug: false,
    enableDebugLogs: false,
    numExpectedConflictStates: 0,
    json: false,
    type: 'lalr',                   // CLI: --parserType option
    compressTables: 2,              // 0, 1, 2
    outputDebugTables: false,
    noDefaultResolve: false,
    defaultActionMode: ["classic", "merge"],       // {classic, ast, none, skip}, {classic, ast, merge, none, skip}
    noTryCatch: false,
    hasPartialLrUpgradeOnConflict: true,
    errorRecoveryTokenDiscardCount: 3,
    exportAllTables: false,
    exportSourceCode: false,
    noMain: true,                   // CLI: not:(--main option)
    moduleMain: null,               // `main()` function source code if `!noMain` is true
    moduleMainImports: null,        // require()/import statements required by the `moduleMain` function source code if `!noMain` is true
    tokenStack: false,
    dumpSourceCodeOnFailure: true,
    throwErrorOnCompileFailure: true,

    moduleName: undefined,
    defaultModuleName: 'parser',
    file: undefined,
    outfile: undefined,
    inputPath: undefined,
    inputFilename: undefined,
    lexfile: undefined,
    warn_cb: undefined,  // function(msg) | true (= use Jison.Print) | false (= throw Exception)

    parseParams: undefined,
    parserErrorsAreRecoverable: false,
    lexerErrorsAreRecoverable: false,
    ranges: undefined,
    showSource: false,
    reportStats: false,
    exportAST: false,               // output grammar in JSON / JSON5 format (CLI version of JISON only)
    prettyCfg: true,                // use `prettier` (or not) to (re)format the generated parser code.

    // internal analysis flags which MAY be forced by special %options
    // to override default jison behaviour for a given grammar.
    //
    // Do note that some analysis options CANNOT be overridden directly
    // as that would allow the user to produce GUARANTEED DEFECTIVE PARSERS
    // when they utilize this advanced behaviour modification power.
    //
    //    actionsAreAllDefault,
    actionsUseLocationAssignment: false,
    actionsUseLocationTracking: false,
    actionsUseParseError: false,
    actionsUseValueAssignment: false,
    actionsUseValueTracking: false,
    actionsUseYYCLEARIN: false,
    actionsUseYYERROK: false,
    actionsUseYYERROR: false,
    actionsUseYYLENG: false,
    actionsUseYYLINENO: false,
    actionsUseYYLOC: false,
    actionsUseYYRECOVERING: false,
    actionsUseYYRULELENGTH: false,
    actionsUseYYMERGELOCATIONINFO: false,
    actionsUseYYSSTACK: false,
    actionsUseYYSTACK: false,
    actionsUseYYSTACKPOINTER: false,
    actionsUseYYTEXT: false,
    hasErrorRecovery: false,
    hasErrorReporting: false,
};

Jison.defaultJisonOptions = defaultJisonOptions;



// Merge sets of options.
//
// Convert alternative jison option names to their base option.
//
// The *last* option set which overrides the default wins, where 'override' is
// defined as specifying a not-undefined value which is not equal to the
// default value.
//
// When the FIRST argument is STRING "NODEFAULT", then we MUST NOT mix the
// default values avialable in Jison.defaultJisonOptions.
//
// Return a fresh set of options.
/** @public */
function mkStdOptions(...args) {
    var h = Object.prototype.hasOwnProperty;

    if (devDebug > 3) {
        Jison.print('mkStdOptions:\n', args);
    }

    var opts = {};
    //var args = Array.prototype.concat.apply([], args);
    // clone defaults, so we do not modify those constants?
    if (args[0] !== "NODEFAULT") {
        args.unshift(Jison.defaultJisonOptions);
    } else {
        args.shift();
    }

    for (var i = 0, len = args.length; i < len; i++) {
        var o = args[i];
        if (!o) continue;

        // clone input (while camel-casing the options), so we do not modify those either.
        var o2 = {};

        for (var p in o) {
            if (typeof o[p] !== 'undefined' && h.call(o, p)) {
                o2[mkIdentifier$1(p)] = o[p];
            }
        }

        // now clean them options up:
        if (typeof o2.main !== 'undefined') {
            o2.noMain = !o2.main;
        }

        if (typeof o2.noDefaultAction !== 'undefined') {
            throw new Error('option "no-default-action" has been OBSOLETED. Use "default-action-mode=[for-value,for-location]" instead (see \'jison --help\' for usage description).');
        }
        if (typeof o2.defaultAction !== 'undefined') {
            throw new Error('option "default-action" has been OBSOLETED. Use "default-action-mode=[for-value,for-location]" instead (see \'jison --help\' for usage description).');
        }
        if (typeof o2.hasDefaultResolve !== 'undefined') {
            o2.noDefaultResolve = !o2.hasDefaultResolve;
        }
        switch (typeof o2.defaultActionMode) {
        case 'undefined':
            break;

        case 'object':
            if (typeof o2.defaultActionMode.slice === 'function') {
                // make a copy of `defaultActionMode` to ensure the default source cannot be mutated through this `opts` instance:
                o2.defaultActionMode = o2.defaultActionMode.slice(0);
                break;
            }
            // fall through
        case 'string':
            var a = String(o2.defaultActionMode).split(',').map(function (m) {
                return m.trim();
            });
            if (a.length === 1) {
                a[1] = a[0];
            }
            o2.defaultActionMode = a;
            break;

        default:
            throw new Error('option "default-action-mode" must be a STRING or 2-element ARRAY value, when specified (see \'jison --help\' for usage description).');
        }

        if (typeof o2.hasTryCatch !== 'undefined') {
            o2.noTryCatch = !o2.hasTryCatch;
        }
        if (typeof o2.parserType !== 'undefined') {
            o2.type = o2.parserType;
        }
        if (typeof o2.moduleType !== 'undefined') {
            switch (o2.moduleType) {
            case 'js':
            case 'amd':
            case 'es':
            case 'commonjs':
                break;

            // aliases a la `rollup` c.s.:
            case 'cjs':
                o2.moduleType = 'commonjs';
                break;

            case 'iife':
                o2.moduleType = 'js';
                break;

            case 'umd':
                o2.moduleType = 'amd';
                break;

            default:
                throw new Error('unsupported moduleType: ' + dquote(opt.moduleType));
            }
        }

        if (o2.errorRecoveryTokenDiscardCount != null) {
            if (typeof o2.errorRecoveryTokenDiscardCount !== 'number') {
                throw new Error('options.errorRecoveryTokenDiscardCount should be a number or undefined; instead it has type: ' + typeof o2.errorRecoveryTokenDiscardCount);
            }
        }

        delete o2.parserType;
        delete o2.main;
        delete o2.hasDefaultResolve;
        delete o2.hasTryCatch;
        delete o2.noDefaultAction;

        // special check for `moduleName` to ensure we detect the 'default' moduleName entering from the CLI
        // NOT overriding the moduleName set in the grammar definition file via an `%options` entry:
        if (o2.moduleName === o2.defaultModuleName) {
            delete o2.moduleName;
        }

        // now see if we have an overriding option here:
        for (var p in o2) {
            if (h.call(o2, p)) {
                if (typeof o2[p] !== 'undefined') {
                    opts[p] = o2[p];
                }
            }
        }
    }

    if (devDebug > 3) {
        Jison.print('GENERATE::OPTIONS: RESULTING OPTIONS SET\n', opts);
    }

    return opts;
}

// set up export/output attributes of the `options` object instance
function prepExportStructures(options) {
    // set up the 'option' `exportAllTables` as a hash object for returning
    // all generated tables to the caller
    var exportDest = options.exportAllTables;
    if (!exportDest || typeof exportDest !== 'object') {
        exportDest = {
            enabled: !!exportDest
        };
    } else if (typeof exportDest.enabled !== 'boolean') {
        exportDest.enabled = true;
    }
    options.exportAllTables = exportDest;

    // set up the 'option' `exportSourceCode` as a hash object for returning
    // all generated source code chunks to the caller
    var exportSourceCode = options.exportSourceCode;
    if (!exportSourceCode || typeof exportSourceCode !== 'object') {
        exportSourceCode = {
            enabled: !!exportSourceCode
        };
    } else if (typeof exportSourceCode.enabled !== 'boolean') {
        exportSourceCode.enabled = true;
    }
    options.exportSourceCode = exportSourceCode;
}

// Autodetect if the input grammar and optional lexer spec is in JSON or JISON
// format when the `options.json` flag is `true`.
//
// Produce the JSON parse result when these are JSON formatted already as that
// would save us the trouble of doing this again, anywhere else in the JISON
// compiler/generator.
//
// Otherwise return the *parsed* grammar and optional lexer specs as they have
// been processed through EBNFParser and LEXParser respectively.
function autodetectAndConvertToJSONformat(grammar, optionalLexerSection, options) {
    var chk_g = null;
    var chk_l = null;
    var ex1, err;

    if (typeof grammar === 'string') {
      if (options.json) {
        try {
            chk_g = json5.parse(grammar);

            // When JSON5-based parsing of the grammar succeeds, this implies the grammar is specified in `JSON mode`
            // *OR* there's a JSON/JSON5 format error in the input:
        } catch (e) {
            ex1 = e;
        }
      }
      if (!chk_g) {
        try {
            chk_g = ebnfParser.parse(grammar, options);
        } catch (e) {
            if (options.json) {
                err = new Error('Could not parse jison grammar in JSON AUTODETECT mode\nError: ' + ex1.message + ' (' + e.message + ')');
                err.secondary_exception = e;
                err.stack = ex1.stack;
            } else {
                err = new Error('Could not parse jison grammar\nError: ' + e.message);
                err.stack = e.stack;
            }
            throw err;
        }
      }

      // Save time! Don't reparse the entire grammar *again* inside the code generators when that's not necessary:
      // if (chk_g) {
      //   grammar = chk_g;
      // }
    } else {
        chk_g = grammar;
    }

    // Now the same treatment for the lexer:
    if (chk_g && optionalLexerSection) {
      if (chk_g.lex) {
          throw new Error('Cannot invoke with both a lexer section in the grammar input and a separate lexer input at the same time!');
      }

      if (typeof optionalLexerSection === 'string') {
        if (options.json) {
          try {
              chk_l = json5.parse(optionalLexerSection);

              // When JSON5-based parsing of the lexer spec succeeds, this implies the lexer spec is specified in `JSON mode`
              // *OR* there's a JSON/JSON5 format error in the input:
          } catch (e) {
              ex1 = e;
          }
        }
        if (!chk_l) {
          // // WARNING: the lexer may receive options specified in the **grammar spec file**,
          // //          hence we should mix the options to ensure the lexParser always
          // //          receives the full set!
          // //
          // // make sure all options are 'standardized' before we go and mix them together:
          // options = mkStdOptions(grammar.options, options);
          try {
              chk_l = jisonlex.parse(optionalLexerSection, options);
          } catch (e) {
              if (options.json) {
                  err = new Error('Could not parse lexer spec in JSON AUTODETECT mode\nError: ' + ex1.message + ' (' + e.message + ')');
                  err.secondary_exception = e;
                  err.stack = ex1.stack;
              } else {
                  err = new Error('Could not parse lexer spec\nError: ' + e.message);
                  err.stack = e.stack;
              }
              throw err;
          }
        }
      } else {
        chk_l = optionalLexerSection;
      }

      // Save time! Don't reparse the entire lexer spec *again* inside the code generators when that's not necessary:
      if (chk_l) {
        chk_g.lex = chk_l;
      }
    }

    return chk_g;
}

Jison.rmCommonWS = rmCommonWS$1;
Jison.mkStdOptions = mkStdOptions;
Jison.camelCase = helpers.camelCase;
Jison.mkIdentifier = mkIdentifier$1;
Jison.autodetectAndConvertToJSONformat = autodetectAndConvertToJSONformat;

// detect print
if (typeof console !== 'undefined' && console.log) {
    // wrap console.log to prevent 'Illegal Invocation' exceptions when Jison.print() is used, e.g.
    // in the web tryout pages where this code is employed.
    Jison.print = function console_log(/* ... */) {
        var args = Array.prototype.slice.call(arguments, 0);
        args.unshift('');           // prevent `%.` printf-style expansions; see https://nodejs.org/api/console.html#console_console_log_data_args
        console.log.apply(console, args);
    };
} else if (typeof puts !== 'undefined') {
    Jison.print = function puts_print() {
        puts([].join.call(arguments, ' '));
    };
} else if (typeof print !== 'undefined') {
    Jison.print = print;
} else {
    Jison.print = function no_op_print() {};
}

// Also export other APIs: the JISON module should act as a 'facade' for the others,
// so applications using the JISON compiler itself can rely on it providing everything
// in a guaranteed compatible version as it allows userland code to use the precise
// same APIs as JISON will be using itself:
Jison.Lexer = RegExpLexer;
Jison.ebnfParser = ebnfParser;
Jison.lexParser = jisonlex;
Jison.codeExec = code_exec;
Jison.XRegExp = XRegExp;
Jison.recast = recast;
Jison.astUtils = astUtils;
//Jison.prettier = prettier;
//Jison.codeShift = codeshift;
Jison.JSON5 = json5;
Jison.prettyPrint = grammarPrinter;


// iterator utility
function each(obj, func) {
    if (typeof obj.forEach === 'function') {
        obj.forEach(func);
    } else {
        var p;
        for (p in obj) {
            if (obj.hasOwnProperty(p)) {
                func.call(obj, obj[p], p, obj);
            }
        }
    }
}

// This was Set.union() but it's not about *Set* at all: it is purely *Array* oriented!
function union(a, b) {
    assert(Array.isArray(a));
    assert(Array.isArray(b));
    // Naive indexOf()-based scanning delivers a faster union()
    // (which takes the brunt of the load for large grammars):
    // for examples/jscore this drops 13.2 seconds down to
    // 8.9 seconds total time spent in the generator!
    //
    // The idea there was that the FIRST/FOLLOW sets are generally
    // quite small; bad cases could run this up to > 128 entries
    // to scan through, but overall the FIRST and FOLLOW sets will
    // be a few tens of entries at best, and thus it was expected
    // that a naive scan would be faster than hash-object creation
    // and O(1) checking that hash... Turns out I was right.
    //
    // The 'arbitrary' threshold of 52 entries in the array to check
    // against is probably at or near the worst-case FIRST/FOLLOW set
    // site for this jscore grammar as the naive scan consistently
    // outperformed the old smarter hash-object code for smaller
    // thresholds (10, 20, 32, 42!)
    var k, len;

    if (a.length > 52) {
        var ar = {};
        for (k = 0, len = a.length; k < len; k++) {
            ar[a[k]] = true;
        }
        for (k = 0, len = b.length; k < len; k++) {
            if (!ar[b[k]]) {
                a.push(b[k]);
            }
        }
    } else {
        var bn = [];
        for (k = 0, len = b.length; k < len; k++) {
            if (a.indexOf(b[k]) < 0) {
                bn.push(b[k]);
            }
        }
        a = a.concat(bn);
    }
    return a;
}

var Nonterminal = typal.construct({
    constructor: function Nonterminal(symbol) {
        this.symbol = symbol;
        this.productions = new Set();
        this.first = [];
        this.follows = [];
        this.nullable = false;
    },
    toString: function Nonterminal_toString() {
        var str = this.symbol;
        var attr_str = [];

        if (this.nullable) {
            attr_str.push('nullable');
        }

        if (attr_str.length) {
            str += '        [' + attr_str.join(' ') + ']';
        }
        str += '\n  Firsts:  [' + this.first.join(']  [') + ']';
        str += '\n  Follows: [' + this.follows.join(']  [') + ']';
        str += '\n  Productions:\n    ' + this.productions.join('\n    ');

        return str;
    }
});

var Production = typal.construct({
    constructor: function Production(symbol, handle, id, handle_aliases, handle_action) {
        this.symbol = symbol;
        this.handle = handle;
        this.nullable = false;
        this.id = id;
        this.aliases = handle_aliases;
        this.action = handle_action;
        this.first = [];
        this.follows = [];
        this.precedence = 0;
        this.reachable = false;
    },
    toString: function Production_toString() {
        var str = this.symbol;

        var attr_str = [];

        if (this.nullable) {
            attr_str.push('~');
        }
        if (this.precedence) {
            attr_str.push('@' + this.precedence);
        }
        if (!this.reachable) {
            attr_str.push('*RIP*');
        }

        if (attr_str.length) {
            str += '[' + attr_str.join(' ') + ']';
        }
        str += ' -> ' + this.handle.join(' ');

        return str;
    },
    describe: function Production_describe() {
        var str = this.symbol;

        var attr_str = [];

        if (this.nullable) {
            attr_str.push('nullable');
        }
        if (this.precedence) {
            attr_str.push('precedence: ' + this.precedence);
        }

        if (attr_str.length) {
            str += '        [' + attr_str.join(' ') + ']';
        }
        str += '\n  Firsts: [' + this.first.join(']  [') + ']';
        str += '\n  -->  ' + this.handle.join(' ');

        return str;
    }
});



var generator = typal.beget();

// `optionalLexerSection` is an optional {String} argument, specifying the lexer rules.
// May only be specified when the specified `grammar` also is a yet-unparsed
// {String} defining the grammar.
//
// Hence these invocations are legal:
//
// - `Generator("String")`
//   --> `String` contains entire grammar, including
//   optional `%lex` lexer rules section
//
//
// - `Generator("String-1", "String-2")`
//   --> The `String-1` string contains grammar, *excluding* `%lex` lexer rules section,
//   while the `String-2` string contains the `%lex` lexer rules section
//
//
// - `Generator("String", {Options})`
//   --> `String` contains entire grammar, including
//   optional `%lex` lexer rules section
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// - `Generator("String", NULL, {Options})`
//   --> `String` contains entire grammar, including
//   optional `%lex` lexer rules section
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// - `Generator("String-1", "String-2", {Options})`
//   --> The `String-1` string contains grammar, *excluding* `%lex` lexer rules section,
//   while the `String-2` string contains the `%lex` lexer rules section
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// - `Generator({Grammar})`
//   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
//   including optional `%lex` lexer rules section in its `.lex` member.
//
//
// - `Generator({Grammar}, {Options})`
//   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
//   including optional `%lex` lexer rules section in its `.lex` member.
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// - `Generator({Grammar}, NULL, {Options})`
//   --> The `Grammar` object contains the entire grammar as an already parsed *structure*,
//   including optional `%lex` lexer rules section in its `.lex` member.
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// - `Generator({Grammar}, "String-2")`
//   --> The `Grammar` object contains grammar, *excluding* `%lex` lexer rules section,
//   while the `String-2` string contains the `%lex` lexer rules section
//
//
// - `Generator({Grammar}, "String-2", {Options})`
//   --> The `Grammar` object contains grammar, *excluding* `%lex` lexer rules section,
//   while the `String-2` string contains the `%lex` lexer rules section
//
//   The `Options` object specifies the desired jison options' settings.
//
//
// Any other arguments / arguments' types sequence is illegal.
//
generator.constructor = function Jison_Generator(grammar, optionalLexerSection, options) {
    // pick the correct argument for the `options` for this call:
    if (!options && optionalLexerSection && typeof optionalLexerSection !== 'string') {
      options = optionalLexerSection;
      optionalLexerSection = null;
    }
    // and standardize it:
    var preliminary_options = mkStdOptions(options);

    grammar = autodetectAndConvertToJSONformat(grammar, optionalLexerSection, preliminary_options);

    // make sure all options are 'standardized' before we go and mix them together
    //
    // WARNING:
    // make sure to mix together the **original options sets** as it's last-come-last-serve
    // in `mkStdOptions` and you don't want the mixed in defaults carried in `preliminary_options`
    // to percolate into the final options set as if those we overrides coming in from
    // the API (via the `options` parameter above)!
    //
    // Anyway, API/CLI options **override** options coming in from the grammar spec.
    //
    options = mkStdOptions(grammar.options, options);

    prepExportStructures(options);

    this.terms = {};
    this.operators = {};
    this.productions = [];
    this.conflicts = 0;
    this.new_conflicts_found_this_round = 0;
    this.conflicting_states = [];
    this.resolutions = [];
    this.conflict_productions_LU = {};
    this.conflict_states_LU = {};
    this.conflict_fixing_round = false;
    this.parseParams = grammar.parseParams;
    this.yy = {}; // accessed as yy free variable in the parser/lexer actions

    // also export the grammar itself *and* the cleaned-up generator options:
    this.options = options;
    this.grammar = grammar;

    this.DEBUG = !!options.debug;

    // // propagate %parse-params into the lexer!
    // if (grammar.lex) {
    //     if (!grammar.lex.options) {
    //         grammar.lex.options = {};
    //     }
    //     if (this.parseParams) {
    //         grammar.lex.options.parseParams = this.parseParams;
    //     }
    // }

    // calculate the input path; if none is specified, it's the present working directory
    var inpath = options.file || options.outfile || './dummy';
    inpath = path.normalize(inpath);
    options.inputPath = path.dirname(inpath);
    options.inputFilename = path.basename(inpath);

    // source included in semantic action execution scope
    if (grammar.actionInclude) {
        if (typeof grammar.actionInclude === 'function') {
            grammar.actionInclude = String(grammar.actionInclude).replace(/^\s*function \(\) \{/, '').replace(/\}\s*$/, '');
        }
        this.actionInclude = grammar.actionInclude;
    }
    this.moduleInclude = grammar.moduleInclude || '';
    this.moduleInit = grammar.moduleInit || [];
    assert(Array.isArray(this.moduleInit));

    this.DEBUG = !!this.options.debug;
    this.enableDebugLogs = !!options.enableDebugLogs;
    this.numExpectedConflictStates = options.numExpectedConflictStates || 0;

    if (this.DEBUG) {
        this.mix(generatorDebug); // mixin debug methods

        Jison.print('Grammar::OPTIONS:\n', this.options);
    }

    this.processGrammar(grammar);

    if (grammar.lex) {
        var lexer_options = {
            // include the knowledge about which parser/lexer
            // features will actually be *used* by the environment:
            //
            // (this stuff comes straight from the jison Optimization Analysis.)
            //
            parseActionsAreAllDefault: this.actionsAreAllDefault,
            parseActionsUseYYLENG: this.actionsUseYYLENG,
            parseActionsUseYYLINENO: this.actionsUseYYLINENO,
            parseActionsUseYYTEXT: this.actionsUseYYTEXT,
            parseActionsUseYYLOC: this.actionsUseYYLOC,
            parseActionsUseParseError: this.actionsUseParseError,
            parseActionsUseYYERROR: this.actionsUseYYERROR,
            parseActionsUseYYRECOVERING: this.actionsUseYYRECOVERING,
            parseActionsUseYYERROK: this.actionsUseYYERROK,
            parseActionsUseYYCLEARIN: this.actionsUseYYCLEARIN,
            parseActionsUseValueTracking: this.actionsUseValueTracking,
            parseActionsUseValueAssignment: this.actionsUseValueAssignment,
            parseActionsUseLocationTracking: this.actionsUseLocationTracking,
            parseActionsUseLocationAssignment: this.actionsUseLocationAssignment,
            parseActionsUseYYSTACK: this.actionsUseYYSTACK,
            parseActionsUseYYSSTACK: this.actionsUseYYSSTACK,
            parseActionsUseYYSTACKPOINTER: this.actionsUseYYSTACKPOINTER,
            parseActionsUseYYRULELENGTH: this.actionsUseYYRULELENGTH,
            parseActionsUseYYMERGELOCATIONINFO: this.actionsUseYYMERGELOCATIONINFO,
            parserHasErrorRecovery: this.hasErrorRecovery,
            parserHasErrorReporting: this.hasErrorReporting,

            // and re-use any useful options:
            moduleType: this.options.moduleType,
            debug: this.options.debug,
            enableDebugLogs: this.options.enableDebugLogs,
            json: this.options.json,
            main: false,
            dumpSourceCodeOnFailure: this.options.dumpSourceCodeOnFailure,
            throwErrorOnCompileFailure: this.options.throwErrorOnCompileFailure,
            moduleName: 'lexer',        // this.options.moduleName + '_Lexer',
            file: this.options.file,
            outfile: this.options.outfile,
            inputPath: this.options.inputPath,
            inputFilename: this.options.inputFilename,       // or should we feed it `this.options.lexfile` instead?
            warn_cb: this.options.warn_cb,
            //parseParams: this.options.parseParams,
            xregexp: this.options.xregexp,
            //parserErrorsAreRecoverable: this.options.parserErrorsAreRecoverable,
            lexerErrorsAreRecoverable: this.options.lexerErrorsAreRecoverable,
            flex: this.options.flex,
            backtrack_lexer: this.options.backtrack_lexer,
            ranges: this.options.ranges,
            caseInsensitive: this.options.caseInsensitive,
            showSource: this.options.showSource,
            exportSourceCode: this.options.exportSourceCode,
            exportAST: this.options.exportAST,
            prettyCfg: this.options.prettyCfg,
            pre_lex: this.options.pre_lex,
            post_lex: this.options.post_lex,
        };

        this.lexer = new RegExpLexer(grammar.lex, null, this.terminals_, lexer_options);
    }
};

generator.processGrammar = function processGrammarDef(grammar) {
    var bnf = grammar.bnf,
        tokens = grammar.tokens,
        nonterminals = this.nonterminals = {},
        productions = this.productions;

    if (!grammar.bnf && grammar.ebnf) {
        bnf = grammar.bnf = ebnfParser.transform(grammar.ebnf);
    }
    if (devDebug) {
        Jison.print('processGrammar: ', JSON.stringify({
            bnf: bnf,
            tokens: tokens,
            productions: productions
        }, null, 2));
    }
    if (tokens) {
        if (typeof tokens === 'string') {
            tokens = tokens.trim().split(' ');
        } else {
            tokens = tokens.slice(0);
        }
    }

    // did the grammar user also provide a predefined set of symbols to be (re)used with this grammar?
    // (This is used when you want to generate multiple lexers and parsers which share a common symbol set
    // so as to make the parsers and lexers mutually interchangeable.)
    var predefined_symbols = null;
    if (grammar.imports) {
        var symbols_import = grammar.imports.find(function (el, idx) {
            if (el.name === 'symbols') {
                return el;
            }
            return false;
        });
        if (symbols_import) {
            var filepath = path.resolve(symbols_import.path);

            var source = fs.readFileSync(filepath, 'utf8');
            // It's either a JSON file or a JISON generated output file:
            //
            //     symbols_: {
            //       "symbol": ID, ...
            //     },
            try {
                predefined_symbols = json5.parse(source);
            } catch (ex) {
                if (devDebug) {
                    console.error('', '%import symbols JSON fail: ', ex);
                }
                try {
                    var m = /[\r\n]\s*symbols_:\s*(\{[\s\S]*?\}),\s*[\r\n]/.exec(source);
                    if (m && m[1]) {
                        source = m[1];
                        predefined_symbols = json5.parse(source);
                    }
                } catch (ex) {
                    if (devDebug) {
                        console.error('', '%import symbols JISON output fail: ', ex);
                    }
                    throw new Error('Error: `%import symbols <path>` must point to either a JSON file containing a symbol table (hash table) or a previously generated JISON JavaScript file, which contains such a symbol table. Error message: ' + ex.message);
                }
            }

            if (!predefined_symbols || typeof predefined_symbols !== 'object') {
                throw new Error('Error: `%import symbols <path>` must point to either a JSON file containing a symbol table (hash table) or a previously generated JISON JavaScript file, which contains such a symbol table.');
            }

            // Make sure all predefined symbols are unique and *numeric* and do not include predefined tokens JISON already defines to a fixed ID on its own:
            delete predefined_symbols['$accept'];
            delete predefined_symbols['$end'];
            delete predefined_symbols['error'];
            delete predefined_symbols['$eof'];
            delete predefined_symbols['EOF'];

            var symdef_uniq_check = {};
            // Only these symbols are allowed to have the values 1 or 2:
            symdef_uniq_check[1] = 'EOF';
            symdef_uniq_check[2] = 'error';
            Object.keys(predefined_symbols).forEach(function cvt_symbol_id_to_numeric(sym) {
                var v = predefined_symbols[sym];

                // Symbol value may be defined as boolean TRUE, in which case we let JISON pick the value for us:
                if (v === true) return;

                // Symbol value may be defined as a one-character string:
                if (typeof v !== 'number') {
                    if (typeof v !== 'string' || v.length !== 1) {
                        throw new Error('Error: `%import symbols <path>`: symbol table contains invalid entry at key \'' + sym + '\': a non-numeric symbol ID value must be a single-character string.');
                    }
                    v = v.charCodeAt(0);
                }
                v = v | 0;
                if (!v || v < 0) {
                    throw new Error('Error: `%import symbols <path>`: symbol table contains invalid entry at key \'' + sym + '\': a symbol ID value must be an integer value, 3 or greater.');
                }
                if (symdef_uniq_check[v]) {
                    if (symdef_uniq_check[v] !== sym) {
                        throw new Error('Error: `%import symbols <path>`: symbol table contains duplicate ID values for keys \'' + sym + '\' and \'' + symdef_uniq_check[v] + '\'');
                    }
                }
                symdef_uniq_check[v] = sym;
                predefined_symbols[sym] = v;
            });
        }
    }

    var symbols = this.symbols = [];

    // calculate precedence of operators
    var operators = this.operators = processOperators(grammar.operators);

    // build productions from CFG and calculate the symbol sets (terminals and nonterminals) and their name-to-ID mappings
    this.buildProductions(bnf, productions, nonterminals, symbols, operators, predefined_symbols, grammar.extra_tokens);

    if (devDebug > 1) {
        Jison.print('terminals vs tokens: ', this.terminals.length, (tokens && tokens.length), this.terminals,
                    '\n###################################### TOKENS\n', tokens,
                    '\n###################################### EXTRA TOKENS\n', grammar.extra_tokens,
                    '\n###################################### LEX\n', grammar.lex,
                    '\n###################################### GRAMMAR\n', grammar);
    }
    if (tokens) {
        var termset = this.terminals.filter(function (t) {
            switch (t) {
            case 'EOF':
            case 'error':
            case '$eof':
            case '$end':
                return false;

            default:
                return true;
            }
        });
        var diffset = termset.filter(function (t) {
            return tokens.indexOf(t) === -1;
        });
        diffset = diffset.concat(tokens.filter(function (t) {
            return termset.indexOf(t) === -1;
        }));

        if (termset.length !== tokens.length) {
            this.trace('\nWarning: declared tokens differ from terminals set found in rules.');
            this.trace('difference: ', diffset);
            this.trace('Terminals:  ', termset);
            this.trace('Tokens:     ', tokens);
        }
    }

    // augment the grammar
    this.augmentGrammar(grammar);

    // detect unused productions and flag them
    this.signalUnusedProductions();

    // build production action code chunks (originally done in `buildProductions` as a side-effect)
    this.buildProductionActions();
};

generator.augmentGrammar = function augmentGrammar(grammar) {
    if (this.productions.length === 0) {
        throw new Error('Grammar error: must have at least one rule.');
    }
    // use specified start symbol, or default to first user defined production
    this.startSymbol = grammar.start || grammar.startSymbol || this.productions[0].symbol;
    if (!this.nonterminals[this.startSymbol]) {
        throw new Error('Grammar error: startSymbol must be a non-terminal found in your grammar.');
    }
    //this.EOF = '$end';       // moved to generator.buildProductions()

    // Augment the grammar:
    //
    // Add the top-most accept rule (and implicit, default, action):
    //
    //     $accept: <startSymbol> $end
    //                  %{ $$ = $1; @$ = @1; %}
    //
    // which, combined with the new parse kernel's `$accept` state behaviour will produce the
    // `$$` value output of the <startSymbol> rule as the parse result, IFF that result is
    // *not* `undefined`. (See also the parser kernel code.)
    //
    // In code:
    //
    //                  %{
    //                      @$ = @1;
    //                      if (typeof $1 !== 'undefined')
    //                          return $1;
    //                      else
    //                          return true;           // the default parse result if the rule actions don't produce anything
    //                  %}
    //
    var acceptProduction = new Production('$accept', [this.startSymbol, '$end'], 0);
    this.productions.unshift(acceptProduction);

    // prepend parser tokens       // moved to generator.buildProductions()
    //this.symbols.unshift('$accept', this.EOF);
    //this.symbols_.$accept = 0;
    //this.symbols_[this.EOF] = 1;
    //this.terminals.unshift(this.EOF);

    //this.nonterminals.$accept = new Nonterminal('$accept');

    this.nonterminals.$accept.productions.push(acceptProduction);

    // add follow $ to start symbol
    this.nonterminals[this.startSymbol].follows.push(this.EOF);
};

// Mark unused productions
generator.signalUnusedProductions = function () {
    var mark = {};

    var productions = this.productions;
    var nonterminals = this.nonterminals;
    var i, p, len, nt, sym;

    for (i = 0, len = nonterminals.length; i < len; i++) {
        nt = nonterminals[i];
        assert(nt.symbol);
        mark[nt.symbol] = false;
    }

    // scan & mark all visited productions
    function traverseGrammar(nt) {
        assert(nt);
        assert(nt.symbol);
        mark[nt.symbol] = true;

        var prods = nt.productions;
        assert(prods);
        prods.forEach(function (p) {
            assert(p.symbol === nt.symbol);
            assert(p.handle);
            var rhs = p.handle;
            if (devDebug > 0) {
                Jison.print('traverse / mark: ', nt.symbol, ' --> ', rhs);
            }

            for (var j = 0, len = rhs.length; j < len; j++) {
                var sym = rhs[j];
                assert(!sym ? !nonterminals[sym] : true);
                if (nonterminals[sym] && !mark[sym]) {
                    traverseGrammar(nonterminals[sym]);
                }
            }
        });
    }

    traverseGrammar(nonterminals['$accept' /* this.startSymbol */ ]);

    // now any production which is not yet marked is *unused*:
    for (sym in mark) {
        nt = nonterminals[sym];
        assert(nt);
        var prods = nt.productions;
        assert(prods);
        var in_use = mark[sym];
        prods.forEach(function (p) {
            assert(p);
            if (in_use) {
                p.reachable = true;
            } else {
                p.reachable = false;
            }
        });

        if (!in_use) {
            // and kill the unused nonterminals:
            delete this.nonterminals[sym];
        }
    }

    this.unused_productions = productions.filter(function (p) {
        return !p.reachable;
    });

    // and kill the unused productions:
    this.productions = productions.filter(function (p) {
        return p.reachable;
    });
};

// set precedence and associativity of operators
function processOperators(ops) {
    if (!ops) return {};
    var operators = {};
    for (var i = 0, k, prec; (prec = ops[i]); i++) {
        for (k = 1; k < prec.length; k++) {
            operators[prec[k]] = {
                precedence: i + 1,
                assoc: prec[0]
            };
        }
    }
    return operators;
}

// Detect the indentation of the given sourcecode chunk and shift the chunk to be indented the given number of spaces.
//
// Note that the first line doesn't count as the chunk is very probably trimmed!
function reindentCodeBlock(action, indent_level) {
    var width = 0;
    var lines = action
    .trim()
    .split('\n')
    // measure the indent:
    .map(function checkIndentation(line, idx) {
        if (idx === 1) {
            // first line didn't matter: reset width to help us find the block indent level:
            width = Infinity;
        }
        if (line.trim() === '') return '';

        // take out any TABs: turn them into spaces (4 per TAB)
        line = line
        .replace(/^[ \t]+/, function expandTabs(s) {
            return s.replace(/\t/g, '    ');
        });

        var m = /^[ ]+/.exec(line);
        if (m) {
            width = Math.min(m[0].length, width);
        }

        return line;
    })
    // remove/adjust the indent:
    .map(function checkIndentation(line, idx) {
        line = line
        .replace(/^[ ]*/, function adjustIndent(s) {
            var l = Math.max(s.length - width, 0) + indent_level;
            var shift = (new Array(l + 1)).join(' ');
            return shift;
        });
        return line;
    });

    return lines.join('\n');
}


generator.buildProductions = function buildProductions(bnf, productions, nonterminals, symbols, operators, predefined_symbols, descriptions) {
    var self = this;
    var prods, symbol, symId;
    var productions_ = [];
    var symbols_ = {};
    var descriptions_ = {};
    var usedSymbolIds = [/* $accept = 0 */ true, /* $end = 1 */ true, /* error = 2 */ true];
    var usedSymbolIdsLowIndex = 3;

    // set up the required symbols `$accept` and `$end` (a.k.a. EOF) and make sure they occupy the expected slots:
    this.EOF = '$end';

    symbols_.$accept = 0;
    symbols_[this.EOF] = 1;
    symbols_['$eof'] = 1;               // `$eof` is a synonym of `$end` for bison compatibility; this is the only place where two symbol names may map to a single symbol ID number!
    symbols_['EOF'] = 1;                // `EOF` is a synonym of `$end` for bison compatibility; this is the only place where two symbol names may map to a single symbol ID number!
    symbols[0] = '$accept';
    symbols[1] = this.EOF;

    nonterminals.$accept = new Nonterminal('$accept');

    // always add the error symbol; will be third symbol, or "2": ($accept, $end, error)
    symbols_.error = 2;
    symbols[2] = 'error';

    if (predefined_symbols) {
        for (symbol in predefined_symbols) {
            symId = predefined_symbols[symbol];
            if (symId === true) {
                // add symbol to queue which must be assigned a value by JISON; after all the other predefined symbols have been processed.
                continue;
            }

            // skip $accept, $end and error:
            if (symId <= 2) continue;

            // has this ID already been taken? If not, pick this ID, otherwise throw a tantrum.
            if (!usedSymbolIds[symId]) {
                usedSymbolIds[symId] = true;
                symbols_[symbol] = symId;
                symbols[symId] = symbol;
            } else {
                throw new Error('Error: Predefined symbol (imported via `%import symbols`) "' + symbol + '" has an ID ' + symId + ' which is already in use by symbol "' + symbols[symId] + '"');
            }
        }

        // preferably assign readable ASCII-range token IDs to tokens added from the predefined list
        // but only when maximum table compression isn't demanded:
        usedSymbolIdsLowIndex = ((this.options.compressTables | 0) < 2 ? 32 : 3);
        for (symbol in predefined_symbols) {
            symId = predefined_symbols[symbol];
            addSymbol(symbol);
        }

        // reset ID low water mark: nonterminals etc. can be assigned any number, preferably a small/low one!
        usedSymbolIdsLowIndex = 3;
    }

    if (descriptions) {
        this.trace('descriptions obtained from grammar: ', descriptions);
        descriptions.forEach(function (tokdef) {
            // fields: id, type, value, description
            if (tokdef.description && tokdef.id) {
                descriptions_[tokdef.id] = tokdef.description;
            }
        });
    }


    var hasErrorRecovery = false; // has error recovery

    // Produce the next available unique symbolID:
    function getNextSymbolId() {
        for (var i = usedSymbolIdsLowIndex; ; i++) {
            if (!usedSymbolIds[i]) {
                usedSymbolIds[i] = true;
                usedSymbolIdsLowIndex = i + 1;
                return i;
            }
        }
    }

    function addSymbol(s) {
        if (s && !symbols_[s]) {
            var i;

            // assign the Unicode codepoint index to single-character symbols,
            // but only when maximum table compression isn't demanded:
            if (s.length === 1 && (self.options.compressTables | 0) < 2) {
                i = s.charCodeAt(0);
                // has this ID already been taken? If not, pick this ID.
                if (i < 128 /* only allow this within the ASCII range */ && !usedSymbolIds[i]) {
                    usedSymbolIds[i] = true;
                } else {
                    i = getNextSymbolId();
                }
            } else {
                // otherwise simply obtain the next available ID number as usual.
                i = getNextSymbolId();
            }
            symbols_[s] = i;
            symbols[i] = s;
        }
        return symbols_[s] || false;
    }

    // `this` is options object with `maxTokenLength` option to guide us which literal tokens we want to process:
    function collectLiteralTokensInProduction(handle) {
        var r, rhs, i, sym;

        if (devDebug) Jison.print('\ncollectLiteralTokensInProduction: ', symbol, ':', JSON.stringify(handle, null, 2), ' @ options: ', this);

        var maxlen = this.maxTokenLength || Infinity;

        if (handle.constructor === Array) {
            var rhs_i;
            rhs = (typeof handle[0] === 'string') ?
                      splitStringIntoSymbols(handle[0]) :
                      handle[0].slice(0);

            for (i = 0; i < rhs.length; i++) {
                sym = rhs[i];
                // check for aliased names, e.g., id[alias] and strip them
                rhs_i = sym.match(new XRegExp(`\\[${ID_REGEX_BASE}\\]$`));
                if (rhs_i) {
                    sym = sym.substr(0, sym.length - rhs_i[0].length);
                }

                if (!bnf[sym] && sym.length <= maxlen) {
                    addSymbol(sym);
                }
            }
        } else {
            // no action -> don't care about aliases; strip them.
            handle = handle.replace(new XRegExp(`\\[${ID_REGEX_BASE}\\]`, 'g'), '');
            rhs = splitStringIntoSymbols(handle);
            for (i = 0; i < rhs.length; i++) {
                sym = rhs[i];
                if (!bnf[sym] && sym.length <= maxlen) {
                    addSymbol(sym);
                }
            }
        }
    }

    // Before we go process the grammar for real, we collect the 'literal' non-terminals and add them to the symbol table
    // before all others: this way these tokens have the maximum chance to get assigned their ASCII value as symbol ID,
    // which helps debugging/diagnosis of generated grammars.
    // (This is why previously we had set `usedSymbolIdsLowIndex` to 127 instead of 3!)

    var prodsLUT = {};
    for (symbol in bnf) {
        if (!bnf.hasOwnProperty(symbol)) continue;

        if (typeof bnf[symbol] === 'string') {
            prods = bnf[symbol].split(/\s*\|\s*/g);
        } else {
            prods = bnf[symbol].slice(0);
        }
        if (devDebug) Jison.print('\ngenerator.buildProductions: ', symbol, JSON.stringify(prods, null, 2));

        prodsLUT[symbol] = prods;
    }

    // First we collect all single-character literal tokens:
    for (symbol in prodsLUT) {
        if (!prodsLUT.hasOwnProperty(symbol)) continue;

        prods = prodsLUT[symbol];
        prods.forEach(collectLiteralTokensInProduction, {
            maxTokenLength: 1
        });
    }
    // Next we collect all other literal tokens:
    for (symbol in prodsLUT) {
        if (!prodsLUT.hasOwnProperty(symbol)) continue;

        prods = prodsLUT[symbol];
        prods.forEach(collectLiteralTokensInProduction, {
            maxTokenLength: Infinity
        });
    }

    // and now go and process the entire grammar:
    // first collect all nonterminals in a symbol table, then build the productions
    // for each of those: nonterminals should all have IDs assigned before they
    // should be processed as part of a *production* rule, where these MAY be
    // referenced:
    for (symbol in bnf) {
        if (!bnf.hasOwnProperty(symbol)) continue;

        addSymbol(symbol);
        nonterminals[symbol] = new Nonterminal(symbol);
    }

    // now that we have collected all nonterminals in our symbol table, it's finally
    // time to process the productions:
    for (symbol in prodsLUT) {
        if (!prodsLUT.hasOwnProperty(symbol)) continue;

        prods = prodsLUT[symbol];
        prods.forEach(buildProduction);
    }

    var sym,
        terms = [],
        terms_ = {};
    each(symbols_, function (id, sym) {
        // `$eof` and `EOF` are synonyms of `$end` (`$eof` is for bison compatibility);
        // this is the only place where two symbol names may map to a single symbol ID number
        // and we do not want `$eof`/`EOF` to show up in the symbol tables of generated parsers
        // as we use `$end` for that one!
        if (!nonterminals[sym] && sym !== '$eof') {
            terms.push(sym);
            terms_[id] = sym;
        }
    });

    this.hasErrorRecovery = hasErrorRecovery;
    // fix error recovery related options now that we know whether we actually have any recovery
    // rules at all:
    if (!this.hasErrorRecovery) {
        var chk_er_opt = function check_error_recovery_option(opt, label) {
            if (self.options[opt]) {
                self.options[opt] = false;
                self.warn('The grammar does not have any error recovery rules, so using the ' + label + ' is rather useless.');
            }
        };

        chk_er_opt('parserErrorsAreRecoverable', 'parser-errors-are-recoverable feature/option');

        // Hmmmm... why would lexer errors need to be NON-recoverable when there's no ERROR rules in the GRAMMAR?!
        chk_er_opt('lexerErrorsAreRecoverable', 'lexer-errors-are-recoverable feature/option');

        chk_er_opt('parseActionsUseYYRECOVERING', 'YYRECOVERING macro/API in grammar rules\' action code');
        chk_er_opt('parseActionsUseYYERROK', 'yyerrok() function/API in grammar rules\' action code');
        chk_er_opt('parseActionsUseYYCLEARIN', 'yyclearin() function/API in grammar rules\' action code');
    }

    this.terminals = terms;
    this.terminals_ = terms_;
    this.symbols_ = symbols_;
    this.symbolIds = symbols;
    this.descriptions_ = descriptions_;

    this.productions_ = productions_;
    assert(this.productions === productions);


    // Cope with literal symbols in the string, including *significant whitespace* tokens
    // as used in a rule like this: `rule: A ' ' B;` which should produce 3 tokens for the
    // rhs: ['A', ' ', 'B']
    function splitStringIntoSymbols(rhs) {
        // when there's no literal tokens in there, we can fast-track this baby:
        rhs = rhs.trim();
        var pos1 = rhs.indexOf("'");
        var pos2 = rhs.indexOf('"');
        if (pos1 < 0 && pos2 < 0) {
            return rhs.split(' ');
        }
        // else:
        //
        // rhs has at least one literal: we will need to parse the rhs into tokens
        // with a little more effort now.
        var tokens = [];
        while (pos1 >= 0 || pos2 >= 0) {
            var pos = pos1;
            var marker = "'";
            if (pos < 0) {
                assert(pos2 >= 0);
                pos = pos2;
                marker = '"';
            } else if (pos >= 0 && pos2 >= 0 && pos2 < pos) {
                pos = pos2;
                marker = '"';
            }
            var ls = rhs.substr(0, pos).trim();
            if (ls.length > 0) {
                tokens.push.apply(tokens, ls.split(' '));
            }
            rhs = rhs.substr(pos + 1);
            // now find the matching end marker.
            //
            // Edge case: token MAY include the ESCAPED MARKER... or other escapes!
            // Hence we need to skip over ALL escapes inside the token!
            var pos3 = rhs.indexOf('\\');
            pos = rhs.indexOf(marker);
            ls = '';
            while (pos3 >= 0 && pos3 < pos) {
                ls += rhs.substr(0, pos3 + 2);  // chop off entire escape (2 chars) and keep as part of next token
                rhs = rhs.substr(pos3 + 2);
                pos3 = rhs.indexOf('\\');
                pos = rhs.indexOf(marker);
            }
            if (pos < 0) {
                throw new Error('internal error parsing literal token(s) in grammar rule');
            }
            ls += rhs.substr(0, pos);
            // check for aliased literals, e.g., `'>'[gt]` and keep it and the alias together
            rhs = rhs.substr(pos + 1);
            var alias = rhs.match(new XRegExp(`^\\[${ID_REGEX_BASE}\\]`));
            if (alias) {
                ls += alias[0];
                rhs = rhs.substr(alias[0].length);
            }
            tokens.push(ls);

            rhs = rhs.trim();

            pos1 = rhs.indexOf("'");
            pos2 = rhs.indexOf('"');
        }
        // Now, outside the loop, we're left with the remainder of the rhs, which does NOT
        // contain any literal tokens.
        if (rhs.length > 0) {
            tokens.push.apply(tokens, rhs.split(' '));
        }
        return tokens;
    }

    function buildProduction(handle) {
        var r, rhs, i,
            precedence_override,
            aliased = [],
            action = null;

        if (devDebug) Jison.print('\nbuildProduction: ', symbol, ':', JSON.stringify(handle, null, 2));

        if (handle.constructor === Array) {
            var rhs_i;

            rhs = (typeof handle[0] === 'string') ?
                      splitStringIntoSymbols(handle[0]) :
                      handle[0].slice(0);

            for (i = 0; i < rhs.length; i++) {
                // check for aliased names, e.g., id[alias] and strip them
                rhs_i = rhs[i].match(new XRegExp(`\\[${ID_REGEX_BASE}\\]$`));
                if (rhs_i) {
                    rhs[i] = rhs[i].substr(0, rhs[i].length - rhs_i[0].length);
                    rhs_i = rhs_i[0].substr(1, rhs_i[0].length - 2);
                    aliased[i] = rhs_i;
                } else {
                    aliased[i] = rhs[i];
                }

                if (rhs[i] === 'error') {
                    hasErrorRecovery = true;
                }
                assert(bnf[rhs[i]] ? symbols_[rhs[i]] : true, 'all nonterminals must already exist in the symbol table');
                assert(rhs[i] ? symbols_[rhs[i]] : true, 'all symbols (terminals and nonterminals) must already exist in the symbol table');
                //addSymbol(rhs[i]);
            }

            assert(handle.length === 3 ? typeof handle[1] === 'string' : true);
            if (typeof handle[1] === 'string') {
                // semantic action specified
                action = handle[1];

                // precedence specified also
                if (handle[2] && operators[handle[2].prec]) {
                    precedence_override = {
                        symbol: handle[2].prec,
                        spec: operators[handle[2].prec]
                    };
                }
            } else {
                // only precedence specified
                if (operators[handle[1].prec]) {
                    precedence_override = {
                        symbol: handle[1].prec,
                        spec: operators[handle[1].prec]
                    };
                }
            }
        } else {
            // no action -> don't care about aliases; strip them.
            handle = handle.replace(new XRegExp(`\\[${ID_REGEX_BASE}\\]`, 'g'), '');
            rhs = splitStringIntoSymbols(handle);
            for (i = 0; i < rhs.length; i++) {
                if (rhs[i] === 'error') {
                    hasErrorRecovery = true;
                }
                assert(bnf[rhs[i]] ? symbols_[rhs[i]] : true, 'all nonterminals must already exist in the symbol table');
                assert(rhs[i] ? symbols_[rhs[i]] : true, 'all symbols (terminals and nonterminals) must already exist in the symbol table');
                //addSymbol(rhs[i]);
            }
        }

        r = new Production(symbol, rhs, productions.length + 1, aliased, action);

        // set precedence
        assert(r.precedence === 0);
        if (precedence_override) {
            r.precedence = precedence_override.spec.precedence;
        }
        else {
            var prec_symbols = [];
            var winning_symbol;

            for (i = r.handle.length - 1; i >= 0; i--) {
                if (!(r.handle[i] in nonterminals) && r.handle[i] in operators) {
                    var old_prec = r.precedence;
                    var new_prec = operators[r.handle[i]].precedence;
                    if (old_prec !== 0 && old_prec !== new_prec) {
                        prec_symbols.push(r.handle[i]);
                        // Jison.print('precedence set twice: ', old_prec, new_prec, r.handle[i], symbol, handle[0]);
                        if (new_prec < old_prec) {
                            winning_symbol = r.handle[i];
                        }
                        else {
                            // keep previously set precedence:
                            new_prec = old_prec;
                        }
                    } else if (old_prec === 0) {
                        prec_symbols.push(r.handle[i]);
                        winning_symbol = r.handle[i];
                        // Jison.print('precedence set first time: ', old_prec, r.handle[i], symbol, handle[0]);
                    }
                    r.precedence = new_prec;
                }
            }

            if (prec_symbols.length > 1) {
                if (self.DEBUG || 1) {
                    self.warn('Ambiguous rule precedence in grammar: picking the (highest) precedence from operator "' + winning_symbol + '" for rule "' + symbol + ': ' + r.handle.join(' ') + '" which contains multiple operators with different precedences: {' + prec_symbols.join(', ') + '}');
                }
            }
        }

        productions.push(r);
        productions_.push([symbols_[r.symbol], r.handle[0] === '' ? 0 : r.handle.length]);
        nonterminals[symbol].productions.push(r);
    }
};


// Preprocess the action code block before we perform any `$n`, `@n` ,`##n` or `#n` expansions:
// Any comment blocks in there should be kept intact (and not cause trouble either as those comments MAY
// contain `$`, `@`, `##` or `#` prefixed bits which might look like references but aren't!)
//
// Also do NOT replace any $x, @x, ##x or #x macros inside any strings!
//
// Note:
// We also replace '/*' comment markers which may (or may not) be lurking inside other comments.
function preprocessActionCode(s) {
    function replace_markers(cmt) {
        cmt = cmt
        .replace(/##/g, '\x01\x89')
        .replace(/#/g, '\x01\x81')
        .replace(/\$/g, '\x01\x82')
        .replace(/@/g, '\x01\x83')
        .replace(/\/\*/g, '\x01\x85')
        .replace(/\/\//g, '\x01\x86')
        .replace(/\'/g, '\x01\x87')
        .replace(/\"/g, '\x01\x88')
        // and also whiteout any other macros we're about to expand in there:
        .replace(/\bYYABORT\b/g, '\x01\x94')
        .replace(/\bYYACCEPT\b/g, '\x01\x95')
        .replace(/\byyvstack\b/g, '\x01\x96')
        .replace(/\byylstack\b/g, '\x01\x97')
        .replace(/\byyerror\b/g, '\x01\x98')
        .replace(/\bYYRECOVERING\b/g, '\x01\x99')
        .replace(/\byyerrok\b/g, '\x01\x9A')
        .replace(/\byyclearin\b/g, '\x01\x9B')
        .replace(/\byysp\b/g, '\x01\x9C')
        .replace(/\byy([a-zA-Z]+)\b/g, '\x01\x9D__$1');   // `yyxxx`: all `yy`-prefixed (camelCased) identifiers are RESERVED USE for jison.

        return cmt;
    }

    s = s
    // do not trim any NEWLINES in the action block:
    .replace(/^\s+/, '')
    .replace(/\s+$/, '')
    // unify CR/LF combo's:
    .replace(/\r\n|\r/g, '\n')
    // replace any '$', '@' and '#' in any C++-style comment line to prevent
    // them from being expanded as if they were part of the action code proper:
    .replace(/^\s*\/\/.+$/mg, replace_markers)
    // also process any //-comments trailing a line of code:
    // (we need to ensure these are real and not a bit of string,
    // which leaves those comments that are very hard to correctly
    // recognize with a simple regex, e.g. '// this isn't a #666 location ref!':
    // we accept that we don't actually *parse* the action block and let these
    // slip through... :-( )
    //
    // WARNING: without that `\n` inside the regex `[...]` set, the set *will*
    // match a NEWLINE and thus *possibly* gobble TWO lines for the price of ONE,
    // when the first line is an *empty* comment line, i.e. nothing trailing
    // the `//` in there and thus the `[^'"]` regex matching the terminating NL *before*
    // the `$` in the regex can get at it. Cave canem therefor!       |8-(
    .replace(/\/\/[^'"\n]+$/mg, replace_markers)
    // now MARK all the not-too-tricky-to-recognize /*...*/ comment blocks and process those!
    // (Here again we accept that we don't actually *parse* the action code and
    // permit to let some of these slip, i.e. comment blocks which trail
    // a line of code and contain string delimiter(s). :-( )
    .replace(/^([^'"\n]*?)\/\*/mg, '$1\x01\x84')                            // comment starts the line, guaranteed not to be inside a string
    .replace(/\/\*([^'"\n]*)$/mg, '\x01\x84$1')                             // comment does not contain any string sentinel in its first line
    .replace(/\/\*([^\/]*?\*\/[^'"\n]*)$/mg, '\x01\x84$1')                  // comment end marker near end of line and since the end is definitely not inside a string, there's bound to be comment start as well
    // and find their END marker: first '*/' found wins!
    // (The `[\s\S]` regex expression is a hack to ensure NEWLINES are matched
    // by that set as well, i.e. this way we can easily cross line boundaries
    // while searching for he end of the multiline comment we're trying to
    // dig out by regex matching. Also note that we employ non-aggressive
    // matching to ensure the regex matcher will find the FIRST occurrence of
    // `*/` and mark that as the end of the regex match!)
    .replace(/\x01\x84[\s\S]*?\*\//g, replace_markers)
    // Now that we have processed all comments in the code, it's time
    // to tackle the strings in the code: any strings must be kept intact
    // as well. Regrettably, there's regexes which may carry quotes,
    // e.g. `/'/`, and escapes of quotes inside strings, e.g. `'\''`,
    // which makes this a non-trivial task. This is when we reconsider whether
    // we should run this stuff through Esprima and deal with that AST
    // verbosity instead...? For now, we accept that regexes can screw
    // us up, but we can handle strings of any kind, by first taking
    // out all explicit `\\` non-escaping characters:
    .replace(/\\\\/g, '\x01\x90')
    // and then we take out all escaped quotes:
    .replace(/\\\'/g, '\x01\x91')
    .replace(/\\\"/g, '\x01\x92')
    // and to top it off, we also take out any more-or-less basic regexes:
    .replace(/\\\//g, '\x01\x93')

    // WARNING: Without that prefix check this would also catch
    // `6/7 + $$ + 8/9` as if `/7 + $$ + 8/` would be a regex   :-(
    // but we need this one to ensure any quotes hiding inside
    // any regex in there are caught and marked, e.g. `/'/g`.
    // Besides, this regex prefix is constructed to prevent
    // the regex matching a `//....` comment line either!
    .replace(/[^_a-zA-Z0-9\$\)\/][\s\n\r]*\/[^\n\/\*][^\n\/]*\//g, replace_markers);

    // ... which leaves us with plain strings of both persuasions to cover
    // next: we MUST do both at the same time, though or we'll be caught
    // with our pants down in constructs like
    // `'"' + $$ + '"'` vs. `"'" + $$ + "'"`

    var dqpos, sqpos, ccmtpos, cppcmtpos, first = -1;
    for (var c = 0;; c++) {
        first++;
        dqpos = s.indexOf('"', first);
        sqpos = s.indexOf("'", first);
        // also look for remaining comments which contain quotes of any kind,
        // as those will not have been caught by the previous global regexes:
        ccmtpos = s.indexOf('/*', first);
        cppcmtpos = s.indexOf('//', first);
        first = s.length;
        first = Math.min((dqpos >= 0 ? dqpos : first), (sqpos >= 0 ? sqpos : first), (ccmtpos >= 0 ? ccmtpos : first), (cppcmtpos >= 0 ? cppcmtpos : first));
        // now it matters which one came up first:
        if (dqpos === first) {
            s = s
            .replace(/"[^"\n]*"/, replace_markers);
        } else if (sqpos === first) {
            s = s
            .replace(/'[^'\n]*'/, replace_markers);
        } else if (ccmtpos === first) {
            s = s
            .replace(/\/\*[\s\S]*?\*\//, replace_markers);
        } else if (cppcmtpos === first) {
            s = s
            .replace(/\/\/[^\n]*$/m, replace_markers);
        } else {
            break;
        }
    }
    // Presto!
    return s;
}

// Postprocess the action code block after we perform any `$n`, `@n`, `##n` or `#n` expansions:
// revert the preprocessing!
function postprocessActionCode(s) {
    s = s
    // multiline comment start markers:
    .replace(/\x01\x84/g, '/*')
    .replace(/\x01\x85/g, '/*')
    .replace(/\x01\x86/g, '//')
    // revert markers:
    .replace(/\x01\x81/g, '#')
    .replace(/\x01\x82/g, '$')
    .replace(/\x01\x83/g, '@')
    // and revert the string and regex markers:
    .replace(/\x01\x87/g, '\'')
    .replace(/\x01\x88/g, '\"')
    .replace(/\x01\x89/g, '##')
    .replace(/\x01\x90/g, '\\\\')
    .replace(/\x01\x91/g, '\\\'')
    .replace(/\x01\x92/g, '\\\"')
    .replace(/\x01\x93/g, '\\\/')
    .replace(/\x01\x94/g, 'YYABORT')
    .replace(/\x01\x95/g, 'YYACCEPT')
    .replace(/\x01\x96/g, 'yyvstack')
    .replace(/\x01\x97/g, 'yylstack')
    .replace(/\x01\x98/g, 'yyerror')
    .replace(/\x01\x99/g, 'YYRECOVERING')
    .replace(/\x01\x9A/g, 'yyerrok')
    .replace(/\x01\x9B/g, 'yyclearin')
    .replace(/\x01\x9C/g, 'yysp')
    .replace(/\x01\x9D__/g, 'yy');

    // And a final, minimal, fixup for the semicolon-lovers -- like me! ;-)
    //
    // Make sure the last statement is properly semicolon-terminated 99.9% of the time:
    s = s
    .replace(/[\s\r\n]+$/, '')          // trim trailing whitespace and empty lines
    .replace(/([^\;}])$/, '$1;');       // append a semicolon to the last statement if it doesn't end with one (or a closing brace, e.g. a function definition)

    return s;
}

// Strip off any insignificant whitespace from the user code to ensure that
// otherwise identical actions are indeed matched up into a single actionGroup:
function mkHashIndex(s) {
    return s.trim()
    .replace(/\s+$/mg, '')          // strip any trailing whitespace for each line of action code
    .replace(/^\s+/mg, '');         // ditto for leading whitespace for each line: we don't care about more or less clean indenting practices in the user code
}

function analyzeFeatureUsage(sourcecode, feature, threshold) {
    var found = sourcecode.match(feature);
    return !!(found && found.length > threshold);
}


function mkParserFeatureHash(self) {
    assert(self.options.exportAllTables);   // check that this function isn't called too early in the process or the hash will be bogus
    assert(self.options.exportSourceCode);
    var h = [
        self.actionsAreAllDefault,
        self.actionsUseLocationAssignment,
        self.actionsUseLocationTracking,
        self.actionsUseParseError,
        self.actionsUseValueAssignment,
        self.actionsUseValueTracking,
        self.actionsUseYYCLEARIN,
        self.actionsUseYYERROK,
        self.actionsUseYYERROR,
        self.actionsUseYYLENG,
        self.actionsUseYYLINENO,
        self.actionsUseYYLOC,
        self.actionsUseYYRECOVERING,
        self.actionsUseYYRULELENGTH,
        self.actionsUseYYMERGELOCATIONINFO,
        self.actionsUseYYSSTACK,
        self.actionsUseYYSTACK,
        self.actionsUseYYSTACKPOINTER,
        self.actionsUseYYTEXT,
        self.hasErrorRecovery,
        self.hasErrorReporting,
        self.onDemandLookahead,
        self.options.compressTables,
        self.options.debug,
        self.options.errorRecoveryTokenDiscardCount,
        self.options.exportAllTables.enabled,
        self.options.exportSourceCode.enabled,
        self.options.hasPartialLrUpgradeOnConflict,
        self.options.lexerErrorsAreRecoverable,
        self.options.moduleType,
        self.options.defaultActionMode.join(','),
        self.options.noDefaultResolve,
        self.options.noMain,
        self.options.moduleMain,
        self.options.moduleMainImports,
        self.options.noTryCatch,
        self.options.numExpectedConflictStates,
        self.options.outputDebugTables,
        self.options.parserErrorsAreRecoverable,
        self.options.tokenStack,
        self.options.type,
        '======================================',
        self.performAction,
        '======================================',
    ];
    return h.join(',');
}

generator.buildProductionActions = function buildProductionActions() {
    /*
        this.terminals = terms;
        this.terminals_ = terms_;
        this.symbols_ = symbols_;
        this.descriptions_ = descriptions_;

        this.productions_ = productions_;
        assert(this.productions === productions);
    */
    var productions = this.productions,
        nonterminals = this.nonterminals,
        symbols = this.symbols,
        operators = this.operators,
        self = this;

    // As a SIDE EFFECT of this call, we also fixup
    // the other code chunks specified in the grammar file:
    //
    // Replace direct symbol references, e.g. #NUMBER# when there's a `%token NUMBER` for your grammar.
    // We allow these tokens to be referenced anywhere in your code as #TOKEN#.
    var moduleInclude = preprocessActionCode(this.moduleInclude)
        .replace(/#([^#\s\r\n]+)#/g, function (_, sym) {
            return provideSymbolAsSourcecode(sym);
        });
    // and COPY the `moduleInit` array, after preprocessing the individual COPIES:
    var moduleInit = this.moduleInit.map(function (chunk) {
        assert(chunk.qualifier);
        assert(typeof chunk.include === 'string');
        return {
            qualifier: chunk.qualifier,
            include: preprocessActionCode(chunk.include)
                .replace(/#([^#\s\r\n]+)#/g, function (_, sym) {
                    return provideSymbolAsSourcecode(sym);
                })
        };
    });
    assert(Array.isArray(moduleInit));

    // We potentially need multiple (2+) rounds to produce the correct actions
    // as userland action code determines whether the default actions should
    // include location tracking or not:
    var gen_level = 0;
    var prev_gen_hash = 'n';
    var gen_hash = 'y';
    this.performAction = null;
    while (gen_hash !== prev_gen_hash) {
        var preludeCode = preprocessActionCode(this.actionInclude || '');
        var actions = [`
          /* this == yyval */

          // the JS engine itself can go and remove these statements when \`yy\` turns out to be unused in any action code!
          var yy = this.yy;
          var yyparser = yy.parser;
          var yylexer = yy.lexer;

          ${preludeCode}

          switch (yystate) {`
        ];
        var actionGroups = {};          // used to combine identical actions into single instances: no use duplicating action code needlessly
        var actionGroupValue = {};      // stores the unaltered, expanded, user-defined action code for each action group.
        var stateHasAction = [];        // marks which state IDs have an action, either user-specified or default.
        var symbol;

        // and now go and process the entire grammar:
        productions.forEach(buildProductionAction);

        for (var hash in actionGroups) {
            actions.push([].concat.apply([], actionGroups[hash]).join('\n') + '\n\n' + actionGroupValue[hash] + '\n    break;\n');
        }

        // add the special error recovery reduction action:
        if (this.hasErrorRecovery) {
            var userland_err_recov_redux_code = '';

            actions.push(`case YY_ERROR_RECOVERY_COMBINE_ID:       // === NO_ACTION[1] :: ensures that anyone (but us) using this new state will fail dramatically!
                // error recovery reduction action (action generated by jison,
                // using the user-specified \`%code error_recovery_reduction\` %{...%}
                // code chunk below.

                ${userland_err_recov_redux_code}
                break;
            `);
        }

        // check if all IDs have an action now:
        var missingActions = [];
        for (var idx = 0, len = stateHasAction.length; idx < len; idx++) {
            if (!stateHasAction[idx]) {
                missingActions.push(idx);
            }
        }
        if (missingActions.length) {
            console.warn("WARNING: missing actions for states: ", missingActions);

            actions.push(`default:
                // default action for all unlisted resolve states: ${missingActions.join(', ')}

                // When we hit this entry, it's always a non-recoverable issue as this is a severe internal parser state failure:
                function __b0rk_on_internal_failure(str) {
                    var hash = yyparser.constructParseErrorInfo(str, null, null, false);

                    var r = yyparser.parseError(str, hash, yyparser.JisonParserError);
                    return r;
                }

                return __b0rk_on_internal_failure("internal parser failure: resolving unlisted state: " + yystate);`
            );
        }
        actions.push('}');

        var parameters = 'yytext, yyleng, yylineno, yyloc, yystate /* action[1] */, yysp, yyrulelength, yyvstack, yylstack, yystack, yysstack';

        this.performAction = [].concat(
            'function parser__PerformAction(' + parameters + ') {',
            actions,
            '}'
        ).join('\n')
        .replace(/\bYYABORT\b/g, 'return false')
        .replace(/\bYYACCEPT\b/g, 'return true')

        // Replace direct symbol references, e.g. #NUMBER# when there's a `%token NUMBER` for your grammar.
        // We allow these tokens to be referenced anywhere in your code as #TOKEN#.
        .replace(/#([^#\s\r\n]+)#/g, function (_, sym) {
            return provideSymbolAsSourcecode(sym);
        });

        this.performAction = this.performAction
        .replace(/\byyerror\b/g, 'yyparser.yyError')
        .replace(/\bYYRECOVERING\b(?:\s*\(\s*\))?/g, 'yyparser.yyRecovering()')
        .replace(/\byyerrok\b(?:\s*\(\s*\))?/g, 'yyparser.yyErrOk()')
        .replace(/\byyclearin\b(?:\s*\(\s*\))?/g, 'yyparser.yyClearIn()');

        this.actionsUseYYLENG = this.actionsUseYYLENG || analyzeFeatureUsage(this.performAction, /\byyleng\b/g, 1);
        this.actionsUseYYLINENO = this.actionsUseYYLINENO || analyzeFeatureUsage(this.performAction, /\byylineno\b/g, 1);
        this.actionsUseYYTEXT = this.actionsUseYYTEXT || analyzeFeatureUsage(this.performAction, /\byytext\b/g, 1);
        this.actionsUseYYLOC = this.actionsUseYYLOC || analyzeFeatureUsage(this.performAction, /\byyloc\b/g, 1);
        this.actionsUseParseError = this.actionsUseParseError || analyzeFeatureUsage(this.performAction, /\.parseError\b/g, 0);
        this.actionsUseYYERROR = this.actionsUseYYERROR || analyzeFeatureUsage(this.performAction, /\.yyError\b/g, 0);
        this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || analyzeFeatureUsage(this.performAction, /\.yyRecovering\b/g, 0);
        this.actionsUseYYERROK = this.actionsUseYYERROK || analyzeFeatureUsage(this.performAction, /\.yyErrOk\b/g, 0);
        this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || analyzeFeatureUsage(this.performAction, /\.yyClearIn\b/g, 0);
        // At this point in time, we have already expanded `$name`, `$$` and `$n` to its `$$[n]` index expression.
        //
        // Also note we cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
        // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
        // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
        // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
        this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(this.performAction, /\byyvstack\b/g, 1);
        // Ditto for the specific case where we are assigning a value to `$$`, i.e. `this.$`:
        this.actionsUseValueAssignment = this.actionsUseValueAssignment || analyzeFeatureUsage(this.performAction, /\bthis\.\$[^\w]/g, 0);
        // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
        this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(this.performAction, /\byylstack\b/g, 1);
        // Ditto for the specific case where we are assigning a value to `@$`, i.e. `this._$`:
        this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || analyzeFeatureUsage(this.performAction, /\bthis\._\$[^\w]/g, 0);
        // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
        // the need to use yystack! Hence yystack is only there for very special use action code.)
        this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(this.performAction, /\byystack\b/g, 1);
        // Ditto for yysstack...
        this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(this.performAction, /\byysstack\b/g, 1);
        this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(this.performAction, /\byysp\b/g, 1);
        this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || analyzeFeatureUsage(this.performAction, /\byyrulelength\b/g, 1);
        this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(this.performAction, /\.yyMergeLocationInfo\b/g, 1);

        // ------------------------------------------------------------------------------------
        // And Check if any of these features occur in the other user-defined chunks of code
        // that will end up as part of the parser at large:
        //
        // ---
        //
        // It does NOT matter that other user code accesses lexer-specific items; this analysis is
        // abut accessing PARSER INTERNALS, hence we have commented out the items which cannot ever
        // reach those variables from here.
        //
        //
        // ### NOTE ###
        //
        // We DO NOT care if some very obscure piece of code transfers a `this` (= yyval) reference from
        // and action code chunk to an outside function: if you are *that* devious, we also reckon you
        // are very well aware of what you are doing and quite capable of 'forcing' these feature
        // flags via the `%options` route. ;-))
        //
        // HOWVER, writing a custom `parseError` handler in there is considered rather more mundane,
        // so we reckon you have found a way to grab yyvstack et al from the error hash in that
        // wicked `parseError` callback of yours! ;-))
        //
        //   (Do note that `constructParseErrorInfo()` **intentionally** DOES NOT include the internal
        //    `yyval` in the produced error info chunk! Meanwhile, `yyvstack` is known under a different
        //    name inside the error info object and that is, as far as we are concerned, the only
        //    sensible way to get access to the internal parse stacks *outside* `performAction()`!
        //    ... Just because we like our copy-pasta, we wave our hands and check for both incantations...)
        //

        //this.actionsUseYYLENG = this.actionsUseYYLENG || analyzeFeatureUsage(moduleInclude, /\byyleng\b/g, 0);
        //this.actionsUseYYLINENO = this.actionsUseYYLINENO || analyzeFeatureUsage(moduleInclude, /\byylineno\b/g, 0);
        //this.actionsUseYYTEXT = this.actionsUseYYTEXT || analyzeFeatureUsage(moduleInclude, /\byytext\b/g, 0);
        //this.actionsUseYYLOC = this.actionsUseYYLOC || analyzeFeatureUsage(moduleInclude, /\byyloc\b/g, 0);
        this.actionsUseParseError = this.actionsUseParseError || analyzeFeatureUsage(moduleInclude, /\.parseError\b/g, 0);
        this.actionsUseYYERROR = this.actionsUseYYERROR || analyzeFeatureUsage(moduleInclude, /\.yyError\b/g, 0);
        this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || analyzeFeatureUsage(moduleInclude, /\.yyRecovering\b/g, 0);
        this.actionsUseYYERROK = this.actionsUseYYERROK || analyzeFeatureUsage(moduleInclude, /\.yyErrOk\b/g, 0);
        this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || analyzeFeatureUsage(moduleInclude, /\.yyClearIn\b/g, 0);
        // We cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
        // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
        // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
        // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
        this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\byyvstack\b/g, 0);
        this.actionsUseValueTracking = this.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\.value_stack\b/g, 0);
        // Ditto for the specific case where we are assigning a value to `$$`, i.e. `this.$`:
        //this.actionsUseValueAssignment = this.actionsUseValueAssignment || analyzeFeatureUsage(moduleInclude, /\bthis\.\$[^\w]/g, 0);
        // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
        this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\byylstack\b/g, 0);
        this.actionsUseLocationTracking = this.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\.location_stack\b/g, 0);
        // Ditto for the specific case where we are assigning a value to `@$`, i.e. `this._$`:
        //this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || analyzeFeatureUsage(moduleInclude, /\bthis\._\$[^\w]/g, 0);
        // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
        // the need to use yystack! Hence yystack is only there for very special use action code.)
        this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\byystack\b/g, 0);
        this.actionsUseYYSTACK = this.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\.symbol_stack\b/g, 0);
        // Ditto for yysstack...
        this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\byysstack\b/g, 0);
        this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\.state_stack\b/g, 0);
        this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\byysp\b/g, 0);
        this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\.stack_pointer\b/g, 0);
        //this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || analyzeFeatureUsage(moduleInclude, /\byyrulelength\b/g, 0);
        this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(moduleInclude, /\.yyMergeLocationInfo\b/g, 0);

        moduleInit.forEach(function (chunk) {
            assert(chunk.qualifier);
            assert(typeof chunk.include === 'string');
            var moduleInclude = chunk.include;

            //self.actionsUseYYLENG = self.actionsUseYYLENG || analyzeFeatureUsage(moduleInclude, /\byyleng\b/g, 0);
            //self.actionsUseYYLINENO = self.actionsUseYYLINENO || analyzeFeatureUsage(moduleInclude, /\byylineno\b/g, 0);
            //self.actionsUseYYTEXT = self.actionsUseYYTEXT || analyzeFeatureUsage(moduleInclude, /\byytext\b/g, 0);
            //self.actionsUseYYLOC = self.actionsUseYYLOC || analyzeFeatureUsage(moduleInclude, /\byyloc\b/g, 0);
            self.actionsUseParseError = self.actionsUseParseError || analyzeFeatureUsage(moduleInclude, /\.parseError\b/g, 0);
            self.actionsUseYYERROR = self.actionsUseYYERROR || analyzeFeatureUsage(moduleInclude, /\.yyError\b/g, 0);
            self.actionsUseYYRECOVERING = self.actionsUseYYRECOVERING || analyzeFeatureUsage(moduleInclude, /\.yyRecovering\b/g, 0);
            self.actionsUseYYERROK = self.actionsUseYYERROK || analyzeFeatureUsage(moduleInclude, /\.yyErrOk\b/g, 0);
            self.actionsUseYYCLEARIN = self.actionsUseYYCLEARIN || analyzeFeatureUsage(moduleInclude, /\.yyClearIn\b/g, 0);
            // We cannot use regex `\b` with `\$` as the regex doesn't consider the literal `$` to be a *word* character
            // hence the *boundary check* `\b` won't deliver as expected. Hence we'll have to wing it but we can, assured
            // in the knowledge that the 'sourcecode' we have here is a complete generated *function* which will include
            // the `function ` prelude and `}` postlude at least! Hence we can replace `\b` with `[^\w]` and we'll be good.
            self.actionsUseValueTracking = self.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\byyvstack\b/g, 0);
            self.actionsUseValueTracking = self.actionsUseValueTracking || analyzeFeatureUsage(moduleInclude, /\.value_stack\b/g, 0);
            // Ditto for the specific case where we are assigning a value to `$$`, i.e. `self.$`:
            //self.actionsUseValueAssignment = self.actionsUseValueAssignment || analyzeFeatureUsage(moduleInclude, /\bself\.\$[^\w]/g, 0);
            // Ditto for the expansion of `@name`, `@$` and `@n` to its `yylstack[n]` index expression:
            self.actionsUseLocationTracking = self.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\byylstack\b/g, 0);
            self.actionsUseLocationTracking = self.actionsUseLocationTracking || analyzeFeatureUsage(moduleInclude, /\.location_stack\b/g, 0);
            // Ditto for the specific case where we are assigning a value to `@$`, i.e. `self._$`:
            //self.actionsUseLocationAssignment = self.actionsUseLocationAssignment || analyzeFeatureUsage(moduleInclude, /\bself\._\$[^\w]/g, 0);
            // Note that the `#name`, `#$` and `#n` constructs are expanded directly to their symbol number without
            // the need to use yystack! Hence yystack is only there for very special use action code.)
            self.actionsUseYYSTACK = self.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\byystack\b/g, 0);
            self.actionsUseYYSTACK = self.actionsUseYYSTACK || analyzeFeatureUsage(moduleInclude, /\.symbol_stack\b/g, 0);
            // Ditto for yysstack...
            self.actionsUseYYSSTACK = self.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\byysstack\b/g, 0);
            self.actionsUseYYSSTACK = self.actionsUseYYSSTACK || analyzeFeatureUsage(moduleInclude, /\.state_stack\b/g, 0);
            self.actionsUseYYSTACKPOINTER = self.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\byysp\b/g, 0);
            self.actionsUseYYSTACKPOINTER = self.actionsUseYYSTACKPOINTER || analyzeFeatureUsage(moduleInclude, /\.stack_pointer\b/g, 0);
            //self.actionsUseYYRULELENGTH = self.actionsUseYYRULELENGTH || analyzeFeatureUsage(moduleInclude, /\byyrulelength\b/g, 0);
            self.actionsUseYYMERGELOCATIONINFO = self.actionsUseYYMERGELOCATIONINFO || analyzeFeatureUsage(moduleInclude, /\.yyMergeLocationInfo\b/g, 0);
        });

        // ------------------------------------------------------------------------------------
        // Mix in user overrides via CLI or %options:
        this.actionsUseLocationAssignment = this.actionsUseLocationAssignment || this.options.actionsUseLocationAssignment;
        this.actionsUseLocationTracking = this.actionsUseLocationTracking || this.options.actionsUseLocationTracking;
        this.actionsUseParseError = this.actionsUseParseError || this.options.actionsUseParseError;
        this.actionsUseValueAssignment = this.actionsUseValueAssignment || this.options.actionsUseValueAssignment;
        this.actionsUseValueTracking = this.actionsUseValueTracking || this.options.actionsUseValueTracking;
        this.actionsUseYYCLEARIN = this.actionsUseYYCLEARIN || this.options.actionsUseYYCLEARIN;
        this.actionsUseYYERROK = this.actionsUseYYERROK || this.options.actionsUseYYERROK;
        this.actionsUseYYERROR = this.actionsUseYYERROR || this.options.actionsUseYYERROR;
        this.actionsUseYYLENG = this.actionsUseYYLENG || this.options.actionsUseYYLENG;
        this.actionsUseYYLINENO = this.actionsUseYYLINENO || this.options.actionsUseYYLINENO;
        this.actionsUseYYLOC = this.actionsUseYYLOC || this.options.actionsUseYYLOC;
        this.actionsUseYYRECOVERING = this.actionsUseYYRECOVERING || this.options.actionsUseYYRECOVERING;
        this.actionsUseYYRULELENGTH = this.actionsUseYYRULELENGTH || this.options.actionsUseYYRULELENGTH;
        this.actionsUseYYMERGELOCATIONINFO = this.actionsUseYYMERGELOCATIONINFO || this.options.actionsUseYYMERGELOCATIONINFO;
        this.actionsUseYYSSTACK = this.actionsUseYYSSTACK || this.options.actionsUseYYSSTACK;
        this.actionsUseYYSTACK = this.actionsUseYYSTACK || this.options.actionsUseYYSTACK;
        this.actionsUseYYSTACKPOINTER = this.actionsUseYYSTACKPOINTER || this.options.actionsUseYYSTACKPOINTER;
        this.actionsUseYYTEXT = this.actionsUseYYTEXT || this.options.actionsUseYYTEXT;
        this.hasErrorRecovery = this.hasErrorRecovery || this.options.hasErrorRecovery;
        this.hasErrorReporting = this.hasErrorReporting || this.options.hasErrorReporting;

        // ------------------------------------------------------------------------------------
        // Now combine fature flags which are related:
        switch (self.options.defaultActionMode[0]) {
        default:
            this.actionsUseValueTracking = true;
            this.actionsUseValueAssignment = true;
            break;

        case "none":    // <-- this one injects "$$ = undefined;", which doesn't count as 'non-trivial code' on its own.
        case "skip":    // <-- this one injects *nothing*
            break;
        }
        this.actionsUseValueTracking = this.actionsUseValueTracking || this.actionsUseYYLENG || this.actionsUseYYTEXT || this.actionsUseValueAssignment;

        switch (self.options.defaultActionMode[1]) {
        default:
            // WARNING: we only turn on default location tracking code **at all** iff
            // any part of the user code actually uses it, otherwise we would be
            // instrumenting an entire parser with location tracking code which' efforts
            // will be discarded at the end of the parse anyhow.
            //
            // Do note that this is different from the **value tracking** default code
            // policy: it **IS** sane to instrument an entire parser with value
            // tracking action code because *those* efforts will ultimately end up
            // as/in the parse **result**!
            
            break;

        case "none":    // <-- this one injects "$$ = undefined;", which doesn't count as 'non-trivial code' on its own.
        case "skip":    // <-- this one injects *nothing*
            break;
        }
        this.actionsUseLocationTracking = this.actionsUseLocationTracking || this.actionsUseYYLINENO || this.actionsUseYYLOC || this.actionsUseLocationAssignment || this.actionsUseYYMERGELOCATIONINFO;

        this.hasErrorReporting = this.hasErrorReporting || this.actionsUseParseError || this.actionsUseYYERROR;
        // --------------------- done! --------------------------------------------------------

        // Now that we've completed all macro expansions, it's time to execute
        // the recovery code, i.e. the postprocess:
        this.performAction = postprocessActionCode(this.performAction);

        // Now check if we produced an *EMPTY* `parser__PerformAction()`.
        // If so, we can discard the entire function!
        this.actionsAreAllDefault = false; // TODO

        gen_level++;
        prev_gen_hash = gen_hash;
        gen_hash = null;

        // create check hash of the new generated code:
        var new_hash = mkParserFeatureHash(this);

        if (devDebug || this.DEBUG) {
            Jison.print('Optimization analysis:\n', {
                cycle: gen_level,
                SAME: prev_gen_hash === new_hash,
                actionsAreAllDefault: this.actionsAreAllDefault,
                actionsUseYYLENG: this.actionsUseYYLENG,
                actionsUseYYLINENO: this.actionsUseYYLINENO,
                actionsUseYYTEXT: this.actionsUseYYTEXT,
                actionsUseYYLOC: this.actionsUseYYLOC,
                actionsUseParseError: this.actionsUseParseError,
                actionsUseYYERROR: this.actionsUseYYERROR,
                actionsUseYYRECOVERING: this.actionsUseYYRECOVERING,
                actionsUseYYERROK: this.actionsUseYYERROK,
                actionsUseYYCLEARIN: this.actionsUseYYCLEARIN,
                actionsUseValueTracking: this.actionsUseValueTracking,
                actionsUseValueAssignment: this.actionsUseValueAssignment,
                actionsUseLocationTracking: this.actionsUseLocationTracking,
                actionsUseLocationAssignment: this.actionsUseLocationAssignment,
                actionsUseYYSTACK: this.actionsUseYYSTACK,
                actionsUseYYSSTACK: this.actionsUseYYSSTACK,
                actionsUseYYSTACKPOINTER: this.actionsUseYYSTACKPOINTER,
                actionsUseYYRULELENGTH: this.actionsUseYYRULELENGTH,
                actionsUseYYMERGELOCATIONINFO: this.actionsUseYYMERGELOCATIONINFO,
                hasErrorRecovery: this.hasErrorRecovery,
                hasErrorReporting: this.hasErrorReporting,
                defaultActionMode: this.options.defaultActionMode,
                noTryCatch: this.options.noTryCatch,
            });
        }

        gen_hash = new_hash;
    }

    // And before we leave, as a SIDE EFFECT of this call, we also fixup
    // the other code chunks specified in the grammar file.
    this.moduleInclude = postprocessActionCode(moduleInclude);
    this.moduleInit = moduleInit.map(function (chunk) {
        assert(chunk.qualifier);
        assert(typeof chunk.include === 'string');
        chunk.include = postprocessActionCode(chunk.include);
        return chunk;
    });
    assert(Array.isArray(this.moduleInit));

    // add helper methods to `this.moduleInit` for later use by our code generator:
    moduleInit = this.moduleInit;
    moduleInit.__consumedInitCodeSlots__ = [];

    moduleInit.getInitCodeSection = function getInitCodeSection(section) {
        var rv = [];
        for (var i = 0, len = this.length; i < len; i++) {
            var m = this[i];
            if (m.qualifier === section) {
                if (m.include.trim()) {
                    rv.push(m.include);
                }
                this.__consumedInitCodeSlots__[i] = true;
            }
        }
        return rv;
    };

    moduleInit.getRemainingInitCodeSections = function getRemainingInitCodeSections() {
        var rv = [];
        for (var i = 0, len = this.length; i < len; i++) {
            var m = this[i];
            if (!this.__consumedInitCodeSlots__[i]) {
                rv.push(rmCommonWS$1`

                    // START code section "${m.qualifier}"
                    ${m.include}
                    // END code section "${m.qualifier}"

                `);
                this.__consumedInitCodeSlots__[i] = true;
            }
        }
        return rv;
    };




    // make sure a comment does not contain any embedded '*/' end-of-comment marker
    // as that would break the generated code
    function postprocessComment(str) {
        if (Array.isArray(str)) {
            str = str.map(function (_) {
                return (_ === '' || _ == null) ? 'ε' : _;
            }).join(' ');
        }
        if (str === '') {
            str = 'ε';
        }
        str = str.replace(/\*\//g, '*\\/');         // destroy any inner `*/` comment terminator sequence.
        return str;
    }

    function getSymbolId(s) {
        if (s && !self.symbols_[s]) {
            throw new Error('Your action code is trying to reference non-existing symbol "' + s + '"');
        }
        return self.symbols_[s] || 0;
    }

    function provideSymbolAsSourcecode(sym) {
        var ss = String(sym);
        return ' /* ' + postprocessComment(ss) + ' */ ' + getSymbolId(sym);
    }

    // helper: convert index string/number to proper JS add/subtract expression
    function indexToJsExpr(n, len, rule4msg) {
        var v = parseInt(n, 10);
        // the usual situation: `$3`; MUST reference an rhs[] element or it will be considered an ERROR:
        if (v > 0) {
            if (v > len) {
                throw new Error(`invalid token reference "\$${v}" in action code for rule: "${rule4msg}"`);
            }
            v = len - v;
            if (v) {
                return ` - ${v}`;
            }
            // do not generate code for superfluous `- 0` JS expression:
            return '';
        }
        // the VERY UNusual situation: `$-1`: referencing *parent* rules' values
        if (v < 0) {
            return ` - ${len - v}`;
        }
        // decode error?
        if (v !== 0) {
            throw new Error(`invalid token reference "\$${v}" in action code for rule: "${rule4msg}"`);
        }
        // the slightly unusual situation: `$0` (instead of `$$`)
        v = len;
        if (v) {
            return ` - ${v}`;
        }
        // do not generate code for superfluous `- 0` JS expression:
        return '';
    }

    function buildProductionAction(handle) {
        var r, i;

        if (devDebug) Jison.print('\nbuildProductionAction: ', handle.symbol, ':', JSON.stringify(handle, null, 2));

        var aliased = handle.aliases,
            rhs_i;

        var rhs = handle.handle;
        var named_token_re = new XRegExp(`^${ID_REGEX_BASE}$`);

        // semantic action specified
        var label = [
            'case ', handle.id, ':',
            '\n    /*! Production::    ', postprocessComment(handle.symbol), ' : '
        ].concat(postprocessComment(rhs.map(function (sym) {
            // check if the symbol is a literal terminal, and if it is, quote it:
            if (sym && !self.nonterminals[sym] && !named_token_re.test(sym) && sym !== self.EOF) {
                return '"' + sym.replace(/["]/g, '\\"') + '"';
            }
            else if (!sym) {
                sym = '%epsilon';
            }
            return sym;
        })), ' */').join('');
        var action = preprocessActionCode(handle.action || '');
        var rule4msg = handle.symbol + ': ' + rhs.join(' ');

        assert(typeof handle.id === 'number');
        assert(handle.id >= 0);
        stateHasAction[handle.id] = true;

        // before anything else, replace direct symbol references, e.g. #NUMBER# when there's a %token NUMBER for your grammar.
        // This is done to prevent incorrect expansions where tokens are used in rules as RHS elements: we allow these to
        // be referenced as both #TOKEN# and #TOKEN where the first is a literal token/symbol reference (unrelated to its use
        // in the rule) and the latter is a reference to the token/symbol being used in the rule.
        //
        // Here we expand those direct token/symbol references: #TOKEN#
        action = action
            .replace(/#([^#\s\r\n]+)#/g, function (_, sym) {
                return provideSymbolAsSourcecode(sym);
            });

        // replace named semantic values ($nonterminal)
        if (action.match(new XRegExp(`(?:[$@#]|##)${ID_REGEX_BASE}`))) {
            var count = {},
                names = {},
                donotalias = {};

            // When the rule is fitted with aliases it doesn't mean that the action code MUST use those:
            // we therefor allow access to both the original (non)terminal and the alias.
            //
            // Also note that each (non)terminal can also be uniquely addressed by [$@]<nonterminal><N>
            // where N is a number representing the number of this particular occurrence of the given
            // (non)terminal.
            //
            // For example, given this (intentionally contrived) production:
            //     elem[alias] elem[another_alias] another_elem[alias] elem[alias] another_elem[another_alias]
            // all the items can be accessed as:
            //     $1 $2 $3 $4 $5
            //     $elem1 $elem2 $another_elem1 $elem3 $another_elem2
            //     $elem $elem2 $another_elem $elem3 $another_elem2
            //     $alias1 $another_alias1 $alias2 $alias3 $another_alias2
            //     $alias $another_alias $alias2 $alias3 $another_alias2
            // where each line above is equivalent to the top-most line. Note the numbers postfixed to
            // both (non)terminal identifiers and aliases alike and also note alias2 === another_elem1:
            // the postfix numbering is independent.
            //
            // WARNING: this feature is disabled for a term when there already exists an
            //          (human-defined) *alias* for this term *or* when the numbered auto-alias already
            //          exists because the user has used it as an alias for another term, e.g.
            //
            //             e: WORD[e1] '=' e '+' e;
            //
            //          would *not* produce the `e1` and `e2` aliases, as `e1` is already defined
            //          as an explicit alias: adding auto-alias `e1` would then break the system,
            //          while `e2` would be ambiguous from the human perspective as he *might* then
            //          expect `e2` and `e3`.
            var addName = function addName(s) {
                var base = s.replace(/[0-9]+$/, '');
                var dna = donotalias[base];

                if (names[s]) {
                    count[s]++;
                    if (!dna) {
                        names[s + count[s]] = i + 1;
                        count[s + count[s]] = 1;
                    }
                } else {
                    names[s] = i + 1;
                    count[s] = 1;
                    if (!dna) {
                        names[s + count[s]] = i + 1;
                        count[s + count[s]] = 1;
                    }
                }
            };

            // register the alias/rule name when the real one ends with a number, e.g. `rule5` as
            // *blocking* the auto-aliasing process for the term of the same base, e.g. `rule`.
            // This will catch the `WORD[e1]` example above too, via `e1` --> `donotalias['e']`
            var markBasename = function markBasename(s) {
                if (/[0-9]$/.test(s)) {
                    s = s.replace(/[0-9]+$/, '');
                    donotalias[s] = true;
                }
            };

            for (i = 0; i < rhs.length; i++) {
                // mark both regular and aliased names, e.g., `id[alias1]` and `id1`
                rhs_i = aliased[i];
                markBasename(rhs_i);
                if (rhs_i !== rhs[i]) {
                    markBasename(rhs[i]);
                }
            }

            for (i = 0; i < rhs.length; i++) {
                // check for aliased names, e.g., id[alias]
                rhs_i = aliased[i];
                addName(rhs_i);
                if (rhs_i !== rhs[i]) {
                    addName(rhs[i]);
                }
            }
            action = action.replace(
                new XRegExp(`([$@#]|##)(${ID_REGEX_BASE})`, 'g'), function (str, mrkr, pl) {
                    if (names[pl] && count[pl] !== 1) {
                        throw new Error(`The action block references the ambiguous named alias or term reference "${pl}" which is mentioned ${count[pl]} times in production "${handle.handle}", implicit and explicit aliases included.` +
                            '\nYou should either provide unambiguous = uniquely named aliases for these terms or use numeric index references (e.g. `$3`) as a stop-gap in your action code.');
                    }
                    return names[pl] ? mrkr + names[pl] : str;
                });
        }
        action = action
            // replace references to `$$` with `this.$`, `@$` with `this._$` and `#$` with the token ID of the current rule
            .replace(/\$\$/g, 'this.$')
            .replace(/@\$/g, 'this._$')
            .replace(/#\$/g, function (_) {
                return provideSymbolAsSourcecode(symbol);
            })
            // replace semantic value references ($n) with stack value (stack[n])
            .replace(/\$(-?\d+)\b/g, function (_, n) {
                return 'yyvstack[yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ']';
            })
            // same as above for location references (@n)
            .replace(/@(-?\d+)\b/g, function (_, n) {
                return 'yylstack[yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ']';
            })
            // same as above for positional value references (##n): these represent stack indexes
            .replace(/##(-?\d+)\b/g, function (_, n) {
                return '(yysp' + indexToJsExpr(n, rhs.length, rule4msg) + ')';
            })
            .replace(/##\$/g, function (_) {
                return 'yysp';
            })
            // same as above for token ID references (#n)
            .replace(/#(-?\d+)\b/g, function (_, n) {
                var i = parseInt(n, 10) - 1;
                if (!rhs[i]) {
                    throw new Error(`invalid token location reference in action code for rule: "${rule4msg}" - location reference: "${_}"`);
                }
                return provideSymbolAsSourcecode(rhs[i]);
            });

        // Now that the user action (if any) has been expanded to valid JavaScript code
        // (we're SOL and very probably looking at bugs in the user-written action code
        // if it is NOT VALID by now!) we can perform code analysis to see which,
        // if any, default actions have to be injected in the code snippet.
        //
        // The rules of the game are:
        // - when there's *use* of `$$` or `@$` *before* they are assigned a value,
        //   the corresponding default action is required.
        // - when there's *nothing* about (no use of, no assignment to) `$$` or `@$`
        //   then the corresponding default action should be injected IFF the
        //   code analysis flags have been set, i.e. only inject the default action
        //   when we already *know* that other parts of the parser state machine
        //   (other rules' actions!) *are* using these.
        //   We DO NOT include "flow analysis" so we cannot determine if
        //   *this particular* rule's values will be accessed; iff location tracking
        //   is used at all, we inject it everywhere. Ditto for value tracking.
        // - value tracking (`$$` et al) is considered *independently* from location
        //   tracking (`@$` et al): the one or the other may need the default
        //   actions for more-or-less sensible (or at least *deterministic*!) results
        //   and consequently should get them, indenpent of whether the user-written
        //   action code fuly addresses the other.
        //
        //   Generally, user actions concern themselves with assigning a value to `$$`,
        //   while not addressing `@$`: in that case, the location tracking default
        //   action `@$ = ...` will be injected in that action snippet.
        //
        //   Also note that, in order to prevent obscure failures due to analysis
        //   false positives, all default actions are injected *before* the user-written
        //   action code.
        //
        // Technical Note
        //
        // We perform the action code analysis *after* jison variable expansions are done
        // because we want the analysis to be *independent* of how the user wrote
        // the action code: if some Smart Alec decides to code `this.$` instead of
        // `$$` it SHOULD NOT confuse the code analysis here!

        var uses_$$ = analyzeFeatureUsage(action, /\bthis\.\$[^\w]/g, 0);   // use includes assignment, not just read accesses!

        // the next check is very rough; we need the AST of the code to do better than this.
        function analyzeFeatureAssignmentBeforeUse(source, assignment_re, access_re) {
            // first match agains the assignment regex: it MUST have a closure
            // to catch all code that came before this first assignment.
            //
            // If no assignment can be found at all, we're probably looking at access-only
            // OR weird constructs we don't yet understand, in which case we play it safe.
            var prelude = source;
            var m = source.match(assignment_re);
            if (m) {
                // check the closure exists in the regex: m[1] is filled with its content:
                assert(m[1] != null);
                prelude = m[1];
            }
            // now check if there's any mention of the feature before its first
            // assignment.
            //
            // We MAY get thwarted by complex action code such as this:
            //
            //     function closure_func(a) {
            //       $$ = a;
            //     }
            //
            //     if ($term1) {
            //       print($$);         // actually this is use before assignment, but we won't recognize it as such!
            //     } else {
            //       closure_func($term2);
            //       print('alt');
            //     }
            //
            // but for now we ignore the complexity of the situation and move on.
            m = prelude.match(access_re);
            if (m) {
                return true;       // access before assignment
            }
            return false;          // assignment before access (or no usage and assignments at all!)
        }

        var uses_$$_before_assignment = uses_$$ && analyzeFeatureAssignmentBeforeUse(action, /^([^]*?)\bthis\.\$\s*=[^=>]/, /\bthis\.\$[^\w]/g);

        // ditto for location tracking, but only iff we use it at all:
        var uses_$loc = false;
        var uses_$loc_before_assignment = false;

        if (self.actionsUseLocationTracking) {
            uses_$loc = analyzeFeatureUsage(action, /\bthis\._\$[^\w]/g, 0);
            uses_$loc_before_assignment = uses_$loc && analyzeFeatureAssignmentBeforeUse(action, /^([^]*?)\bthis\._\$\s*=[^=>]/, /\bthis\._\$[^\w]/g);
        }

        var inject_default_value_action = (uses_$$_before_assignment || (self.actionsUseValueTracking && !uses_$$));
        var inject_default_loc_action = (uses_$loc_before_assignment || (self.actionsUseLocationTracking && !uses_$loc));

        var default_action = [];

        // Note:
        //
        // when the option defaultActionMode="none,none" has been set, we still strive to produce
        // a deterministic output, hence we take the swiftest route towards producing
        // a deterministic rule result: we assign it the value `undefined`:
        //
        //     $$ = undefined;
        //     $@ = undefined;
        //
        var vmode = !inject_default_value_action ? "skip" : self.options.defaultActionMode[0];
        var lmode = !inject_default_loc_action ? "skip" : self.options.defaultActionMode[1];

        // check if there's no user action specified. Insert default action if it isn't.

        // first determine the actual number of terms in the production:
        var rhs = handle.handle.slice(0);
        var real_rhs_length = rhs.length;

        // strip away EOF terms at the end of the rule, ditto for epsilon terms:
        if (rhs.length) {
            switch (rhs[rhs.length - 1]) {
            case '$end':
                rhs.length--;
                break;

            case '':                // %epsilon
                rhs.length--;
                break;
            }
        }

        // then we can choose what to do, depending on the number of terms in the production.
        //
        // There are a few reasons *why* one would choose to inject the default action:
        //
        // 1. there's use (read access) before assignment (write).
        // 2. there's no use nor any assignment, but the rest of the parser *does* use rule values.
        //    (In which case we would need flow analysis to determine if our default action would
        //    really matter, but absent that, we just inject the default action everywhere and
        //    we can be certain the other action code chunks will work as expected, though
        //    the parser may be a bit sub-optimal due to possibly unused default actions being
        //    executed in some states.)
        //
        // Ditto for location tracking default actions...
        //
        switch (rhs.length) {
        case 0:
            switch (vmode) {
            case "classic":
                // $$ = $1;   <-- but that would cause nondeterministic behaviour, so
                //                we fall back to the default here!
            case "ast":
            case "none":
                default_action.push("this.$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
            }

            switch (lmode) {
            case "classic":
            case "ast":
            case "merge":
                // an empty production has no location as there are no terms parsed.
                // ergo: we produce a zero-width location which points at the tail
                // end of the previous content:
                // @$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);
                default_action.push("this._$ = yyparser.yyMergeLocationInfo(null, null, null, null, true);");
                break;

            case "none":
                // @$ = undefined;
                default_action.push("this._$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
            }
            break;

        case 1:
            switch (vmode) {
            case "classic":
                // $$ = $1;
                //
                // WARNING: be careful with the ACCEPT rule as that one's production has
                // rhs.length === 1 **BUT** has real_rhs_length === 2 as we have discarded
                // the `$end` term at the end!
                // Here we need to account for that magick though!
                default_action.push("this.$ = yyvstack[yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + "];");
                break;

            case "ast":
                // bundle all production terms in an array:
                //   $$ = yyvstack.slice(yysp - ${rhs.length - 1}, yysp + 1);
                // As we're looking at a production which has one(1) useful term, we can simply
                // reference-copy that one intom a fresh array, instead of `slice()`-ing it out
                // of the vstack.
                //   $$ = [$1];
                //
                // WARNING/NOTE: as above, and ditto BTW for rule productions which end with
                // `EOF` as a last term: as we now construct an entire AST, we DO NOT include
                // those 'values' here!
                default_action.push("this.$ = [yyvstack[yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + "]];");
                break;

            case "none":
                default_action.push("this.$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
            }

            switch (lmode) {
            case "classic":
            case "ast":
            case "merge":
                // merge all production terms' locations into a single range:
                // as we have a production length of 1 only, we can simply ref-copy @1:
                // @$ = @1;
                //
                // WARNING: same as above for the value copying: we may have discarded an `EOF` or `$end` term!
                default_action.push("this._$ = yylstack[yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + "];");
                break;

            case "none":
                // @$ = undefined;
                default_action.push("this._$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
            }
            break;

        default:
            switch (vmode) {
            case "classic":
                // $$ = $1;
                default_action.push("this.$ = yyvstack[yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + "];");
                break;

            case "ast":
                // bundle all production terms in an array:
                // $$ = yyvstack.slice(yysp - ${rhs.length - 1}, yysp + 1);
                //
                // WARNING: as with the situation further above where rhs.length === 1 after we
                // have got rid of a possible `EOF` or `$end` at the end of the production,
                // we again have to account for our trickery earlier and compensate the
                // action above: again we DO NOT include the value of the EOF/$end token in the
                // resulting array 'AST', hence our `slice()` end index may vary by one(1):
                var end_offset = 1 - real_rhs_length + rhs.length;
                default_action.push("this.$ = yyvstack.slice(yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + ", yysp" + /* CANNOT USE indexToJsExpr(rhs.length + 1, real_rhs_length, rule4msg) HERE! */ (end_offset === 0 ? "" : " + " + end_offset) + ");");
                break;

            case "none":
                default_action.push("this.$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction value mode: "${vmode}"`);
            }

            switch (lmode) {
            case "classic":
            case "ast":
            case "merge":
                // merge all production terms' locations into a single range:
                // @$ = yyparser.yyMergeLocationInfo(yysp - ${rhs.length - 1}, yysp);
                default_action.push("this._$ = yyparser.yyMergeLocationInfo(yysp" + indexToJsExpr(1, real_rhs_length, rule4msg) + ", yysp);");
                break;

            case "none":
                // @$ = undefined;
                default_action.push("this._$ = undefined;");
                break;

            case "skip":
                // nothing to inject
                break;

            default:
                throw new Error(`unsupported defaultAction location mode: "${lmode}"`);
            }
            break;
        }

        // comment/mark the default action chunk, if any, so we can simply observe
        // what is user code and what is generated by us in the final product:
        if (default_action.length > 0) {
            var flags = [
                rhs.length,
                self.actionsUseValueTracking ? "VT" : "-",
                self.actionsUseValueAssignment ? "VA" : "-",
                uses_$$ ? "VU" : "-",
                uses_$$_before_assignment ? "VUbA" : "-",
                self.actionsUseLocationTracking ? "LT" : "-",
                self.actionsUseLocationAssignment ? "LA" : "-",
                uses_$loc ? "LU" : "-",
                uses_$loc_before_assignment ? "LUbA" : "-",
            ].join(',');

            default_action.unshift(`// default action (generated by JISON mode ${self.options.defaultActionMode[0]}/${self.options.defaultActionMode[1]} :: ${flags}):`);
            default_action.push(`// END of default action (generated by JISON mode ${self.options.defaultActionMode[0]}/${self.options.defaultActionMode[1]} :: ${flags})`);

            if (action.trim() !== '') {
                default_action.push('\n', action);
            }
            action = default_action.join('\n');
        }

        action = reindentCodeBlock(action, 4);

        var actionHash = mkHashIndex(action);

        // Delay running the postprocess (restore) process until we've done ALL macro expansions:
        //action = postprocessActionCode(action);

        if (actionHash in actionGroups) {
            actionGroups[actionHash].push(label);
        } else {
            actionGroups[actionHash] = [label];
            actionGroupValue[actionHash] = action;
        }
    }
};



generator.createParser = function createParser() {
    throw new Error('Calling abstract method.');
};

generator.createLexer = function createLexer() {
    throw new Error('Calling abstract method.');
};

// no-op. implemented in debug mixin
generator.trace = function no_op_trace() { };

generator.warn = function warn() {
    var args = Array.prototype.slice.call(arguments, 0);
    Jison.print.call(null, args.join(''));
};

generator.error = function error(msg) {
    throw new Error(msg);
};

// Report a few things about the grammar:
//
// - unused rules
// - stats:
//   + production count     (-> parser table size indicator)
//   + state count          (-> parser table size indicator)
//
generator.reportGrammarInformation = function reportGrammarInformation() {
    if (this.unused_productions.length) {
        this.warn('\nUnused productions in your grammar:\n  ' + this.unused_productions.join('\n  ') + '\n\n');
    }

    if (!this.options.reportStats) {
        return;
    }

    // nonterminals = this.nonterminals,
    // operators = this.operators,
    // this.table
    // this.states
    // this.defaultActions
    // this.productions,
    // this.terms = {};
    // this.operators = {};
    // this.productions = [];
    // this.conflicts = 0;
    // this.new_conflicts_found_this_round = 0;
    // this.conflicting_states = [];
    // this.resolutions = [];
    // this.options = options;
    // this.parseParams = grammar.parseParams;
    // exportDest.parseTable = this.table;
    // exportDest.defaultParseActions = this.defaultActions;
    // exportDest.parseProductions = this.productions_;

    // TODO: the next bit of code is LR type specific: refactor into a
    //       LR specific mixin class later on, so that we can have another
    //       implementation/report for LL and PEG type grammars.

    var rows = 0, cols = 0;
    var colmarks = {};
    var i, j, len;

    for (i = 0, len = this.table.length; i < len; i++) {
        rows++;
        for (j in this.table[i]) {
            if (!colmarks[j]) {
                colmarks[j] = true;
                cols++;
            }
        }
    }
    var defrows = 0;
    var rowmarks = {};
    for (j in this.defaultActions) {
        if (!rowmarks[j]) {
            rowmarks[j] = true;
            defrows++;
        }
    }

    var ntc = 0;
    for (var nt in this.nonterminals) {
        ntc++;
    }

    if (devDebug > 3) Jison.print('LALR parse table: ', {
      table: this.table,
      defaultActions: this.defaultActions
    });

    this.warn('Number of productions in parser:........ ' + this.productions_.length);
    this.warn('Number of non-terminals in grammar:..... ' + ntc);
    this.warn('Number of states:....................... ' + this.states.size());
    this.warn('Number of rows (states) in table:....... ' + this.table.length);
    this.warn('Number of rows in table:................ ' + rows);
    this.warn('Number of columns in table:............. ' + cols);
    this.warn('Number of defaulted rows in table:...... ' + defrows);
    this.warn('Number of unresolvable conflicts:....... ' + this.conflicts);
    this.warn('\n');
};


// Generator debug mixin

var generatorDebug = {
    trace: function debug_trace() {
        if (typeof Jison !== 'undefined' && Jison.print) {
            Jison.print.apply(null, arguments);
        } else if (typeof print !== 'undefined') {
            print.apply(null, arguments);
        } else if (typeof console !== 'undefined' && console.log) {
            var args = Array.prototype.slice.call(arguments, 0);
            args.unshift('');           // prevent `%.` printf-style expansions; see https://nodejs.org/api/console.html#console_console_log_data_args
            console.log.apply(null, args);
        }
    },
    beforeprocessGrammar: function () {
        this.trace('Processing grammar.');
    },
    afteraugmentGrammar: function () {
        var trace = this.trace;
        trace('\nSymbols:\n');
        each(this.symbols, function (sym, i) {
            trace(sym + '(' + i + ')');
        });
        trace('\n');
    }
};



/*
 * Mixin for common behaviors of lookahead parsers
 */
var lookaheadMixin = {};

lookaheadMixin.computeLookaheads = function computeLookaheads() {
    if (this.DEBUG) {
        this.mix(lookaheadDebug); // mixin debug methods
    }

    this.computeLookaheads = function () {};
    this.nullableSets();
    this.firstSets();
    this.followSets();
};

lookaheadMixin.displayFollowSets = function displayFollowSets() {
    var self = this;
    var symfollowdbg = {};
    this.productions.forEach(function Follow_prod_forEach_debugOut(production, k) {
        var key = ['prod-', k, ':  ', production.symbol, ' := ', production.handle.join(' ')].join('');
        var flw = '[' + self.nonterminals[production.symbol].follows.join(']  [') + ']';
        if (!symfollowdbg[flw]) {
            symfollowdbg[flw] = {};
        }
        if (!symfollowdbg[flw][key]) {
            symfollowdbg[flw][key] = 1;
        } else {
            assert(0);
            symfollowdbg[flw][key]++;
        }
    });
    for (var l in symfollowdbg) {
        var lst = [];
        for (var k in symfollowdbg[l]) {
            lst.push(k);
        }
        self.trace('Symbol/Follows:\n   ', lst.join('\n    '), ' -->\n        ', l);
    }
};

// calculate follow sets based on first and nullable
lookaheadMixin.followSets = function followSets() {
    var productions = this.productions,
        nonterminals = this.nonterminals,
        self = this,
        cont = true,
        count = 0;

    // loop until no further changes have been made
    while (cont) {
        cont = false;
        count++;

        productions.forEach(function Follow_prod_forEach(production, k) {
            if (devDebug > 3) Jison.print('Symbol/Follows: ', 'round:' + count, 'prod:' + k, ':', production.symbol, ' --> ', nonterminals[production.symbol].follows.join(', '));

            // q is used in Simple LALR algorithm determine follows in context
            var q;
            var ctx = !!self.go_;

            for (var i = 0, t; (t = production.handle[i]); ++i) {
                if (!nonterminals[t]) continue;

                // for Simple LALR algorithm, self.go_ checks if
                if (ctx) {
                    q = self.go_(production.symbol, production.handle.slice(0, i));
                }
                var bool = (!ctx || q === self.nterms_[t]);
                var set;

                if (i === production.handle.length - 1 && bool) {
                    set = nonterminals[production.symbol].follows;
                } else {
                    var part = production.handle.slice(i + 1);

                    set = self.first(part);
                    if (self.nullable(part) && bool) {
                        assert(nonterminals[production.symbol].follows);
                        set.push.apply(set, nonterminals[production.symbol].follows);
                    }
                }
                var follows = nonterminals[t].follows;
                var oldcount = follows.length;
                follows = union(follows, set);
                if (oldcount !== follows.length) {
                    cont = true;
                }
                nonterminals[t].follows = follows;
            }
        });
    }

    if (devDebug || this.DEBUG) {
        this.displayFollowSets();
    }
};

// return the FIRST set of a symbol or series of symbols
lookaheadMixin.first = function first(symbol) {
    // epsilon
    if (symbol === '') {
        return [];
    // RHS
    } else if (symbol instanceof Array) {
        var firsts = [];
        for (var i = 0, t; (t = symbol[i]); ++i) {
            if (!this.nonterminals[t]) {
                if (firsts.indexOf(t) === -1) {
                    firsts.push(t);
                }
            } else {
                firsts = union(firsts, this.nonterminals[t].first);
            }
            if (!this.nullable(t))
                break;
        }
        return firsts;
    // terminal
    } else if (!this.nonterminals[symbol]) {
        return [symbol];
    // nonterminal
    } else {
        return this.nonterminals[symbol].first;
    }
};

// fixed-point calculation of FIRST sets
lookaheadMixin.firstSets = function firstSets() {
    var productions = this.productions,
        nonterminals = this.nonterminals,
        self = this,
        cont = true,
        symbol, firsts;

    // loop until no further changes have been made
    while (cont) {
        cont = false;

        productions.forEach(function FirstSets_forEach(production, k) {
            var firsts = self.first(production.handle);
            if (firsts.length !== production.first.length) {
                production.first = firsts;
                cont = true;
            }
        });

        for (symbol in nonterminals) {
            firsts = [];
            nonterminals[symbol].productions.forEach(function FirstSets_forEachNonTerm(production) {
                firsts = union(firsts, production.first);
            });
            if (firsts.length !== nonterminals[symbol].first.length) {
                nonterminals[symbol].first = firsts;
                cont = true;
            }
        }
    }
};

// fixed-point calculation of NULLABLE
lookaheadMixin.nullableSets = function nullableSets() {
    var nonterminals = this.nonterminals,
        self = this,
        cont = true;

    // loop until no further changes have been made
    while (cont) {
        cont = false;

        // check if each production is nullable
        this.productions.forEach(function isEachProductionNullable(production, k) {
            if (!production.nullable) {
                for (var i = 0, n = 0, t; (t = production.handle[i]); ++i) {
                    if (self.nullable(t)) n++;
                }
                if (n === i) { // production is nullable if all tokens are nullable
                    production.nullable = cont = true;
                }
            }
        });

        // check if each symbol is nullable
        for (var symbol in nonterminals) {
            if (!this.nullable(symbol)) {
                for (var i = 0, production; (production = nonterminals[symbol].productions.item(i)); i++) {
                    if (production.nullable) {
                        nonterminals[symbol].nullable = cont = true;
                    }
                }
            }
        }
    }
};

// check if a token or series of tokens is nullable
lookaheadMixin.nullable = function nullable(symbol) {
    // epsilon
    if (symbol === '') {
        return true;
    // RHS
    } else if (symbol instanceof Array) {
        for (var i = 0, t; (t = symbol[i]); ++i) {
            if (!this.nullable(t)) {
                return false;
            }
        }
        return true;
    // terminal
    } else if (!this.nonterminals[symbol]) {
        return false;
    // nonterminal
    } else {
        return this.nonterminals[symbol].nullable;
    }
};


// lookahead debug mixin
var lookaheadDebug = {
    beforenullableSets: function () {
        this.trace('Computing Nullable sets.');
    },
    beforefirstSets: function () {
        this.trace('Computing First sets.');
    },
    beforefollowSets: function () {
        this.trace('Computing Follow sets.');
    },
    afterfollowSets: function () {
        var trace = this.trace;
        trace('\nNonterminals:\n');
        each(this.nonterminals, function (nt, t) {
            trace(nt.toString(), '\n');
        });
        trace('\n');
    }
};

/*
 * Mixin for common LR parser behavior
 */
var lrGeneratorMixin = {};


// LR state machine actions:
const NONASSOC = 0;
const SHIFT = 1; // shift
const REDUCE = 2; // reduce
const ACCEPT = 3; // accept


lrGeneratorMixin.buildTable = function buildTable() {
    if (this.DEBUG) {
        this.mix(lrGeneratorDebug); // mixin debug methods
    }

    this.states = this.canonicalCollection();

    if (devDebug || this.DEBUG) {
        Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER canonicalCollection:');
        this.displayFollowSets();
        Jison.print('\n');
    }

    this.table = this.parseTable(this.states);

    if (devDebug || this.DEBUG) {
        Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable:');
        this.displayFollowSets();
        Jison.print('\n');
    }

    this.defaultActions = findDefaults(this.table, this.hasErrorRecovery);
    cleanupTable(this.table);

    traceStates(this.trace, this.states, 'at the end of LR::buildTable(), after cleanupTable()');
};

lrGeneratorMixin.Item = typal.construct({
    constructor: function Item(production, dotPosition, followSet, predecessor) {
        this.production = production;
        this.dotPosition = dotPosition || 0;
        this.follows = followSet || [];
        this.predecessor = predecessor;
        this.id = production.id + '#' + this.dotPosition;
        this.markedSymbol = this.production.handle[this.dotPosition];
    },
    remainingHandle: function () {
        return this.production.handle.slice(this.dotPosition + 1);
    },
    eq: function (e) {
        return e.id === this.id;
    },
    handleToString: function () {
        var handle = this.production.handle.slice(0);
        handle[this.dotPosition] = '.' + (handle[this.dotPosition] || '');
        return handle.join(' ');
    },
    toString: function () {
        var temp = this.production.handle.slice(0);
        temp[this.dotPosition] = '.' + (temp[this.dotPosition] || '');
        var s = this.production.symbol + ' -> ' + temp.join(' ');
        var padlen = Math.max(4, 40 - s.length);
        var pad = new Array(padlen);
        if (this.follows.length) {
            s += pad.join(' ') + '#lookaheads= [' + this.follows.join(']  [') + ']';
            pad = new Array(2);
        }
        if (this.reductions && this.reductions.length) {
            s += pad.join(' ') + '#reductions= [' + this.reductions.join(']  [') + ']';
            pad = new Array(2);
        }
        return s;
    }
});

lrGeneratorMixin.ItemSet = Set.prototype.construct({
    afterconstructor: function () {
        this.reductions = [];
        this.goes = {};
        this.edges = {};
        this.shifts = false;
        this.inadequate = false;
        this.hash_ = {};
        for (var i = this._items.length - 1; i >= 0; i--) {
            this.hash_[this._items[i].id] = true; //i;
        }
    },
    concat: function concat(set) {
        var a = set._items || set;
        for (var i = a.length - 1; i >= 0; i--) {
            this.hash_[a[i].id] = true;
        }
        this._items.push.apply(this._items, a);
        return this;
    },
    push: function (item) {
        this.hash_[item.id] = true;
        return this._items.push(item);
    },
    contains: function (item) {
        return this.hash_[item.id];
    },
    valueOf: function toValue() {
        var v = this._items.map(function (a) { return a.id; }).sort().join('|');
        this.valueOf = function valueOf_inner() { return v; };
        return v;
    }
});

lrGeneratorMixin.closureOperation = function closureOperation(itemSet) {
    var closureSet = new this.ItemSet();
    var self = this;

    var set = itemSet,
        itemQueue,
        syms = {};

    do {
        itemQueue = new Set();
        closureSet = closureSet.concat(set);
        set.forEach(function CO_set_forEach(item) {
            var symbol = item.markedSymbol;

            // if token is a non-terminal, recursively add closures
            if (symbol && self.nonterminals[symbol]) {
                if (!syms[symbol]) {
                    self.nonterminals[symbol].productions.forEach(function CO_nt_forEach(production) {
                        var newItem = new self.Item(production, 0);
                        if (!closureSet.contains(newItem)) {
                            itemQueue.push(newItem);
                        }
                    });
                    syms[symbol] = true;
                }
            } else if (!symbol) {
                // reduction
                closureSet.reductions.push(item);
                closureSet.inadequate = (closureSet.reductions.length > 1 || closureSet.shifts);
            } else {
                // shift
                closureSet.shifts = true;
                closureSet.inadequate = closureSet.reductions.length > 0;
            }
        });

        set = itemQueue;
    } while (!itemQueue.isEmpty());

    return closureSet;
};

lrGeneratorMixin.gotoOperation = function gotoOperation(itemSet, symbol) {
    var gotoSet = new this.ItemSet(),
        self = this;

    itemSet.forEach(function goto_forEach(item, n) {
        if (item.markedSymbol === symbol) {
            gotoSet.push(new self.Item(item.production, item.dotPosition + 1, item.follows, n));
        }
    });

    return gotoSet;
};

/*
 * Create unique set of item sets
 */
lrGeneratorMixin.canonicalCollection = function canonicalCollection() {
    var item1 = new this.Item(this.productions[0], 0, [this.EOF]);
    var firstStateNoClosure = new this.ItemSet(item1),
        firstState = this.closureOperation(firstStateNoClosure),
        states = new Set(firstState),
        marked = 0,
        self = this,
        itemSet,
        markedSymbols;

    states.has = {};
    states.has[firstStateNoClosure.valueOf()] = 0;

    if (devDebug > 0) Jison.print('canonicalCollection: ', states.has);

    while (marked !== states.size()) {
        itemSet = states.item(marked);
        markedSymbols = {};
        itemSet.forEach(function CC_itemSet_forEach(item) {
            if (item.markedSymbol && !markedSymbols[item.markedSymbol] && item.markedSymbol !== self.EOF) {
                markedSymbols[item.markedSymbol] = true;
                self.canonicalCollectionInsert(item.markedSymbol, itemSet, states, marked);
            }
        });
        marked++;
    }

    return states;
};

// Pushes a unique state into the queue. Some parsing algorithms may perform additional operations
lrGeneratorMixin.canonicalCollectionInsert = function canonicalCollectionInsert(symbol, itemSet, states, stateNum) {
    var g = this.gotoOperation(itemSet, symbol),
        state = states.has[g.valueOf()];

    if (typeof state !== 'undefined') {
        itemSet.edges[symbol] = state;       // store goto transition for table
        states.item(state).predecessors[symbol].push(stateNum);
    } else {
        // add g to queue if not empty or duplicate
        if (!g.isEmpty()) {
            states.has[g.valueOf()] = states.size();
            g = this.closureOperation(g);
            if (!g.predecessors) {
                g.predecessors = {};
            }
            itemSet.edges[symbol] = states.size();  // store goto transition for table
            states.push(g);
            g.predecessors[symbol] = [stateNum];
        }
    }
};

lrGeneratorMixin.parseTable = function lrParseTable(itemSets) {
    var states = [],
        nonterminals = this.nonterminals,
        operators = this.operators,
        conflictedStates = {}, // set of [state, token] tuples
        self = this;

    // for each item set
    itemSets.forEach(function parseTableItem(itemSet, k) {
        k = +k;
        var state = states[k] = {};
        var action, stackSymbol;

        // set shift and goto actions
        for (stackSymbol in itemSet.edges) {
            itemSet.forEach(function findShiftAndGotoActions(item, j) {
                // find shift and goto actions
                if (item.markedSymbol === stackSymbol) {
                    var gotoState = itemSet.edges[stackSymbol];
                    assert(gotoState);
                    if (nonterminals[stackSymbol]) {
                        // store state to go to after a reduce
                        state[self.symbols_[stackSymbol]] = gotoState;
                    } else {
                        state[self.symbols_[stackSymbol]] = [SHIFT, gotoState];
                    }
                }
            });
        }

        // set accept action
        itemSet.forEach(function setAcceptAction(item, j) {
            if (item.markedSymbol === self.EOF) {
                // accept
                state[self.symbols_[self.EOF]] = [ACCEPT];
            }
        });

        var allterms = self.lookAheads ? false : self.terminals;

        // set reductions and resolve potential conflicts
        itemSet.reductions.forEach(function calcReduction(item, j) {
            // if parser uses lookahead, only enumerate those terminals
            var terminals = allterms || self.lookAheads(itemSet, item);

            terminals.forEach(function (stackSymbol) {
                action = state[self.symbols_[stackSymbol]];
                var op = operators[stackSymbol];

                // Reading a terminal and current position is at the end of a production, try to reduce
                if (action) {
                    var sol = resolveConflict(item.production, op, [REDUCE, item.production.id], action[0] instanceof Array ? action[0] : action);
                    self.resolutions.push([k, stackSymbol, sol]);
                    if (sol.bydefault) {
                        self.conflicts++;

                        if (self.conflict_fixing_round && self.options.hasPartialLrUpgradeOnConflict) {
                            // have we encountered a *new* conflict, compared to previous rounds?
                            if (!self.conflict_productions_LU[item.production.id]) {
                                self.new_conflicts_found_this_round++;
                                // and we RESET the `conflict_fixing_round` flag to signal that
                                // this round needs another one to attempt a *complete* fix
                                // of the grammar.
                                //
                                // This little act also conveniently helps to manage the
                                // *finity* of the big parsetable production loop, which
                                // wraps around all this work (and more).
                                self.conflict_fixing_round = false;
                                if (self.enableDebugLogs) {
                                    self.warn('RESET conflict fixing: we need another round to see us through...');
                                }
                            }
                        }
                        if (!self.conflict_fixing_round && self.options.hasPartialLrUpgradeOnConflict) {
                            self.conflict_productions_LU[item.production.id] = true;
                            self.conflict_states_LU[k] = true;

                            if (devDebug > 4) Jison.print('Registering conflict: ', {
                                prod_id: item.production.id,
                                stateNum: k,
                                state: state,
                                production: item.production
                            });
                        }

                        if (self.enableDebugLogs) {
                            self.warn('Conflict in grammar: multiple actions possible when lookahead token is ', stackSymbol, ' in state ', k, '\n- ', printAction(sol.r, self), '\n- ', printAction(sol.s, self), '\n  (', sol.msg, ')');
                        }
                        conflictedStates[k] = {
                            reduction: item,
                            symbol: stackSymbol,
                            resolution: sol,
                            state: k
                        };

                        if (self.options.noDefaultResolve) {
                            if (!(action[0] instanceof Array)) {
                                action = [action];
                            }
                            action.push(sol.r);
                        }
                    } else {
                        action = sol.action;
                    }
                } else {
                    action = [REDUCE, item.production.id];
                }
                if (action && action.length) {
                    state[self.symbols_[stackSymbol]] = action;
                } else if (action === NONASSOC) {
                    state[self.symbols_[stackSymbol]] = NONASSOC;
                    // ^- Can't delete this node right away as it will influence
                    // `findDefaults()` decision-making process adversely when this state is
                    // not visible at that time. Hence we defer cleanup to the function
                    // `cleanupTable()` which will be invoked at the very end: the NONASSOC
                    // transition signals a transition into an ERROR state and we don't care
                    // for the explicit zero(0) to be present in our table as anything
                    // 'falsey' as an action code will be considered an error state in
                    // the parser and not having these zeroes around keeps the table small(er).
                }
            });
        });
    });

    self.conflicting_states = conflictedStates;

    if (self.conflicts > 0) {
        if (this.numExpectedConflictStates !== self.conflicts || self.enableDebugLogs) {
            self.warn('\nStates with conflicts:');
            each(conflictedStates, function report_conflict_state(val, state) {
                self.warn('\nState ' + state, '    (' + val.symbol + ' @ ' + val.reduction.production.symbol + ' -> ' + val.reduction.handleToString() + ')\n');
                self.warn('  ', itemSets.item(state).join('\n  '));
            });
            self.warn('\n');
        }
    }

    return states;
};

// find states with only one action: a reduction.
//
// Note: only the state columns for EOF/ERROR/terminals are relevant here as those
// columns are the only ones ever visited by the table lookup code at the top
// of the loop in the parse kernel as the `symbol` index used there cannot ever
// contain a *nonterminal* value!
//
// The nonterminals are recognizable in the table by having numeric entries, rather
// than 1-or-2-element array values, as they only store a GOTO state.
//
// ---
//
// Another 'default' is when all listed terminals all point to the exact same reduce state;
// only this time we are careful about the TERROR symbol as a state carrying that one
// is an explicitly encoded error recovery rule and should remain as-is.
function findDefaults(states, hasErrorRecovery) {
    var defaults = {};
    states.forEach(function (state, k) {
        var act, sym, st;
        var i = 0;
        var gotos = {};

        for (sym in state) {
            assert({}.hasOwnProperty.call(state, sym));    // it this isn't true, the last part of this function won't work!
            // keep state rows where there's an error recovery state:
            if (sym === 2 /* TERROR */) {
                return;
            }
            st = state[sym];
            if (typeof st !== 'number') {
                if (st[0] !== REDUCE) {
                    // not a reduce action: forget about this row!
                    return;
                }
                var go = st[1];
                if (!gotos[go]) {
                    gotos[go] = true;
                    i++;
                    act = sym;
                }
            } else if (st === NONASSOC) {
                // forget about this row: it's a state where we should kick up an error
                // because you're trying to get associativity going where there is none!
                return;
            }
        }

        if (i === 1) {
            // only one action in state and it's a reduction; hence we only need to store the new (goto production) state:
            defaults[k] = state[act][1];

            // ... and nuke the entry/entries in the parse table to save space in the generated output: we won't be needing
            // it any more! But make sure we keep the slots for the nonterminal symbols, so only nuke the *terminal* entries!
            //
            // Aber Oh-ho! The table[] entries themselves *are* used: they are needed by
            // the error recovery code to decide, when SHIFTING, if the ERROR token would
            // improve (fix) matters when it is treated as an *inserted* token.  This code
            // is therefor not executed then!
            //
            // ... hence we only nuke these table entries (as that makes for a smaller table --> smaller parser file)
            // when there's no error recovery code included in the generated parser:
            if (!hasErrorRecovery) {
                for (sym in state) {
                    st = state[sym];
                    if (typeof st !== 'number') {
                        delete state[sym];
                    }
                }
            }
        }
    });

    return defaults;
}

// Remove all NONASSOC state transitions from the generated table now that we don't need them any longer
function cleanupTable(table) {
    table.forEach(function (state, k) {
        var symbol;

        for (symbol in state) {
            if (state[symbol] === NONASSOC) {
                delete state[symbol];
            }
        }
    });
}

// resolves shift-reduce and reduce-reduce conflicts
function resolveConflict(production, op, reduce, shift) {
    var sln = {
            production: production,
            operator: op,
            r: reduce,
            s: shift,

            msg: null,
            action: null,
            bydefault: false
        };

    if (shift[0] === REDUCE) {
        sln.msg = 'Resolved R/R conflict: use first production declared in grammar.';
        sln.action = shift[1] < reduce[1] ? shift : reduce;
        if (shift[1] !== reduce[1]) sln.bydefault = true;
        return sln;
    }

    if (production.precedence === 0 || !op) {
        sln.msg = 'Resolved S/R conflict: shift by default.';
        sln.bydefault = true;
        sln.action = shift;
    } else if (production.precedence < op.precedence) {
        sln.msg = 'Resolved S/R conflict: shift for higher precedent operator.';
        sln.action = shift;
    } else if (production.precedence === op.precedence) {
        if (op.assoc === 'right') {
            sln.msg = 'Resolved S/R conflict: shift for right associative operator.';
            sln.action = shift;
        } else if (op.assoc === 'left') {
            sln.msg = 'Resolved S/R conflict: reduce for left associative operator.';
            sln.action = reduce;
        } else if (op.assoc === 'nonassoc') {
            sln.msg = 'Resolved S/R conflict: no action for non-associative operator.';
            sln.action = NONASSOC;
        }
    } else {
        sln.msg = 'Resolved conflict: reduce for higher precedent production.';
        sln.action = reduce;
    }

    return sln;
}

/*
 * Mixin for common LR/LL/*any* parser behavior
 */
var generatorMixin = {};

// internal helper function:
generatorMixin.__prepareOptions = function parser___prepare_Options(opt) {
    opt = mkStdOptions(this.options, opt);

    prepExportStructures(opt);

    this.options = opt;
    this.DEBUG = !!opt.debug;
    if (devDebug > 3) {
        Jison.print('GENERATE::OPTIONS:\n', this.options);
    }

    // check for illegal identifier
    if (!opt.moduleName || !opt.moduleName.match(/^[a-zA-Z_$][a-zA-Z0-9_$\.]*?[a-zA-Z0-9_$]$/)) {
        if (opt.moduleName) {
            var msg = 'WARNING: The specified moduleName "' + opt.moduleName + '" is illegal (only characters [a-zA-Z0-9_$] and "." dot are accepted); using the default moduleName "parser" instead.';
            if (typeof opt.warn_cb === 'function') {
                opt.warn_cb(msg);
            } else if (opt.warn_cb) {
                Jison.print(msg);
            } else {
                // do not treat as warning; barf hairball instead so that this oddity gets noticed right away!
                throw new Error(msg);
            }
        }
        opt.moduleName = opt.defaultModuleName;
    }
    return opt;
};

generatorMixin.generateGenericHeaderComment = function generateGenericHeaderComment() {
    var out = `
/* parser generated by jison ${version$1} */

/*
 * Returns a Parser object of the following structure:
 *
 *  Parser: {
 *    yy: {}     The so-called "shared state" or rather the *source* of it;
 *               the real "shared state" \`yy\` passed around to
 *               the rule actions, etc. is a derivative/copy of this one,
 *               not a direct reference!
 *  }
 *
 *  Parser.prototype: {
 *    yy: {},
 *    EOF: 1,
 *    TERROR: 2,
 *
 *    trace: function(errorMessage, ...),
 *
 *    JisonParserError: function(msg, hash),
 *
 *    quoteName: function(name),
 *               Helper function which can be overridden by user code later on: put suitable
 *               quotes around literal IDs in a description string.
 *
 *    originalQuoteName: function(name),
 *               The basic quoteName handler provided by JISON.
 *               \`cleanupAfterParse()\` will clean up and reset \`quoteName()\` to reference this function
 *               at the end of the \`parse()\`.
 *
 *    describeSymbol: function(symbol),
 *               Return a more-or-less human-readable description of the given symbol, when
 *               available, or the symbol itself, serving as its own 'description' for lack
 *               of something better to serve up.
 *
 *               Return NULL when the symbol is unknown to the parser.
 *
 *    symbols_: {associative list: name ==> number},
 *    terminals_: {associative list: number ==> name},
 *    nonterminals: {associative list: rule-name ==> {associative list: number ==> rule-alt}},
 *    terminal_descriptions_: (if there are any) {associative list: number ==> description},
 *    productions_: [...],
 *
 *    performAction: function parser__performAction(yytext, yyleng, yylineno, yyloc, yystate, yysp, yyvstack, yylstack, yystack, yysstack),
 *
 *               The function parameters and \`this\` have the following value/meaning:
 *               - \`this\`    : reference to the \`yyval\` internal object, which has members (\`$\` and \`_$\`)
 *                             to store/reference the rule value \`$$\` and location info \`@$\`.
 *
 *                 One important thing to note about \`this\` a.k.a. \`yyval\`: every *reduce* action gets
 *                 to see the same object via the \`this\` reference, i.e. if you wish to carry custom
 *                 data from one reduce action through to the next within a single parse run, then you
 *                 may get nasty and use \`yyval\` a.k.a. \`this\` for storing you own semi-permanent data.
 *
 *                 \`this.yy\` is a direct reference to the \`yy\` shared state object.
 *
 *                 \`%parse-param\`-specified additional \`parse()\` arguments have been added to this \`yy\`
 *                 object at \`parse()\` start and are therefore available to the action code via the
 *                 same named \`yy.xxxx\` attributes (where \`xxxx\` represents a identifier name from
 *                 the \%parse-param\` list.
 *
 *               - \`yytext\`  : reference to the lexer value which belongs to the last lexer token used
 *                             to match this rule. This is *not* the look-ahead token, but the last token
 *                             that's actually part of this rule.
 *
 *                 Formulated another way, \`yytext\` is the value of the token immediately preceeding
 *                 the current look-ahead token.
 *                 Caveats apply for rules which don't require look-ahead, such as epsilon rules.
 *
 *               - \`yyleng\`  : ditto as \`yytext\`, only now for the lexer.yyleng value.
 *
 *               - \`yylineno\`: ditto as \`yytext\`, only now for the lexer.yylineno value.
 *
 *               - \`yyloc\`   : ditto as \`yytext\`, only now for the lexer.yylloc lexer token location info.
 *
 *                               WARNING: since jison 0.4.18-186 this entry may be NULL/UNDEFINED instead
 *                               of an empty object when no suitable location info can be provided.
 *
 *               - \`yystate\` : the current parser state number, used internally for dispatching and
 *                               executing the action code chunk matching the rule currently being reduced.
 *
 *               - \`yysp\`    : the current state stack position (a.k.a. 'stack pointer')
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *                 Also note that you can access this and other stack index values using the new double-hash
 *                 syntax, i.e. \`##$ === ##0 === yysp\`, while \`##1\` is the stack index for all things
 *                 related to the first rule term, just like you have \`$1\`, \`@1\` and \`#1\`.
 *                 This is made available to write very advanced grammar action rules, e.g. when you want
 *                 to investigate the parse state stack in your action code, which would, for example,
 *                 be relevant when you wish to implement error diagnostics and reporting schemes similar
 *                 to the work described here:
 *
 *                 + Pottier, F., 2016. Reachability and error diagnosis in LR(1) automata.
 *                   In Journées Francophones des Languages Applicatifs.
 *
 *                 + Jeffery, C.L., 2003. Generating LR syntax error messages from examples.
 *                   ACM Transactions on Programming Languages and Systems (TOPLAS), 25(5), pp.631–640.
 *
 *               - \`yyrulelength\`: the current rule's term count, i.e. the number of entries occupied on the stack.
 *
 *                 This one comes in handy when you are going to do advanced things to the parser
 *                 stacks, all of which are accessible from your action code (see the next entries below).
 *
 *               - \`yyvstack\`: reference to the parser value stack. Also accessed via the \`$1\` etc.
 *                             constructs.
 *
 *               - \`yylstack\`: reference to the parser token location stack. Also accessed via
 *                             the \`@1\` etc. constructs.
 *
 *                             WARNING: since jison 0.4.18-186 this array MAY contain slots which are
 *                             UNDEFINED rather than an empty (location) object, when the lexer/parser
 *                             action code did not provide a suitable location info object when such a
 *                             slot was filled!
 *
 *               - \`yystack\` : reference to the parser token id stack. Also accessed via the
 *                             \`#1\` etc. constructs.
 *
 *                 Note: this is a bit of a **white lie** as we can statically decode any \`#n\` reference to
 *                 its numeric token id value, hence that code wouldn't need the \`yystack\` but *you* might
 *                 want access this array for your own purposes, such as error analysis as mentioned above!
 *
 *                 Note that this stack stores the current stack of *tokens*, that is the sequence of
 *                 already parsed=reduced *nonterminals* (tokens representing rules) and *terminals*
 *                 (lexer tokens *shifted* onto the stack until the rule they belong to is found and
 *                 *reduced*.
 *
 *               - \`yysstack\`: reference to the parser state stack. This one carries the internal parser
 *                             *states* such as the one in \`yystate\`, which are used to represent
 *                             the parser state machine in the *parse table*. *Very* *internal* stuff,
 *                             what can I say? If you access this one, you're clearly doing wicked things
 *
 *               - \`...\`     : the extra arguments you specified in the \`%parse-param\` statement in your
 *                             grammar definition file.
 *
 *    table: [...],
 *               State transition table
 *               ----------------------
 *
 *               index levels are:
 *               - \`state\`  --> hash table
 *               - \`symbol\` --> action (number or array)
 *
 *                 If the \`action\` is an array, these are the elements' meaning:
 *                 - index [0]: 1 = shift, 2 = reduce, 3 = accept
 *                 - index [1]: GOTO \`state\`
 *
 *                 If the \`action\` is a number, it is the GOTO \`state\`
 *
 *    defaultActions: {...},
 *
 *    parseError: function(str, hash, ExceptionClass),
 *    yyError: function(str, ...),
 *    yyRecovering: function(),
 *    yyErrOk: function(),
 *    yyClearIn: function(),
 *
 *    constructParseErrorInfo: function(error_message, exception_object, expected_token_set, is_recoverable),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               Produces a new errorInfo 'hash object' which can be passed into \`parseError()\`.
 *               See it's use in this parser kernel in many places; example usage:
 *
 *                   var infoObj = parser.constructParseErrorInfo('fail!', null,
 *                                     parser.collect_expected_token_set(state), true);
 *                   var retVal = parser.parseError(infoObj.errStr, infoObj, parser.JisonParserError);
 *
 *    originalParseError: function(str, hash, ExceptionClass),
 *               The basic \`parseError\` handler provided by JISON.
 *               \`cleanupAfterParse()\` will clean up and reset \`parseError()\` to reference this function
 *               at the end of the \`parse()\`.
 *
 *    options: { ... parser %options ... },
 *
 *    parse: function(input[, args...]),
 *               Parse the given \`input\` and return the parsed value (or \`true\` when none was provided by
 *               the root action, in which case the parser is acting as a *matcher*).
 *               You MAY use the additional \`args...\` parameters as per \`%parse-param\` spec of this grammar:
 *               these extra \`args...\` are added verbatim to the \`yy\` object reference as member variables.
 *
 *               WARNING:
 *               Parser's additional \`args...\` parameters (via \`%parse-param\`) MAY conflict with
 *               any attributes already added to \`yy\` by the jison run-time;
 *               when such a collision is detected an exception is thrown to prevent the generated run-time
 *               from silently accepting this confusing and potentially hazardous situation!
 *
 *               The lexer MAY add its own set of additional parameters (via the \`%parse-param\` line in
 *               the lexer section of the grammar spec): these will be inserted in the \`yy\` shared state
 *               object and any collision with those will be reported by the lexer via a thrown exception.
 *
 *    cleanupAfterParse: function(resultValue, invoke_post_methods, do_not_nuke_errorinfos),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               This helper API is invoked at the end of the \`parse()\` call, unless an exception was thrown
 *               and \`%options no-try-catch\` has been defined for this grammar: in that case this helper MAY
 *               be invoked by calling user code to ensure the \`post_parse\` callbacks are invoked and
 *               the internal parser gets properly garbage collected under these particular circumstances.
 *
 *    yyMergeLocationInfo: function(first_index, last_index, first_yylloc, last_yylloc, dont_look_back),
 *               Helper function **which will be set up during the first invocation of the \`parse()\` method**.
 *               This helper API can be invoked to calculate a spanning \`yylloc\` location info object.
 *
 *               Note: %epsilon rules MAY specify no \`first_index\` and \`first_yylloc\`, in which case
 *               this function will attempt to obtain a suitable location marker by inspecting the location stack
 *               backwards.
 *
 *               For more info see the documentation comment further below, immediately above this function's
 *               implementation.
 *
 *    lexer: {
 *        yy: {...},           A reference to the so-called "shared state" \`yy\` once
 *                             received via a call to the \`.setInput(input, yy)\` lexer API.
 *        EOF: 1,
 *        ERROR: 2,
 *        JisonLexerError: function(msg, hash),
 *        parseError: function(str, hash, ExceptionClass),
 *        setInput: function(input, [yy]),
 *        input: function(),
 *        unput: function(str),
 *        more: function(),
 *        reject: function(),
 *        less: function(n),
 *        pastInput: function(n),
 *        upcomingInput: function(n),
 *        showPosition: function(),
 *        test_match: function(regex_match_array, rule_index, ...),
 *        next: function(...),
 *        lex: function(...),
 *        begin: function(condition),
 *        pushState: function(condition),
 *        popState: function(),
 *        topState: function(),
 *        _currentRules: function(),
 *        stateStackSize: function(),
 *        cleanupAfterLex: function()
 *
 *        options: { ... lexer %options ... },
 *
 *        performAction: function(yy, yy_, $avoiding_name_collisions, YY_START, ...),
 *        rules: [...],
 *        conditions: {associative list: name ==> set},
 *    }
 *  }
 *
 *
 *  token location info (@$, _$, etc.): {
 *    first_line: n,
 *    last_line: n,
 *    first_column: n,
 *    last_column: n,
 *    range: [start_number, end_number]
 *               (where the numbers are indexes into the input string, zero-based)
 *  }
 *
 * ---
 *
 * The \`parseError\` function receives a 'hash' object with these members for lexer and
 * parser errors:
 *
 *  {
 *    text:        (matched text)
 *    token:       (the produced terminal token, if any)
 *    token_id:    (the produced terminal token numeric ID, if any)
 *    line:        (yylineno)
 *    loc:         (yylloc)
 *  }
 *
 * parser (grammar) errors will also provide these additional members:
 *
 *  {
 *    expected:    (array describing the set of expected tokens;
 *                  may be UNDEFINED when we cannot easily produce such a set)
 *    state:       (integer (or array when the table includes grammar collisions);
 *                  represents the current internal state of the parser kernel.
 *                  can, for example, be used to pass to the \`collect_expected_token_set()\`
 *                  API to obtain the expected token set)
 *    action:      (integer; represents the current internal action which will be executed)
 *    new_state:   (integer; represents the next/planned internal state, once the current
 *                  action has executed)
 *    recoverable: (boolean: TRUE when the parser MAY have an error recovery rule
 *                  available for this particular error)
 *    state_stack: (array: the current parser LALR/LR internal state stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    value_stack: (array: the current parser LALR/LR internal \`$$\` value stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    location_stack: (array: the current parser LALR/LR internal location stack; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    yy:          (object: the current parser internal "shared state" \`yy\`
 *                  as is also available in the rule actions; this can be used,
 *                  for instance, for advanced error analysis and reporting)
 *    lexer:       (reference to the current lexer instance used by the parser)
 *    parser:      (reference to the current parser instance)
 *  }
 *
 * while \`this\` will reference the current parser instance.
 *
 * When \`parseError\` is invoked by the lexer, \`this\` will still reference the related *parser*
 * instance, while these additional \`hash\` fields will also be provided:
 *
 *  {
 *    lexer:       (reference to the current lexer instance which reported the error)
 *  }
 *
 * When \`parseError\` is invoked by the parser due to a **JavaScript exception** being fired
 * from either the parser or lexer, \`this\` will still reference the related *parser*
 * instance, while these additional \`hash\` fields will also be provided:
 *
 *  {
 *    exception:   (reference to the exception thrown)
 *  }
 *
 * Please do note that in the latter situation, the \`expected\` field will be omitted as
 * this type of failure is assumed not to be due to *parse errors* but rather due to user
 * action code in either parser or lexer failing unexpectedly.
 *
 * ---
 *
 * You can specify parser options by setting / modifying the \`.yy\` object of your Parser instance.
 * These options are available:
 *
 * ### options which are global for all parser instances
 *
 *  Parser.pre_parse: function(yy)
 *                 optional: you can specify a pre_parse() function in the chunk following
 *                 the grammar, i.e. after the last \`%%\`.
 *  Parser.post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: you can specify a post_parse() function in the chunk following
 *                 the grammar, i.e. after the last \`%%\`. When it does not return any value,
 *                 the parser will return the original \`retval\`.
 *
 * ### options which can be set up per parser instance
 *
 *  yy: {
 *      pre_parse:  function(yy)
 *                 optional: is invoked before the parse cycle starts (and before the first
 *                 invocation of \`lex()\`) but immediately after the invocation of
 *                 \`parser.pre_parse()\`).
 *      post_parse: function(yy, retval, parseInfo) { return retval; }
 *                 optional: is invoked when the parse terminates due to success ('accept')
 *                 or failure (even when exceptions are thrown).
 *                 \`retval\` contains the return value to be produced by \`Parser.parse()\`;
 *                 this function can override the return value by returning another.
 *                 When it does not return any value, the parser will return the original
 *                 \`retval\`.
 *                 This function is invoked immediately before \`parser.post_parse()\`.
 *
 *      parseError: function(str, hash, ExceptionClass)
 *                 optional: overrides the default \`parseError\` function.
 *      quoteName: function(name),
 *                 optional: overrides the default \`quoteName\` function.
 *  }
 *
 *  parser.lexer.options: {
 *      pre_lex:  function()
 *                 optional: is invoked before the lexer is invoked to produce another token.
 *                 \`this\` refers to the Lexer object.
 *      post_lex: function(token) { return token; }
 *                 optional: is invoked when the lexer has produced a token \`token\`;
 *                 this function can override the returned token value by returning another.
 *                 When it does not return any (truthy) value, the lexer will return
 *                 the original \`token\`.
 *                 \`this\` refers to the Lexer object.
 *
 *      ranges: boolean
 *                 optional: \`true\` ==> token location info will include a .range[] member.
 *      flex: boolean
 *                 optional: \`true\` ==> flex-like lexing behaviour where the rules are tested
 *                 exhaustively to find the longest match.
 *      backtrack_lexer: boolean
 *                 optional: \`true\` ==> lexer regexes are tested in order and for invoked;
 *                 the lexer terminates the scan when a token is returned by the action code.
 *      xregexp: boolean
 *                 optional: \`true\` ==> lexer rule regexes are "extended regex format" requiring the
 *                 \`XRegExp\` library. When this \`%option\` has not been specified at compile time, all lexer
 *                 rule regexes have been written as standard JavaScript RegExp expressions.
 *  }
 */
`;

    return out;
};

generatorMixin.generate = function parser_generate(opt) {
    opt = this.__prepareOptions(opt);

    var code = '';

    switch (opt.moduleType) {
    case 'js':
        code = this.generateModule(opt);
        break;
    case 'amd':
        code = this.generateAMDModule(opt);
        break;
    case 'es':
        code = this.generateESModule(opt);
        break;
    case 'commonjs':
        code = this.generateCommonJSModule(opt);
        break;
    default:
        throw new Error('unsupported moduleType: ' + opt.moduleType);
    }

    return code;
};


generatorMixin.generateAMDModule = function generateAMDModule(opt) {
    opt = this.__prepareOptions(opt);

    var module = this.generateModule_();
    var out = [
        this.generateGenericHeaderComment(),
        '',
        'define(function (require) {',
        module.initCode,
        module.commonCode,
        '',
        'var parser = ' + module.moduleCode,
        module.modulePostlude
    ];
    if (this.lexer && this.lexer.generateModule) {
        var lexSrc = this.lexer.generateModule();
        opt.exportSourceCode.lexer = lexSrc;
        out.push(lexSrc);
        out.push('parser.lexer = lexer;');
    }
    out.push('', module.moduleInclude, '', 'return parser;');
    out.push('});');

    var src = out.join('\n') + '\n';
    opt.exportSourceCode.all = src;
    return src;
};

lrGeneratorMixin.generateESModule = function generateESModule(opt) {
    opt = this.__prepareOptions(opt);

    var module = this.generateModule_();
    var out = [
        this.generateGenericHeaderComment(),
        '',
        module.initCode,
        module.commonCode,
        '',
        'var parser = ' + module.moduleCode,
        module.modulePostlude,
    ];
    if (this.lexer && this.lexer.generateModule) {
        var lexSrc = this.lexer.generateModule();
        opt.exportSourceCode.lexer = lexSrc;
        out.push(this.lexer.generateModule());
        out.push('parser.lexer = lexer;');
    }
    out.push('', module.moduleInclude, '');

    var exportMain = '';
    var invokeMain = '';
    if (!opt.noMain) {
        var moduleNameAsCode = String(opt.moduleMain || commonjsMain);
        var moduleImportsAsCode = String(opt.moduleMainImports || commonjsMainImports);

        out.push(rmCommonWS$1`

            ${moduleImportsAsCode}

            var yymain = ${moduleNameAsCode.trim()};

            function yyExecMain() {
              yymain(process.argv.slice(1));
            }
        `);
        exportMain = 'main: yyExecMain,';
        invokeMain = rmCommonWS$1`
            // IFF this is the main module executed by NodeJS,
            // then run 'main()' immediately:
            if (typeof module !== 'undefined' && require.main === module) {
              yyExecMain();
            }
        `;
    }
    out.push(rmCommonWS$1`
        function Parser() {
            this.yy = {};
        }
        Parser.prototype = parser;
        parser.Parser = Parser;

        function yyparse() {
            return parser.parse.apply(parser, arguments);
        }

        ${invokeMain}

        export default {
            parser,
            Parser,
            parse: yyparse,
            ${exportMain}
        };
    `);

    var src = out.join('\n') + '\n';
    opt.exportSourceCode.all = src;
    return src;
};

generatorMixin.generateCommonJSModule = function generateCommonJSModule(opt) {
    opt = this.__prepareOptions(opt);

    var moduleName = opt.moduleName;
    var main = '';
    if (!opt.noMain) {
        var moduleNameAsCode = String(opt.moduleMain || commonjsMain);
        var moduleImportsAsCode = String(opt.moduleMainImports || commonjsMainImports);

        main = rmCommonWS$1`

            ${moduleImportsAsCode}

            exports.main = ${moduleNameAsCode.trim()};

            // IFF this is the main module executed by NodeJS,
            // then run 'main()' immediately:
            if (typeof module !== 'undefined' && require.main === module) {
              exports.main(process.argv.slice(1));
            }
        `;
    }
    var out = this.generateModule(opt) +
        rmCommonWS$1`


        if (typeof require !== 'undefined' && typeof exports !== 'undefined') {
          exports.parser = ${moduleName};
          exports.Parser = ${moduleName}.Parser;
          exports.parse = function () {
            return ${moduleName}.parse.apply(${moduleName}, arguments);
          };
          ${main}
        }
        `;

    opt.exportSourceCode.all = out;
    return out;
};

generatorMixin.generateModule = function generateModule(opt) {
    opt = this.__prepareOptions(opt);

    var moduleName = opt.moduleName;
    var out = this.generateGenericHeaderComment();

    var self = this;
    function _generateNamespace(namespaces, previousNamespace, callback) {
        var subModuleName = namespaces.shift();
        if (subModuleName != null) {
            var moduleName = previousNamespace == null ? subModuleName : previousNamespace + '.' + subModuleName;
            if (namespaces.length > 0) {
                return 'var ' + subModuleName + ';\n'
                    + '(function (' + subModuleName + ') {\n'
                    + _generateNamespace(namespaces, subModuleName, callback)
                    + '\n})(' + subModuleName + (previousNamespace == null ? '' : ' = ' + moduleName) + ' || (' + moduleName + ' = {}));\n';
            }
            return callback(moduleName);
        }
        return '';
    }

    var sourceCodeDef = self.generateModuleExpr();

    out += `
        ${sourceCodeDef.init}
    `;

    out += _generateNamespace(moduleName.split('.'), null, function _generateNamespace_cb(moduleName) {
        var name = (moduleName.match(/\./) ? moduleName : 'var ' + moduleName);
        return `
            ${name} = ${sourceCodeDef.src}
        `;
    });

    opt.exportSourceCode.all = out;
    return out;
};


generatorMixin.generateModuleExpr = function generateModuleExpr() {
    var out;
    var opt = this.__prepareOptions();
    var module = this.generateModule_();

    out = [
        '(function () {',
        module.commonCode,
        '',
        'var parser = ' + module.moduleCode,
        module.modulePostlude,
    ];
    if (this.lexer && this.lexer.generateModule) {
        var lexSrc = this.lexer.generateModule();
        opt.exportSourceCode.lexer = lexSrc;
        out.push(lexSrc);
        out.push('parser.lexer = lexer;');
    }
    out = out.concat(['',
        module.moduleInclude,
        '',
        'function Parser() {',
        '  this.yy = {};',
        '}',
        'Parser.prototype = parser;',
        'parser.Parser = Parser;',
        '',
        'return new Parser();',
        '})();'
    ]);

    var src = out.join('\n') + '\n';
    opt.exportSourceCode.all = src;

    return {
        src,
        init: module.initCode
    };
};

function removeUnusedKernelFeatures(parseFn, info) {
    var actionFn = info.performAction;

    if (info.actionsAreAllDefault) {
        // in this case, there's no need to call the parseAction function at all:
        // it is functionally empty anyway.
        actionFn = '';

        // remove:
        //
        //     r = this.performAction.call(yyval, ...);
        //
        //     if (typeof r !== 'undefined') {
        //         retval = r;
        //         break;
        //     }
        //

        parseFn = parseFn
        .replace(/\s+r = this\.performAction\.call[^)]+\)\;/g, '')
        .replace(/\s+if \(typeof r !== 'undefined'\) \{[^}]+\}/g, '');
    }

    if (!info.actionsUseYYTEXT) {
        // Wait with this bit of cleanup until the very end to help keep the
        // other cleanup/optimization options below that much simpler to code:
        parseFn = parseFn
        .replace(/, yytext\b/g, '')
        .replace(/^.*?\bvar yytext\b.*?$/gm, '')
        .replace(/^.*[^.]\byytext = .+$/gm, '')
        .replace(/^.+ = yytext\b.+$/gm, '');
    }

    if (!info.actionsUseYYLENG) {
        actionFn = actionFn
        .replace(/, yyleng\b/g, '');

        // remove:
        //
        //     if (typeof lexer.yyleng === 'undefined') {
        //       lexer.yyleng = 0;
        //     }
        //     var yyleng;
        //     ...

        parseFn = parseFn
        .replace(/, yyleng\b/g, '')
        .replace(/^.*?\bvar yyleng\b.*?$/gm, '')
        .replace(/\s+if\b.*?\.yyleng\b.*?\{[^}]+\}/g, '\n')
        .replace(/^.*?\byyleng = .+$/gm, '')
        .replace(/^.*?\byyleng\b.*?=.*?\byyleng\b.*?$/gm, '');
    }

    if (!info.actionsUseYYLINENO) {
        // The error handling code inside the kernel still uses this one, but only straight off the lexer
        // so we can kill the local var and its usage at least:
        actionFn = actionFn
        .replace(/, yylineno\b/g, '');

        // remove:
        //
        //     var yylineno;
        //     ...

        parseFn = parseFn
        .replace(/\bvar yylineno\b.*?$/gm, '')
        .replace(/, yylineno\b/g, '')
        .replace(/^.*?\byylineno\b.*?=.*?\byylineno\b.*?$/gm, '');
    }

    if (!info.actionsUseYYSTACK) {
        actionFn = actionFn
        .replace(/, yystack\b/g, '');

        parseFn = parseFn
        .replace(/, stack\b/g, '');
    }

    if (!info.actionsUseYYSSTACK) {
        actionFn = actionFn
        .replace(/, yysstack\b/g, '');

        parseFn = parseFn
        .replace(/, sstack\b/g, '');
    }

    if (!info.actionsUseYYRULELENGTH) {
        actionFn = actionFn
        .replace(/, yyrulelength\b/g, '');

        parseFn = parseFn
        .replace(/, yyrulelen\b/g, '');
    }

    if (!info.actionsUseYYSTACKPOINTER) {
        actionFn = actionFn
        .replace(/, yysp\b/g, '');

        parseFn = parseFn
        .replace(/, sp - 1\b/g, '');
    }

    if (!info.actionsUseYYMERGELOCATIONINFO) {
        // remove the entire function plus all leading comment:
        parseFn = parseFn
        .replace(/\n.*?merge yylloc info into a new yylloc instance[^]*?\bthis\.yyMergeLocationInfo\b[^]*?\};[^]*?\n/g, (new Array(134)).join('\n'))
        // also remove its invocation in the error recovery code:
        .replace(/\n.*?\bthis\.yyMergeLocationInfo\b[^\n]+\n/g, '\n');
    }

    if (!info.actionsUseLocationTracking) {
        actionFn = actionFn
        .replace(/\byyloc, (.*?), yylstack\b/g, '$1');

        // remove:
        //
        //    var yyloc = lexer.yylloc;
        //    lstack[sp] = yyloc;
        //    ...
        //        lstack[sp] = copy_yylloc(lexer.yylloc);
        //    ...

        parseFn = parseFn
        .replace(/\byyloc, (.*?), lstack\b/g, '$1')
        .replace(/\s+yyval\._\$\s*=\s*.+$/gm, '\n')
        .replace(/^.*?\blstack\b.*$/gm, '')
        .replace(/^.*?\byyloc\b.*?$/gm, '')
        .replace(/^.*?\byylloc\b.*?$/gm, '')
        .replace(/^\s*_\$:\s+undefined\s*$/gm, '')
        .replace(/\s+function\s+copy_yylloc\b[^]*?return\s+rv[^}]+\}/g, '')
        .replace(/^.*?\bcopy_yylloc\b.*?$/gm, '')
        .replace(/^.*?\blocation_stack\b.*?$/gm, '')
        ;
    }

    if (!info.actionsUseValueTracking) {
        actionFn = actionFn
        .replace(/, yyvstack\b/g, '');

        parseFn = parseFn
        .replace(/, vstack\b/g, '');

        // also nuke all `yyval`-related code as we know, when this set of
        // features is set, that the grammar doesn't produce any value:
        // we are looking at a *matcher*, rather than a *parser*!
        //
        // remove
        //
        //     // Return the `$accept` rule's `$$` result, if available.
        //     // ...
        //     sp--;
        //     if (typeof vstack[sp] !== 'undefined') {
        //         retval = vstack[sp];
        //     }
        //
        // and
        // 
        //     if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
        //         retval = vstack[sp];
        //     }
        // 
        // but keep the yyval declaration as either location tracking MAY
        // still be employed by the grammar OR the grammar uses advanced
        // code which uses `yyval` as a run-time store which carries data
        // across multiple reduction calls to `performAction`, as per
        // the suggestion in the document comment for the grammar:
        //
        // >
        // > One important thing to note about `this` a.k.a. `yyval`: ...
        // >
        parseFn = parseFn
        .replace(/\s+\/\/ Return the \`\$accept\` rule's \`\$\$\` result[\s\S]+?if \((?:sp\b.*?)?typeof vstack\[sp\] !== 'undefined'\)[^\}]+\}[^\n]*\n/g, '\n\n\n\n\n\n');

        // kill all vstack entries which would be copied into the
        // error recovery `value_stack`:
        //
        //     recoveringErrorInfo.value_stack[esp] = ...
        //
        //     if (errStr) {
        //         recoveringErrorInfo.value_stack[esp] = {
        //             ...
        //         };
        //         ...
        //     } else {
        //         recoveringErrorInfo.value_stack[esp] = {
        //             ...
        //         };
        //     }
        //
        //     rv.value_stack = ...
        //
        parseFn = parseFn
        .replace(/[^\n]+if \(errStr\) \{\s*\n.*?\.value_stack\b[^]*?\};[^]*?\} else \{\s*\n.*?\.value_stack\b[^]*?\};[^}]*\}[^\n]*\n/g, '\n\n\n\n\n\n\n\n\n\n\n\n')
        .replace(/[^\n]+\.value_stack\b[^n]*\n/g, '\n');

        // kill *all* value tracking when there's also no *implicit* `$$ = ...` action any more:

        // remove all lines using `vstack[xyz...]` ...
        parseFn = parseFn
        .replace(/^.*?\bvstack\b.*$/gm, '');

        // When there's no `performAction()` call at all, then
        // the `yyval` declaration can safely be discarded as well.
        if (info.actionsAreAllDefault) {
            // remove
            //
            //     var yyval = {
            //         $: true,
            //         _$: undefined,
            //         yy: sharedState_yy
            //     };
            parseFn = parseFn
            .replace(/\s+var yyval =[\s\S]+?\};[^\n]*\n/g, '\n\n\n\n\n\n');
        }
    }

    if (!info.DEBUG) {
        // When 'debug mode' hasn't been turned on during parser generation,
        // then we don't allow it at all: this gives us faster production parsers.
        //
        // When you want debug output at parse run-time, then you MUST produce a parser
        // with either the
        //     %debug
        // option set or by invoking JISON with the debug flag `-t`.

        // remove:
        //
        //     var yydebug = false;
        //     ... and delete yydebug function definition ...
        //     ...
        //     if (yydebug) yydebug(...);
        //
        // and
        //
        //     // disable debugging at run-time ANYWAY when you've *explicitly* set "yy.yydebug = false":
        //     if (sharedState_yy.yydebug === false) {
        //         yydebug = undefined;
        //     }


        parseFn = parseFn
        .replace(/\s+var yydebug = [\s\S]+?self\.trace[\s\S]+?};[^}]+}/g, '\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n')
        // strip multi-line `if (debug) yydebug(..., {...});` statements
        // also strip simple yet possibly multi-line `if (debug) yydebug('...');` statements
        .replace(/\n\s+if\s+\(yydebug\)\s+yydebug\([^]+?['}]\);[^\r\n]*?/g, '\n\n\n\n\n\n\n\n\n')
        // strip single-line `yydebug(...);` statements
        .replace(/^.*?\byydebug\b[^;]+?\);[^\r\n]*?$/gm, '')
        // strip `if (sharedState_yy.yydebug) {...}` chunk
        .replace(/\n\s+\/\/\s*disable\s*debugging.*?[\r\n]+\s+if\s+\(sharedState_yy\.yydebug[^]+?\}/g, '\n\n\n\n');
    }

    if (!info.actionsUseYYERROK && !info.actionsUseYYRECOVERING && !info.actionsUseYYCLEARIN && !info.actionsUseYYERROR) {
        /*
         * Kill long multi-line comment about yyerror + YYRECOVERING + yyerrok + yyclearin before this code:
         *
         *       if (this.yyError) {
         *           ...
         */
        parseFn = parseFn
        .replace(/\s+\/\/.*setup `yyError`, `YYRECOVERING`, `yyErrOk` and `yyClearIn` functions[^\0]+?\n\s+if \(/g, '\n\n\n\n\n  if (');
    }

    if (!info.actionsUseYYERROR) {
        /*
         * Kill this code:
         *
         *       if (this.yyError) {
         *           this.yyError = function yyError(str) {
         *               ...
         *           };
         *       }
         */
        parseFn = parseFn
        .replace(/\s+if \(this\.yyError\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
    }

    if (!info.actionsUseYYRECOVERING) {
        /*
         * Kill this code:
         *
         *       if (this.yyRecovering) {
         *           this.yyRecovering = function yyRecovering() {
         *               return recovering;
         *           };
         *       }
         */
        parseFn = parseFn
        .replace(/\s+if \(this\.yyRecovering\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
    }

    if (!info.actionsUseYYERROK) {
        /*
         * Kill this code:
         *
         *       if (this.yyErrOk) {
         *           this.yyErrOk = function yyErrOk() {
         *               recovering = 0;
         *           };
         *       }
         */
        parseFn = parseFn
        .replace(/\s+if \(this\.yyErrOk\) \{[^\0]+?\};\n\s+\}\n/g, '\n\n\n\n\n');
    }

    if (!info.actionsUseYYCLEARIN) {
        parseFn = parseFn
        .replace(/\s+if \(this\.yyClearIn\) \{[^\0]+?[^{]\};\n\s+\}\n/g, '\n\n\n\n\n\n');
    }

    if (info.options.noTryCatch) {
        /*
         * Kill this code:
         *
         *     try {
         *         this.__reentrant_call_depth++;
         *         ... keep all this stuff ...
         *     } catch (ex) {
         *         ... remove this stuff ...
         *     } finally {
         *         retval = this.cleanupAfterParse(retval, true, true);       // <-- keep this line
         *     } // /finally
         *
         * and also remove any re-entrant parse() call support:
         *
         *     ... __reentrant_call_depth ...
         */
        parseFn = parseFn
        .replace(/\s+try \{([\s\r\n]+this\.__reentrant_call_depth[\s\S]+?)\} catch \(ex\) \{[\s\S]+?\} finally \{([^]+?)\}\s+\/\/\s+\/finally/, function replace_noTryCatch(m, p1, p2) {
            p1 = p1.replace(/^        /mg, '    ');
            p2 = p2.replace(/^        /mg, '    ');
            return '\n' + p1 + '\n    // ... AND FINALLY ...\n' + p2;
        })
        .replace(/^[^\n]+\b__reentrant_call_depth\b[^\n]+$/gm, '\n');
    }

    if (!info.actionsUseYYTEXT) {
        // See the comment for the same section near the start of this function:
        //
        // Wait with this bit of cleanup until the very end to help keep the
        // other cleanup/optimization options below that much simpler to code:
        actionFn = actionFn
        .replace(/\(\byytext\b(,\s*)?/g, '(');
    }


    // When we're done feature stripping, we can clean up any lingering
    // internals, which would otherwise go unused:
    if (!analyzeFeatureUsage(parseFn, /\bshallowCopyErrorInfo\b/g, 1)) {
        // Remove:
        //
        //     // clone some parts of the (possibly enhanced!) errorInfo object
        //     // to give them some persistence.
        //     this.shallowCopyErrorInfo = function ...(p) {
        //         ...
        //         return rv;
        //     }
        //
        parseFn = parseFn
        .replace(/\n[^\n]*?clone some parts of the[^\n]*?errorInfo object[^]*?\bshallowCopyErrorInfo\b[^]*?return rv;[^}]*\};[^\n]*/g, '\n\n\n\n\n\n\n\n\n\n\n');
    }
    if (!analyzeFeatureUsage(parseFn, /\bshallow_copy\b/g, 1)) {
        // Remove:
        //
        //     // shallow clone objects, straight copy of simple `src` values
        //     // ...
        //     function shallow_copy(...) {
        //         ...
        //         return src;
        //     }
        //
        parseFn = parseFn
        .replace(/\n[^\n]*?shallow clone objects, straight copy[^]*?\bshallow_copy\b[^]*?return src;[^}]*\}[^\n]*/g, '\n\n\n\n\n\n');
    }


    info.performAction = actionFn;

    return parseFn;
}

// Fill in the optional, extra parse parameters (`%parse-param ...`)
// in the generated parser.
//
// See for important context:
//
//     https://github.com/zaach/jison/pull/332
function expandParseArguments(parseFn, self) {
    var arglist = self.parseParams;

    if (!arglist || arglist.length === 0) {
        parseFn = parseFn.replace(/, parseParams\b/g, '');
        parseFn = parseFn.replace(/\bparseParams\b/g, '');
        parseFn = parseFn.replace(/,\s*[\r\n]+\s*parseParamsAsMembers:\s+parseParamsAsMembers\b/g, '');
    } else {
        parseFn = parseFn.replace(/, parseParams\b/g, ', ' + arglist.join(', '));
        parseFn = parseFn.replace(/\bparseParams\b/g, arglist.join(', '));
        parseFn = parseFn.replace(/,\s*[\r\n]+(\s*)parseParamsAsMembers:\s+parseParamsAsMembers\b/g, function parseParamsReplF(m, ws) {
            var s = ',';

            // determine longest name of the bunch (for formatting the generated code)
            var max_k_len = 0;
            for (var i = 0, len = arglist.length; i < len; i++) {
                var k = arglist[i];
                max_k_len = Math.max(max_k_len, k.length);
            }
            var wsi2 = (new Array(max_k_len + 1)).join(' ');

            // generate the member assignment list for the `sharedState_yy` object which will store the `parseParams` for everyone to access
            for (var i = 0, len = arglist.length; i < len; i++) {
                var k = arglist[i];
                s += '\n' + ws + k + ': ' + k + (i < len - 1 ? ',' + wsi2.substr(0, max_k_len - k.length - 1) : wsi2.substr(0, max_k_len - k.length)) + '  // parseParams::' + k;
            }
            return s;
        });
    }
    return parseFn;
}


function expandConstantsInGeneratedCode(src, self) {
    // expand the error recovery 'combine rule' action constant in the generated code
    src = src
    .replace(/\bYY_ERROR_RECOVERY_COMBINE_ID\b/g, '' + self.table.length)
    // the next 'constant' has explicit `\n` newlines included for protection:
    // it should only occur in *one* place in the *entire* code stream.
    .replace(/\nYY_REMAINING_INIT_CODE_SECTIONS_GO_HERE\n/g, self.moduleInit.getRemainingInitCodeSections().join('\n'));

    return src;
}


function pickOneOfTwoCodeAlternatives(parseFn, pick_A_not_B, A_start_marker, B_start_marker, end_marker) {
    // Notes:
    // 1) we use the special /[^\0]*/ regex set as that one will also munch newlines, etc.
    //    while the obvious /.*/ does not as '.' doesn't eat the newlines.
    return parseFn.replace(new RegExp('(' + A_start_marker + '[^\\n]*\\n)([^\\0]*?)(' + B_start_marker + '[^\\n]*\\n)([^\\0]*?)(' + end_marker + '[^\\n]*\\n)', 'g'), function pick_code_alt(str, mA, cA, mB, cB, mE) {
        if (pick_A_not_B) {
            return cA;
        }
        return cB;
    });
}

function addOrRemoveTokenStack(fn, wantTokenStack) {
    var parseFn = fn;
    // We don't use the Esprima+Escodegen toolchain as those loose the code comments easily;
    // instead we just chop the code using labels as sentinels for our chopping-it-up regexes:
    //
    // if (wantTokenStack) {
    //     try {
    //         var ast = esprima.parse(parseFn);
    //         var stackAst = esprima.parse(String(tokenStackLex)).body[0];
    //         stackAst.id.name = 'lex';
    //
    //         var labeled = JSONSelect.match(':has(:root > .label > .name:val("_token_stack"))', ast);
    //
    //         labeled[0].body = stackAst;
    //
    //         return escodegen.generate(ast);
    //     } catch (e) {
    //         return parseFn;
    //     }
    // } else {
    //     // remove the line:
    //     // var tstack = []; // token stack
    //     parseFn = parseFn.replace(/tstack = .*$/m, '');
    //     return parseFn;
    // }
    parseFn = pickOneOfTwoCodeAlternatives(parseFn, !wantTokenStack, '//_lexer_without_token_stack:', '//_lexer_with_token_stack:', '//_lexer_with_token_stack_end:');
    // and some post-coital touch-ups:
    if (wantTokenStack) {
        // And rename the `tokenStackLex` function to become the new `lex`:
        return parseFn.replace(/\btokenStackLex\b/g, 'lex');
    } else {
        // Also nuke the support declaration statement:
        //     var tstack = [];
        return parseFn.replace(/^.*?\btstack\b.*$/gm, '');
    }
}

// returns parse function with/without error recovery code
function pickErrorHandlingChunk(fn, hasErrorRecovery) {
    var parseFn = fn;

    // We don't use the Esprima+Escodegen toolchain as those loose the code comments easily;
    // instead we just chop the code using labels as sentinels for our chopping-it-up regexes:
    // try {
    //     var ast = esprima.parse(parseFn);

    //     var labeled = JSONSelect.match(':has(:root > .label > .name:val("' +
    //         (!hasErrorRecovery ? '_handle_error_with_recovery' : '_handle_error_no_recovery') +
    //         '"))', ast);
    //     Jison.print('labeled: ', labeled);
    //     assert(labeled[0].body.type === 'IfStatement');
    //     labeled[0].body.type = 'DebuggerStatement';
    //     Jison.print('patched::labeled: ', labeled);

    //     return escodegen.generate(ast);
    // } catch (e) {
    //     return parseFn;
    // }
    parseFn = pickOneOfTwoCodeAlternatives(parseFn, hasErrorRecovery, '//_handle_error_with_recovery:', '//_handle_error_no_recovery:', '//_handle_error_end_of_section:');
    // and some post-coital touch-ups:
    if (!hasErrorRecovery) {
        // Also nuke the support declaration statement:
        //          var recovering = 0;
        // and the recovery support statements:
        //          if (recovering > 0) {
        //              recovering--;
        //          }
        // and these yydebug particles:
        //          , recovering: recovering
        //          ASSERT(recovering === 0);
        parseFn = parseFn
        .replace(/^\s*var recovering.*$/gm, '')
        .replace(/, recovering: recovering/g, '')
        .replace(/^.*?recovering =.*$/gm, '')
        .replace(/^\s+recovering[,]?\s*$/gm, '')
        .replace(/[ \t]*if \(recovering[^\)]+\) \{[^\0]+?\}\n/g, '\n\n\n\n\n')
        // And nuke the preErrorSymbol code as it is unused when there's no error recovery
        //        if (!preErrorSymbol) {
        //            ... keep this chunk ...
        //        } else {
        //            ... KILL this chunk ...
        //        }
        .replace(/\s+if[^a-z]+preErrorSymbol.*?\{\s*\/\/[^\n]+([\s\S]+?)\} else \{[\s\S]+?\}\n\s+\}\n/g, '\n$1\n\n\n\n')
        .replace(/^\s+(?:var )?preErrorSymbol = .*$/gm, '')
        .replace(/^.*?\bpreErrorSymbol =.*$/gm, '')
        // And nuke the support declaration statement:
        //         var lastEofErrorStateDepth = 0;
        .replace(/^\s*var lastEofErrorStateDepth.*$/gm, '');
    }
    return parseFn;
}

// Generates the code of the parser module, which consists of two parts:
// - module.commonCode: initialization code that should be placed before the module
// - module.moduleCode: code that creates the module object
lrGeneratorMixin.generateModule_ = function generateModule_() {
    var parseFn = String(parser.parse);
    parseFn = pickErrorHandlingChunk(parseFn, this.hasErrorRecovery);

    parseFn = addOrRemoveTokenStack(parseFn, this.options.tokenStack);

    parseFn = removeUnusedKernelFeatures(parseFn, this);

    parseFn = expandParseArguments(parseFn, this);

    var errorClassCode = this.generateErrorClass();

    var exportDest = this.options.exportAllTables;
    assert(exportDest);

    // store the parse tables:
    exportDest.parseTable = this.table;
    exportDest.defaultParseActions = this.defaultActions;
    exportDest.parseProductions = this.productions_;

    var exportSourceCode = this.options.exportSourceCode;
    assert(exportSourceCode);

    var tableCode;
    switch (this.options.compressTables | 0) {
    case 0: // no compression
        tableCode = this.generateTableCode0(this.table, this.defaultActions, this.productions_);
        break;

    default:
    case 1: // default: vanilla JISON table compression = run-length encoding
        tableCode = this.generateTableCode1(this.table, this.defaultActions, this.productions_);
        break;

    case 2: // column-mode compression
        // this compression method corrupts the table when this option is turned on (and one or more conflicts occur)
        if (this.options.noDefaultResolve && this.conflicts > 0) {
            tableCode = this.generateTableCode1(this.table, this.defaultActions, this.productions_);
        } else {
            tableCode = this.generateTableCode2(this.table, this.defaultActions, this.productions_);
        }
        break;
    }

    // Generate the initialization code

    var initCode = [].concat(
        this.moduleInit.getInitCodeSection('imports'),
        this.moduleInit.getInitCodeSection('init')
    );

    var commonCode = [].concat(
        this.moduleInit.getInitCodeSection('required'),
        errorClassCode.commonCode,
        errorClassCode.moduleCode,
        ['\nYY_REMAINING_INIT_CODE_SECTIONS_GO_HERE\n'],
        tableCode.commonCode
    );



    // sort hash table by key to produce a nicer output:
    function produceSymbolTable(tbl) {
        var a = Object.keys(tbl);
        a.sort();
        var nt = {};
        var k;
        for (var i = 0, len = a.length; i < len; i++) {
            k = a[i];
            // `$eof` and `EOF` are synonyms of `$end` (`$eof` is for bison compatibility);
            // this is the only place where two symbol names may map to a single symbol ID number
            // and we do not want `$eof`/`EOF` to show up in the symbol tables of generated parsers
            // as we use `$end` for that one!
            if (k !== '$eof') {
                nt[k] = tbl[k];
            }
        }
        return nt;
    }

    // swap key and value and then sort hash table by key to produce a nicer output:
    function produceTerminalTable(tbl) {
        var a = Object.keys(tbl);
        var nt = {};
        var k, v;
        for (var i = 0, len = a.length; i < len; i++) {
            k = a[i];
            v = tbl[k];
            nt[v] = +k;  // convert numeric key back to number type; all terminals have numeric keys
        }
        return produceSymbolTable(nt);
    }

    function produceProductionsForDebugging(options, symbols, base) {
        function get_orig_symbol(s) {
            var a = s.split(':');
            if (a.length === 1 || a[0] === '') {
                return {
                    state: -1,
                    symbol: s
                };
            }
            var state = a[0];
            a.shift();
            return {
                state: +state,
                symbol: a.join(':'),
            };
        }
        function get_orig_symbol_set(arr) {
            var rv = {};
            for (var i = 0, len = arr.length; i < len; i++) {
                var item = arr[i];
                var symbol = get_orig_symbol(item);
                rv[symbol.symbol] = symbol.state;
            }
            return Object.keys(rv);
        }

        var tbl = this.nonterminals;
        var sym = this.symbols_ || symbols;

        if (!options.outputDebugTables && !options.exportAllTables.enabled) {
            return undefined;
        }

        var prods = {
            ids: {},
            states: {},
            rules: {},
            nonterminals: {},
            symbols: {},
            first: {},
            follows: {},
        };

        var self = this;
        this.productions.forEach(function Follow_prod_forEach_genDebugTable(production, k) {
            var nonterm = production.symbol;
            prods.states[k] = nonterm;
            prods.ids[nonterm] = sym[nonterm];

            var lst = prods.rules[nonterm] || {};
            lst[k] = gen_lalr_states_production(production, k, false, k, true);
            prods.rules[nonterm] = lst;
        });

        function gen_nonterminal(nt) {
            var l = nt.productions._items;
            var lst = l.map(function (p, i) {
                return gen_lalr_states_production(p, i, false, false, false);
            });
            var rv = {
                symbol: nt.symbol,
                productions: lst,
                first: nt.first,
                base_first: get_orig_symbol_set(nt.first),
                follows: nt.follows,
                base_follows: get_orig_symbol_set(nt.follows),
                nullable: nt.nullable,
            };

            // clean up structure: ditch superfluous elements:
            if (rv.base_first.join(' ') === rv.first.join(' ')) {
                delete rv.base_first;
            }
            if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                delete rv.base_follows;
            }

            return rv;
        }

        for (var key in tbl) {
            prods.nonterminals[key] = gen_nonterminal(tbl[key]);
        }

        if (this.nterms_) {
            prods.nterms_ = this.nterms_;
        }

        function gen_lalr_states_production(production, index, dotPosition, state, patch_base) {
            var nonterm = production.symbol;
            var hlen = production.handle.length;
            var rulestr = production.handle.map(function (t, idx) {
                if (!t) {
                    t = '%epsilon';
                }

                if (dotPosition === idx) {
                    t = '⬤' + t;
                }
                return t;
            }).join(' ');
            if (dotPosition === hlen) {
                rulestr += ' ⬤';
            }

            var base_rulestr = production.handle.map(function (t) {
                if (!t) {
                    t = '%epsilon';
                }
                t = get_orig_symbol(t).symbol;
                return t;
            }).join(' ');

            var rv = {
                symbol: nonterm,
                base_symbol: get_orig_symbol(nonterm).symbol,
                handle: rulestr,
                base_handle: base_rulestr,
                nullable: production.nullable,
                id: production.id,
                index: index,
                state: (state !== false ? state : -1),
                base_state: -1,
                first: production.first,
                base_first: get_orig_symbol_set(production.first),
                follows: production.follows,
                base_follows: get_orig_symbol_set(production.follows),
                precedence: production.precedence,
                reachable: production.reachable
            };

            // Determine state for given production, if it's not a production that's listed as part of a state:
            var chk, idx;
            var lst = prods.rules[nonterm];
            chk = rv.symbol + ' : ' + rv.handle;
            for (idx in lst) {
                idx = +idx;
                var p = lst[idx];
                if (p) {
                    if (p.symbol + ' : ' + p.handle === chk) {
                        assert(rv.state === -1);
                        rv.state = idx;
                        break;
                    }
                }
            }

            // Try to reference base productions from newg child productions and vice versa:
            chk = rv.base_symbol + ' : ' + rv.base_handle;
            if (base && base.rules) {
                var pr = base.rules[rv.base_symbol];
                for (idx in pr) {
                    var bprod = pr[idx];
                    if (bprod.symbol + ' : ' + bprod.handle === chk) {
                        assert(rv.base_state === -1);
                        rv.base_state = bprod.state;
                        if (patch_base) {
                            bprod.newg_states = (bprod.newg_states || []);
                            bprod.newg_states.push(rv.index);
                        }
                        break;
                    }
                }
            }

            // clean up structure: ditch superfluous elements:
            if (rv.base_symbol === rv.symbol) {
                delete rv.base_symbol;
            }
            if (rv.base_handle === rv.handle) {
                delete rv.base_handle;
            }
            if (rv.base_first.join(' ') === rv.first.join(' ')) {
                delete rv.base_first;
            }
            if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                delete rv.base_follows;
            }
            if (rv.base_state === -1) {
                delete rv.base_state;
            }
            return rv;
        }

        if (this.states) {
            prods.lalr_states = [];
            var these_states = this.states;
            these_states.forEach(function traverse_states(state, i) {
                //assert(state.inadequate ? these_states.inadequate : true);
                state.forEach(function traverse_state(item, j) {
                    // is this a REDUCE state?
                    var nterm_first = self.nonterminals[item.production.symbol].first;
                    var rv = {
                        state: i,
                        item_index: j,
                        is_reduce_state: (item.dotPosition === item.production.handle.length),
                        dot_position: item.dotPosition,
                        state_inadequate: state.inadequate ? true : undefined,
                        item_inadequate: item.inadequate ? true : undefined,
                        production: gen_lalr_states_production(item.production, j, item.dotPosition, i, true),
                        follows: item.follows,
                        base_follows: get_orig_symbol_set(item.follows),
                        nterm_first: nterm_first,
                        base_nterm_first: get_orig_symbol_set(nterm_first),
                        prod_first: item.production.first,
                        base_prod_first: get_orig_symbol_set(item.production.first),
                    };

                    // clean up structure: ditch superfluous elements:
                    if (rv.base_follows.join(' ') === rv.follows.join(' ')) {
                        delete rv.base_follows;
                    }
                    if (rv.base_nterm_first.join(' ') === rv.nterm_first.join(' ')) {
                        delete rv.base_nterm_first;
                    }
                    if (rv.base_prod_first.join(' ') === rv.prod_first.join(' ')) {
                        delete rv.base_prod_first;
                    }

                    prods.lalr_states.push(rv);
                });
            });
        }

        var nt = tbl;
        var sbn;
        for (sbn in nt) {
            var orig_symbol = get_orig_symbol(sbn);
            var item = nt[sbn];
            var firsts = item.first;
            var follows = item.follows;
            if (!prods.symbols[orig_symbol.symbol]) {
                prods.symbols[orig_symbol.symbol] = orig_symbol.state;
            }
            if (!prods.first[orig_symbol.symbol]) {
                prods.first[orig_symbol.symbol] = firsts;
            } else {
                prods.first[orig_symbol.symbol] = prods.first[orig_symbol.symbol].concat(firsts);
            }
            if (!prods.follows[orig_symbol.symbol]) {
                prods.follows[orig_symbol.symbol] = follows;
            } else {
                prods.follows[orig_symbol.symbol] = prods.follows[orig_symbol.symbol].concat(follows);
            }
        }
        for (sbn in prods.first) {
            prods.first[sbn] = get_orig_symbol_set(prods.first[sbn]);
        }
        for (sbn in prods.follows) {
            prods.follows[sbn] = get_orig_symbol_set(prods.follows[sbn]);
        }

        if (this.newg) {
            prods.newg = produceProductionsForDebugging.call(this.newg, options, sym, prods);
        }
        return prods;
    }

    function produceTerminalDescriptions(tbl, sym) {
        var rv = {};
        var count = 0;
        for (var k in tbl) {
            var descr = tbl[k];
            var id = sym[k];
            if (id && descr && descr !== id) {
                rv[id] = descr;
                count++;
            }
        }
        return (count ? rv : undefined);
    }

    function produceOptions(opts) {
        var obj = {};
        var do_not_pass = {
          type: 0,                   // CLI: --parserType option
          debug: !opts.debug,     // do not include this item when it is FALSE as there's no debug tracing built into the generated grammar anyway!
          enableDebugLogs: 1,
          numExpectedConflictStates: 1,
          dumpSourceCodeOnFailure: 1,
          throwErrorOnCompileFailure: 1,
          json: 1,
          _: 1,
          noMain: 1,
          moduleMain: 1,
          moduleMainImports: 1,
          noDefaultResolve: 1,
          defaultActionMode: 1,
          noTryCatch: 1,
          hasPartialLrUpgradeOnConflict: 0,
          compressTables: 1,
          outputDebugTables: 1,
          reportStats: 1,
          file: 1,
          outfile: 1,
          inputPath: 1,
          inputFilename: 1,
          lexfile: 1,
          defaultModuleName: 1,
          moduleName: 1,
          moduleType: 1,
          exportAllTables: 1,
          exportSourceCode: 1,
          tokenStack: 0,
          parserErrorsAreRecoverable: 0,
          lexerErrorsAreRecoverable: 1,
          showSource: 1,
          exportAST: 1,
          prettyCfg: 1,

          errorRecoveryTokenDiscardCount: 0,

          warn_cb: 0,  // function(msg) | true (= use Jison.Print) | false (= throw Exception)

          parseParams: 1,
          ranges: 0,
        };
        for (var k in opts) {
            if (!do_not_pass[k] && opts[k] != null && opts[k] !== false) {
                // make sure numeric values are encoded as numeric, the rest as boolean/string.
                if (typeof opts[k] === 'string') {
                    var f = parseFloat(opts[k]);
                    if (f == opts[k]) {
                        obj[k] = f;
                        continue;
                    }
                }
                obj[k] = opts[k];
            }
        }

        // And now some options which should receive some special processing:
        if (!obj.hasPartialLrUpgradeOnConflict) {
          // only list this option when it's actually TRUE:
          delete obj.hasPartialLrUpgradeOnConflict;
        }

        var pre = obj.pre_parse;
        var post = obj.post_parse;
        // since JSON cannot encode functions, we'll have to do it manually at run-time, i.e. later on:
        if (pre) {
            obj.pre_parse = true;
        }
        if (post) {
            obj.post_parse = true;
        }

        var js = JSON.stringify(obj, null, 2);

        js = js.replace(new XRegExp(`  "(${ID_REGEX_BASE})": `, 'g'), '  $1: ');
        js = js.replace(/^( +)pre_parse: true(,)?$/gm, function (m, ls, tc) {
            return ls + 'pre_parse: ' + String(pre) + (tc || '');
        });
        js = js.replace(/^( +)post_parse: true(,)?$/gm, function (m, ls, tc) {
            return ls + 'post_parse: ' + String(post) + (tc || '');
        });
        return js;
    }


    // Generate the module creation code
    var termDescrs = produceTerminalDescriptions(this.descriptions_, this.symbols_);
    exportDest.terminalDescriptions = termDescrs;
    var descrLst = JSON.stringify(termDescrs, null, 2);
    if (descrLst) {
        descrLst = descrLst.replace(/"([0-9]+)":/g, '$1:');
    }

    var rules4Dbg = produceProductionsForDebugging.call(this, this.options);
    exportDest.parseRules = rules4Dbg;
    var rulesLst = ((this.options.outputDebugTables || this.options.exportAllTables.enabled) ? JSON.stringify(rules4Dbg, null, 2) : undefined);
    if (rulesLst) {
        rulesLst = rulesLst.replace(/"([0-9]+)":/g, '$1:').replace(/^(\s+)"([a-z_][a-z_0-9]*)":/gmi, '$1$2:');
    }

    var symbolTable = produceSymbolTable(this.symbols_);
    exportDest.symbolTable = symbolTable;

    // produce a hash lookup table from the terminal set
    exportDest.terminalTable = produceTerminalTable(this.terminals_);

    var moduleCode = `{
    // Code Generator Information Report
    // ---------------------------------
    //
    // Options:
    //
    //   default action mode: ............. ${this.options.defaultActionMode.join(',')}
    //   try..catch: ...................... ${!this.options.noTryCatch}
    //   default resolve on conflict: ..... ${!this.options.noDefaultResolve}
    //   on-demand look-ahead: ............ ${this.onDemandLookahead}
    //   error recovery token skip maximum: ${this.options.errorRecoveryTokenDiscardCount}
    //   yyerror in parse actions is: ..... ${this.options.parserErrorsAreRecoverable ? 'recoverable' : 'NOT recoverable'},
    //   yyerror in lexer actions and other non-fatal lexer are:
    //   .................................. ${this.options.lexerErrorsAreRecoverable ? 'recoverable' : 'NOT recoverable'},
    //   debug grammar/output: ............ ${this.options.debug}
    //   has partial LR conflict upgrade:   ${this.options.hasPartialLrUpgradeOnConflict}
    //   rudimentary token-stack support:   ${this.options.tokenStack}
    //   parser table compression mode: ... ${this.options.compressTables}
    //   export debug tables: ............. ${this.options.outputDebugTables}
    //   export *all* tables: ............. ${this.options.exportAllTables.enabled}
    //   module type: ..................... ${this.options.moduleType}
    //   parser engine type: .............. ${this.options.type}
    //   output main() in the module: ..... ${this.options.noMain}
    //   has user-specified main(): ....... ${!!this.options.moduleMain}
    //   has user-specified require()/import modules for main():
    //   .................................. ${!!this.options.moduleMainImports}
    //   number of expected conflicts: .... ${this.options.numExpectedConflictStates}
    //
    //
    // Parser Analysis flags:
    //
    //   no significant actions (parser is a language matcher only):
    //   .................................. ${this.actionsAreAllDefault}
    //   uses yyleng: ..................... ${this.actionsUseYYLENG}
    //   uses yylineno: ................... ${this.actionsUseYYLINENO}
    //   uses yytext: ..................... ${this.actionsUseYYTEXT}
    //   uses yylloc: ..................... ${this.actionsUseYYLOC}
    //   uses ParseError API: ............. ${this.actionsUseParseError}
    //   uses YYERROR: .................... ${this.actionsUseYYERROR}
    //   uses YYRECOVERING: ............... ${this.actionsUseYYRECOVERING}
    //   uses YYERROK: .................... ${this.actionsUseYYERROK}
    //   uses YYCLEARIN: .................. ${this.actionsUseYYCLEARIN}
    //   tracks rule values: .............. ${this.actionsUseValueTracking}
    //   assigns rule values: ............. ${this.actionsUseValueAssignment}
    //   uses location tracking: .......... ${this.actionsUseLocationTracking}
    //   assigns location: ................ ${this.actionsUseLocationAssignment}
    //   uses yystack: .................... ${this.actionsUseYYSTACK}
    //   uses yysstack: ................... ${this.actionsUseYYSSTACK}
    //   uses yysp: ....................... ${this.actionsUseYYSTACKPOINTER}
    //   uses yyrulelength: ............... ${this.actionsUseYYRULELENGTH}
    //   uses yyMergeLocationInfo API: .... ${this.actionsUseYYMERGELOCATIONINFO}
    //   has error recovery: .............. ${this.hasErrorRecovery}
    //   has error reporting: ............. ${this.hasErrorReporting}
    //
    // --------- END OF REPORT -----------

`;
    moduleCode += [
        'trace: ' + String(this.trace || parser.trace),
        'JisonParserError: JisonParserError',
        'yy: {}',
        'options: ' + produceOptions(this.options),
        'symbols_: ' + JSON.stringify(symbolTable, null, 2),
        'terminals_: ' + JSON.stringify(this.terminals_, null, 2).replace(/"([0-9]+)":/g, '$1:'),
    ].concat(
        rulesLst ?
        'nonterminals_: ' + rulesLst :
        []
    ).concat(
        descrLst ?
        'terminal_descriptions_: ' + descrLst :
        []
    ).concat([
        String(define_parser_APIs_1)
            .replace(/^[\s\S]+?return \{/, '')
            .replace(/\};[s\r\n]+\}\s*$/, '')
            .replace(/^        /mg, '')
            .trim(),
        'productions_: ' + tableCode.productionsCode
    ]).concat(
        String(this.performAction).trim() !== '' ?
        'performAction: ' + String(this.performAction) :
        []
    ).concat([
        'table: ' + tableCode.tableCode,
        'defaultActions: ' + tableCode.defaultActionsCode,
        'parseError: ' + String(this.parseError || parseErrorSourceCode),
        'parse: ' + parseFn
    ]).concat(
        this.actionsUseYYERROR ?
        'yyError: 1' :
        []
    ).concat(
        this.actionsUseYYRECOVERING ?
        'yyRecovering: 1' :
        []
    ).concat(
        this.actionsUseYYERROK ?
        'yyErrOk: 1' :
        []
    ).concat(
        this.actionsUseYYCLEARIN ?
        'yyClearIn: 1' :
        []
    ).join(',\n');
    moduleCode += '\n};';

    var exportSourceCode = this.options.exportSourceCode;
    assert(exportSourceCode);
    exportSourceCode.parserChunks = {
        initCode: expandConstantsInGeneratedCode(initCode.join('\n'), this),
        commonCode: expandConstantsInGeneratedCode(commonCode.join('\n'), this),
        moduleCode: expandConstantsInGeneratedCode(moduleCode, this),
        modulePostlude: [
            'parser.originalParseError = parser.parseError;',
            'parser.originalQuoteName = parser.quoteName;',
            ].join('\n'),
        moduleInclude: expandConstantsInGeneratedCode(this.moduleInclude, this)
    };
    return exportSourceCode.parserChunks;
};

lrGeneratorMixin.generateErrorClass = function () {
    // --- START parser error class ---

var prelude = `// See also:
// http://stackoverflow.com/questions/1382107/whats-a-good-way-to-extend-error-in-javascript/#35881508
// but we keep the prototype.constructor and prototype.name assignment lines too for compatibility
// with userland code which might access the derived class in a 'classic' way.
function JisonParserError(msg, hash) {
    Object.defineProperty(this, 'name', {
        enumerable: false,
        writable: false,
        value: 'JisonParserError'
    });

    if (msg == null) msg = '???';

    Object.defineProperty(this, 'message', {
        enumerable: false,
        writable: true,
        value: msg
    });

    this.hash = hash;

    var stacktrace;
    if (hash && hash.exception instanceof Error) {
        var ex2 = hash.exception;
        this.message = ex2.message || msg;
        stacktrace = ex2.stack;
    }
    if (!stacktrace) {
        if (Error.hasOwnProperty('captureStackTrace')) {        // V8/Chrome engine
            Error.captureStackTrace(this, this.constructor);
        } else {
            stacktrace = (new Error(msg)).stack;
        }
    }
    if (stacktrace) {
        Object.defineProperty(this, 'stack', {
            enumerable: false,
            writable: false,
            value: stacktrace
        });
    }
}

if (typeof Object.setPrototypeOf === 'function') {
    Object.setPrototypeOf(JisonParserError.prototype, Error.prototype);
} else {
    JisonParserError.prototype = Object.create(Error.prototype);
}
JisonParserError.prototype.constructor = JisonParserError;
JisonParserError.prototype.name = 'JisonParserError';`;

    // --- END parser error class ---

    return {
        commonCode: '',
        moduleCode: prelude
    };
};

// Generate code that represents the specified parser table
lrGeneratorMixin.generateTableCode0 = function (table, defaultActions, productions) {
    var tableCode = JSON.stringify(table, null, 2);
    var defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
    var productionsCode = JSON.stringify(productions, null, 2);

    // Don't surround numerical property name numbers in quotes
    tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');

    var prelude = [];

    // Return the variable initialization code and the table code
    return {
        commonCode: prelude.join('\n'),
        tableCode: tableCode,
        defaultActionsCode: defaultActionsCode,
        productionsCode: productionsCode
    };
};

// Generate code that represents the specified parser table
lrGeneratorMixin.generateTableCode1 = function (table, defaultActions, productions) {
    var tableCode = JSON.stringify(table, null, 2);
    var defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
    var productionsCode = JSON.stringify(productions, null, 2);
    var usesCompressor = false;

    // Don't surround numerical property name numbers in quotes
    tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');

    // Replace objects with several identical values by function calls
    // e.g., { 1: [6, 7]; 3: [6, 7], 4: [6, 7], 5: 8 } = x([1, 3, 4], [6, 7], { 5: 8 })
    tableCode = tableCode.replace(/\{[\s\r\n]*\d+:[^\}]+,[\s\r\n]*\d+:[^\}]+\}/g, function (object) {
        // Find the value that occurs with the highest number of keys
        var value, frequentValue, key,
            keys = {},
            keyCount,
            maxKeyCount = 0,
            keyValue,
            keyValues = [],
            keyValueMatcher = /(\d+):[\s\r\n]*([^:\}]+)(?=,[\s\r\n]*\d+:|\})/g;

        while ((keyValue = keyValueMatcher.exec(object))) {
            // For each value, store the keys where that value occurs
            key = keyValue[1];
            value = keyValue[2].trim();
            keyCount = 1;

            if (!(value in keys)) {
                keys[value] = [key];
            } else {
                keyCount = keys[value].push(key);
            }
            // Remember this value if it is the most frequent one
            if (keyCount > maxKeyCount) {
                maxKeyCount = keyCount;
                frequentValue = value;
            }
        }
        // Construct the object with a function call if the most frequent value occurs multiple times
        if (maxKeyCount > 1) {
            // Collect all non-frequent values into a remainder object
            for (value in keys) {
                if (value !== frequentValue) {
                    for (var k = keys[value], i = 0, l = k.length; i < l; i++) {
                        keyValues.push(k[i] + ':' + value);
                    }
                }
            }
            keyValues = keyValues.length ? ', {' + keyValues.join(',') + '}' : '';
            // Create the function call `x(keys, value, remainder)`
            object = 'x([' + keys[frequentValue].join(',') + '], ' + frequentValue + keyValues + ')';
            usesCompressor = true;
        }
        return object;
    });

    // Count occurrences of number lists
    var list;
    var lists = {};
    var listMatcher = /\[[0-9,]+\]/g;
    var frequentLists = [];

    while ((list = listMatcher.exec(tableCode))) {
        lists[list] = (lists[list] || 0) + 1;
    }

    // Replace frequently occurring number lists with variables
    tableCode = tableCode.replace(listMatcher, function (list) {
        var listId = lists[list];
        // If listId is a number, it represents the list's occurrence frequency
        if (typeof listId === 'number') {
            // If the list does not occur frequently, represent it by the list
            if (listId === 1) {
                lists[list] = listId = list;
            // If the list occurs frequently, represent it by a newly assigned variable
            } else {
                lists[list] = listId = 'u[' + frequentLists.length + ']';
                frequentLists.push(list);
            }
        }
        return listId;
    });

    var prelude = [];

    // Only include the expander function when it's actually used
    // (tiny grammars don't have much state duplication, so this shaves off
    // another couple bytes off the generated output)
    if (usesCompressor) {
        prelude.push(createObjectCode.toString().replace('createObjectCode', 'x'));
        prelude.push('');
    }

    if (frequentLists.length > 0) {
        prelude.push('var u = [\n    ' + frequentLists.join(',\n    ') + '\n];');
        prelude.push('');
    }

    // Return the variable initialization code and the table code
    return {
        commonCode: prelude.join('\n'),
        tableCode: tableCode,
        defaultActionsCode: defaultActionsCode,
        productionsCode: productionsCode
    };
};

// Function that extends an object with the given value for all given keys
// e.g., x([1, 3, 4], [6, 7], { x: 1, y: 2 }) = { 1: [6, 7]; 3: [6, 7], 4: [6, 7], x: 1, y: 2 }
function createObjectCode(k, v, o) {
  o = o || {};
  for (var l = k.length; l--; ) {
    o[k[l]] = v;
  }
  return o;
}

// Generate code that represents the specified parser table
lrGeneratorMixin.generateTableCode2 = function (table, defaultActions, productions) {
    if (this.options.noDefaultResolve && this.conflicts > 0) {
        throw new Error("Table Compression mode 2 corrupts the table when the 'noDefaultResolve' option is turned on and one or more conflicts occur. Please use a different compression mode and/or disable this option.");
    }

    var tableCode = JSON.stringify(table, null, 2);
    var defaultActionsCode = JSON.stringify(defaultActions, null, 2).replace(/"([0-9]+)":/g, '$1:');
    var productionsCode = JSON.stringify(productions, null, 2);

    // We know a couple of things about the parse table:
    //
    // - The first level is an array with continuous indexes
    // - Each entry of the array is an object which contains a series of numeric states as a hash table
    // - Each 'hash table' entry is either a state number or a 2-element array
    //
    // So we can start by encoding the table 'vertically', i.e. by column rather than by row,
    // and then provide a bit of code to transform that series of arrays to the real parse table
    // at run time.
    // We can encode the columns by encoding the array-or-number aspect as a separate column,
    // while encoding the size of each hash table in yet another column: number of entries per state.
    // Then thanks to that length info, plus the 'is this hash-table entry going to be a number or an array' flag column,
    // we can transform those back to what we need at run-time.
    //
    // Meanwhile, we can inspect each of the columns and see if we can compress them.
    //
    // Of course the flags array is compressible as it's only 1 bit per entry, but there's sure to
    // be more compression goodies to be had in there, such as run-length encoding and maybe
    // delta-encoding of the hashtable indexes themselves.
    //
    //

    // Don't surround numerical property name numbers in quotes
    tableCode = tableCode.replace(/"([0-9]+)"(?=:)/g, '$1');




    function reportColumnsForCompression(def_arr) {
        var i, key, len;
        var report = [];

        len = 0;
        for (key in def_arr) {
            len = Math.max(len, def_arr[key].length);
        }

        var col_width = 6;
        var col_delta_width = 4;

        function clip(val, width) {
            var s = '        ' + val;
            s = s.substr(s.length - width);
            return s;
        }

        var track_prev4delta = {};
        var c, delta, val, delta_val;
        var line = [];
        line.push('║');
        for (c in def_arr) {
            key = clip(c, col_width);
            delta = clip('∆', col_delta_width);
            line.push(key);
            line.push('┊');
            line.push(delta);
            line.push('║');

            track_prev4delta[c] = 10000000;
        }
        report.push(line.join(''));

        for (i = 0; i < len; i++) {
            line = [];
            line.push('║');

            for (c in def_arr) {
                var tbl = def_arr[c];
                if (tbl.length > i) {
                    val = tbl[i] || 0;

                    delta_val = val - track_prev4delta[c];
                    // negative deltas are jumps: don't treat those as delta but as absolute value, sign-flipped:
                    if (delta_val < 0) {
                        delta_val = -val - 1;  // so that absolute 0 becomes -1, so it can be recognized from delta=0 ('no change')
                    }
                    track_prev4delta[c] = val;
                } else {
                    val = '.';
                    delta_val = '.';
                }

                key = clip(val, col_width);
                delta = clip(delta_val, col_delta_width);
                line.push(key);
                line.push('┊');
                line.push(delta);
                line.push('║');
            }
            report.push(line.join(''));
        }

        return '\n\n\n// ------------------------------\n\n\n// ' + report.join('\n// ') + '\n\n\n// ------------------\n\n\n';
    }


    // table is array of 1/2-len arrays:
    function analyzeTableForCompression(table) {
        // column: productions' row length
        var len_col = [];
        // column: productions' shift size / action column
        var pop_col = [];
        // column: rule number for each slot ('rule'):
        var rule_col = [];

        var i;
        var row_count = table.length;
        for (i = 0; i < row_count; i++) {
            var prod = table[i];

            len_col.push(prod.length);
            assert(prod.length <= 2);
            assert(prod.length > 0);
            // and the special knowledge about the productions[] table:
            assert(prod.length === 2);
            pop_col.push(prod[0]);
            rule_col.push(prod[1]);
        }

        var def_arr = {
            'len': len_col,
            'pop': pop_col,
            'rule': rule_col,
        };
        return def_arr;
    }




    // table is hash of 1/2-len arrays:
    function analyzeSetForCompression(table) {
        // column: row index
        var idx_col = [];
        // column: REDUCE productions' goto column
        var goto_col = [];

        var i;
        for (i in table) {
            i = +i;
            var prod = table[i];
            idx_col.push(i);

            // and the special knowledge about the defaultActions[] table:
            assert(typeof prod === 'number');
            goto_col.push(prod);
        }

        var def_arr = {
            'idx': idx_col,
            'goto': goto_col,
        };
        return def_arr;
    }



    function analyzeGotoTableForCompression(table) {
        // column: number of symbol hash entries per state slot ('length'):
        var len_col = [];
        // column: symbol hash entry key for each slot ('symbol'):
        var symbol_col = [];
        // column: symbol hash entry value type: number (0) or array (array.length) ('type'):
        var type_col = [];
        // column: symbol hash entry value if single GOTO state number ('state'):
        var state_col = [];
        // column: symbol hash entry mode value if array slot type (reduce/shift/accept):
        var mode_col = [];
        // column: symbol hash entry goto state value if array slot type:
        var goto_col = [];
        // // column: merged: state_col + goto_col:
        // var next_col = [];

        var row_count = table.length;
        for (var state = 0; state < row_count; state++) {
            var hashtable = table[state];
            var count = 0;
            var symbol;
            for (symbol in hashtable) {
                symbol = +symbol;
                symbol_col.push(symbol);

                var slot = hashtable[symbol];
                if (slot && slot.length) {
                    // array type slot:
                    assert(slot.length === 2 || slot.length === 1);
                    assert(slot.length === 1 ? slot[0] === 3 /* $accept */ : true);
                    type_col.push(slot.length);
                    if (slot.length > 1) {
                        mode_col.push(slot[0]);
                        goto_col.push(slot[1]);
                        //next_col.push(slot[1]);
                    }
                } else if (slot) {
                    // number type slot:
                    type_col.push(0);
                    state_col.push(slot);
                    //next_col.push(slot);
                } else {
                    assert(0);
                    type_col.push(666);
                    state_col.push((typeof slot) + state + '/' + symbol);
                    //next_col.push((typeof slot) + state + '/' + symbol);
                }
                count++;
            }
            len_col.push(count);
        }

        var def_arr = {
            'len': len_col,
            'symbol': symbol_col,
            'type': type_col,
            'state': state_col,
            'mode': mode_col,
            'goto': goto_col,
            //'next': next_col,
        };
        return def_arr;
    }


    var has_compressed_a_table = false;


    function generateColumn(name, col) {
        var rv = [];
        var i, j, len, l;

        for (i = 0, len = col.length; i < len; i++) {
            // try basic run-length encoding first:
            var v = col[i];

            for (j = i + 1; j < len; j++) {
                if (col[j] !== v) {
                    break;
                }
            }
            var runlength = j - i;

            // try stepped run-length encoding next:
            var delta = col[i + 1] - v;
            var steplength = 0;

            // we don't want to replicate the runlength result, so only look for a match
            // when delta !== 0:
            if (delta !== 0) {
                for (j = i + 2; j < len; j++) {
                    if (col[j] - col[j - 1] !== delta) {
                        break;
                    }
                }
                steplength = j - i;
            }

            // try to match the pattern in history:
            var best_pos = 0;
            var best_len = 0;
            var upper_bound = i - 2;
            for (j = 0; j < upper_bound; j++) {
                for (l = 0; col[j + l] === col[i + l]; l++) {
                    // No need to check for:
                    //    if (j + l === i) break;
                    // because we know how the c() helper function will regenerate
                    // this pattern: it is perfectly fine to overlap on itself: we always
                    // have an offset of relative -1 or more, so we can encode runlength
                    // patterns as duplicates this way too:
                    //   [4, c(0, 7)]   (note the written offset is 0!)
                    // will output an sequence of 7+1 '4' values: one '4' and then 7 more.
                    //
                    // Encoding such a pattern as direct runlength `s(4, 8)` is cheaper
                    // though. Hence we loop until `i - 2`: we want to find ABABABAB...
                    // patterns, but no AAAAAA... patterns here.
                }

                // We want the nearest offset for the longest pattern:
                if (l >= best_len) {
                    best_len = l;
                    best_pos = i - j;
                }
            }

            // weight our options now:
            var gain = [
                runlength - 2,
                steplength - 3,
                best_len - 2
            ];
            var optimum_gain = Math.max.apply(null, gain);
            if (optimum_gain <= 0) {
                rv.push(v);
            }
            else if (optimum_gain === gain[0]) {
                rv.push('s', '[' + v + ', ' + runlength + ']');
                i += runlength - 1;
            }
            else if (optimum_gain === gain[1]) {
                rv.push('s', '[' + v + ', ' + steplength + ', ' + delta + ']');
                i += steplength - 1;
            }
            else if (optimum_gain === gain[2]) {
                rv.push('c', '[' + best_pos + ', ' + best_len + ']');
                i += best_len - 1;
            }
            else {
                rv.push(v);
                //assert(0);      // should never get here!
            }

            if (optimum_gain > 0) {
                has_compressed_a_table = true;
            }
        }

        var code = [
            '  ', name, ': ',
            'u([',
            '\n  ',
                rv.join(',\n  '),                // JSON.stringify(col, null, 2),
            '\n',
            '])'
        ].join('');
        return code;
    }


    function generateCompressedTable(def_arr) {
        var code = [
            'bp({',
            generateColumn('pop', def_arr.pop) + ',',
            generateColumn('rule', def_arr.rule),
            '})'
        ].join('\n');
        return code;
    }


    function generateCompressedSet(def_arr) {
        var code = [
            'bda({',
            generateColumn('idx', def_arr.idx) + ',',
            generateColumn('goto', def_arr.goto),
            '})'
        ].join('\n');
        return code;
    }


    function generateCompressedGotoTable(def_arr) {
        var code = [
            'bt({',
            generateColumn('len', def_arr.len) + ',',
            generateColumn('symbol', def_arr.symbol) + ',',
            generateColumn('type', def_arr.type) + ',',
            generateColumn('state', def_arr.state) + ',',
            generateColumn('mode', def_arr.mode) + ',',
            generateColumn('goto', def_arr.goto),
            '})'
        ].join('\n');
        return code;
    }


    var tableDef = analyzeGotoTableForCompression(table);
    var defaultActionsDef = analyzeSetForCompression(defaultActions);
    var productionsDef = analyzeTableForCompression(productions);


    var bp_code_container = `
        // helper: reconstruct the productions[] table
        function bp(s) {
            var rv = [];
            var p = s.pop;
            var r = s.rule;
            for (var i = 0, l = p.length; i < l; i++) {
                rv.push([
                    p[i],
                    r[i]
                ]);
            }
            return rv;
        }
    `;

    var bda_code_container = `
        // helper: reconstruct the defaultActions[] table
        function bda(s) {
            var rv = {};
            var d = s.idx;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var j = d[i];
                rv[j] = g[i];
            }
            return rv;
        }
    `;

    var bt_code_container = `
        // helper: reconstruct the 'goto' table
        function bt(s) {
            var rv = [];
            var d = s.len;
            var y = s.symbol;
            var t = s.type;
            var a = s.state;
            var m = s.mode;
            var g = s.goto;
            for (var i = 0, l = d.length; i < l; i++) {
                var n = d[i];
                var q = {};
                for (var j = 0; j < n; j++) {
                    var z = y.shift();
                    switch (t.shift()) {
                    case 2:
                        q[z] = [
                            m.shift(),
                            g.shift()
                        ];
                        break;

                    case 0:
                        q[z] = a.shift();
                        break;

                    default:
                        // type === 1: accept
                        q[z] = [
                            3
                        ];
                    }
                }
                rv.push(q);
            }
            return rv;
        }
    `;

    var c_s_u_code_container = `
        // helper: runlength encoding with increment step: code, length: step (default step = 0)
        // \`this\` references an array
        function s(c, l, a) {
            a = a || 0;
            for (var i = 0; i < l; i++) {
                this.push(c);
                c += a;
            }
        }

        // helper: duplicate sequence from *relative* offset and length.
        // \`this\` references an array
        function c(i, l) {
            i = this.length - i;
            for (l += i; i < l; i++) {
                this.push(this[i]);
            }
        }

        // helper: unpack an array using helpers and data, all passed in an array argument 'a'.
        function u(a) {
            var rv = [];
            for (var i = 0, l = a.length; i < l; i++) {
                var e = a[i];
                // Is this entry a helper function?
                if (typeof e === 'function') {
                    i++;
                    e.apply(rv, a[i]);
                } else {
                    rv.push(e);
                }
            }
            return rv;
        }
    `;

    has_compressed_a_table = false;
    var tc = generateCompressedGotoTable(tableDef);
    var compressGotoTable = has_compressed_a_table;

    has_compressed_a_table = false;
    var dac = generateCompressedSet(defaultActionsDef);
    var compressDefaultActions = has_compressed_a_table;

    has_compressed_a_table = false;
    var pc = generateCompressedTable(productionsDef);
    var compressProductions = has_compressed_a_table;

    var compressAnything = (compressProductions || compressDefaultActions || compressGotoTable);

    tableCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(tableDef) : '') + (compressGotoTable ? tc : tableCode);
    defaultActionsCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(defaultActionsDef) : '') + (compressDefaultActions ? dac : defaultActionsCode);
    productionsCode = ((this.DEBUG || devDebug) ? reportColumnsForCompression(productionsDef) : '') + (compressProductions ? pc : productionsCode);


    var prelude = [
        '',
        compressProductions ? bp_code_container : '',
        '',
        compressDefaultActions ? bda_code_container : '',
        '',
        compressGotoTable ? bt_code_container : '',
        '',
        c_s_u_code_container,
    ];
    if (!compressAnything) {
        prelude = [];
    }

    // Return the variable initialization code and the table code
    return {
        commonCode: prelude.join('\n'),
        tableCode: tableCode,
        defaultActionsCode: defaultActionsCode,
        productionsCode: productionsCode
    };
};

// default main method for generated commonjs modules
const commonjsMain = `
function (args) {
    // When the parser comes with its own \`main\` function, then use that one:
    if (typeof exports.parser.main === 'function') {
      return exports.parser.main(args);
    }

    if (!args[1]) {
        console.log('Usage:', path.basename(args[0]) + ' FILE');
        process.exit(1);
    }
    var source = fs.readFileSync(path.normalize(args[1]), 'utf8');
    var dst = exports.parser.parse(source);
    console.log('parser output:\\n\\n', {
        type: typeof dst,
        value: dst
    });
    try {
        console.log("\\n\\nor as JSON:\\n", JSON.stringify(dst, null, 2));
    } catch (e) { /* ignore crashes; output MAY not be serializable! We are a generic bit of code, after all... */ }
    var rv = 0;
    if (typeof dst === 'number' || typeof dst === 'boolean') {
        rv = dst;
    }
    return dst;
}`;

const commonjsMainImports = `
var fs = require('fs');
var path = require('path');
`;

// debug mixin for LR parser generators

function printAction(a, gen) {
    var s = a[0] === SHIFT ? 'shift token (then go to state ' + a[1] + ')' :
        a[0] === REDUCE ? 'reduce by rule: ' + gen.productions[a[1]] :
        a[0] === ACCEPT ? 'accept' : 'UNDEFINED ACTION: ' + a[0];

    return s;
}

function traceStates(trace, states, title) {
    trace('\nItem sets -- ' + title + '\n------');

    states.forEach(function (state, i) {
        trace('\nitem set', i, '\n' + state.join('\n'), '\ntransitions -> ', JSON.stringify(state.edges));
    });
    trace('\n');
}

var lrGeneratorDebug = {
    beforeparseTable: function () {
        this.trace('Building parse table.');
    },
    afterparseTable: function () {
        var trace = this.trace;
        var self = this;
        if (this.conflicts > 0) {
            trace('\nConflicts:\n');
            this.resolutions.forEach(function (r, i) {
                if (r[2].bydefault) {
                    trace('Conflict at state: ', r[0], ', token: ', r[1], '\n  ', printAction(r[2].r, self), '\n  ', printAction(r[2].s, self));
                }
            });
            trace('\n' + this.conflicts + ' Conflict(s) found in grammar.');
        }
        trace('Done.\n');
    },
    aftercanonicalCollection: function (states /* as produced by `this.canonicalCollection()` */ ) {
        traceStates(this.trace, states, 'as produced by LR::canonicalCollection()');
    }
};

var parser = typal.beget();

generatorMixin.createParser = function createParser() {
    var sourceCodeDef = this.generateModuleExpr();

    // produce a chunk of sourcecode that's suitable for evaluation through `eval()`:
    var sourcecode = rmCommonWS$1`
        ${sourceCodeDef.init}

        var yy__parser = ${sourceCodeDef.src};

        // produce the generated parser function/class as the last value
        // in this chunk of code so that we can be sure to produce *that*
        // one as the 'return value' of the \`eval()\` call we'll submit
        // this code to.
        //
        // See also: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval

        yy__parser;
    `;
    var p = code_exec(sourcecode, function generated_code_exec_wrapper_jison(sourcecode) {
        //console.log("===============================PARSER TEST CODE\n", sourcecode, "\n=====================END====================\n");
        var rv = eval(sourcecode);
        return rv;
    }, mkStdOptions(this.options, {
        dumpSourceCodeOnFailure: this.DEBUG,
        throwErrorOnCompileFailure: true
    }), "parser");

    assert(typeof p === 'object');
    assert(typeof p.parse === 'function');
    assert(typeof p.parser === 'undefined');
    assert(typeof p.Parser === 'function');
    assert(typeof p.yy === 'object');
    assert(typeof p.EOF === 'number');
    assert(typeof p.TERROR === 'number');
    // assert(typeof p.trace === 'function');
    assert(typeof p.JisonParserError === 'function');
    assert(typeof p.quoteName === 'function');
    assert(typeof p.originalQuoteName === 'function');
    assert(typeof p.describeSymbol === 'function');
    assert(typeof p.symbols_ === 'object');
    assert(typeof p.terminals_ === 'object');
    // assert(typeof p.nonterminals === 'undefined');
    // assert(typeof p.terminal_descriptions_ === 'undefined');
    // assert(typeof p.productions_ === 'object');
    assert(typeof p.performAction === 'function');
    assert(typeof p.table === 'object');
    // assert(typeof p.defaultActions === 'object');
    assert(typeof p.parseError === 'function');
    // assert(typeof p.yyError === 'undefined');
    // assert(typeof p.yyRecovering === 'undefined');
    // assert(typeof p.yyErrOk === 'undefined');
    // assert(typeof p.yyClearIn === 'undefined');
    assert(typeof p.constructParseErrorInfo === 'object');
    assert(typeof p.originalParseError === 'function');
    assert(typeof p.options === 'object');
    assert(typeof p.cleanupAfterParse === 'object');
    assert(typeof p.yyMergeLocationInfo === 'object');
    assert(typeof p.lexer === 'object' || typeof p.lexer === 'undefined');

    // for debugging
    p.productions = this.productions;
    p.unused_productions = this.unused_productions;
    p.conflicts = this.conflicts;
    if (p.conflicts && this.options.hasPartialLrUpgradeOnConflict) {
        p.conflicts_have_been_fixed = this.conflict_fixing_round;
        p.conflict_productions_LU = this.conflict_productions_LU;
        p.conflict_states_LU = this.conflict_states_LU;
    }
    p.sourceCode = sourceCodeDef;

    var self = this;
    function bind(method) {
        return function () {
            self.lexer = p.lexer;
            return method.apply(self, arguments);
        };
    }

    // backwards compatibility
    p.lexer = this.lexer;
    p.generate = bind(this.generate);
    p.generateAMDModule = bind(this.generateAMDModule);
    p.generateModule = bind(this.generateModule);
    p.generateCommonJSModule = bind(this.generateCommonJSModule);

    this.reportGrammarInformation();

    return p;
};

parser.trace = generator.trace;
parser.warn = generator.warn;
parser.error = generator.error;

const parseErrorSourceCode = `
function parseError(str, hash, ExceptionClass) {
    if (hash.recoverable) {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        hash.destroy();             // destroy... well, *almost*!
    } else {
        if (typeof this.trace === 'function') {
            this.trace(str);
        }
        if (!ExceptionClass) {
            ExceptionClass = this.JisonParserError;
        }
        throw new ExceptionClass(str, hash);
    }
}`;    // END of parseErrorSourceCode chunk

parser.parseError = lrGeneratorMixin.parseError = eval(parseErrorSourceCode + '\n\nparseError;');

generatorMixin.createLexer = function createLexer(lexerSpec, input, tokens, options) {
    // TODO: construct options from generator options:
    // lexer_options = ...
    var lexer = new RegExpLexer(lexerSpec, input, tokens, options);

    return lexer;
};


// wrapper function so we easily stringify the APIs defined inside to code *with comments*
// in the generated code:
function define_parser_APIs_1() {
    return {
        TERROR: 2,
        EOF: 1,

        // internals: defined here so the object *structure* doesn't get modified by parse() et al,
        // thus helping JIT compilers like Chrome V8.
        originalQuoteName: null,
        originalParseError: null,
        cleanupAfterParse: null,
        constructParseErrorInfo: null,
        yyMergeLocationInfo: null,

        __reentrant_call_depth: 0,      // INTERNAL USE ONLY
        __error_infos: [],              // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup
        __error_recovery_infos: [],     // INTERNAL USE ONLY: the set of parseErrorInfo objects created since the last cleanup

        // APIs which will be set up depending on user action code analysis:
        //yyRecovering: 0,
        //yyErrOk: 0,
        //yyClearIn: 0,

        // Helper APIs
        // -----------

        // Helper function which can be overridden by user code later on: put suitable quotes around
        // literal IDs in a description string.
        quoteName: function parser_quoteName(id_str) {
            return '"' + id_str + '"';
        },

        // Return the name of the given symbol (terminal or non-terminal) as a string, when available.
        //
        // Return NULL when the symbol is unknown to the parser.
        getSymbolName: function parser_getSymbolName(symbol) {
            if (this.terminals_[symbol]) {
                return this.terminals_[symbol];
            }

            // Otherwise... this might refer to a RULE token i.e. a non-terminal: see if we can dig that one up.
            //
            // An example of this may be where a rule's action code contains a call like this:
            //
            //      parser.getSymbolName(#$)
            //
            // to obtain a human-readable name of the current grammar rule.
            var s = this.symbols_;
            for (var key in s) {
                if (s[key] === symbol) {
                    return key;
                }
            }
            return null;
        },

        // Return a more-or-less human-readable description of the given symbol, when available,
        // or the symbol itself, serving as its own 'description' for lack of something better to serve up.
        //
        // Return NULL when the symbol is unknown to the parser.
        describeSymbol: function parser_describeSymbol(symbol) {
            if (symbol !== this.EOF && this.terminal_descriptions_ && this.terminal_descriptions_[symbol]) {
                return this.terminal_descriptions_[symbol];
            }
            else if (symbol === this.EOF) {
                return 'end of input';
            }
            var id = this.getSymbolName(symbol);
            if (id) {
                return this.quoteName(id);
            }
            return null;
        },

        // Produce a (more or less) human-readable list of expected tokens at the point of failure.
        //
        // The produced list may contain token or token set descriptions instead of the tokens
        // themselves to help turning this output into something that easier to read by humans
        // unless `do_not_describe` parameter is set, in which case a list of the raw, *numeric*,
        // expected terminals and nonterminals is produced.
        //
        // The returned list (array) will not contain any duplicate entries.
        collect_expected_token_set: function parser_collect_expected_token_set(state, do_not_describe) {
            var TERROR = this.TERROR;
            var tokenset = [];
            var check = {};
            // Has this (error?) state been outfitted with a custom expectations description text for human consumption?
            // If so, use that one instead of the less palatable token set.
            if (!do_not_describe && this.state_descriptions_ && this.state_descriptions_[state]) {
                return [
                    this.state_descriptions_[state]
                ];
            }
            for (var p in this.table[state]) {
                p = +p;
                if (p !== TERROR) {
                    var d = do_not_describe ? p : this.describeSymbol(p);
                    if (d && !check[d]) {
                        tokenset.push(d);
                        check[d] = true;        // Mark this token description as already mentioned to prevent outputting duplicate entries.
                    }
                }
            }
            return tokenset;
        }
    };
}

var api_set = define_parser_APIs_1();
for (var api in api_set) {
    parser[api] = api_set[api];
}


// --- START parser kernel ---
parser.parse = `function parse(input, parseParams) {
    var self = this;
    var stack = new Array(128);         // token stack: stores token which leads to state at the same index (column storage)
    var sstack = new Array(128);        // state stack: stores states (column storage)
    var tstack = [];                    // token stack (only used when \`%options token_stack\` support has been enabled)
    var vstack = new Array(128);        // semantic value stack
    var lstack = new Array(128);        // location stack
    var table = this.table;
    var sp = 0;                         // 'stack pointer': index into the stacks
    var yyloc;
    var yytext;
    var yylineno;
    var yyleng;

    var symbol = 0;
    var preErrorSymbol = 0;
    var lastEofErrorStateDepth = Infinity;
    var recoveringErrorInfo = null;
    var recovering = 0;                 // (only used when the grammar contains error recovery rules)
    var TERROR = this.TERROR;
    var EOF = this.EOF;
    var ERROR_RECOVERY_TOKEN_DISCARD_COUNT = (this.options.errorRecoveryTokenDiscardCount | 0) || 3;
    var NO_ACTION = [0, YY_ERROR_RECOVERY_COMBINE_ID /* === table.length :: ensures that anyone using this new state will fail dramatically! */];

    var lexer;
    if (this.__lexer__) {
        lexer = this.__lexer__;
    } else {
        lexer = this.__lexer__ = Object.create(this.lexer);
    }

    var sharedState_yy = {
        parseError: undefined,
        quoteName: undefined,
        lexer: undefined,
        parser: undefined,
        pre_parse: undefined,
        post_parse: undefined,
        pre_lex: undefined,
        post_lex: undefined,
        parseParamsAsMembers: parseParamsAsMembers      // WARNING: must be written this way for the code expanders to work correctly in both ES5 and ES6 modes!
    };

    var ASSERT;
    if (typeof assert !== 'function') {
        ASSERT = function JisonAssert(cond, msg) {
            if (!cond) {
                throw new Error('assertion failed: ' + (msg || '***'));
            }
        };
    } else {
        ASSERT = assert;
    }

    this.yyGetSharedState = function yyGetSharedState() {
        return sharedState_yy;
    };

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    this.yyGetErrorInfoTrack = function yyGetErrorInfoTrack() {
        return recoveringErrorInfo;
    };

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    // shallow clone objects, straight copy of simple \`src\` values
    // e.g. \`lexer.yytext\` MAY be a complex value object,
    // rather than a simple string/value.
    function shallow_copy(src) {
        if (typeof src === 'object') {
            var dst = {};
            for (var k in src) {
                if (Object.prototype.hasOwnProperty.call(src, k)) {
                    dst[k] = src[k];
                }
            }
            return dst;
        }
        return src;
    }
    function shallow_copy_noclobber(dst, src) {
        for (var k in src) {
            if (typeof dst[k] === 'undefined' && Object.prototype.hasOwnProperty.call(src, k)) {
                dst[k] = src[k];
            }
        }
    }
    function copy_yylloc(loc) {
        var rv = shallow_copy(loc);
        if (rv && rv.range) {
            rv.range = rv.range.slice(0);
        }
        return rv;
    }

    // copy state
    shallow_copy_noclobber(sharedState_yy, this.yy);

    sharedState_yy.lexer = lexer;
    sharedState_yy.parser = this;

    var yydebug = false;
    if (this.options.debug) {
        yydebug = function yydebug_impl(msg, obj) {
            var ref_list;
            var ref_names;

            function deepClone(from, sub) {
                if (sub == null) {
                    ref_list = [];
                    ref_names = [];
                    sub = 'root';
                }
                if (typeof from === 'function') return '[Function]';
                if (from == null || typeof from !== 'object') return from;
                if (from.constructor !== Object && from.constructor !== Array) {
                    return from;
                }

                for (var i = 0, len = ref_list.length; i < len; i++) {
                    if (ref_list[i] === from) {
                        return '[Circular/Xref:' + ref_names[i] + ']';   // circular or cross reference
                    }
                }
                ref_list.push(from);
                ref_names.push(sub);

                var to = new from.constructor();
                for (var name in from) {
                    if (name === 'parser') continue;
                    if (name === 'lexer') continue;
                    to[name] = deepClone(from[name], name);
                }
                return to;
            }

            obj = obj || {};
            if (obj.symbol) {
                obj.local_yytext = yytext;
                obj.lexer_yytext = lexer.yytext;
                obj.lexer_yylloc = lexer.yylloc;
                obj.lexer_yyllineno = lexer.yyllineno;
            }

            // warning: here we fetch from closure (stack et al)
            obj.symbol_stack = stack;
            obj.state_stack = sstack;
            obj.value_stack = vstack;
            obj.location_stack = lstack;
            obj.stack_pointer = sp;

            // ready the object for printing:
            obj = deepClone(obj);

            // wrap try/catch in a function to help the V8 JIT compiler...
            function yydebug_cvt(obj) {
                var js;
                try {
                    var re1;
                    if (typeof XRegExp === 'undefined') {
                        re1 = /  \\"([a-z_][a-z_0-9. ]*)\\": /ig;
                    } else {
                        re1 = new XRegExp('  \\"([\\\\p{Alphabetic}_][\\\\p{Alphabetic}\\\\p{Number}_. ]*)\\": ', 'g');
                    }
                    js = JSON.stringify(obj, null, 2).replace(re1, '  $1: ').replace(/[\\n\\s]+/g, ' ');
                } catch (ex) {
                    js = String(obj);
                }
                return js;
            }

            self.trace(msg, yydebug_cvt(obj), '\\n');
        };
    }

    // disable debugging at run-time ANYWAY when you've *explicitly* set "yy.yydebug = false":
    if (sharedState_yy.yydebug === false) {
        yydebug = undefined;
    }

    // *Always* setup \`yyError\`, \`YYRECOVERING\`, \`yyErrOk\` and \`yyClearIn\` functions as it is paramount
    // to have *their* closure match ours -- if we only set them up once,
    // any subsequent \`parse()\` runs will fail in very obscure ways when
    // these functions are invoked in the user action code block(s) as
    // their closure will still refer to the \`parse()\` instance which set
    // them up. Hence we MUST set them up at the start of every \`parse()\` run!
    if (this.yyError) {
        this.yyError = function yyError(str /*, ...args */) {
            if (yydebug) yydebug('yyerror: ', { message: str, args: arguments, symbol: symbol, state: state, newState: newState, recovering: recovering, action: action });

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

            var error_rule_depth = (this.options.parserErrorsAreRecoverable ? locateNearestErrorRecoveryRule(state) : -1);
            var expected = this.collect_expected_token_set(state);
            var hash = this.constructParseErrorInfo(str, null, expected, (error_rule_depth >= 0));
            // append to the old one?
            if (recoveringErrorInfo) {
                var esp = recoveringErrorInfo.info_stack_pointer;

                recoveringErrorInfo.symbol_stack[esp] = symbol;
                var v = this.shallowCopyErrorInfo(hash);
                v.yyError = true;
                v.errorRuleDepth = error_rule_depth;
                v.recovering = recovering;
                // v.stackSampleLength = error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH;

                recoveringErrorInfo.value_stack[esp] = v;
                recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                ++esp;
                recoveringErrorInfo.info_stack_pointer = esp;
            } else {
                recoveringErrorInfo = this.shallowCopyErrorInfo(hash);
                recoveringErrorInfo.yyError = true;
                recoveringErrorInfo.errorRuleDepth = error_rule_depth;
                recoveringErrorInfo.recovering = recovering;
            }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules

            var expected = this.collect_expected_token_set(state);
            var hash = this.constructParseErrorInfo(str, null, expected, false);

//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

            // Add any extra args to the hash under the name \`extra_error_attributes\`:
            var args = Array.prototype.slice.call(arguments, 1);
            if (args.length) {
                hash.extra_error_attributes = args;
            }

            var r = this.parseError(str, hash, this.JisonParserError);
            return r;
        };
    }

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    if (this.yyRecovering) {
        this.yyRecovering = function yyRecovering() {
            if (yydebug) yydebug('yyrecovering: ', { symbol: symbol, state: state, newState: newState, recovering: recovering, action: action });
            return recovering;
        };
    }

    if (this.yyErrOk) {
        this.yyErrOk = function yyErrOk() {
            if (yydebug) yydebug('yyerrok: ', { symbol: symbol, state: state, newState: newState, recovering: recovering, action: action });
            recovering = 0;

            // DO NOT reset/cleanup \`recoveringErrorInfo\` yet: userland code
            // MAY invoke this API before the error is actually fully
            // recovered, in which case the parser recovery code won't be able
            // to append the skipped tokens to this info object.
            // 
            // The rest of the kernel code is safe enough that it won't inadvertedly
            // re-use an old \`recoveringErrorInfo\` chunk so we'ld better wait
            // with destruction/cleanup until the end of the parse or until another
            // fresh parse error rears its ugly head...
            //
            // if (recoveringErrorInfo && typeof recoveringErrorInfo.destroy === 'function') {
            //     recoveringErrorInfo.destroy();
            //     recoveringErrorInfo = undefined;
            // }
        };
    }

    if (this.yyClearIn) {
        this.yyClearIn = function yyClearIn() {
            if (yydebug) yydebug('yyclearin: ', { symbol: symbol, newState: newState, recovering: recovering, action: action, preErrorSymbol: preErrorSymbol });
            if (symbol === TERROR) {
                symbol = 0;
                yytext = null;
                yyleng = 0;
                yyloc = undefined;
            }
            preErrorSymbol = 0;
        };
    }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    // Does the shared state override the default \`parseError\` that already comes with this instance?
    if (typeof sharedState_yy.parseError === 'function') {
        this.parseError = function parseErrorAlt(str, hash, ExceptionClass) {
            if (!ExceptionClass) {
                ExceptionClass = this.JisonParserError;
            }
            return sharedState_yy.parseError.call(this, str, hash, ExceptionClass);
        };
    } else {
        this.parseError = this.originalParseError;
    }

    // Does the shared state override the default \`quoteName\` that already comes with this instance?
    if (typeof sharedState_yy.quoteName === 'function') {
        this.quoteName = function quoteNameAlt(id_str) {
            return sharedState_yy.quoteName.call(this, id_str);
        };
    } else {
        this.quoteName = this.originalQuoteName;
    }

    // set up the cleanup function; make it an API so that external code can re-use this one in case of
    // calamities or when the \`%options no-try-catch\` option has been specified for the grammar, in which
    // case this parse() API method doesn't come with a \`finally { ... }\` block any more!
    //
    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your \`sharedState\`, etc. references will be *wrong*!
    this.cleanupAfterParse = function parser_cleanupAfterParse(resultValue, invoke_post_methods, do_not_nuke_errorinfos) {
        var rv;

        if (invoke_post_methods) {
            var hash;

            if (sharedState_yy.post_parse || this.post_parse) {
                // create an error hash info instance: we re-use this API in a **non-error situation**
                // as this one delivers all parser internals ready for access by userland code.
                hash = this.constructParseErrorInfo(null /* no error! */, null /* no exception! */, null, false);
            }

            if (sharedState_yy.post_parse) {
                rv = sharedState_yy.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }
            if (this.post_parse) {
                rv = this.post_parse.call(this, sharedState_yy, resultValue, hash);
                if (typeof rv !== 'undefined') resultValue = rv;
            }

            // cleanup:
            if (hash && hash.destroy) {
                hash.destroy();
            }
        }

        if (this.__reentrant_call_depth > 1) return resultValue;        // do not (yet) kill the sharedState when this is a reentrant run.

        // clean up the lingering lexer structures as well:
        if (lexer.cleanupAfterLex) {
            lexer.cleanupAfterLex(do_not_nuke_errorinfos);
        }

        // prevent lingering circular references from causing memory leaks:
        if (sharedState_yy) {
            sharedState_yy.lexer = undefined;
            sharedState_yy.parser = undefined;
            if (lexer.yy === sharedState_yy) {
                lexer.yy = undefined;
            }
        }
        sharedState_yy = undefined;
        this.parseError = this.originalParseError;
        this.quoteName = this.originalQuoteName;

        // nuke the vstack[] array at least as that one will still reference obsoleted user values.
        // To be safe, we nuke the other internal stack columns as well...
        stack.length = 0;               // fastest way to nuke an array without overly bothering the GC
        sstack.length = 0;
        lstack.length = 0;
        vstack.length = 0;
        sp = 0;

        // nuke the error hash info instances created during this run.
        // Userland code must COPY any data/references
        // in the error hash instance(s) it is more permanently interested in.
        if (!do_not_nuke_errorinfos) {
            for (var i = this.__error_infos.length - 1; i >= 0; i--) {
                var el = this.__error_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_infos.length = 0;

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

            for (var i = this.__error_recovery_infos.length - 1; i >= 0; i--) {
                var el = this.__error_recovery_infos[i];
                if (el && typeof el.destroy === 'function') {
                    el.destroy();
                }
            }
            this.__error_recovery_infos.length = 0;

            // \`recoveringErrorInfo\` is also part of the \`__error_recovery_infos\` array,
            // hence has been destroyed already: no need to do that *twice*.
            if (recoveringErrorInfo) {
                recoveringErrorInfo = undefined;
            }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

        }

        return resultValue;
    };

    // merge yylloc info into a new yylloc instance.
    //
    // \`first_index\` and \`last_index\` MAY be UNDEFINED/NULL or these are indexes into the \`lstack[]\` location stack array.
    //
    // \`first_yylloc\` and \`last_yylloc\` MAY be UNDEFINED/NULL or explicit (custom or regular) \`yylloc\` instances, in which
    // case these override the corresponding first/last indexes.
    //
    // \`dont_look_back\` is an optional flag (default: FALSE), which instructs this merge operation NOT to search
    // through the parse location stack for a location, which would otherwise be used to construct the new (epsilon!)
    // yylloc info.
    //
    // Note: epsilon rule's yylloc situation is detected by passing both \`first_index\` and \`first_yylloc\` as UNDEFINED/NULL.
    this.yyMergeLocationInfo = function parser_yyMergeLocationInfo(first_index, last_index, first_yylloc, last_yylloc, dont_look_back) {
        var i1 = first_index | 0,
            i2 = last_index | 0;
        var l1 = first_yylloc,
            l2 = last_yylloc;
        var rv;

        // rules:
        // - first/last yylloc entries override first/last indexes

        if (!l1) {
            if (first_index != null) {
                for (var i = i1; i <= i2; i++) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
        }

        if (!l2) {
            if (last_index != null) {
                for (var i = i2; i >= i1; i--) {
                    l2 = lstack[i];
                    if (l2) {
                        break;
                    }
                }
            }
        }

        // - detect if an epsilon rule is being processed and act accordingly:
        if (!l1 && first_index == null) {
            // epsilon rule span merger. With optional look-ahead in l2.
            if (!dont_look_back) {
                for (var i = (i1 || sp) - 1; i >= 0; i--) {
                    l1 = lstack[i];
                    if (l1) {
                        break;
                    }
                }
            }
            if (!l1) {
                if (!l2) {
                    // when we still don't have any valid yylloc info, we're looking at an epsilon rule
                    // without look-ahead and no preceding terms and/or \`dont_look_back\` set:
                    // in that case we ca do nothing but return NULL/UNDEFINED:
                    return undefined;
                } else {
                    // shallow-copy L2: after all, we MAY be looking
                    // at unconventional yylloc info objects...
                    rv = shallow_copy(l2);
                    if (rv.range) {
                        // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                        rv.range = rv.range.slice(0);
                    }
                    return rv;
                }
            } else {
                // shallow-copy L1, then adjust first col/row 1 column past the end.
                rv = shallow_copy(l1);
                rv.first_line = rv.last_line;
                rv.first_column = rv.last_column;
                if (rv.range) {
                    // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
                    rv.range = rv.range.slice(0);
                    rv.range[0] = rv.range[1];
                }

                if (l2) {
                    // shallow-mixin L2, then adjust last col/row accordingly.
                    shallow_copy_noclobber(rv, l2);
                    rv.last_line = l2.last_line;
                    rv.last_column = l2.last_column;
                    if (rv.range && l2.range) {
                        rv.range[1] = l2.range[1];
                    }
                }
                return rv;
            }
        }

        if (!l1) {
            l1 = l2;
            l2 = null;
        }
        if (!l1) {
            return undefined;
        }

        // shallow-copy L1|L2, before we try to adjust the yylloc values: after all, we MAY be looking
        // at unconventional yylloc info objects...
        rv = shallow_copy(l1);

        // first_line: ...,
        // first_column: ...,
        // last_line: ...,
        // last_column: ...,
        if (rv.range) {
            // shallow copy the yylloc ranges info to prevent us from modifying the original arguments' entries:
            rv.range = rv.range.slice(0);
        }

        if (l2) {
            shallow_copy_noclobber(rv, l2);
            rv.last_line = l2.last_line;
            rv.last_column = l2.last_column;
            if (rv.range && l2.range) {
                rv.range[1] = l2.range[1];
            }
        }

        return rv;
    };

    // NOTE: as this API uses parse() as a closure, it MUST be set again on every parse() invocation,
    //       or else your \`lexer\`, \`sharedState\`, etc. references will be *wrong*!
    this.constructParseErrorInfo = function parser_constructParseErrorInfo(msg, ex, expected, recoverable) {
        var pei = {
            errStr: msg,
            exception: ex,
            text: lexer.match,
            value: lexer.yytext,
            token: this.describeSymbol(symbol) || symbol,
            token_id: symbol,
            line: lexer.yylineno,
            loc: copy_yylloc(lexer.yylloc),
            expected: expected,
            recoverable: recoverable,
            state: state,
            action: action,
            new_state: newState,
            symbol_stack: stack,
            state_stack: sstack,
            value_stack: vstack,
            location_stack: lstack,
            stack_pointer: sp,
            yy: sharedState_yy,
            lexer: lexer,
            parser: this,

            // and make sure the error info doesn't stay due to potential
            // ref cycle via userland code manipulations.
            // These would otherwise all be memory leak opportunities!
            //
            // Note that only array and object references are nuked as those
            // constitute the set of elements which can produce a cyclic ref.
            // The rest of the members is kept intact as they are harmless.
            destroy: function destructParseErrorInfo() {
                // remove cyclic references added to error info:
                // info.yy = null;
                // info.lexer = null;
                // info.value = null;
                // info.value_stack = null;
                // ...
                var rec = !!this.recoverable;
                for (var key in this) {
                    if (this.hasOwnProperty(key) && typeof key === 'object') {
                        this[key] = undefined;
                    }
                }
                this.recoverable = rec;
            }
        };
        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_infos.push(pei);
        return pei;
    };

    // clone some parts of the (possibly enhanced!) errorInfo object
    // to give them some persistence.
    this.shallowCopyErrorInfo = function parser_shallowCopyErrorInfo(p) {
        var rv = shallow_copy(p);

        // remove the large parts which can only cause cyclic references
        // and are otherwise available from the parser kernel anyway.
        delete rv.sharedState_yy;
        delete rv.parser;
        delete rv.lexer;

        // lexer.yytext MAY be a complex value object, rather than a simple string/value:
        rv.value = shallow_copy(rv.value);

        // yylloc info:
        rv.loc = copy_yylloc(rv.loc);

        // the 'expected' set won't be modified, so no need to clone it:
        //rv.expected = rv.expected.slice(0);

        //symbol stack is a simple array:
        rv.symbol_stack = rv.symbol_stack.slice(0);
        // ditto for state stack:
        rv.state_stack = rv.state_stack.slice(0);
        // clone the yylloc's in the location stack?:
        rv.location_stack = rv.location_stack.map(copy_yylloc);
        // and the value stack may carry both simple and complex values:
        // shallow-copy the latter.
        rv.value_stack = rv.value_stack.map(shallow_copy);

        // and we don't bother with the sharedState_yy reference:
        //delete rv.yy;

        // now we prepare for tracking the COMBINE actions
        // in the error recovery code path:
        //
        // as we want to keep the maximum error info context, we
        // *scan* the state stack to find the first *empty* slot.
        // This position will surely be AT OR ABOVE the current
        // stack pointer, but we want to keep the 'used but discarded'
        // part of the parse stacks *intact* as those slots carry
        // error context that may be useful when you want to produce
        // very detailed error diagnostic reports.
        //
        // ### Purpose of each stack pointer:
        //
        // - stack_pointer: points at the top of the parse stack
        //                  **as it existed at the time of the error
        //                  occurrence, i.e. at the time the stack
        //                  snapshot was taken and copied into the
        //                  errorInfo object.**
        // - base_pointer:  the bottom of the **empty part** of the
        //                  stack, i.e. **the start of the rest of
        //                  the stack space /above/ the existing
        //                  parse stack. This section will be filled
        //                  by the error recovery process as it
        //                  travels the parse state machine to
        //                  arrive at the resolving error recovery rule.**
        // - info_stack_pointer:
        //                  this stack pointer points to the **top of
        //                  the error ecovery tracking stack space**, i.e.
        //                  this stack pointer takes up the role of
        //                  the \`stack_pointer\` for the error recovery
        //                  process. Any mutations in the **parse stack**
        //                  are **copy-appended** to this part of the
        //                  stack space, keeping the bottom part of the
        //                  stack (the 'snapshot' part where the parse
        //                  state at the time of error occurrence was kept)
        //                  intact.
        // - root_failure_pointer:
        //                  copy of the \`stack_pointer\`...
        //
        for (var i = rv.stack_pointer; typeof rv.state_stack[i] !== 'undefined'; i++) {
            // empty
        }
        rv.base_pointer = i;
        rv.info_stack_pointer = i;

        rv.root_failure_pointer = rv.stack_pointer;

        // track this instance so we can \`destroy()\` it once we deem it superfluous and ready for garbage collection!
        this.__error_recovery_infos.push(rv);

        return rv;
    };

    function getNonTerminalFromCode(symbol) {
        var tokenName = self.getSymbolName(symbol);
        if (!tokenName) {
            tokenName = symbol;
        }
        return tokenName;
    }

//_lexer_without_token_stack:

    function stdLex() {
        var token = lexer.lex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    function fastLex() {
        var token = lexer.fastLex();
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            token = self.symbols_[token] || token;
        }

        return token || EOF;
    }

    var lex = stdLex;

//_lexer_with_token_stack:

    // lex function that supports token stacks
    function tokenStackLex() {
        var token;
        token = tstack.pop() || lexer.lex() || EOF;
        // if token isn't its numeric value, convert
        if (typeof token !== 'number') {
            if (token instanceof Array) {
                tstack = token;
                token = tstack.pop();
            }
            // if token isn't its numeric value, convert
            if (typeof token !== 'number') {
                token = self.symbols_[token] || token;
            }
        }

        return token || EOF;
    }

//_lexer_with_token_stack_end:

    var state, action, r, t;
    var yyval = {
        $: true,
        _$: undefined,
        yy: sharedState_yy
    };
    var p;
    var yyrulelen;
    var this_production;
    var newState;
    var retval = false;

//_handle_error_with_recovery:                    // run this code when the grammar includes error recovery rules

    // Return the rule stack depth where the nearest error rule can be found.
    // Return -1 when no error recovery rule was found.
    function locateNearestErrorRecoveryRule(state) {
        var stack_probe = sp - 1;
        var depth = 0;

        // try to recover from error
        while (stack_probe >= 0) {
            // check for error recovery rule in this state
            if (yydebug) yydebug('locateNearestErrorRecoveryRule #test#: ', { symbol: symbol, state: state, depth: depth, stackidx: sp - 1 - depth, lastidx: lastEofErrorStateDepth });
            var t = table[state][TERROR] || NO_ACTION;
            if (t[0]) {
                // We need to make sure we're not cycling forever:
                // once we hit EOF, even when we \`yyerrok()\` an error, we must
                // prevent the core from running forever,
                // e.g. when parent rules are still expecting certain input to
                // follow after this, for example when you handle an error inside a set
                // of braces which are matched by a parent rule in your grammar.
                //
                // Hence we require that every error handling/recovery attempt
                // *after we've hit EOF* has a diminishing state stack: this means
                // we will ultimately have unwound the state stack entirely and thus
                // terminate the parse in a controlled fashion even when we have
                // very complex error/recovery code interplay in the core + user
                // action code blocks:
                if (yydebug) yydebug('locateNearestErrorRecoveryRule #found#: ', { symbol: symbol, state: state, depth: depth, stackidx: sp - 1 - depth, lastidx: lastEofErrorStateDepth });
                if (symbol === EOF) {
                    if (lastEofErrorStateDepth > sp - 1 - depth) {
                        lastEofErrorStateDepth = sp - 1 - depth;
                    } else {
                        if (yydebug) yydebug('locateNearestErrorRecoveryRule #skip#: ', { symbol: symbol, state: state, depth: depth, stackidx: sp - 1 - depth, lastidx: lastEofErrorStateDepth });
                        --stack_probe; // popStack(1): [symbol, action]
                        state = sstack[stack_probe];
                        ++depth;
                        continue;
                    }
                }
                return depth;
            }
            if (state === 0 /* $accept rule */ || stack_probe < 1) {
                if (yydebug) yydebug('locateNearestErrorRecoveryRule #end=NIL#: ', { symbol: symbol, state: state, depth: depth, stackidx: sp - 1 - depth, lastidx: lastEofErrorStateDepth });
                return -1; // No suitable error recovery rule available.
            }
            --stack_probe; // popStack(1): [symbol, action]
            state = sstack[stack_probe];
            ++depth;
        }
        if (yydebug) yydebug('locateNearestErrorRecoveryRule #EMPTY#: ', { symbol: symbol, state: state, depth: depth, stackidx: sp - 1 - depth, lastidx: lastEofErrorStateDepth });
        return -1; // No suitable error recovery rule available.
    }

//_handle_error_no_recovery:                      // run this code when the grammar does not include any error recovery rules
//_handle_error_end_of_section:                   // this concludes the error recovery / no error recovery code section choice above

    try {
        this.__reentrant_call_depth++;

        lexer.setInput(input, sharedState_yy);

        // NOTE: we *assume* no lexer pre/post handlers are set up *after* 
        // this initial \`setInput()\` call: hence we can now check and decide
        // whether we'll go with the standard, slower, lex() API or the
        // \`fast_lex()\` one:
        if (typeof lexer.canIUse === 'function') {
            var lexerInfo = lexer.canIUse();
            if (lexerInfo.fastLex && typeof fastLex === 'function') {
                lex = fastLex;
            }
        } 

        yyloc = lexer.yylloc;
        lstack[sp] = yyloc;
        vstack[sp] = null;
        sstack[sp] = 0;
        stack[sp] = 0;
        ++sp;

        yytext = lexer.yytext;
        yylineno = lexer.yylineno;
        yyleng = lexer.yyleng;

        if (this.pre_parse) {
            this.pre_parse.call(this, sharedState_yy);
        }
        if (sharedState_yy.pre_parse) {
            sharedState_yy.pre_parse.call(this, sharedState_yy);
        }

        newState = sstack[sp - 1];
        for (;;) {
            // retrieve state number from top of stack
            state = newState;               // sstack[sp - 1];

            // use default actions if available
            if (this.defaultActions[state]) {
                action = 2;
                newState = this.defaultActions[state];
            } else {
                // The single \`==\` condition below covers both these \`===\` comparisons in a single
                // operation:
                //
                //     if (symbol === null || typeof symbol === 'undefined') ...
                if (!symbol) {
                    symbol = lex();
                }
                // read action for current state and first input
                t = (table[state] && table[state][symbol]) || NO_ACTION;
                newState = t[1];
                action = t[0];

                if (yydebug) yydebug('after FETCH/LEX: ', { symbol: symbol, symbolID: this.terminals_ && this.terminals_[symbol], state: state, newState: newState, recovering: recovering, action: action });

//_handle_error_with_recovery:                // run this code when the grammar includes error recovery rules

                // handle parse error
                if (!action) {
                    // first see if there's any chance at hitting an error recovery rule:
                    var error_rule_depth = locateNearestErrorRecoveryRule(state);
                    var errStr = null;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    if (!recovering) {
                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                        } else {
                            errStr = 'Parse error: ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, (error_rule_depth >= 0));

                        // DO NOT cleanup the old one before we start the new error info track:
                        // the old one will *linger* on the error stack and stay alive until we 
                        // invoke the parser's cleanup API!
                        recoveringErrorInfo = this.shallowCopyErrorInfo(p);

                        r = this.parseError(p.errStr, p, this.JisonParserError);

                        if (yydebug) yydebug('error recovery rule detected: ', { error_rule_depth: error_rule_depth, error: p.errStr, error_hash: p });
                        // Protect against overly blunt userland \`parseError\` code which *sets*
                        // the \`recoverable\` flag without properly checking first:
                        // we always terminate the parse when there's no recovery rule available anyhow!
                        if (!p.recoverable || error_rule_depth < 0) {
                            if (typeof r !== 'undefined') {
                                retval = r;
                            }
                            break;
                        } else {
                            // TODO: allow parseError callback to edit symbol and or state at the start of the error recovery process...
                        }
                    }

                    if (yydebug) yydebug('after ERROR DETECT: ', { error_rule_depth: error_rule_depth, error: p.errStr, error_hash: p });

                    var esp = recoveringErrorInfo.info_stack_pointer;

                    // just recovered from another error
                    if (recovering === ERROR_RECOVERY_TOKEN_DISCARD_COUNT && error_rule_depth >= 0) {
                        // SHIFT current lookahead and grab another
                        recoveringErrorInfo.symbol_stack[esp] = symbol;
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(lexer.yytext);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                        recoveringErrorInfo.state_stack[esp] = newState; // push state
                        ++esp;

                        // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                        yyleng = lexer.yyleng;
                        yytext = lexer.yytext;
                        yylineno = lexer.yylineno;
                        yyloc = lexer.yylloc;

                        preErrorSymbol = 0;
                        symbol = lex();

                        if (yydebug) yydebug('after ERROR RECOVERY-3: ', { symbol: symbol, symbolID: this.terminals_ && this.terminals_[symbol] });
                    }

                    // try to recover from error
                    if (error_rule_depth < 0) {
                        ASSERT(recovering > 0, "line 897");
                        recoveringErrorInfo.info_stack_pointer = esp;

                        // barf a fatal hairball when we're out of look-ahead symbols and none hit a match
                        // while we are still busy recovering from another error:
                        var po = this.__error_infos[this.__error_infos.length - 1];

                        // Report error
                        if (typeof lexer.yylineno === 'number') {
                            errStr = 'Parsing halted on line ' + (lexer.yylineno + 1) + ' while starting to recover from another error';
                        } else {
                            errStr = 'Parsing halted while starting to recover from another error';
                        }

                        if (po) {
                            errStr += ' -- previous error which resulted in this fatal result: ' + po.errStr;
                        } else {
                            errStr += ': ';
                        }

                        if (typeof lexer.showPosition === 'function') {
                            errStr += '\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                        }
                        if (expected.length) {
                            errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                        } else {
                            errStr += 'Unexpected ' + errSymbolDescr;
                        }

                        p = this.constructParseErrorInfo(errStr, null, expected, false);
                        if (po) {
                            p.extra_error_attributes = po;
                        }

                        r = this.parseError(p.errStr, p, this.JisonParserError);
                        if (typeof r !== 'undefined') {
                            retval = r;
                        }
                        break;
                    }

                    preErrorSymbol = (symbol === TERROR ? 0 : symbol); // save the lookahead token
                    symbol = TERROR;            // insert generic error symbol as new lookahead

                    const EXTRA_STACK_SAMPLE_DEPTH = 3;

                    // REDUCE/COMBINE the pushed terms/tokens to a new ERROR token:
                    recoveringErrorInfo.symbol_stack[esp] = preErrorSymbol;
                    if (errStr) {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            errStr: errStr,
                            errorSymbolDescr: errSymbolDescr,
                            expectedStr: expected,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                        if (yydebug) yydebug('Error recovery process: pushed error info item on the info stack: ', {
                            item: vstack[sp],
                            sp,
                            esp,
                            vstack,
                            stack,
                            sstack,
                            combineState: NO_ACTION[1]
                        });
                    } else {
                        recoveringErrorInfo.value_stack[esp] = {
                            yytext: shallow_copy(lexer.yytext),
                            errorRuleDepth: error_rule_depth,
                            stackSampleLength: error_rule_depth + EXTRA_STACK_SAMPLE_DEPTH
                        };
                    }
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(lexer.yylloc);
                    recoveringErrorInfo.state_stack[esp] = newState || NO_ACTION[1];

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    yyval.$ = recoveringErrorInfo;
                    yyval._$ = undefined;

                    yyrulelen = error_rule_depth;

                    if (yydebug) yydebug('Error recovery process: performAction: COMBINE: ', {
                        yyval, yytext, sp, pop_size: yyrulelen, vstack, stack, sstack,
                        combineState: NO_ACTION[1]
                    });
                    r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, NO_ACTION[1], sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                    if (typeof r !== 'undefined') {
                        retval = r;
                        break;
                    }

                    // pop off stack
                    sp -= yyrulelen;

                    // and move the top entries + discarded part of the parse stacks onto the error info stack:
                    for (var idx = sp - EXTRA_STACK_SAMPLE_DEPTH, top = idx + yyrulelen; idx < top; idx++, esp++) {
                        recoveringErrorInfo.symbol_stack[esp] = stack[idx];
                        recoveringErrorInfo.value_stack[esp] = shallow_copy(vstack[idx]);
                        recoveringErrorInfo.location_stack[esp] = copy_yylloc(lstack[idx]);
                        recoveringErrorInfo.state_stack[esp] = sstack[idx];
                    }

                    recoveringErrorInfo.symbol_stack[esp] = TERROR;
                    recoveringErrorInfo.value_stack[esp] = shallow_copy(yyval.$);
                    recoveringErrorInfo.location_stack[esp] = copy_yylloc(yyval._$);

                    // goto new state = table[STATE][NONTERMINAL]
                    newState = sstack[sp - 1];

                    if (this.defaultActions[newState]) {
                        recoveringErrorInfo.state_stack[esp] = this.defaultActions[newState];
                    } else {
                        t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                        recoveringErrorInfo.state_stack[esp] = t[1];
                    }

                    ++esp;
                    recoveringErrorInfo.info_stack_pointer = esp;

                    // allow N (default: 3) real symbols to be shifted before reporting a new error
                    recovering = ERROR_RECOVERY_TOKEN_DISCARD_COUNT;

                    if (yydebug) yydebug('after ERROR POP: ', { error_rule_depth: error_rule_depth, symbol: symbol, preErrorSymbol: preErrorSymbol });

                    // Now duplicate the standard parse machine here, at least its initial
                    // couple of rounds until the TERROR symbol is **pushed onto the parse stack**,
                    // as we wish to push something special then!
                    //
                    // Run the state machine in this copy of the parser state machine
                    // until we *either* consume the error symbol (and its related information)
                    // *or* we run into another error while recovering from this one
                    // *or* we execute a \`reduce\` action which outputs a final parse
                    // result (yes, that MAY happen!).
                    //
                    // We stay in this secondary parse loop until we have completed
                    // the *error recovery phase* as the main parse loop (further below)
                    // is optimized for regular parse operation and DOES NOT cope with
                    // error recovery *at all*.
                    //
                    // We call the secondary parse loop just below the "slow parse loop",
                    // while the main parse loop, which is an almost-duplicate of this one,
                    // yet optimized for regular parse operation, is called the "fast
                    // parse loop".
                    //
                    // Compare this to \`bison\` & (vanilla) \`jison\`, both of which have
                    // only a single parse loop, which handles everything. Our goal is
                    // to eke out every drop of performance in the main parse loop...

                    ASSERT(recoveringErrorInfo, "line 1049");
                    ASSERT(symbol === TERROR, "line 1050");
                    ASSERT(!action, "line 1051");
                    var errorSymbolFromParser = true;
                    for (;;) {
                        // retrieve state number from top of stack
                        state = newState;               // sstack[sp - 1];

                        // use default actions if available
                        if (this.defaultActions[state]) {
                            action = 2;
                            newState = this.defaultActions[state];
                        } else {
                            // The single \`==\` condition below covers both these \`===\` comparisons in a single
                            // operation:
                            //
                            //     if (symbol === null || typeof symbol === 'undefined') ...
                            if (!symbol) {
                                symbol = lex();
                                // **Warning: Edge Case**: the *lexer* may produce
                                // TERROR tokens of its own volition: *those* TERROR
                                // tokens should be treated like *regular tokens*
                                // i.e. tokens which have a lexer-provided \`yyvalue\`
                                // and \`yylloc\`:
                                errorSymbolFromParser = false;
                            }
                            // read action for current state and first input
                            t = (table[state] && table[state][symbol]) || NO_ACTION;
                            newState = t[1];
                            action = t[0];

                            if (yydebug) yydebug('after FETCH/LEX: ', { symbol: symbol, symbolID: this.terminals_ && this.terminals_[symbol], state: state, newState: newState, recovering: recovering, action: action });

                            // encountered another parse error? If so, break out to main loop
                            // and take it from there!
                            if (!action) {
                                if (yydebug) yydebug('**NESTED ERROR DETECTED** while still recovering from previous error');

                                ASSERT(recoveringErrorInfo, "line 1087");

                                // Prep state variables so that upon breaking out of
                                // this "slow parse loop" and hitting the \`continue;\`
                                // statement in the outer "fast parse loop" we redo
                                // the exact same state table lookup as the one above
                                // so that the outer=main loop will also correctly
                                // detect the 'parse error' state (\`!action\`) we have
                                // just encountered above.
                                newState = state;
                                break;
                            }
                        }

                        if (yydebug) yydebug('::: SLOW ERROR RECOVERY PHASE CYCLE action: ' + (action === 1 ? 'shift token ' + symbol + ' (then go to state ' + newState + ')' : action === 2 ? 'reduce by rule: ' + newState + (function __print_rule(nt, state) {
                            if (!nt || !nt.states || !nt.rules)
                              return '';
                            var rulename = nt.states[state];
                            var rulespec = nt.rules[rulename][state];
                            return ' (' + rulespec.symbol + ' := ' + rulespec.handle + ')';
                        })(this.nonterminals_, newState) : action === 3 ? 'accept' : '???unexpected???'), { action: action, newState: newState, recovering: recovering, symbol: symbol });

                        switch (action) {
                        // catch misc. parse failures:
                        default:
                            // this shouldn't happen, unless resolve defaults are off
                            //
                            // SILENTLY SIGNAL that the outer "fast parse loop" should
                            // take care of this internal error condition:
                            // prevent useless code duplication now/here.
                            break;

                        // shift:
                        case 1:
                            stack[sp] = symbol;
                            // ### Note/Warning ###
                            //
                            // The *lexer* may also produce TERROR tokens on its own,
                            // so we specifically test for the TERROR we did set up
                            // in the error recovery logic further above!
                            if (symbol === TERROR && errorSymbolFromParser) {
                                // Push a special value onto the stack when we're
                                // shifting the \`error\` symbol that is related to the
                                // error we're recovering from.
                                ASSERT(recoveringErrorInfo, "line 1131");
                                vstack[sp] = recoveringErrorInfo;
                                lstack[sp] = this.yyMergeLocationInfo(null, null, recoveringErrorInfo.loc, lexer.yylloc, true);
                            } else {
                                ASSERT(symbol !== 0, "line 1135");
                                ASSERT(preErrorSymbol === 0, "line 1136");
                                vstack[sp] = lexer.yytext;
                                lstack[sp] = copy_yylloc(lexer.yylloc);
                            }
                            sstack[sp] = newState; // push state

                            ++sp;
                            symbol = 0;
                            // **Warning: Edge Case**: the *lexer* may have produced
                            // TERROR tokens of its own volition: *those* TERROR
                            // tokens should be treated like *regular tokens*
                            // i.e. tokens which have a lexer-provided \`yyvalue\`
                            // and \`yylloc\`:
                            errorSymbolFromParser = false;
                            if (!preErrorSymbol) { // normal execution / no error
                                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                                yyleng = lexer.yyleng;
                                yytext = lexer.yytext;
                                yylineno = lexer.yylineno;
                                yyloc = lexer.yylloc;

                                if (recovering > 0) {
                                    recovering--;
                                    if (yydebug) yydebug('... SHIFT:error rule matching: ', { recovering: recovering, symbol: symbol });
                                }
                            } else {
                                // error just occurred, resume old lookahead f/ before error, *unless* that drops us straight back into error mode:
                                ASSERT(recovering > 0, "line 1163");
                                symbol = preErrorSymbol;
                                preErrorSymbol = 0;
                                if (yydebug) yydebug('... SHIFT:error recovery: ', { recovering: recovering, symbol: symbol });
                                // read action for current state and first input
                                t = (table[newState] && table[newState][symbol]) || NO_ACTION;
                                if (!t[0] || symbol === TERROR) {
                                    // forget about that symbol and move forward: this wasn't a 'forgot to insert' error type where
                                    // (simple) stuff might have been missing before the token which caused the error we're
                                    // recovering from now...
                                    //
                                    // Also check if the LookAhead symbol isn't the ERROR token we set as part of the error
                                    // recovery, for then this we would we idling (cycling) on the error forever.
                                    // Yes, this does not take into account the possibility that the *lexer* may have
                                    // produced a *new* TERROR token all by itself, but that would be a very peculiar grammar!
                                    if (yydebug) yydebug('... SHIFT:error recovery: re-application of old symbol doesn\\'t work: instead, we\\'re moving forward now. ', { recovering: recovering, symbol: symbol });
                                    symbol = 0;
                                }
                            }

                            // once we have pushed the special ERROR token value,
                            // we REMAIN in this inner, "slow parse loop" until
                            // the entire error recovery phase has completed.
                            //
                            // ### Note About Edge Case ###
                            //
                            // Userland action code MAY already have 'reset' the
                            // error recovery phase marker \`recovering\` to ZERO(0)
                            // while the error symbol hasn't been shifted onto
                            // the stack yet. Hence we only exit this "slow parse loop"
                            // when *both* conditions are met!
                            ASSERT(preErrorSymbol === 0, "line 1194");
                            if (recovering === 0) {
                                break;
                            }
                            continue;

                        // reduce:
                        case 2:
                            this_production = this.productions_[newState - 1];  // \`this.productions_[]\` is zero-based indexed while states start from 1 upwards...
                            yyrulelen = this_production[1];

                            if (yydebug) yydebug('~~~ REDUCE: ', { pop_size: yyrulelen, newState: newState, recovering: recovering, symbol: symbol });

                            r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, newState, sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                            if (typeof r !== 'undefined') {
                                // signal end of error recovery loop AND end of outer parse loop
                                action = 3;
                                sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up \`retval\` parser return value.
                                retval = r;
                                break;
                            }

                            // pop off stack
                            sp -= yyrulelen;

                            // don't overwrite the \`symbol\` variable: use a local var to speed things up:
                            var ntsymbol = this_production[0];    // push nonterminal (reduce)
                            stack[sp] = ntsymbol;
                            vstack[sp] = yyval.$;
                            lstack[sp] = yyval._$;
                            // goto new state = table[STATE][NONTERMINAL]
                            newState = table[sstack[sp - 1]][ntsymbol];
                            sstack[sp] = newState;
                            ++sp;
                            if (yydebug) yydebug('REDUCED: ', { newState: newState, recovering: recovering, symbol: symbol });
                            continue;

                        // accept:
                        case 3:
                            retval = true;
                            // Return the \`$accept\` rule's \`$$\` result, if available.
                            //
                            // Also note that JISON always adds this top-most \`$accept\` rule (with implicit,
                            // default, action):
                            //
                            //     $accept: <startSymbol> $end
                            //                  %{ $$ = $1; @$ = @1; %}
                            //
                            // which, combined with the parse kernel's \`$accept\` state behaviour coded below,
                            // will produce the \`$$\` value output of the <startSymbol> rule as the parse result,
                            // IFF that result is *not* \`undefined\`. (See also the parser kernel code.)
                            //
                            // In code:
                            //
                            //                  %{
                            //                      @$ = @1;            // if location tracking support is included
                            //                      if (typeof $1 !== 'undefined')
                            //                          return $1;
                            //                      else
                            //                          return true;           // the default parse result if the rule actions don't produce anything
                            //                  %}
                            sp--;
                            if (sp >= 0 && typeof vstack[sp] !== 'undefined') {
                                retval = vstack[sp];
                            }
                            sp = -2;      // magic number: signal outer "fast parse loop" ACCEPT state that we already have a properly set up \`retval\` parser return value.
                            break;
                        }

                        // break out of loop: we accept or fail with error
                        break;
                    }

                    // should we also break out of the regular/outer parse loop,
                    // i.e. did the parser already produce a parse result in here?!
                    // *or* did we hit an unsupported parse state, to be handled
                    // in the \`switch/default\` code further below?
                    ASSERT(action !== 2, "line 1272");
                    if (!action || action === 1) {
                        continue;
                    }
                }

//_handle_error_no_recovery:                  // run this code when the grammar does not include any error recovery rules

                // handle parse error
                if (!action) {
                    var errStr;
                    var errSymbolDescr = (this.describeSymbol(symbol) || symbol);
                    var expected = this.collect_expected_token_set(state);

                    // Report error
                    if (typeof lexer.yylineno === 'number') {
                        errStr = 'Parse error on line ' + (lexer.yylineno + 1) + ': ';
                    } else {
                        errStr = 'Parse error: ';
                    }
                    if (typeof lexer.showPosition === 'function') {
                        errStr += '\\n' + lexer.showPosition(79 - 10, 10) + '\\n';
                    }
                    if (expected.length) {
                        errStr += 'Expecting ' + expected.join(', ') + ', got unexpected ' + errSymbolDescr;
                    } else {
                        errStr += 'Unexpected ' + errSymbolDescr;
                    }
                    // we cannot recover from the error!
                    p = this.constructParseErrorInfo(errStr, null, expected, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }

//_handle_error_end_of_section:                  // this concludes the error recovery / no error recovery code section choice above

            }

            if (yydebug) yydebug('::: MAIN CYCLE action: ' + (action === 1 ? 'shift token ' + symbol + ' (then go to state ' + newState + ')' : action === 2 ? 'reduce by rule: ' + newState + (function __print_rule(nt, state) {
                if (!nt || !nt.states || !nt.rules)
                  return '';
                var rulename = nt.states[state];
                var rulespec = nt.rules[rulename][state];
                return ' (' + rulespec.symbol + ' := ' + rulespec.handle + ')';
            })(this.nonterminals_, newState) : action === 3 ? 'accept' : '???unexpected???'), { action: action, newState: newState, recovering: recovering, symbol: symbol });

            switch (action) {
            // catch misc. parse failures:
            default:
                // this shouldn't happen, unless resolve defaults are off
                if (action instanceof Array) {
                    p = this.constructParseErrorInfo('Parse Error: multiple actions possible at state: ' + state + ', token: ' + symbol, null, null, false);
                    r = this.parseError(p.errStr, p, this.JisonParserError);
                    if (typeof r !== 'undefined') {
                        retval = r;
                    }
                    break;
                }
                // Another case of better safe than sorry: in case state transitions come out of another error recovery process
                // or a buggy LUT (LookUp Table):
                p = this.constructParseErrorInfo('Parsing halted. No viable error recovery approach available due to internal system failure.', null, null, false);
                r = this.parseError(p.errStr, p, this.JisonParserError);
                if (typeof r !== 'undefined') {
                    retval = r;
                }
                break;

            // shift:
            case 1:
                stack[sp] = symbol;
                vstack[sp] = lexer.yytext;
                lstack[sp] = copy_yylloc(lexer.yylloc);
                sstack[sp] = newState; // push state

                ++sp;
                symbol = 0;

                ASSERT(preErrorSymbol === 0, "line 1352");         // normal execution / no error
                ASSERT(recovering === 0, "line 1353");             // normal execution / no error

                // Pick up the lexer details for the current symbol as that one is not 'look-ahead' any more:
                yyleng = lexer.yyleng;
                yytext = lexer.yytext;
                yylineno = lexer.yylineno;
                yyloc = lexer.yylloc;
                continue;

            // reduce:
            case 2:
                ASSERT(preErrorSymbol === 0, "line 1364");         // normal execution / no error
                ASSERT(recovering === 0, "line 1365");             // normal execution / no error

                this_production = this.productions_[newState - 1];  // \`this.productions_[]\` is zero-based indexed while states start from 1 upwards...
                yyrulelen = this_production[1];

                if (yydebug) yydebug('~~~ REDUCE: ', { pop_size: yyrulelen, newState: newState, recovering: recovering, symbol: symbol });

                r = this.performAction.call(yyval, yytext, yyleng, yylineno, yyloc, newState, sp - 1, yyrulelen, vstack, lstack, stack, sstack);

                if (typeof r !== 'undefined') {
                    retval = r;
                    break;
                }

                // pop off stack
                sp -= yyrulelen;

                // don't overwrite the \`symbol\` variable: use a local var to speed things up:
                var ntsymbol = this_production[0];    // push nonterminal (reduce)
                stack[sp] = ntsymbol;
                vstack[sp] = yyval.$;
                lstack[sp] = yyval._$;
                // goto new state = table[STATE][NONTERMINAL]
                newState = table[sstack[sp - 1]][ntsymbol];
                sstack[sp] = newState;
                ++sp;
                if (yydebug) yydebug('REDUCED: ', { newState: newState, recovering: recovering, symbol: symbol });
                continue;

            // accept:
            case 3:
                if (sp !== -2) {
                    retval = true;
                    // Return the \`$accept\` rule's \`$$\` result, if available.
                    //
                    // Also note that JISON always adds this top-most \`$accept\` rule (with implicit,
                    // default, action):
                    //
                    //     $accept: <startSymbol> $end
                    //                  %{ $$ = $1; @$ = @1; %}
                    //
                    // which, combined with the parse kernel's \`$accept\` state behaviour coded below,
                    // will produce the \`$$\` value output of the <startSymbol> rule as the parse result,
                    // IFF that result is *not* \`undefined\`. (See also the parser kernel code.)
                    //
                    // In code:
                    //
                    //                  %{
                    //                      @$ = @1;            // if location tracking support is included
                    //                      if (typeof $1 !== 'undefined')
                    //                          return $1;
                    //                      else
                    //                          return true;           // the default parse result if the rule actions don't produce anything
                    //                  %}
                    sp--;
                    if (typeof vstack[sp] !== 'undefined') {
                        retval = vstack[sp];
                    }
                }
                break;
            }

            // break out of loop: we accept or fail with error
            break;
        }
    } catch (ex) {
        // report exceptions through the parseError callback too, but keep the exception intact
        // if it is a known parser or lexer error which has been thrown by parseError() already:
        if (ex instanceof this.JisonParserError) {
            throw ex;
        }
        else if (lexer && typeof lexer.JisonLexerError === 'function' && ex instanceof lexer.JisonLexerError) {
            throw ex;
        }
        else {
            p = this.constructParseErrorInfo('Parsing aborted due to exception.', ex, null, false);
            retval = false;
            r = this.parseError(p.errStr, p, this.JisonParserError);
            if (typeof r !== 'undefined') {
                retval = r;
            }
        }
    } finally {
        retval = this.cleanupAfterParse(retval, true, true);
        this.__reentrant_call_depth--;
    }   // /finally

    return retval;
}`;
// --- END parser kernel ---


/*
 * LR(0) Parser
 */

var lr0 = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
    type: 'LR(0)',
    afterconstructor: function lr0_afterconstructor() {
        this.buildTable();
    }
});

var LR0Generator = Jison.LR0Generator = lr0.construct();

/*
 * Simple LALR(1)
 */

var lalr = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
    type: 'LALR(1)',

    afterconstructor: function lalr_afterconstructor() {
        var self = this;

        if (this.DEBUG) {
            this.mix(lrGeneratorDebug, lalrGeneratorDebug); // mixin debug methods
        }

        for (var round = 1; /* infinite loop if it weren't for the `break`s at the end */ ; round++) {
            this.states = this.canonicalCollection();

            if (this.DEBUG || devDebug) {
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER canonicalCollection:');
                this.displayFollowSets();
                Jison.print('\n');
            }

            this.terms_ = {};

            var newg = this.newg = typal.beget(lookaheadMixin, {
                oldg: this,
                trace: this.trace,
                nterms_: {},
                DEBUG: false,
                go_: function (productionSymbol, productionHandle) {
                    var stateNum = productionSymbol.split(':')[0]; // grab state #
                    assert(stateNum == +stateNum);
                    stateNum = +stateNum;
                    productionHandle = productionHandle.map(function (rhsElem) {
                        return rhsElem.slice(rhsElem.indexOf(':') + 1);
                    });
                    return this.oldg.go(stateNum, productionHandle, productionSymbol);
                }
            });
            newg.nonterminals = {};
            newg.productions = [];

            //this.inadequateStates = [];

            // if true, only lookaheads in inadequate states are computed (faster, larger table)
            // if false, lookaheads for all reductions will be computed (slower, smaller table)
            //
            // WARNING: using this has a negative effect on your error reports:
            //          a lot of 'expected' symbols are reported which are not in the real FOLLOW set,
            //          resulting in 'illogical' error messages!
            this.onDemandLookahead = !!this.options.onDemandLookahead;
            if (devDebug || this.DEBUG) Jison.print('LALR: using on-demand look-ahead: ', (this.onDemandLookahead ? 'yes' : 'no'));

            this.buildNewGrammar();

            if (devDebug || this.DEBUG) {
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER buildNewGrammar: NEW GRAMMAR');
                newg.displayFollowSets();
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER buildNewGrammar: ORIGINAL GRAMMAR');
                this.displayFollowSets();
            }

            newg.computeLookaheads();

            // backprop `nullable` value for each nonterminal and production back to original grammar:
            each(newg.nonterminals, function (newg_nt, t) {
                // extract original symbol:
                var sym;
                var a = newg_nt.symbol.split(':');
                if (a.length === 1 || a[0] === '') {
                    sym = newg_nt.symbol;
                } else {
                    a.shift();
                    sym = a.join(':');
                }
                if (self.nonterminals[sym] && newg_nt.nullable) {
                    self.nonterminals[sym].nullable = true;
                } else {
                    //console.error('cannot find symbol ', sym);
                }
            });

            if (devDebug || this.DEBUG) {
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads: NEW GRAMMAR');
                newg.displayFollowSets();
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads: ORIGINAL GRAMMAR');
                this.displayFollowSets();
            }

            this.unionLookaheads();

            if (devDebug || this.DEBUG) {
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER unionLookaheads: NEW GRAMMAR');
                newg.displayFollowSets();
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER unionLookaheads: ORIGINAL GRAMMAR');
                this.displayFollowSets();
            }

            this.table = this.parseTable(this.states);

            if (devDebug || this.DEBUG) {
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable: NEW GRAMMAR');
                newg.displayFollowSets();
                Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable: ORIGINAL GRAMMAR');
                this.displayFollowSets();
            }

            // When some productions are flagged as conflicting, we redo the G' generation and consequent union-ing of the productions
            // in the `.goes[]` arrays.
            //
            // Also quit when we're at the end of the conflict resolution round (which is round #2)
            if (this.conflicts === 0 || this.conflict_fixing_round || !this.options.hasPartialLrUpgradeOnConflict) {
                break;
            }

            if (devDebug > 4) {
                Jison.print('\n-------------------------------------------\nNew round to fix conflicts? Completed round:', {
                    round: round,
                    conflict_fixing_round: this.conflict_fixing_round,
                    states: this.conflict_states_LU,
                    productions: this.conflict_productions_LU
                });
            } else {
                Jison.print('\n'
                    + '----------------------------------- NOTICE -------------------------------\n'
                    + 'Attempting to resolve the unresolved conflicts in partial LR mode...\n\n'
                    + 'When no conflicts are reported in the next round below, your grammar is\n'
                    + 'accepted as mixed LR/LALR and should work as expected.\n'
                    + '--------------------------------------------------------------------------\n\n');
            }

            this.conflict_fixing_round = true;

            // and reset the conflict trackers, which we do not use to attempt to fix the conflict in round #2:
            this.conflicts = 0;
            this.new_conflicts_found_this_round = 0;
            this.conflicting_states = [];
            this.resolutions = [];
        }

        this.defaultActions = findDefaults(this.table, this.hasErrorRecovery);
        cleanupTable(this.table);

        traceStates(this.trace, this.states, 'at the end of the LALR constructor, after cleanupTable() and findDefaults()');
    },

    lookAheads: function LALR_lookaheads(state, item) {
        return (this.onDemandLookahead && !state.inadequate) ? this.terminals : item.follows;
    },

    go: function LALR_go(stateNum, productionHandle, productionSymbol) {
        assert(typeof stateNum === 'number');
        var endStateNum = stateNum;
        for (var i = 0; i < productionHandle.length; i++) {
            endStateNum = this.states.item(endStateNum).edges[productionHandle[i]] || endStateNum;
        }
        if (devDebug > 0) {
            Jison.print('GO: ', {
                stateNum: stateNum,
                symbol: productionSymbol,
                endState: endStateNum
            });
        }
        return endStateNum;
    },

    goPath: function LALR_goPath(stateNum, productionHandle, productionSymbol) {
        assert(typeof stateNum === 'number');
        var endStateNum = stateNum,
            t,
            path$$1 = [];
        for (var i = 0; i < productionHandle.length; i++) {
            t = productionHandle[i] ? endStateNum + ':' + productionHandle[i] /* + ':' + productionSymbol */ : '';
            if (t) {
                this.newg.nterms_[t] = endStateNum;
            }
            path$$1.push(t);
            endStateNum = this.states.item(endStateNum).edges[productionHandle[i]] || endStateNum;
            assert(t ? typeof this.terms_[t] === 'undefined' || this.terms_[t] === productionHandle[i] : true);
            this.terms_[t] = productionHandle[i];
        }
        if (devDebug > 0) {
            Jison.print('GOPATH: ', {
                stateNum: stateNum,
                symbol: productionSymbol,
                path: path$$1,
                endState: endStateNum
            });
        }
        return {
            path: path$$1,
            endState: endStateNum
        };
    },

    // every disjoint reduction of a nonterminal becomes a production in G'
    buildNewGrammar: function LALR_buildNewGrammar() {
        var self = this,
            newg = this.newg;

        this.states.forEach(function (state, i) {
            i = +i;
            state.forEach(function LALR_buildNewHandle(item) {
                if (item.dotPosition === 0) {
                    // new symbols are a combination of state and transition symbol
                    var symbol = i + ':' + item.production.symbol;
                    assert(typeof self.terms_[symbol] === 'undefined' || self.terms_[symbol] === item.production.symbol);
                    self.terms_[symbol] = item.production.symbol;
                    newg.nterms_[symbol] = i;
                    if (!newg.nonterminals[symbol]) {
                        newg.nonterminals[symbol] = new Nonterminal(symbol);
                    }
                    var pathInfo = self.goPath(i, item.production.handle, item.production.symbol);
                    var p = new Production(symbol, pathInfo.path, newg.productions.length);
                    newg.productions.push(p);
                    newg.nonterminals[symbol].productions.push(p);

                    // store the transition that gets 'backed up to' after reduction on path
                    var handle = item.production.handle.join(' ');
                    if (self.conflict_fixing_round && self.conflict_states_LU[i]) {
                        // handle += ':C' + i;
                    }
                    if (self.conflict_fixing_round && self.conflict_productions_LU[item.production.id]) {
                        handle += ':P' + item.production.id;
                    }

                    var goes = self.states.item(pathInfo.endState).goes;
                    if (!goes[handle]) {
                        goes[handle] = [];
                    }
                    goes[handle].push(symbol);

                    if (devDebug > 2) Jison.print('new production:', {
                        prod_id: item.production.id,
                        new_prod_id: p.id,
                        state: state,
                        stateNum: i,
                        production: p,
                        item_production: item.production,
                        goes: goes,
                        handle: handle,
                        symbol: symbol,
                        pathInfo: pathInfo
                    });
                }
            });
            // if (state.inadequate) {
            //     self.inadequateStates.push(i);
            // }
        });
    },

    unionLookaheads: function LALR_unionLookaheads() {
        var self = this,
            newg = this.newg;
        // var states = !!this.onDemandLookahead ? this.inadequateStates : this.states;

        var these_states = this.states;
        these_states.forEach(function union_states_forEach(state, i) {
            i = +i;
            //assert(state.inadequate ? these_states.inadequate : true);
            var treat_me = (self.onDemandLookahead ? these_states.inadequate || state.inadequate : true);
            if (state.reductions.length && treat_me) {
                state.reductions.forEach(function union_reduction_forEach(item) {
                    var follows = {};
                    for (var k = 0; k < item.follows.length; k++) {
                        follows[item.follows[k]] = true;
                    }
                    var handle = item.production.handle.join(' ');
                    if (self.conflict_fixing_round && self.conflict_states_LU[i]) {
                        // handle += ':C' + i;
                    }
                    if (self.conflict_fixing_round && self.conflict_productions_LU[item.production.id]) {
                        handle += ':P' + item.production.id;
                    }
                    if (!state.goes[handle]) {
                        state.goes[handle] = [];
                    }

                    if (devDebug > 2) Jison.print('not-yet-unioned item', {
                        handle: handle,
                        item: item,
                        follows: follows,
                        goes: state.goes,
                        state: state,
                        stateNum: i
                    });

                    state.goes[handle].forEach(function reduction_goes_forEach(symbol) {
                        newg.nonterminals[symbol].follows.forEach(function goes_follows_forEach(symbol) {
                            var terminal = self.terms_[symbol];
                            if (!follows[terminal]) {
                                follows[terminal] = true;

                                if (devDebug > 2) Jison.print('adding to FOLLOW set (union)', {
                                    terminal: terminal,
                                    nonterminal: symbol,
                                    in_follows: newg.nonterminals[symbol],
                                    out_follows: item.follows
                                });

                                item.follows.push(terminal);
                            }
                        });
                    });

                    if (devDebug > 2) Jison.print('unioned item', item);
                });
            }
        });
    }
});

var LALRGenerator = Jison.LALRGenerator = lalr.construct();

// LALR generator debug mixin

var lalrGeneratorDebug = {
    beforebuildNewGrammar: function () {
        this.trace(this.states.size() + ' states.');
        this.trace('Building lookahead grammar.');
    },
    beforeunionLookaheads: function () {
        this.trace('Computing lookaheads.');
    },
    afterbuildNewGrammar: function () {
        traceStates(this.trace, this.states, 'after LALR::buildNewGrammar()');
    },
    afterunionLookaheads: function () {
        traceStates(this.trace, this.states, 'after LALR::unionLookaheads()');
    },
    aftercomputeLookaheads: function () {
        traceStates(this.trace, this.states, 'after LALR::computeLookaheads()');
    },
    aftercanonicalCollection: function (states /* as produced by `this.canonicalCollection()` */ ) {
        traceStates(this.trace, states, 'as produced by LALR::canonicalCollection()');
    }
};

/*
 * Lookahead parser definitions
 *
 * Define base type
 */
var lrLookaheadGenerator = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
    afterconstructor: function lr_aftercontructor() {
        this.computeLookaheads();

        if (devDebug || this.DEBUG) {
            Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads:');
            this.displayFollowSets();
            Jison.print('\n');
        }

        this.buildTable();
    }
});

/*
 * SLR Parser
 */
var SLRGenerator = Jison.SLRGenerator = lrLookaheadGenerator.construct({
    type: 'SLR(1)',

    lookAheads: function SLR_lookAhead(state, item) {
        return this.nonterminals[item.production.symbol].follows;
    }
});


/*
 * LR(1) Parser
 */
var lr1 = lrLookaheadGenerator.beget({
    type: 'Canonical LR(1)',

    lookAheads: function LR_lookAheads(state, item) {
        return item.follows;
    },

    Item: lrGeneratorMixin.Item.prototype.construct({
        afterconstructor: function () {
            this.id = this.production.id + '#' + this.dotPosition + '#' + this.follows.sort().join(',');
        },
        eq: function (e) {
            return e.id === this.id;
        }
    }),

    closureOperation: function LR_ClosureOperation(itemSet) {
        var closureSet = new this.ItemSet();
        var self = this;

        var set = itemSet,
            itemQueue;

        do {
            itemQueue = new Set();
            closureSet = closureSet.concat(set);
            set.forEach(function LR_AddItemToClosureSets(item) {
                var symbol = item.markedSymbol;
                var b, r;

                // if token is a nonterminal, recursively add closures
                if (symbol && self.nonterminals[symbol]) {
                    r = item.remainingHandle();
                    b = self.first(r);
                    if (b.length === 0 || item.production.nullable || self.nullable(r)) {
                        b = b.concat(item.follows);
                    }
                    self.nonterminals[symbol].productions.forEach(function (production) {
                        var newItem = new self.Item(production, 0, b);
                        if (!closureSet.contains(newItem) && !itemQueue.contains(newItem)) {
                            itemQueue.push(newItem);
                        }
                    });
                } else if (!symbol) {
                    // reduction
                    closureSet.reductions.push(item);
                }
            });

            set = itemQueue;
        } while (!itemQueue.isEmpty());

        return closureSet;
    }
});

var LR1Generator = Jison.LR1Generator = lr1.construct();

/*
 * LL Parser
 */
var ll = generator.beget(lookaheadMixin, generatorMixin, lrGeneratorMixin, {
    type: 'LL(1)',

    afterconstructor: function ll_aftercontructor() {
        this.computeLookaheads();

        if (devDebug || this.DEBUG) {
            Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER computeLookaheads:');
            this.displayFollowSets();
        }

        this.table = this.parseTable(this.productions);

        if (devDebug || this.DEBUG) {
            Jison.print('\n-------------------------------------------\nSymbol/Follow sets AFTER parseTable:');
            this.displayFollowSets();
        }

        this.defaultActions = {}; // findDefaults(this.table, this.hasErrorRecovery);
        //cleanupTable(this.table);
    },

    parseTable: function ll_ParseTable(productions) {
        var table = {},
            symbols_ = this.symbols_,
            self = this;

        productions.forEach(function (production, i) {
            var row = table[production.symbol] || {};
            var tokens = production.first;
            if (self.nullable(production.handle)) {
                tokens = union(tokens, self.nonterminals[production.symbol].follows);
            }
            tokens.forEach(function (token) {
                if (row[token]) {
                    row[token].push(i);
                    self.conflicts++;
                } else {
                    row[token] = [i];
                }
            });
            table[production.symbol] = row;
            production.first = tokens;
        });

        return table;
    }
});

var LLGenerator = Jison.LLGenerator = ll.construct();

Jison.Generator = function Jison_Generator(grammar, optionalLexerSection, options) {
    // pick the correct argument for the `options` for this call:
    if (!options && optionalLexerSection && typeof optionalLexerSection !== 'string') {
      options = optionalLexerSection;
      optionalLexerSection = null;
    }
    // and standardize it:
    var preliminary_options = mkStdOptions(options);

    // Provisionally parse the grammar, really only to obtain the *options.type*
    // specified within the grammar, if specified (via `%parser-type`).
    //
    // Meanwhile, we *auto-detect* if the input is in JSON or JISON format
    // and parse the specs, so we don't have to, nor should we have to, do
    // *that* activity again in the specific generators below: they all
    // share a common grammar+lexer spec format (JSON/JSON5/JISON) which will
    // be parsed by `autodetectAndConvertToJSONformat()` right now!
    grammar = autodetectAndConvertToJSONformat(grammar, optionalLexerSection, preliminary_options);

    // make sure all options are 'standardized' before we go and mix them together
    //
    // WARNING:
    // make sure to mix together the **original options sets** as it's last-come-last-serve
    // in `mkStdOptions` and you don't want the mixed in defaults carried in `preliminary_options`
    // to percolate into the final options set as if those we overrides coming in from
    // the API (via the `options` parameter above)!
    //
    // Anyway, API/CLI options **override** options coming in from the grammar spec.
    //
    options = mkStdOptions("NODEFAULT", grammar.options, options);
    switch (options.type || Jison.defaultJisonOptions.type) {
    case 'lr0':
        options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
        return new LR0Generator(grammar, null, options);
    case 'slr':
        options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
        return new SLRGenerator(grammar, null, options);
    case 'lr':
    case 'lr1':
        options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
        return new LR1Generator(grammar, null, options);
    case 'll':
    case 'll1':
        options.hasPartialLrUpgradeOnConflict = false;        // kill this unsupported option
        return new LLGenerator(grammar, null, options);
    case 'lalr1':
    case 'lalr':
    case '':
        return new LALRGenerator(grammar, null, options);
    default:
        throw new Error('Unsupported parser type: ' + options.type);
    }
};

function Parser(g, l, options) {
    var gen = Jison.Generator(g, l, options);
    return gen.createParser();
}

Jison.Parser = Parser;

var rmCommonWS = helpers.rmCommonWS;
var mkIdentifier = helpers.mkIdentifier;
assert(Jison);
assert(typeof Jison.prettyPrint === 'function');
assert(Jison.defaultJisonOptions);
assert(typeof Jison.mkStdOptions === 'function');
assert(typeof Jison.Generator === 'function');


var version = '0.6.1-214';


function getCommandlineOptions() {
    var defaults = Jison.defaultJisonOptions;
    var opts = nomnom
        .script('jison')
        .unknownOptionTreatment(false)              // do not accept unknown options!
        .produceExplicitOptionsOnly(true)
        .options({
            file: {
                flag: true,
                position: 0,
                help: 'file containing a grammar.'
            },
            lexfile: {
                flag: true,
                position: 1,
                help: 'file containing a lexical grammar.'
            },
            json: {
                abbr: 'j',
                flag: true,
                default: defaults.json,
                help: 'jison will expect a grammar in either JSON/JSON5 or JISON format: the precise format is autodetected.'
            },
            outfile: {
                abbr: 'o',
                metavar: 'FILE',
                help: 'Filepath and base module name of the generated parser. When terminated with a "/" (dir separator) it is treated as the destination directory where the generated output will be stored.'
            },
            debug: {
                abbr: 't',
                flag: true,
                default: defaults.debug,
                help: 'Debug mode.'
            },
            dumpSourceCodeOnFailure: {
                full: 'dump-sourcecode-on-failure',
                flag: true,
                default: defaults.dumpSourceCodeOnFailure,
                help: 'Dump the generated source code to a special named file when the internal generator tests fail, i.e. when the generated source code does not compile in the JavaScript engine. Enabling this option helps you to diagnose/debug crashes (thrown exceptions) in the code generator due to various reasons: you can, for example, load the dumped sourcecode in another environment (e.g. NodeJS) to get more info on the precise location and cause of the compile failure.'
            },
            throwErrorOnCompileFailure: {
                full: 'throw-on-compile-failure',
                flag: true,
                default: defaults.throwErrorOnCompileFailure,
                help: 'Throw an exception when the generated source code fails to compile in the JavaScript engine. **WARNING**: Turning this feature OFF permits the code generator to produce non-working source code and treat that as SUCCESS. This MAY be desirable code generator behaviour, but only rarely.'
            },
            reportStats: {
                full: 'info',
                abbr: 'I',
                flag: true,
                default: defaults.reportStats,
                help: 'Report some statistics about the generated parser.'
            },
            moduleType: {
                full: 'module-type',
                abbr: 'm',
                default: defaults.moduleType,
                metavar: 'TYPE',
                choices: ['commonjs', 'cjs', 'amd', 'umd', 'js', 'iife', 'es'],
                help: 'The type of module to generate.'
            },
            moduleName: {
                full: 'module-name',
                abbr: 'n',
                metavar: 'NAME',
                default: defaults.defaultModuleName,
                help: 'The name of the generated parser object, namespace supported.'
            },
            parserType: {
                full: 'parser-type',
                abbr: 'p',
                default: defaults.type,
                metavar: 'TYPE',
                help: 'The type of algorithm to use for the parser. (lr0, slr, lalr, lr, ll)'
            },
            compressTables: {
                full: 'compress-tables',
                abbr: 'c',
                flag: false,
                default: defaults.compressTables,             // 0, 1, 2
                choices: [0, 1, 2],
                help: 'Output compressed parser tables in generated modules. (0 = no compression, 1 = default compression, 2 = deep compression)'
            },
            outputDebugTables: {
                full: 'output-debug-tables',
                abbr: 'T',
                flag: true,
                default: defaults.outputDebugTables,
                help: 'Output extra parser tables (rules list + look-ahead analysis) in generated modules to assist debugging / diagnostics purposes.'
            },
            hasDefaultResolve: {
                full: 'default-resolve',
                abbr: 'X',
                flag: true,
                default: !defaults.noDefaultResolve,
                help: 'Turn this OFF to make jison act another way when a conflict is found in the grammar.'
            },
            hasPartialLrUpgradeOnConflict: {
                full: 'partial-lr-upgrade-on-conflict',
                abbr: 'Z',
                flag: true,
                default: defaults.hasPartialLrUpgradeOnConflict,
                help: 'When enabled, the grammar generator attempts to resolve LALR(1) conflicts by, at least for the conflicting rules, moving towards LR(1) behaviour.'
            },
            noDefaultAction: {
                flag: false,
                callback: function () {
                    // FAIL when found:
                    return this.help;
                },
                help: 'OBSOLETED. Use \'--default-action=[for-value,for-location]\' instead. (See below in \'--help\' output.)'
            },
            defaultActionMode: {
                full: 'default-action',
                flag: false,
                default: defaults.defaultActionMode,
                callback: function (val) {
                    // split value at comma, expect zero, one or two values:
                    var v = ('' + val).split(',');
                    if (v.length > 2) {
                        return 'default-action=yyval,yylloc expects at most 2 modes! You specified ' + v.length;
                    }
                },
                transform: function (val) {
                    // split value at comma, expect zero, one or two values:
                    var option = this;
                    var def = option.default;
                    var v = ('' + val).split(',').map(function cvt_modes(mode, idx) {
                        mode = mode.trim();
                        switch (mode) {
                        case 'false':
                        case '0':
                            return "none";

                        case 'true':
                        case '1':
                        case '':
                            return def[idx];

                        default:
                            return mode;
                        }
                    });
                    if (v.length === 1) {
                        v[1] = v[0];
                    }
                    return v;
                },
                help: rmCommonWS`
                    Specify the kind of default action that jison should include for every parser rule.

                    You can specify a mode for *value handling* ("$$") and one for *location tracking* ("@$"), separated by a comma, e.g.:
                        --default-action=ast,none

                    Supported value modes:
                    - classic : generate a parser which includes the default
                                    $$ = $1;
                                action for every rule.
                    - ast     : generate a parser which produces a simple AST-like tree-of-arrays structure: every rule produces an array of its production terms' values. Otherwise it is dentical to "classic" mode.
                    - none    : JISON will produce a slightly faster parser but then you are solely responsible for propagating rule action "$$" results. The default rule value is still deterministic though as it is set to "undefined": "$$ = undefined;"
                    - skip    : same as "none" mode, except JISON does NOT INJECT a default value action ANYWHERE, hence rule results are not deterministic when you do not properly manage the "$$" value yourself!

                    Supported location modes:
                    - merge   : generate a parser which includes the default "@$ = merged(@1..@n);" location tracking action for every rule, i.e. the rule\'s production \'location\' is the range spanning its terms.
                    - classic : same as "merge" mode.
                    - ast     : ditto.
                    - none    : JISON will produce a slightly faster parser but then you are solely responsible for propagating rule action "@$" location results. The default rule location is still deterministic though, as it is set to "undefined": "@$ = undefined;"
                    - skip    : same as "none" mode, except JISON does NOT INJECT a default location action ANYWHERE, hence rule location results are not deterministic when you do not properly manage the "@$" value yourself!

                    Notes:
                    - when you do specify a value default mode, but DO NOT specify a location value mode, the latter is assumed to be the same as the former. Hence:
                          --default-action=ast
                      equals:
                          --default-action=ast,ast
                    - when you do not specify an explicit default mode or only a "true"/"1" value, the default is assumed: "ast,merge".
                    - when you specify "false"/"0" as an explicit default mode, "none,none" is assumed. This produces the fastest deterministic parser.
                `
            },
            hasTryCatch: {
                full: 'try-catch',
                flag: true,
                default: !defaults.noTryCatch,
                help: 'Generate a parser which catches exceptions from the grammar action code or parseError error reporting calls using a try/catch/finally code block. When you turn this OFF, it will produce a slightly faster parser at the cost of reduced code safety.'
            },
            errorRecoveryTokenDiscardCount: {
                full: 'error-recovery-token-discard-count',
                abbr: 'Q',
                flag: false,
                default: defaults.errorRecoveryTokenDiscardCount,
                callback: function (count) {
                    if (count != parseInt(count)) {
                        return "count must be an integer";
                    }
                    count = parseInt(count);
                    if (count < 2) {
                        return "count must be >= 2";
                    }
                },
                transform: function (val) {
                    return parseInt(val);
                },
                help: 'Specify the number of lexed tokens that may be gobbled by an error recovery process before we cry wolf.'
            },
            exportAllTables: {
                full: 'export-all-tables',
                abbr: 'E',
                flag: true,
                default: defaults.exportAllTables,
                help: 'Next to producing a grammar source file, also export the symbols, terminals, grammar and parse tables to separate JSON files for further use by other tools. The files\' names will be derived from the outputFile name by appending a suffix.'
            },
            exportAST: {
                full: 'export-ast',
                optional: true,
                metavar: 'false|true|FILE',
                default: defaults.exportAST,
                help: 'Output grammar AST to file in JSON / JSON5 format (as identified by the file extension, JSON by default).',
                transform: function (val) {
                    switch (val) {
                    case 'false':
                    case '0':
                        return false;

                    case 'true':
                    case '1':
                        return true;

                    default:
                        return val;
                    }
                }
            },
            prettyCfg: {
                full: 'pretty',
                flag: true,
                metavar: 'false|true|CFGFILE',
                default: defaults.prettyCfg,
                help: 'Output the generated code pretty-formatted; turning this option OFF will output the generated code as-is a.k.a. \'raw\'.',
            },
            main: {
                full: 'main',
                abbr: 'x',
                flag: true,
                default: !defaults.noMain,
                help: 'Include .main() entry point in generated commonjs module.'
            },
            moduleMain: {
                full: 'module-main',
                abbr: 'y',
                metavar: 'NAME',
                help: 'The main module function definition.'
            },
            version: {
                abbr: 'V',
                flag: true,
                help: 'Print version and exit.',
                callback: function () {
                    console.log(version);
                    process$1.exit(0);
                }
            }
        }).parse();

    if (opts.debug) {
        console.log("JISON CLI options:\n", opts);
    }

    return opts;
}

var cli = {
    main: function cliMain(opts) {
        //opts = Jison.mkStdOptions(opts);

        function isDirectory(fp) {
            try {
                return fs.lstatSync(fp).isDirectory();
            } catch (e) {
                return false;
            }
        }

        function mkdirp(fp) {
            if (!fp || fp === '.' || fp.length === 0) {
                return false;
            }
            try {
                fs.mkdirSync(fp);
                return true;
            } catch (e) {
                if (e.code === 'ENOENT') {
                    var parent = path.dirname(fp);
                    // Did we hit the root directory by now? If so, abort!
                    // Else, create the parent; iff that fails, we fail too...
                    if (parent !== fp && mkdirp(parent)) {
                        try {
                            // Retry creating the original directory: it should succeed now
                            fs.mkdirSync(fp);
                            return true;
                        } catch (e) {
                            return false;
                        }
                    }
                }
            }
            return false;
        }

        function processInputFile() {
            // getting raw files
            var lex;
            var original_cwd = process$1.cwd();

            if (opts.lexfile) {
                lex = fs.readFileSync(path.normalize(opts.lexfile), 'utf8');
            }
            var raw = fs.readFileSync(path.normalize(opts.file), 'utf8');

            // making best guess at json mode
            opts.json = path.extname(opts.file) === '.json' || opts.json;

            // When only the directory part of the output path was specified, then we
            // do NOT have the target module name in there as well!
            var outpath = opts.outfile;
            if (typeof outpath === 'string') {
                if (/[\\\/]$/.test(outpath) || isDirectory(outpath)) {
                    opts.outfile = null;
                    outpath = outpath.replace(/[\\\/]$/, '');
                } else {
                    outpath = path.dirname(outpath);
                }
            } else {
                outpath = null;
            }
            if (outpath && outpath.length > 0) {
                outpath += '/';
            } else {
                outpath = '';
            }

            // setting output file name and module name based on input file name
            // if they aren't specified.
            var name = path.basename(opts.outfile || opts.file);

            // get the base name (i.e. the file name without extension)
            // i.e. strip off only the extension and keep any other dots in the filename
            name = path.basename(name, path.extname(name));

            opts.outfile = opts.outfile || (outpath + name + '.js');
            if (!opts.moduleName && name) {
                opts.moduleName = opts.defaultModuleName = mkIdentifier(name);
            }

            if (opts.exportAST) {
                // When only the directory part of the AST output path was specified, then we
                // still need to construct the JSON AST output file name!
                var astpath, astname, ext;

                astpath = opts.exportAST;
                if (typeof astpath === 'string') {
                    if (/[\\\/]$/.test(astpath) || isDirectory(astpath)) {
                        opts.exportAST = null;
                        astpath = astpath.replace(/[\\\/]$/, '');
                    } else {
                        astpath = path.dirname(astpath);
                    }
                } else {
                    astpath = path.dirname(opts.outfile);
                }
                if (astpath && astpath.length > 0) {
                    astpath = astpath.replace(/[\\\/]$/, '') + '/';
                } else {
                    astpath = '';
                }

                // setting AST output file name and module name based on input file name
                // if they aren't specified.
                if (typeof opts.exportAST === 'string') {
                    astname = path.basename(opts.exportAST);
                    ext = path.extname(astname);

                    // get the base name (i.e. the file name without extension)
                    // i.e. strip off only the extension and keep any other dots in the filename.
                    astname = path.basename(astname, ext);
                } else {
                    // get the base name (i.e. the file name without extension)
                    // i.e. strip off only the extension and keep any other dots in the filename.
                    astname = path.basename(opts.outfile, path.extname(opts.outfile));

                    // Then add the name postfix '-AST' to ensure we won't collide with the input file.
                    astname += '-AST';
                    ext = '.jison';
                }

                opts.exportAST = path.normalize(astpath + astname + ext);
            }

            // Change CWD to the directory where the source grammar resides: this helps us properly
            // %include any files mentioned in the grammar with relative paths:
            var new_cwd = path.dirname(path.normalize(opts.file));
            process$1.chdir(new_cwd);

            var parser = cli.generateParserString(raw, lex, opts);

            // and change back to the CWD we started out with:
            process$1.chdir(original_cwd);

            opts.outfile = path.normalize(opts.outfile);
            mkdirp(path.dirname(opts.outfile));
            fs.writeFileSync(opts.outfile, parser, 'utf8');
            console.log('JISON output', 'for module [' + opts.moduleName + '] has been written to file:', opts.outfile);

            if (opts.exportAllTables.enabled) {
                // Determine the output file path 'template' for use by the exportAllTables
                // functionality:
                var out_base_fname = path.join(path.dirname(opts.outfile), path.basename(opts.outfile, path.extname(opts.outfile)));

                var t = opts.exportAllTables;

                for (var id in t) {
                    if (t.hasOwnProperty(id) && id !== 'enabled') {
                        var content = t[id];
                        if (content) {
                            var fname = out_base_fname + '.' + id.replace(/[^a-zA-Z0-9_]/g, '_') + '.json';
                            fs.writeFileSync(fname, JSON.stringify(content, null, 2), 'utf8');
                            console.log('JISON table export', 'for [' + id + '] has been written to file:', fname);
                        }
                    }
                }
            }

            if (opts.exportAST) {
                var content = opts.exportedAST;
                var fname = opts.exportAST;

                var ext = path.extname(fname);
                switch (ext) {
                case '.json5':
                case '.jison':
                case '.y':
                case '.yacc':
                case '.l':
                case '.lex':
                    content = Jison.prettyPrint(content, {
                        format: ext.substr(1)
                    });
                    break;

                default:
                case '.json':
                    content = JSON.stringify(content, null, 2);
                    break;
                }
                mkdirp(path.dirname(fname));
                fs.writeFileSync(fname, content, 'utf8');
                console.log('Grammar AST export', 'for module [' + opts.moduleName + '] has been written to file:', fname);
            }
        }

        function readin(cb) {
            var stdin = process$1.openStdin(),
            data = '';

            stdin.setEncoding('utf8');
            stdin.addListener('data', function (chunk) {
                data += chunk;
            });
            stdin.addListener('end', function () {
                cb(data);
            });
        }

        function processStdin() {
            readin(function processStdinReadInCallback(raw) {
                console.log('', cli.generateParserString(raw, null, opts));
            });
        }

        // if an input file wasn't given, assume input on stdin
        if (opts.file) {
            processInputFile();
        } else {
            processStdin();
        }
    },

    generateParserString: function generateParserString(grammar, optionalLexSection, opts) {
        var generator = new Jison.Generator(grammar, optionalLexSection, opts);
        var srcCode = generator.generate(opts);
        generator.reportGrammarInformation();

        // as `opts` is cloned inside `generator.generate()`, we need to fetch
        // the extra exported tables from the `options` member of the generator
        // itself:
        opts.exportAllTables = generator.options.exportAllTables;
        opts.exportedAST = generator.grammar;

        return srcCode;
    }
};


if (require.main === module) {
    var opts = getCommandlineOptions();
    cli.main(opts);
}

export default cli;
